[2023-08-29 13:58:38,067][02050] Saving configuration to /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/config.json...
[2023-08-29 13:58:38,089][02050] Rollout worker 0 uses device cpu
[2023-08-29 13:58:38,090][02050] Rollout worker 1 uses device cpu
[2023-08-29 13:58:38,090][02050] Rollout worker 2 uses device cpu
[2023-08-29 13:58:38,090][02050] Rollout worker 3 uses device cpu
[2023-08-29 13:58:38,090][02050] Rollout worker 4 uses device cpu
[2023-08-29 13:58:38,090][02050] Rollout worker 5 uses device cpu
[2023-08-29 13:58:38,090][02050] Rollout worker 6 uses device cpu
[2023-08-29 13:58:38,090][02050] Rollout worker 7 uses device cpu
[2023-08-29 13:58:38,090][02050] In synchronous mode, we only accumulate one batch. Setting num_batches_to_accumulate to 1
[2023-08-29 13:58:38,262][02050] InferenceWorker_p0-w0: min num requests: 2
[2023-08-29 13:58:38,296][02050] Starting all processes...
[2023-08-29 13:58:38,296][02050] Starting process learner_proc0
[2023-08-29 13:58:38,352][02050] Starting all processes...
[2023-08-29 13:58:38,443][02050] Starting process inference_proc0-0
[2023-08-29 13:58:38,457][02050] Starting process rollout_proc0
[2023-08-29 13:58:38,470][02050] Starting process rollout_proc1
[2023-08-29 13:58:38,476][02050] Starting process rollout_proc2
[2023-08-29 13:58:38,479][02050] Starting process rollout_proc3
[2023-08-29 13:58:38,483][02050] Starting process rollout_proc4
[2023-08-29 13:58:38,489][02050] Starting process rollout_proc5
[2023-08-29 13:58:38,495][02050] Starting process rollout_proc6
[2023-08-29 13:58:38,515][02050] Starting process rollout_proc7
[2023-08-29 13:58:41,008][02059] Starting seed is not provided
[2023-08-29 13:58:41,008][02059] Initializing actor-critic model on device cpu
[2023-08-29 13:58:41,009][02059] RunningMeanStd input shape: (8,)
[2023-08-29 13:58:41,009][02059] RunningMeanStd input shape: (1,)
[2023-08-29 13:58:41,058][02059] Created Actor Critic model with architecture:
[2023-08-29 13:58:41,058][02059] ActorCriticSharedWeights(
  (obs_normalizer): ObservationNormalizer(
    (running_mean_std): RunningMeanStdDictInPlace(
      (running_mean_std): ModuleDict(
        (obs): RunningMeanStdInPlace()
      )
    )
  )
  (returns_normalizer): RecursiveScriptModule(original_name=RunningMeanStdInPlace)
  (encoder): MultiInputEncoder(
    (encoders): ModuleDict(
      (obs): MlpEncoder(
        (mlp_head): RecursiveScriptModule(
          original_name=Sequential
          (0): RecursiveScriptModule(original_name=Linear)
          (1): RecursiveScriptModule(original_name=ELU)
          (2): RecursiveScriptModule(original_name=Linear)
          (3): RecursiveScriptModule(original_name=ELU)
        )
      )
    )
  )
  (core): ModelCoreIdentity()
  (decoder): MlpDecoder(
    (mlp): Identity()
  )
  (critic_linear): Linear(in_features=64, out_features=1, bias=True)
  (action_parameterization): ActionParameterizationDefault(
    (distribution_linear): Linear(in_features=64, out_features=18, bias=True)
  )
)
[2023-08-29 13:58:41,063][02059] Using optimizer <class 'torch.optim.adam.Adam'>
[2023-08-29 13:58:41,064][02059] No checkpoints found
[2023-08-29 13:58:41,064][02059] Did not load from checkpoint, starting from scratch!
[2023-08-29 13:58:41,064][02059] Initialized policy 0 weights for model version 0
[2023-08-29 13:58:41,065][02059] LearnerWorker_p0 finished initialization!
[2023-08-29 13:58:41,091][02063] On MacOS, not setting affinity
[2023-08-29 13:58:41,118][02068] On MacOS, not setting affinity
[2023-08-29 13:58:41,118][02066] On MacOS, not setting affinity
[2023-08-29 13:58:41,123][02061] On MacOS, not setting affinity
[2023-08-29 13:58:41,134][02062] On MacOS, not setting affinity
[2023-08-29 13:58:41,153][02065] On MacOS, not setting affinity
[2023-08-29 13:58:41,158][02067] On MacOS, not setting affinity
[2023-08-29 13:58:41,158][02060] RunningMeanStd input shape: (8,)
[2023-08-29 13:58:41,159][02060] RunningMeanStd input shape: (1,)
[2023-08-29 13:58:41,178][02064] On MacOS, not setting affinity
[2023-08-29 13:58:41,203][02050] Inference worker 0-0 is ready!
[2023-08-29 13:58:41,204][02050] All inference workers are ready! Signal rollout workers to start!
[2023-08-29 13:58:41,421][02065] Decorrelating experience for 0 frames...
[2023-08-29 13:58:41,421][02063] Decorrelating experience for 0 frames...
[2023-08-29 13:58:41,423][02067] Decorrelating experience for 0 frames...
[2023-08-29 13:58:41,424][02066] Decorrelating experience for 0 frames...
[2023-08-29 13:58:41,429][02062] Decorrelating experience for 0 frames...
[2023-08-29 13:58:41,439][02068] Decorrelating experience for 0 frames...
[2023-08-29 13:58:41,443][02061] Decorrelating experience for 0 frames...
[2023-08-29 13:58:41,454][02064] Decorrelating experience for 0 frames...
[2023-08-29 13:58:41,555][02066] Decorrelating experience for 64 frames...
[2023-08-29 13:58:41,562][02065] Decorrelating experience for 64 frames...
[2023-08-29 13:58:41,568][02062] Decorrelating experience for 64 frames...
[2023-08-29 13:58:41,571][02063] Decorrelating experience for 64 frames...
[2023-08-29 13:58:41,576][02067] Decorrelating experience for 64 frames...
[2023-08-29 13:58:41,582][02061] Decorrelating experience for 64 frames...
[2023-08-29 13:58:41,582][02068] Decorrelating experience for 64 frames...
[2023-08-29 13:58:41,590][02064] Decorrelating experience for 64 frames...
[2023-08-29 13:58:42,101][02050] Fps is (10 sec: nan, 60 sec: nan, 300 sec: nan). Total num frames: 4096. Throughput: 0: nan. Samples: 0. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-29 13:58:44,498][02060] Updated weights for policy 0, policy_version 80 (0.0003)
[2023-08-29 13:58:47,102][02050] Fps is (10 sec: 13923.8, 60 sec: 13923.8, 300 sec: 13923.8). Total num frames: 73728. Throughput: 0: 7291.4. Samples: 36464. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-29 13:58:47,455][02060] Updated weights for policy 0, policy_version 160 (0.0002)
[2023-08-29 13:58:49,848][02050] Keyboard interrupt detected in the event loop EvtLoop [Runner_EvtLoop, process=main process 2050], exiting...
[2023-08-29 13:58:49,848][02050] Runner profile tree view:
main_loop: 11.5529
[2023-08-29 13:58:49,848][02050] Collected {0: 114688}, FPS: 9927.2
[2023-08-29 13:58:49,848][02062] Stopping RolloutWorker_w1...
[2023-08-29 13:58:49,849][02062] Loop rollout_proc1_evt_loop terminating...
[2023-08-29 13:58:49,848][02059] Stopping Batcher_0...
[2023-08-29 13:58:49,849][02067] Stopping RolloutWorker_w6...
[2023-08-29 13:58:49,849][02068] Stopping RolloutWorker_w7...
[2023-08-29 13:58:49,848][02066] Stopping RolloutWorker_w5...
[2023-08-29 13:58:49,849][02068] Loop rollout_proc7_evt_loop terminating...
[2023-08-29 13:58:49,849][02059] Loop batcher_evt_loop terminating...
[2023-08-29 13:58:49,849][02066] Loop rollout_proc5_evt_loop terminating...
[2023-08-29 13:58:49,849][02059] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000000224_114688.pth...
[2023-08-29 13:58:49,849][02063] Stopping RolloutWorker_w2...
[2023-08-29 13:58:49,849][02067] Loop rollout_proc6_evt_loop terminating...
[2023-08-29 13:58:49,851][02059] Stopping LearnerWorker_p0...
[2023-08-29 13:58:49,851][02059] Loop learner_proc0_evt_loop terminating...
[2023-08-29 13:58:49,852][02063] Loop rollout_proc2_evt_loop terminating...
[2023-08-29 13:58:49,854][02061] Stopping RolloutWorker_w0...
[2023-08-29 13:58:49,855][02064] Stopping RolloutWorker_w3...
[2023-08-29 13:58:49,855][02064] Loop rollout_proc3_evt_loop terminating...
[2023-08-29 13:58:49,855][02061] Loop rollout_proc0_evt_loop terminating...
[2023-08-29 13:58:49,872][02065] Stopping RolloutWorker_w4...
[2023-08-29 13:58:49,872][02065] Loop rollout_proc4_evt_loop terminating...
[2023-08-29 13:58:49,882][02060] Weights refcount: 2 0
[2023-08-29 13:58:49,885][02060] Stopping InferenceWorker_p0-w0...
[2023-08-29 13:58:49,885][02060] Loop inference_proc0-0_evt_loop terminating...
[2023-08-29 13:59:32,931][02125] Saving configuration to /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/config.json...
[2023-08-29 13:59:32,952][02125] Rollout worker 0 uses device cpu
[2023-08-29 13:59:32,952][02125] Rollout worker 1 uses device cpu
[2023-08-29 13:59:32,952][02125] Rollout worker 2 uses device cpu
[2023-08-29 13:59:32,952][02125] Rollout worker 3 uses device cpu
[2023-08-29 13:59:32,952][02125] Rollout worker 4 uses device cpu
[2023-08-29 13:59:32,952][02125] Rollout worker 5 uses device cpu
[2023-08-29 13:59:32,952][02125] Rollout worker 6 uses device cpu
[2023-08-29 13:59:32,952][02125] Rollout worker 7 uses device cpu
[2023-08-29 13:59:32,952][02125] In synchronous mode, we only accumulate one batch. Setting num_batches_to_accumulate to 1
[2023-08-29 13:59:33,131][02125] InferenceWorker_p0-w0: min num requests: 2
[2023-08-29 13:59:33,167][02125] Starting all processes...
[2023-08-29 13:59:33,167][02125] Starting process learner_proc0
[2023-08-29 13:59:33,227][02125] Starting all processes...
[2023-08-29 13:59:33,236][02125] Starting process inference_proc0-0
[2023-08-29 13:59:33,240][02125] Starting process rollout_proc0
[2023-08-29 13:59:33,246][02125] Starting process rollout_proc1
[2023-08-29 13:59:33,249][02125] Starting process rollout_proc2
[2023-08-29 13:59:33,250][02125] Starting process rollout_proc3
[2023-08-29 13:59:33,250][02125] Starting process rollout_proc4
[2023-08-29 13:59:33,251][02125] Starting process rollout_proc5
[2023-08-29 13:59:33,259][02125] Starting process rollout_proc6
[2023-08-29 13:59:33,263][02125] Starting process rollout_proc7
[2023-08-29 13:59:35,237][02136] On MacOS, not setting affinity
[2023-08-29 13:59:35,256][02143] On MacOS, not setting affinity
[2023-08-29 13:59:35,292][02139] On MacOS, not setting affinity
[2023-08-29 13:59:35,292][02137] On MacOS, not setting affinity
[2023-08-29 13:59:35,292][02140] On MacOS, not setting affinity
[2023-08-29 13:59:35,297][02138] On MacOS, not setting affinity
[2023-08-29 13:59:35,303][02141] On MacOS, not setting affinity
[2023-08-29 13:59:35,305][02134] Starting seed is not provided
[2023-08-29 13:59:35,308][02134] Initializing actor-critic model on device cpu
[2023-08-29 13:59:35,308][02134] RunningMeanStd input shape: (8,)
[2023-08-29 13:59:35,309][02134] RunningMeanStd input shape: (1,)
[2023-08-29 13:59:35,353][02134] Created Actor Critic model with architecture:
[2023-08-29 13:59:35,356][02134] ActorCriticSharedWeights(
  (obs_normalizer): ObservationNormalizer(
    (running_mean_std): RunningMeanStdDictInPlace(
      (running_mean_std): ModuleDict(
        (obs): RunningMeanStdInPlace()
      )
    )
  )
  (returns_normalizer): RecursiveScriptModule(original_name=RunningMeanStdInPlace)
  (encoder): MultiInputEncoder(
    (encoders): ModuleDict(
      (obs): MlpEncoder(
        (mlp_head): RecursiveScriptModule(
          original_name=Sequential
          (0): RecursiveScriptModule(original_name=Linear)
          (1): RecursiveScriptModule(original_name=ELU)
          (2): RecursiveScriptModule(original_name=Linear)
          (3): RecursiveScriptModule(original_name=ELU)
        )
      )
    )
  )
  (core): ModelCoreIdentity()
  (decoder): MlpDecoder(
    (mlp): Identity()
  )
  (critic_linear): Linear(in_features=64, out_features=1, bias=True)
  (action_parameterization): ActionParameterizationDefault(
    (distribution_linear): Linear(in_features=64, out_features=18, bias=True)
  )
)
[2023-08-29 13:59:35,357][02134] Using optimizer <class 'torch.optim.adam.Adam'>
[2023-08-29 13:59:35,360][02134] Loading state from checkpoint /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000000224_114688.pth...
[2023-08-29 13:59:35,361][02134] Loading model from checkpoint
[2023-08-29 13:59:35,365][02134] Loaded experiment state at self.train_step=224, self.env_steps=114688
[2023-08-29 13:59:35,367][02134] Initialized policy 0 weights for model version 224
[2023-08-29 13:59:35,368][02134] LearnerWorker_p0 finished initialization!
[2023-08-29 13:59:35,369][02135] RunningMeanStd input shape: (8,)
[2023-08-29 13:59:35,371][02135] RunningMeanStd input shape: (1,)
[2023-08-29 13:59:35,377][02142] On MacOS, not setting affinity
[2023-08-29 13:59:35,414][02125] Inference worker 0-0 is ready!
[2023-08-29 13:59:35,414][02125] All inference workers are ready! Signal rollout workers to start!
[2023-08-29 13:59:35,506][02139] Decorrelating experience for 0 frames...
[2023-08-29 13:59:35,512][02142] Decorrelating experience for 0 frames...
[2023-08-29 13:59:35,514][02140] Decorrelating experience for 0 frames...
[2023-08-29 13:59:35,522][02138] Decorrelating experience for 0 frames...
[2023-08-29 13:59:35,531][02136] Decorrelating experience for 0 frames...
[2023-08-29 13:59:35,559][02141] Decorrelating experience for 0 frames...
[2023-08-29 13:59:35,576][02143] Decorrelating experience for 0 frames...
[2023-08-29 13:59:35,580][02137] Decorrelating experience for 0 frames...
[2023-08-29 13:59:35,667][02136] Decorrelating experience for 64 frames...
[2023-08-29 13:59:35,668][02141] Decorrelating experience for 64 frames...
[2023-08-29 13:59:35,670][02140] Decorrelating experience for 64 frames...
[2023-08-29 13:59:35,689][02138] Decorrelating experience for 64 frames...
[2023-08-29 13:59:35,702][02139] Decorrelating experience for 64 frames...
[2023-08-29 13:59:35,706][02137] Decorrelating experience for 64 frames...
[2023-08-29 13:59:35,716][02143] Decorrelating experience for 64 frames...
[2023-08-29 13:59:35,730][02142] Decorrelating experience for 64 frames...
[2023-08-29 13:59:36,961][02125] Fps is (10 sec: nan, 60 sec: nan, 300 sec: nan). Total num frames: 135168. Throughput: 0: nan. Samples: 0. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-29 13:59:38,048][02135] Updated weights for policy 0, policy_version 304 (0.0002)
[2023-08-29 13:59:40,413][02135] Updated weights for policy 0, policy_version 384 (0.0002)
[2023-08-29 13:59:41,962][02125] Fps is (10 sec: 17200.6, 60 sec: 17200.6, 300 sec: 17200.6). Total num frames: 221184. Throughput: 0: 19957.0. Samples: 99800. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-29 13:59:42,803][02135] Updated weights for policy 0, policy_version 464 (0.0002)
[2023-08-29 13:59:43,261][02134] KL-divergence is very high: 133.5418
[2023-08-29 13:59:45,158][02135] Updated weights for policy 0, policy_version 544 (0.0002)
[2023-08-29 13:59:46,962][02125] Fps is (10 sec: 17202.0, 60 sec: 17202.0, 300 sec: 17202.0). Total num frames: 307200. Throughput: 0: 15134.0. Samples: 151350. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2023-08-29 13:59:47,504][02135] Updated weights for policy 0, policy_version 624 (0.0002)
[2023-08-29 13:59:49,758][02135] Updated weights for policy 0, policy_version 704 (0.0002)
[2023-08-29 13:59:50,717][02125] Keyboard interrupt detected in the event loop EvtLoop [Runner_EvtLoop, process=main process 2125], exiting...
[2023-08-29 13:59:50,717][02142] Stopping RolloutWorker_w6...
[2023-08-29 13:59:50,717][02141] Stopping RolloutWorker_w5...
[2023-08-29 13:59:50,718][02139] Stopping RolloutWorker_w3...
[2023-08-29 13:59:50,718][02142] Loop rollout_proc6_evt_loop terminating...
[2023-08-29 13:59:50,718][02141] Loop rollout_proc5_evt_loop terminating...
[2023-08-29 13:59:50,718][02136] Stopping RolloutWorker_w0...
[2023-08-29 13:59:50,718][02139] Loop rollout_proc3_evt_loop terminating...
[2023-08-29 13:59:50,718][02136] Loop rollout_proc0_evt_loop terminating...
[2023-08-29 13:59:50,718][02143] Stopping RolloutWorker_w7...
[2023-08-29 13:59:50,718][02143] Loop rollout_proc7_evt_loop terminating...
[2023-08-29 13:59:50,718][02138] Stopping RolloutWorker_w2...
[2023-08-29 13:59:50,718][02138] Loop rollout_proc2_evt_loop terminating...
[2023-08-29 13:59:50,718][02137] Stopping RolloutWorker_w1...
[2023-08-29 13:59:50,719][02137] Loop rollout_proc1_evt_loop terminating...
[2023-08-29 13:59:50,718][02140] Stopping RolloutWorker_w4...
[2023-08-29 13:59:50,730][02140] Loop rollout_proc4_evt_loop terminating...
[2023-08-29 13:59:50,720][02134] Stopping Batcher_0...
[2023-08-29 13:59:50,717][02125] Runner profile tree view:
main_loop: 17.5511
[2023-08-29 13:59:50,731][02125] Collected {0: 376832}, FPS: 14936.0
[2023-08-29 13:59:50,731][02134] Loop batcher_evt_loop terminating...
[2023-08-29 13:59:50,724][02134] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000000736_376832.pth...
[2023-08-29 13:59:50,744][02134] Stopping LearnerWorker_p0...
[2023-08-29 13:59:50,744][02134] Loop learner_proc0_evt_loop terminating...
[2023-08-29 13:59:50,765][02135] Weights refcount: 2 0
[2023-08-29 13:59:50,766][02135] Stopping InferenceWorker_p0-w0...
[2023-08-29 13:59:50,766][02135] Loop inference_proc0-0_evt_loop terminating...
[2023-08-29 14:01:03,660][02257] Saving configuration to /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/config.json...
[2023-08-29 14:01:03,682][02257] Rollout worker 0 uses device cpu
[2023-08-29 14:01:03,682][02257] Rollout worker 1 uses device cpu
[2023-08-29 14:01:03,682][02257] Rollout worker 2 uses device cpu
[2023-08-29 14:01:03,682][02257] Rollout worker 3 uses device cpu
[2023-08-29 14:01:03,682][02257] Rollout worker 4 uses device cpu
[2023-08-29 14:01:03,683][02257] Rollout worker 5 uses device cpu
[2023-08-29 14:01:03,683][02257] Rollout worker 6 uses device cpu
[2023-08-29 14:01:03,683][02257] Rollout worker 7 uses device cpu
[2023-08-29 14:01:03,683][02257] In synchronous mode, we only accumulate one batch. Setting num_batches_to_accumulate to 1
[2023-08-29 14:01:03,861][02257] InferenceWorker_p0-w0: min num requests: 2
[2023-08-29 14:01:03,898][02257] Starting all processes...
[2023-08-29 14:01:03,898][02257] Starting process learner_proc0
[2023-08-29 14:01:03,954][02257] Starting all processes...
[2023-08-29 14:01:03,992][02257] Starting process inference_proc0-0
[2023-08-29 14:01:04,001][02257] Starting process rollout_proc0
[2023-08-29 14:01:04,013][02257] Starting process rollout_proc1
[2023-08-29 14:01:04,037][02257] Starting process rollout_proc2
[2023-08-29 14:01:04,051][02257] Starting process rollout_proc4
[2023-08-29 14:01:04,055][02257] Starting process rollout_proc5
[2023-08-29 14:01:04,059][02257] Starting process rollout_proc6
[2023-08-29 14:01:04,064][02257] Starting process rollout_proc7
[2023-08-29 14:01:04,040][02257] Starting process rollout_proc3
[2023-08-29 14:01:05,954][02277] On MacOS, not setting affinity
[2023-08-29 14:01:05,961][02269] Starting seed is not provided
[2023-08-29 14:01:05,963][02269] Initializing actor-critic model on device cpu
[2023-08-29 14:01:05,963][02269] RunningMeanStd input shape: (8,)
[2023-08-29 14:01:05,964][02269] RunningMeanStd input shape: (1,)
[2023-08-29 14:01:05,965][02274] On MacOS, not setting affinity
[2023-08-29 14:01:05,982][02278] On MacOS, not setting affinity
[2023-08-29 14:01:06,004][02272] On MacOS, not setting affinity
[2023-08-29 14:01:06,004][02273] On MacOS, not setting affinity
[2023-08-29 14:01:06,004][02276] On MacOS, not setting affinity
[2023-08-29 14:01:06,016][02269] Created Actor Critic model with architecture:
[2023-08-29 14:01:06,016][02269] ActorCriticSharedWeights(
  (obs_normalizer): ObservationNormalizer(
    (running_mean_std): RunningMeanStdDictInPlace(
      (running_mean_std): ModuleDict(
        (obs): RunningMeanStdInPlace()
      )
    )
  )
  (returns_normalizer): RecursiveScriptModule(original_name=RunningMeanStdInPlace)
  (encoder): MultiInputEncoder(
    (encoders): ModuleDict(
      (obs): MlpEncoder(
        (mlp_head): RecursiveScriptModule(
          original_name=Sequential
          (0): RecursiveScriptModule(original_name=Linear)
          (1): RecursiveScriptModule(original_name=ELU)
          (2): RecursiveScriptModule(original_name=Linear)
          (3): RecursiveScriptModule(original_name=ELU)
        )
      )
    )
  )
  (core): ModelCoreIdentity()
  (decoder): MlpDecoder(
    (mlp): Identity()
  )
  (critic_linear): Linear(in_features=64, out_features=1, bias=True)
  (action_parameterization): ActionParameterizationDefault(
    (distribution_linear): Linear(in_features=64, out_features=18, bias=True)
  )
)
[2023-08-29 14:01:06,021][02269] Using optimizer <class 'torch.optim.adam.Adam'>
[2023-08-29 14:01:06,024][02269] Loading state from checkpoint /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000000736_376832.pth...
[2023-08-29 14:01:06,025][02269] Loading model from checkpoint
[2023-08-29 14:01:06,029][02269] Loaded experiment state at self.train_step=736, self.env_steps=376832
[2023-08-29 14:01:06,032][02269] Initialized policy 0 weights for model version 736
[2023-08-29 14:01:06,033][02269] LearnerWorker_p0 finished initialization!
[2023-08-29 14:01:06,034][02270] RunningMeanStd input shape: (8,)
[2023-08-29 14:01:06,036][02270] RunningMeanStd input shape: (1,)
[2023-08-29 14:01:06,045][02271] On MacOS, not setting affinity
[2023-08-29 14:01:06,053][02275] On MacOS, not setting affinity
[2023-08-29 14:01:06,079][02257] Inference worker 0-0 is ready!
[2023-08-29 14:01:06,080][02257] All inference workers are ready! Signal rollout workers to start!
[2023-08-29 14:01:06,185][02273] Decorrelating experience for 0 frames...
[2023-08-29 14:01:06,188][02275] Decorrelating experience for 0 frames...
[2023-08-29 14:01:06,190][02276] Decorrelating experience for 0 frames...
[2023-08-29 14:01:06,195][02274] Decorrelating experience for 0 frames...
[2023-08-29 14:01:06,198][02277] Decorrelating experience for 0 frames...
[2023-08-29 14:01:06,198][02272] Decorrelating experience for 0 frames...
[2023-08-29 14:01:06,205][02278] Decorrelating experience for 0 frames...
[2023-08-29 14:01:06,210][02271] Decorrelating experience for 0 frames...
[2023-08-29 14:01:06,328][02276] Decorrelating experience for 64 frames...
[2023-08-29 14:01:06,336][02272] Decorrelating experience for 64 frames...
[2023-08-29 14:01:06,338][02273] Decorrelating experience for 64 frames...
[2023-08-29 14:01:06,339][02275] Decorrelating experience for 64 frames...
[2023-08-29 14:01:06,339][02277] Decorrelating experience for 64 frames...
[2023-08-29 14:01:06,347][02274] Decorrelating experience for 64 frames...
[2023-08-29 14:01:06,347][02271] Decorrelating experience for 64 frames...
[2023-08-29 14:01:06,358][02278] Decorrelating experience for 64 frames...
[2023-08-29 14:01:07,662][02257] Fps is (10 sec: nan, 60 sec: nan, 300 sec: nan). Total num frames: 397312. Throughput: 0: nan. Samples: 0. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-29 14:01:08,665][02270] Updated weights for policy 0, policy_version 816 (0.0002)
[2023-08-29 14:01:10,837][02270] Updated weights for policy 0, policy_version 896 (0.0002)
[2023-08-29 14:01:12,663][02257] Fps is (10 sec: 18019.3, 60 sec: 18019.3, 300 sec: 18019.3). Total num frames: 487424. Throughput: 0: 21059.0. Samples: 105313. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[2023-08-29 14:01:13,118][02270] Updated weights for policy 0, policy_version 976 (0.0002)
[2023-08-29 14:01:15,515][02270] Updated weights for policy 0, policy_version 1056 (0.0002)
[2023-08-29 14:01:17,663][02257] Fps is (10 sec: 18021.1, 60 sec: 18021.1, 300 sec: 18021.1). Total num frames: 577536. Throughput: 0: 15919.3. Samples: 159204. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-29 14:01:17,663][02257] Avg episode reward: [(0, '-33769.784')]
[2023-08-29 14:01:17,664][02269] Saving new best policy, reward=-33769.784!
[2023-08-29 14:01:17,737][02270] Updated weights for policy 0, policy_version 1136 (0.0002)
[2023-08-29 14:01:19,945][02270] Updated weights for policy 0, policy_version 1216 (0.0002)
[2023-08-29 14:01:22,328][02270] Updated weights for policy 0, policy_version 1296 (0.0002)
[2023-08-29 14:01:22,663][02257] Fps is (10 sec: 18022.7, 60 sec: 18021.6, 300 sec: 18021.6). Total num frames: 667648. Throughput: 0: 17661.8. Samples: 264939. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-29 14:01:22,664][02257] Avg episode reward: [(0, '-33769.784')]
[2023-08-29 14:01:23,847][02257] Heartbeat connected on Batcher_0
[2023-08-29 14:01:23,854][02257] Heartbeat connected on LearnerWorker_p0
[2023-08-29 14:01:23,862][02257] Heartbeat connected on InferenceWorker_p0-w0
[2023-08-29 14:01:23,866][02257] Heartbeat connected on RolloutWorker_w0
[2023-08-29 14:01:23,871][02257] Heartbeat connected on RolloutWorker_w1
[2023-08-29 14:01:23,876][02257] Heartbeat connected on RolloutWorker_w2
[2023-08-29 14:01:23,881][02257] Heartbeat connected on RolloutWorker_w3
[2023-08-29 14:01:23,885][02257] Heartbeat connected on RolloutWorker_w4
[2023-08-29 14:01:23,890][02257] Heartbeat connected on RolloutWorker_w5
[2023-08-29 14:01:23,894][02257] Heartbeat connected on RolloutWorker_w6
[2023-08-29 14:01:23,898][02257] Heartbeat connected on RolloutWorker_w7
[2023-08-29 14:01:24,883][02270] Updated weights for policy 0, policy_version 1376 (0.0002)
[2023-08-29 14:01:27,202][02270] Updated weights for policy 0, policy_version 1456 (0.0002)
[2023-08-29 14:01:27,662][02257] Fps is (10 sec: 17613.6, 60 sec: 17817.4, 300 sec: 17817.4). Total num frames: 753664. Throughput: 0: 18326.1. Samples: 366527. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2023-08-29 14:01:27,663][02257] Avg episode reward: [(0, '-32315.751')]
[2023-08-29 14:01:27,663][02269] Saving new best policy, reward=-32315.751!
[2023-08-29 14:01:28,614][02269] KL-divergence is very high: 148.2714
[2023-08-29 14:01:29,624][02270] Updated weights for policy 0, policy_version 1536 (0.0002)
[2023-08-29 14:01:32,009][02270] Updated weights for policy 0, policy_version 1616 (0.0002)
[2023-08-29 14:01:32,663][02257] Fps is (10 sec: 16793.7, 60 sec: 17530.4, 300 sec: 17530.4). Total num frames: 835584. Throughput: 0: 16711.9. Samples: 417808. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-29 14:01:32,663][02257] Avg episode reward: [(0, '-32315.751')]
[2023-08-29 14:01:34,489][02270] Updated weights for policy 0, policy_version 1696 (0.0002)
[2023-08-29 14:01:36,770][02270] Updated weights for policy 0, policy_version 1776 (0.0002)
[2023-08-29 14:01:37,664][02257] Fps is (10 sec: 16790.7, 60 sec: 17475.1, 300 sec: 17475.1). Total num frames: 921600. Throughput: 0: 17339.1. Samples: 520208. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-29 14:01:37,664][02257] Avg episode reward: [(0, '-40243.279')]
[2023-08-29 14:01:39,136][02270] Updated weights for policy 0, policy_version 1856 (0.0002)
[2023-08-29 14:01:41,417][02270] Updated weights for policy 0, policy_version 1936 (0.0002)
[2023-08-29 14:01:42,664][02257] Fps is (10 sec: 17611.3, 60 sec: 17553.5, 300 sec: 17553.5). Total num frames: 1011712. Throughput: 0: 17904.5. Samples: 626684. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-29 14:01:42,664][02257] Avg episode reward: [(0, '-40243.279')]
[2023-08-29 14:01:43,872][02270] Updated weights for policy 0, policy_version 2016 (0.0002)
[2023-08-29 14:01:46,125][02270] Updated weights for policy 0, policy_version 2096 (0.0002)
[2023-08-29 14:01:47,663][02257] Fps is (10 sec: 18024.7, 60 sec: 17612.5, 300 sec: 17612.5). Total num frames: 1101824. Throughput: 0: 16960.4. Samples: 678429. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-29 14:01:47,663][02257] Avg episode reward: [(0, '-37792.610')]
[2023-08-29 14:01:48,260][02270] Updated weights for policy 0, policy_version 2176 (0.0002)
[2023-08-29 14:01:50,483][02270] Updated weights for policy 0, policy_version 2256 (0.0002)
[2023-08-29 14:01:52,664][02257] Fps is (10 sec: 17612.0, 60 sec: 17566.5, 300 sec: 17566.5). Total num frames: 1187840. Throughput: 0: 17536.0. Samples: 789156. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-29 14:01:52,665][02257] Avg episode reward: [(0, '-39378.139')]
[2023-08-29 14:01:52,956][02270] Updated weights for policy 0, policy_version 2336 (0.0002)
[2023-08-29 14:01:55,183][02270] Updated weights for policy 0, policy_version 2416 (0.0002)
[2023-08-29 14:01:57,416][02270] Updated weights for policy 0, policy_version 2496 (0.0002)
[2023-08-29 14:01:57,663][02257] Fps is (10 sec: 18021.9, 60 sec: 17694.4, 300 sec: 17694.4). Total num frames: 1282048. Throughput: 0: 17555.1. Samples: 895294. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-29 14:01:57,663][02257] Avg episode reward: [(0, '-39378.139')]
[2023-08-29 14:01:59,674][02270] Updated weights for policy 0, policy_version 2576 (0.0002)
[2023-08-29 14:02:01,926][02270] Updated weights for policy 0, policy_version 2656 (0.0002)
[2023-08-29 14:02:02,662][02257] Fps is (10 sec: 18027.1, 60 sec: 17650.2, 300 sec: 17650.2). Total num frames: 1368064. Throughput: 0: 17580.4. Samples: 950298. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-29 14:02:02,662][02257] Avg episode reward: [(0, '-42305.740')]
[2023-08-29 14:02:04,318][02270] Updated weights for policy 0, policy_version 2736 (0.0002)
[2023-08-29 14:02:06,491][02270] Updated weights for policy 0, policy_version 2816 (0.0002)
[2023-08-29 14:02:07,663][02257] Fps is (10 sec: 18022.6, 60 sec: 17749.1, 300 sec: 17749.1). Total num frames: 1462272. Throughput: 0: 17602.0. Samples: 1057031. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-29 14:02:07,663][02257] Avg episode reward: [(0, '-42305.740')]
[2023-08-29 14:02:08,723][02270] Updated weights for policy 0, policy_version 2896 (0.0002)
[2023-08-29 14:02:11,209][02270] Updated weights for policy 0, policy_version 2976 (0.0002)
[2023-08-29 14:02:12,664][02257] Fps is (10 sec: 18018.6, 60 sec: 17680.9, 300 sec: 17706.9). Total num frames: 1548288. Throughput: 0: 17700.8. Samples: 1163084. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-29 14:02:12,664][02257] Avg episode reward: [(0, '-40927.609')]
[2023-08-29 14:02:13,398][02270] Updated weights for policy 0, policy_version 3056 (0.0002)
[2023-08-29 14:02:15,651][02270] Updated weights for policy 0, policy_version 3136 (0.0002)
[2023-08-29 14:02:17,664][02257] Fps is (10 sec: 18020.6, 60 sec: 17749.0, 300 sec: 17787.9). Total num frames: 1642496. Throughput: 0: 17814.9. Samples: 1219502. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-29 14:02:17,664][02257] Avg episode reward: [(0, '-40927.609')]
[2023-08-29 14:02:17,832][02270] Updated weights for policy 0, policy_version 3216 (0.0002)
[2023-08-29 14:02:20,274][02270] Updated weights for policy 0, policy_version 3296 (0.0002)
[2023-08-29 14:02:22,504][02270] Updated weights for policy 0, policy_version 3376 (0.0002)
[2023-08-29 14:02:22,664][02257] Fps is (10 sec: 18022.4, 60 sec: 17680.8, 300 sec: 17749.0). Total num frames: 1728512. Throughput: 0: 17912.0. Samples: 1326240. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-29 14:02:22,664][02257] Avg episode reward: [(0, '-36912.494')]
[2023-08-29 14:02:24,734][02270] Updated weights for policy 0, policy_version 3456 (0.0002)
[2023-08-29 14:02:26,946][02270] Updated weights for policy 0, policy_version 3536 (0.0002)
[2023-08-29 14:02:27,664][02257] Fps is (10 sec: 17612.8, 60 sec: 17748.9, 300 sec: 17766.0). Total num frames: 1818624. Throughput: 0: 17996.4. Samples: 1436530. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-29 14:02:27,665][02257] Avg episode reward: [(0, '-31034.878')]
[2023-08-29 14:02:27,665][02269] Saving new best policy, reward=-31034.878!
[2023-08-29 14:02:29,387][02270] Updated weights for policy 0, policy_version 3616 (0.0002)
[2023-08-29 14:02:31,630][02270] Updated weights for policy 0, policy_version 3696 (0.0002)
[2023-08-29 14:02:32,663][02257] Fps is (10 sec: 18023.7, 60 sec: 17885.8, 300 sec: 17781.3). Total num frames: 1908736. Throughput: 0: 17997.7. Samples: 1488328. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-29 14:02:32,663][02257] Avg episode reward: [(0, '-31034.878')]
[2023-08-29 14:02:33,925][02270] Updated weights for policy 0, policy_version 3776 (0.0002)
[2023-08-29 14:02:36,152][02270] Updated weights for policy 0, policy_version 3856 (0.0002)
[2023-08-29 14:02:36,643][02269] KL-divergence is very high: 697.4426
[2023-08-29 14:02:37,663][02257] Fps is (10 sec: 17614.7, 60 sec: 17886.2, 300 sec: 17749.2). Total num frames: 1994752. Throughput: 0: 17938.8. Samples: 1596382. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-29 14:02:37,663][02257] Avg episode reward: [(0, '-26120.967')]
[2023-08-29 14:02:37,663][02269] Saving new best policy, reward=-26120.967!
[2023-08-29 14:02:38,647][02270] Updated weights for policy 0, policy_version 3936 (0.0002)
[2023-08-29 14:02:40,980][02270] Updated weights for policy 0, policy_version 4016 (0.0002)
[2023-08-29 14:02:42,663][02257] Fps is (10 sec: 17612.8, 60 sec: 17886.1, 300 sec: 17763.6). Total num frames: 2084864. Throughput: 0: 17879.0. Samples: 1699846. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-29 14:02:42,663][02257] Avg episode reward: [(0, '-26120.967')]
[2023-08-29 14:02:42,665][02269] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000004072_2084864.pth...
[2023-08-29 14:02:42,667][02269] Removing /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000000224_114688.pth
[2023-08-29 14:02:43,209][02270] Updated weights for policy 0, policy_version 4096 (0.0002)
[2023-08-29 14:02:45,753][02269] KL-divergence is very high: 667.0187
[2023-08-29 14:02:45,758][02270] Updated weights for policy 0, policy_version 4176 (0.0002)
[2023-08-29 14:02:47,663][02257] Fps is (10 sec: 17612.6, 60 sec: 17817.5, 300 sec: 17735.5). Total num frames: 2170880. Throughput: 0: 17839.5. Samples: 1753104. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-29 14:02:47,663][02257] Avg episode reward: [(0, '-20283.983')]
[2023-08-29 14:02:47,664][02269] Saving new best policy, reward=-20283.983!
[2023-08-29 14:02:47,959][02270] Updated weights for policy 0, policy_version 4256 (0.0002)
[2023-08-29 14:02:50,302][02270] Updated weights for policy 0, policy_version 4336 (0.0002)
[2023-08-29 14:02:52,561][02270] Updated weights for policy 0, policy_version 4416 (0.0002)
[2023-08-29 14:02:52,662][02257] Fps is (10 sec: 17613.6, 60 sec: 17886.4, 300 sec: 17749.3). Total num frames: 2260992. Throughput: 0: 17798.5. Samples: 1857953. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-29 14:02:52,663][02257] Avg episode reward: [(0, '-20283.983')]
[2023-08-29 14:02:55,154][02270] Updated weights for policy 0, policy_version 4496 (0.0002)
[2023-08-29 14:02:57,370][02270] Updated weights for policy 0, policy_version 4576 (0.0002)
[2023-08-29 14:02:57,663][02257] Fps is (10 sec: 17612.6, 60 sec: 17749.3, 300 sec: 17724.4). Total num frames: 2347008. Throughput: 0: 17727.6. Samples: 1960817. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[2023-08-29 14:02:57,663][02257] Avg episode reward: [(0, '-13399.593')]
[2023-08-29 14:02:57,664][02269] Saving new best policy, reward=-13399.593!
[2023-08-29 14:02:59,599][02270] Updated weights for policy 0, policy_version 4656 (0.0002)
[2023-08-29 14:03:01,875][02270] Updated weights for policy 0, policy_version 4736 (0.0002)
[2023-08-29 14:03:02,664][02257] Fps is (10 sec: 17610.2, 60 sec: 17816.9, 300 sec: 17737.2). Total num frames: 2437120. Throughput: 0: 17697.6. Samples: 2015892. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-29 14:03:02,664][02257] Avg episode reward: [(0, '-13399.593')]
[2023-08-29 14:03:04,179][02269] KL-divergence is very high: 3411.2600
[2023-08-29 14:03:04,436][02270] Updated weights for policy 0, policy_version 4816 (0.0002)
[2023-08-29 14:03:06,679][02270] Updated weights for policy 0, policy_version 4896 (0.0002)
[2023-08-29 14:03:07,663][02257] Fps is (10 sec: 17613.0, 60 sec: 17681.1, 300 sec: 17715.1). Total num frames: 2523136. Throughput: 0: 17633.1. Samples: 2119720. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-29 14:03:07,663][02257] Avg episode reward: [(0, '-11299.859')]
[2023-08-29 14:03:07,664][02269] Saving new best policy, reward=-11299.859!
[2023-08-29 14:03:09,081][02270] Updated weights for policy 0, policy_version 4976 (0.0002)
[2023-08-29 14:03:11,401][02270] Updated weights for policy 0, policy_version 5056 (0.0002)
[2023-08-29 14:03:12,664][02257] Fps is (10 sec: 17202.8, 60 sec: 17680.9, 300 sec: 17694.4). Total num frames: 2609152. Throughput: 0: 17502.6. Samples: 2224146. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[2023-08-29 14:03:12,664][02257] Avg episode reward: [(0, '-11299.859')]
[2023-08-29 14:03:13,260][02269] KL-divergence is very high: 3359.1050
[2023-08-29 14:03:13,490][02269] KL-divergence is very high: 155.1156
[2023-08-29 14:03:13,694][02269] KL-divergence is very high: 127.9870
[2023-08-29 14:03:13,701][02269] KL-divergence is very high: 317.7355
[2023-08-29 14:03:13,954][02269] KL-divergence is very high: 148.8682
[2023-08-29 14:03:13,966][02270] Updated weights for policy 0, policy_version 5136 (0.0002)
[2023-08-29 14:03:16,203][02270] Updated weights for policy 0, policy_version 5216 (0.0002)
[2023-08-29 14:03:17,664][02257] Fps is (10 sec: 17202.3, 60 sec: 17544.7, 300 sec: 17675.6). Total num frames: 2695168. Throughput: 0: 17443.5. Samples: 2273296. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[2023-08-29 14:03:17,664][02257] Avg episode reward: [(0, '-10466.034')]
[2023-08-29 14:03:17,664][02269] Saving new best policy, reward=-10466.034!
[2023-08-29 14:03:18,504][02270] Updated weights for policy 0, policy_version 5296 (0.0002)
[2023-08-29 14:03:20,799][02270] Updated weights for policy 0, policy_version 5376 (0.0002)
[2023-08-29 14:03:22,662][02257] Fps is (10 sec: 16796.7, 60 sec: 17476.7, 300 sec: 17628.0). Total num frames: 2777088. Throughput: 0: 17422.2. Samples: 2380371. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-29 14:03:22,663][02257] Avg episode reward: [(0, '-13499.459')]
[2023-08-29 14:03:22,682][02269] KL-divergence is very high: 329.4608
[2023-08-29 14:03:23,351][02270] Updated weights for policy 0, policy_version 5456 (0.0002)
[2023-08-29 14:03:25,645][02270] Updated weights for policy 0, policy_version 5536 (0.0002)
[2023-08-29 14:03:27,664][02257] Fps is (10 sec: 17202.2, 60 sec: 17476.2, 300 sec: 17641.8). Total num frames: 2867200. Throughput: 0: 17424.0. Samples: 2483949. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[2023-08-29 14:03:27,664][02257] Avg episode reward: [(0, '-13499.459')]
[2023-08-29 14:03:27,953][02270] Updated weights for policy 0, policy_version 5616 (0.0002)
[2023-08-29 14:03:30,233][02270] Updated weights for policy 0, policy_version 5696 (0.0002)
[2023-08-29 14:03:31,840][02269] KL-divergence is very high: 1499.4238
[2023-08-29 14:03:32,663][02257] Fps is (10 sec: 17611.5, 60 sec: 17408.0, 300 sec: 17626.8). Total num frames: 2953216. Throughput: 0: 17412.5. Samples: 2536667. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-29 14:03:32,663][02257] Avg episode reward: [(0, '-14665.199')]
[2023-08-29 14:03:32,795][02270] Updated weights for policy 0, policy_version 5776 (0.0002)
[2023-08-29 14:03:35,072][02270] Updated weights for policy 0, policy_version 5856 (0.0002)
[2023-08-29 14:03:37,322][02270] Updated weights for policy 0, policy_version 5936 (0.0002)
[2023-08-29 14:03:37,663][02257] Fps is (10 sec: 17615.0, 60 sec: 17476.3, 300 sec: 17640.0). Total num frames: 3043328. Throughput: 0: 17365.7. Samples: 2639419. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-29 14:03:37,663][02257] Avg episode reward: [(0, '-14665.199')]
[2023-08-29 14:03:39,632][02270] Updated weights for policy 0, policy_version 6016 (0.0002)
[2023-08-29 14:03:41,187][02269] KL-divergence is very high: 270.1259
[2023-08-29 14:03:41,190][02269] KL-divergence is very high: 1043.5261
[2023-08-29 14:03:42,097][02270] Updated weights for policy 0, policy_version 6096 (0.0002)
[2023-08-29 14:03:42,662][02257] Fps is (10 sec: 17614.1, 60 sec: 17408.2, 300 sec: 17626.0). Total num frames: 3129344. Throughput: 0: 17411.9. Samples: 2744336. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-29 14:03:42,663][02257] Avg episode reward: [(0, '-14139.799')]
[2023-08-29 14:03:44,373][02270] Updated weights for policy 0, policy_version 6176 (0.0002)
[2023-08-29 14:03:46,613][02270] Updated weights for policy 0, policy_version 6256 (0.0002)
[2023-08-29 14:03:47,663][02257] Fps is (10 sec: 17613.5, 60 sec: 17476.4, 300 sec: 17638.4). Total num frames: 3219456. Throughput: 0: 17375.8. Samples: 2797781. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-29 14:03:47,663][02257] Avg episode reward: [(0, '-14139.799')]
[2023-08-29 14:03:48,879][02270] Updated weights for policy 0, policy_version 6336 (0.0002)
[2023-08-29 14:03:50,024][02269] KL-divergence is very high: 158.6016
[2023-08-29 14:03:50,229][02269] KL-divergence is very high: 128.4095
[2023-08-29 14:03:50,232][02269] KL-divergence is very high: 113.2888
[2023-08-29 14:03:50,235][02269] KL-divergence is very high: 129.1388
[2023-08-29 14:03:51,403][02270] Updated weights for policy 0, policy_version 6416 (0.0002)
[2023-08-29 14:03:52,664][02257] Fps is (10 sec: 17610.0, 60 sec: 17407.6, 300 sec: 17625.0). Total num frames: 3305472. Throughput: 0: 17401.8. Samples: 2902816. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[2023-08-29 14:03:52,664][02257] Avg episode reward: [(0, '-16637.548')]
[2023-08-29 14:03:53,626][02270] Updated weights for policy 0, policy_version 6496 (0.0002)
[2023-08-29 14:03:55,879][02270] Updated weights for policy 0, policy_version 6576 (0.0002)
[2023-08-29 14:03:57,661][02257] Fps is (10 sec: 17614.8, 60 sec: 17476.8, 300 sec: 17637.0). Total num frames: 3395584. Throughput: 0: 17504.9. Samples: 3011818. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[2023-08-29 14:03:57,662][02257] Avg episode reward: [(0, '-16637.548')]
[2023-08-29 14:03:58,117][02270] Updated weights for policy 0, policy_version 6656 (0.0002)
[2023-08-29 14:03:58,560][02269] KL-divergence is very high: 466.0750
[2023-08-29 14:03:58,572][02269] KL-divergence is very high: 4378.1611
[2023-08-29 14:03:59,046][02269] KL-divergence is very high: 4080.8794
[2023-08-29 14:03:59,050][02269] KL-divergence is very high: 249.0270
[2023-08-29 14:03:59,056][02269] KL-divergence is very high: 110.2269
[2023-08-29 14:03:59,059][02269] KL-divergence is very high: 14969.0225
[2023-08-29 14:03:59,062][02269] KL-divergence is very high: 14197.9629
[2023-08-29 14:03:59,281][02269] KL-divergence is very high: 1017.9431
[2023-08-29 14:03:59,284][02269] High loss value: l:254.6120 pl:-0.0215 vl:0.1524 exp_l:0.0000 kl_l:254.4810 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:03:59,284][02269] KL-divergence is very high: 92329.3047
[2023-08-29 14:03:59,288][02269] High loss value: l:396.4715 pl:0.0286 vl:0.2348 exp_l:0.0000 kl_l:396.2082 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:03:59,288][02269] KL-divergence is very high: 162577.8906
[2023-08-29 14:03:59,291][02269] High loss value: l:332.8129 pl:-0.0535 vl:0.4644 exp_l:0.0000 kl_l:332.4021 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:03:59,291][02269] KL-divergence is very high: 218388.5156
[2023-08-29 14:03:59,295][02269] KL-divergence is very high: 11566.8867
[2023-08-29 14:03:59,298][02269] High loss value: l:128.6794 pl:0.0220 vl:0.1553 exp_l:0.0000 kl_l:128.5021 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:03:59,298][02269] KL-divergence is very high: 45962.1953
[2023-08-29 14:03:59,301][02269] High loss value: l:254.8789 pl:-0.0513 vl:0.2203 exp_l:0.0000 kl_l:254.7099 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:03:59,301][02269] KL-divergence is very high: 112328.7812
[2023-08-29 14:03:59,305][02269] High loss value: l:254.8794 pl:-0.0452 vl:0.4378 exp_l:0.0000 kl_l:254.4868 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:03:59,305][02269] KL-divergence is very high: 142660.5000
[2023-08-29 14:03:59,511][02269] High loss value: l:47.9729 pl:-0.0252 vl:1.0947 exp_l:0.0000 kl_l:46.9034 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:03:59,511][02269] KL-divergence is very high: 39611.0625
[2023-08-29 14:03:59,515][02269] High loss value: l:109.1943 pl:-0.0416 vl:1.1069 exp_l:0.0000 kl_l:108.1290 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:03:59,515][02269] KL-divergence is very high: 80260.8438
[2023-08-29 14:03:59,519][02269] KL-divergence is very high: 11330.1523
[2023-08-29 14:03:59,522][02269] KL-divergence is very high: 8787.7402
[2023-08-29 14:03:59,525][02269] KL-divergence is very high: 15297.0264
[2023-08-29 14:03:59,528][02269] High loss value: l:77.6982 pl:-0.0359 vl:1.0193 exp_l:0.0000 kl_l:76.7148 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:03:59,528][02269] KL-divergence is very high: 48738.4297
[2023-08-29 14:03:59,532][02269] KL-divergence is very high: 10601.1680
[2023-08-29 14:03:59,736][02269] KL-divergence is very high: 544.1205
[2023-08-29 14:03:59,738][02269] KL-divergence is very high: 4621.1294
[2023-08-29 14:03:59,741][02269] KL-divergence is very high: 115.6930
[2023-08-29 14:03:59,745][02269] KL-divergence is very high: 153.4109
[2023-08-29 14:03:59,748][02269] KL-divergence is very high: 2167.7378
[2023-08-29 14:03:59,750][02269] KL-divergence is very high: 13151.4131
[2023-08-29 14:03:59,954][02269] KL-divergence is very high: 127.8784
[2023-08-29 14:03:59,957][02269] KL-divergence is very high: 144.8802
[2023-08-29 14:03:59,960][02269] KL-divergence is very high: 1745.6932
[2023-08-29 14:03:59,966][02269] KL-divergence is very high: 278.9655
[2023-08-29 14:03:59,970][02269] KL-divergence is very high: 1596.2111
[2023-08-29 14:04:00,669][02270] Updated weights for policy 0, policy_version 6736 (0.0002)
[2023-08-29 14:04:02,663][02257] Fps is (10 sec: 17614.6, 60 sec: 17408.3, 300 sec: 17624.4). Total num frames: 3481600. Throughput: 0: 17527.5. Samples: 3062020. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[2023-08-29 14:04:02,663][02257] Avg episode reward: [(0, '-18933.096')]
[2023-08-29 14:04:02,877][02270] Updated weights for policy 0, policy_version 6816 (0.0002)
[2023-08-29 14:04:05,158][02270] Updated weights for policy 0, policy_version 6896 (0.0002)
[2023-08-29 14:04:07,461][02270] Updated weights for policy 0, policy_version 6976 (0.0002)
[2023-08-29 14:04:07,663][02257] Fps is (10 sec: 17610.1, 60 sec: 17476.3, 300 sec: 17635.5). Total num frames: 3571712. Throughput: 0: 17554.2. Samples: 3170323. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-29 14:04:07,663][02257] Avg episode reward: [(0, '-18933.096')]
[2023-08-29 14:04:09,970][02270] Updated weights for policy 0, policy_version 7056 (0.0002)
[2023-08-29 14:04:12,246][02270] Updated weights for policy 0, policy_version 7136 (0.0002)
[2023-08-29 14:04:12,663][02257] Fps is (10 sec: 17612.6, 60 sec: 17476.6, 300 sec: 17623.8). Total num frames: 3657728. Throughput: 0: 17549.3. Samples: 3273648. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-29 14:04:12,663][02257] Avg episode reward: [(0, '-34051.541')]
[2023-08-29 14:04:14,479][02270] Updated weights for policy 0, policy_version 7216 (0.0002)
[2023-08-29 14:04:16,734][02270] Updated weights for policy 0, policy_version 7296 (0.0002)
[2023-08-29 14:04:17,663][02257] Fps is (10 sec: 17612.6, 60 sec: 17544.7, 300 sec: 17634.3). Total num frames: 3747840. Throughput: 0: 17606.5. Samples: 3328962. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-29 14:04:17,664][02257] Avg episode reward: [(0, '-33459.126')]
[2023-08-29 14:04:19,168][02270] Updated weights for policy 0, policy_version 7376 (0.0002)
[2023-08-29 14:04:21,503][02270] Updated weights for policy 0, policy_version 7456 (0.0002)
[2023-08-29 14:04:22,663][02257] Fps is (10 sec: 18022.2, 60 sec: 17680.8, 300 sec: 17644.2). Total num frames: 3837952. Throughput: 0: 17639.4. Samples: 3433194. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-29 14:04:22,663][02257] Avg episode reward: [(0, '-33459.126')]
[2023-08-29 14:04:22,666][02269] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000007496_3837952.pth...
[2023-08-29 14:04:22,668][02269] Removing /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000000736_376832.pth
[2023-08-29 14:04:23,762][02270] Updated weights for policy 0, policy_version 7536 (0.0002)
[2023-08-29 14:04:26,273][02270] Updated weights for policy 0, policy_version 7616 (0.0002)
[2023-08-29 14:04:27,663][02257] Fps is (10 sec: 17613.7, 60 sec: 17613.3, 300 sec: 17633.2). Total num frames: 3923968. Throughput: 0: 17624.6. Samples: 3537446. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2023-08-29 14:04:27,664][02257] Avg episode reward: [(0, '-32372.235')]
[2023-08-29 14:04:28,522][02270] Updated weights for policy 0, policy_version 7696 (0.0002)
[2023-08-29 14:04:30,765][02270] Updated weights for policy 0, policy_version 7776 (0.0002)
[2023-08-29 14:04:32,662][02257] Fps is (10 sec: 17614.0, 60 sec: 17681.2, 300 sec: 17642.8). Total num frames: 4014080. Throughput: 0: 17655.2. Samples: 3592265. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-29 14:04:32,663][02257] Avg episode reward: [(0, '-32372.235')]
[2023-08-29 14:04:32,933][02270] Updated weights for policy 0, policy_version 7856 (0.0002)
[2023-08-29 14:04:35,412][02270] Updated weights for policy 0, policy_version 7936 (0.0002)
[2023-08-29 14:04:37,626][02270] Updated weights for policy 0, policy_version 8016 (0.0002)
[2023-08-29 14:04:37,664][02257] Fps is (10 sec: 18020.3, 60 sec: 17680.8, 300 sec: 17651.7). Total num frames: 4104192. Throughput: 0: 17686.7. Samples: 3698713. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-29 14:04:37,664][02257] Avg episode reward: [(0, '-34263.295')]
[2023-08-29 14:04:39,849][02270] Updated weights for policy 0, policy_version 8096 (0.0002)
[2023-08-29 14:04:42,132][02270] Updated weights for policy 0, policy_version 8176 (0.0002)
[2023-08-29 14:04:42,663][02257] Fps is (10 sec: 18021.5, 60 sec: 17749.2, 300 sec: 17660.4). Total num frames: 4194304. Throughput: 0: 17720.4. Samples: 3809264. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-29 14:04:42,663][02257] Avg episode reward: [(0, '-34263.295')]
[2023-08-29 14:04:44,657][02270] Updated weights for policy 0, policy_version 8256 (0.0002)
[2023-08-29 14:04:46,976][02270] Updated weights for policy 0, policy_version 8336 (0.0002)
[2023-08-29 14:04:47,663][02257] Fps is (10 sec: 17204.7, 60 sec: 17612.7, 300 sec: 17631.4). Total num frames: 4276224. Throughput: 0: 17690.6. Samples: 3858095. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[2023-08-29 14:04:47,663][02257] Avg episode reward: [(0, '-36905.953')]
[2023-08-29 14:04:49,259][02270] Updated weights for policy 0, policy_version 8416 (0.0002)
[2023-08-29 14:04:51,443][02270] Updated weights for policy 0, policy_version 8496 (0.0002)
[2023-08-29 14:04:52,663][02257] Fps is (10 sec: 17612.8, 60 sec: 17749.6, 300 sec: 17658.3). Total num frames: 4370432. Throughput: 0: 17687.6. Samples: 3966266. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-29 14:04:52,663][02257] Avg episode reward: [(0, '-36905.953')]
[2023-08-29 14:04:53,913][02270] Updated weights for policy 0, policy_version 8576 (0.0002)
[2023-08-29 14:04:56,220][02270] Updated weights for policy 0, policy_version 8656 (0.0002)
[2023-08-29 14:04:57,663][02257] Fps is (10 sec: 18022.2, 60 sec: 17680.6, 300 sec: 17648.4). Total num frames: 4456448. Throughput: 0: 17704.9. Samples: 4070370. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-29 14:04:57,663][02257] Avg episode reward: [(0, '-35662.948')]
[2023-08-29 14:04:58,110][02269] KL-divergence is very high: 377.1249
[2023-08-29 14:04:58,113][02269] KL-divergence is very high: 439.5258
[2023-08-29 14:04:58,547][02270] Updated weights for policy 0, policy_version 8736 (0.0002)
[2023-08-29 14:05:00,752][02270] Updated weights for policy 0, policy_version 8816 (0.0002)
[2023-08-29 14:05:01,898][02269] KL-divergence is very high: 560.1690
[2023-08-29 14:05:02,662][02257] Fps is (10 sec: 17205.6, 60 sec: 17681.5, 300 sec: 17639.0). Total num frames: 4542464. Throughput: 0: 17682.8. Samples: 4124659. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[2023-08-29 14:05:02,662][02257] Avg episode reward: [(0, '-25706.690')]
[2023-08-29 14:05:03,307][02270] Updated weights for policy 0, policy_version 8896 (0.0002)
[2023-08-29 14:05:05,613][02270] Updated weights for policy 0, policy_version 8976 (0.0002)
[2023-08-29 14:05:07,663][02257] Fps is (10 sec: 17203.4, 60 sec: 17612.8, 300 sec: 17629.8). Total num frames: 4628480. Throughput: 0: 17642.3. Samples: 4227092. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-29 14:05:07,663][02257] Avg episode reward: [(0, '-25706.690')]
[2023-08-29 14:05:07,911][02270] Updated weights for policy 0, policy_version 9056 (0.0002)
[2023-08-29 14:05:10,241][02270] Updated weights for policy 0, policy_version 9136 (0.0002)
[2023-08-29 14:05:11,864][02269] KL-divergence is very high: 255.4448
[2023-08-29 14:05:11,867][02269] High loss value: l:101.9697 pl:0.0202 vl:0.0474 exp_l:0.0000 kl_l:101.9021 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:11,868][02269] KL-divergence is very high: 102942.4219
[2023-08-29 14:05:11,877][02269] High loss value: l:70.7525 pl:0.1419 vl:0.0130 exp_l:0.0000 kl_l:70.5977 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:11,877][02269] KL-divergence is very high: 52569.9375
[2023-08-29 14:05:11,880][02269] KL-divergence is very high: 16281.8535
[2023-08-29 14:05:11,883][02269] KL-divergence is very high: 150.1327
[2023-08-29 14:05:12,133][02269] KL-divergence is very high: 653.5459
[2023-08-29 14:05:12,136][02269] KL-divergence is very high: 1328.8704
[2023-08-29 14:05:12,139][02269] KL-divergence is very high: 185.8762
[2023-08-29 14:05:12,144][02269] KL-divergence is very high: 230.5563
[2023-08-29 14:05:12,348][02269] KL-divergence is very high: 25730.9375
[2023-08-29 14:05:12,351][02269] KL-divergence is very high: 116.7110
[2023-08-29 14:05:12,355][02269] KL-divergence is very high: 119.7257
[2023-08-29 14:05:12,358][02269] KL-divergence is very high: 116.9390
[2023-08-29 14:05:12,361][02269] High loss value: l:117.2373 pl:0.0861 vl:0.1485 exp_l:0.0000 kl_l:117.0027 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:12,361][02269] KL-divergence is very high: 574194.8125
[2023-08-29 14:05:12,365][02269] KL-divergence is very high: 909.2070
[2023-08-29 14:05:12,605][02269] KL-divergence is very high: 16825.3281
[2023-08-29 14:05:12,608][02269] KL-divergence is very high: 80809.1875
[2023-08-29 14:05:12,610][02269] High loss value: l:269.4311 pl:-0.0287 vl:0.9178 exp_l:0.0000 kl_l:268.5420 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:12,611][02269] KL-divergence is very high: 630892.3750
[2023-08-29 14:05:12,614][02269] KL-divergence is very high: 7873.9766
[2023-08-29 14:05:12,617][02269] KL-divergence is very high: 7061.5698
[2023-08-29 14:05:12,620][02269] KL-divergence is very high: 31509.0742
[2023-08-29 14:05:12,623][02269] High loss value: l:43.6385 pl:-0.0272 vl:0.8778 exp_l:0.0000 kl_l:42.7879 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:12,623][02269] KL-divergence is very high: 59242.1914
[2023-08-29 14:05:12,663][02257] Fps is (10 sec: 17200.3, 60 sec: 17612.7, 300 sec: 17621.1). Total num frames: 4714496. Throughput: 0: 17583.4. Samples: 4328708. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-29 14:05:12,663][02257] Avg episode reward: [(0, '-19021.244')]
[2023-08-29 14:05:12,825][02269] KL-divergence is very high: 335.4756
[2023-08-29 14:05:12,828][02269] High loss value: l:2169.6594 pl:-0.0427 vl:0.5099 exp_l:0.0000 kl_l:2169.1921 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:12,828][02269] KL-divergence is very high: 434563.9688
[2023-08-29 14:05:12,831][02269] High loss value: l:2985.5588 pl:-0.0373 vl:0.4207 exp_l:0.0000 kl_l:2985.1755 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:12,831][02269] KL-divergence is very high: 744654.1250
[2023-08-29 14:05:12,834][02269] High loss value: l:2183.0200 pl:-0.0268 vl:0.7129 exp_l:0.0000 kl_l:2182.3340 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:12,834][02269] KL-divergence is very high: 1132371.5000
[2023-08-29 14:05:12,838][02269] High loss value: l:579.0637 pl:-0.0234 vl:1.3857 exp_l:0.0000 kl_l:577.7015 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:12,838][02269] KL-divergence is very high: 225883.5938
[2023-08-29 14:05:12,842][02269] High loss value: l:2749.4138 pl:-0.0322 vl:0.4833 exp_l:0.0000 kl_l:2748.9626 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:12,842][02269] KL-divergence is very high: 445505.8125
[2023-08-29 14:05:12,845][02269] High loss value: l:3870.2283 pl:-0.0345 vl:0.5050 exp_l:0.0000 kl_l:3869.7578 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:12,845][02269] KL-divergence is very high: 1092729.7500
[2023-08-29 14:05:12,849][02269] High loss value: l:5715.3301 pl:-0.0154 vl:0.8643 exp_l:0.0000 kl_l:5714.4814 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:12,849][02269] KL-divergence is very high: 2629551.5000
[2023-08-29 14:05:12,853][02270] Updated weights for policy 0, policy_version 9216 (0.0002)
[2023-08-29 14:05:13,054][02269] KL-divergence is very high: 369.0032
[2023-08-29 14:05:13,056][02269] KL-divergence is very high: 333.0984
[2023-08-29 14:05:13,059][02269] KL-divergence is very high: 185.5498
[2023-08-29 14:05:13,062][02269] KL-divergence is very high: 1119.8888
[2023-08-29 14:05:13,065][02269] KL-divergence is very high: 1805.7213
[2023-08-29 14:05:13,069][02269] KL-divergence is very high: 1166.5697
[2023-08-29 14:05:13,292][02269] KL-divergence is very high: 265.9895
[2023-08-29 14:05:13,295][02269] KL-divergence is very high: 293.1416
[2023-08-29 14:05:13,300][02269] KL-divergence is very high: 162.0991
[2023-08-29 14:05:13,303][02269] KL-divergence is very high: 189.2346
[2023-08-29 14:05:13,307][02269] KL-divergence is very high: 182.0590
[2023-08-29 14:05:13,310][02269] KL-divergence is very high: 435.4019
[2023-08-29 14:05:13,540][02269] KL-divergence is very high: 2522.8826
[2023-08-29 14:05:13,543][02269] KL-divergence is very high: 1667.5056
[2023-08-29 14:05:13,545][02269] KL-divergence is very high: 335.0720
[2023-08-29 14:05:13,548][02269] KL-divergence is very high: 3258.5496
[2023-08-29 14:05:13,551][02269] KL-divergence is very high: 6059.7817
[2023-08-29 14:05:13,554][02269] KL-divergence is very high: 2171.6685
[2023-08-29 14:05:13,558][02269] KL-divergence is very high: 1383.0406
[2023-08-29 14:05:13,757][02269] KL-divergence is very high: 2523.0588
[2023-08-29 14:05:13,759][02269] KL-divergence is very high: 4046.4834
[2023-08-29 14:05:13,763][02269] KL-divergence is very high: 1776.8835
[2023-08-29 14:05:13,765][02269] KL-divergence is very high: 1501.9344
[2023-08-29 14:05:13,768][02269] KL-divergence is very high: 2154.8770
[2023-08-29 14:05:13,770][02269] KL-divergence is very high: 3988.2891
[2023-08-29 14:05:13,774][02269] KL-divergence is very high: 1817.4935
[2023-08-29 14:05:13,979][02269] KL-divergence is very high: 1018.3633
[2023-08-29 14:05:13,982][02269] KL-divergence is very high: 1823.3926
[2023-08-29 14:05:13,984][02269] KL-divergence is very high: 1208.1263
[2023-08-29 14:05:13,987][02269] KL-divergence is very high: 839.1346
[2023-08-29 14:05:13,991][02269] KL-divergence is very high: 1027.7970
[2023-08-29 14:05:13,993][02269] KL-divergence is very high: 1467.1227
[2023-08-29 14:05:13,996][02269] KL-divergence is very high: 484.5173
[2023-08-29 14:05:14,220][02269] KL-divergence is very high: 2719.7673
[2023-08-29 14:05:14,223][02269] KL-divergence is very high: 2576.0303
[2023-08-29 14:05:14,226][02269] KL-divergence is very high: 801.9417
[2023-08-29 14:05:14,229][02269] KL-divergence is very high: 2393.9912
[2023-08-29 14:05:14,232][02269] KL-divergence is very high: 403.4016
[2023-08-29 14:05:14,235][02269] KL-divergence is very high: 869.4836
[2023-08-29 14:05:14,239][02269] KL-divergence is very high: 698.6886
[2023-08-29 14:05:14,438][02269] KL-divergence is very high: 655.1866
[2023-08-29 14:05:14,440][02269] High loss value: l:3737.1270 pl:-0.0514 vl:4.4182 exp_l:0.0000 kl_l:3732.7603 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:14,441][02269] KL-divergence is very high: 946586.9375
[2023-08-29 14:05:14,444][02269] High loss value: l:1953.9850 pl:-0.0520 vl:4.5499 exp_l:0.0000 kl_l:1949.4872 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:14,444][02269] KL-divergence is very high: 733107.0625
[2023-08-29 14:05:14,447][02269] High loss value: l:43.8721 pl:-0.0455 vl:4.4439 exp_l:0.0000 kl_l:39.4737 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:14,447][02269] KL-divergence is very high: 10463.8945
[2023-08-29 14:05:14,451][02269] High loss value: l:7027.4966 pl:-0.0146 vl:3.9917 exp_l:0.0000 kl_l:7023.5195 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:14,451][02269] KL-divergence is very high: 1853461.0000
[2023-08-29 14:05:14,454][02269] High loss value: l:14995.4268 pl:-0.0391 vl:4.2798 exp_l:0.0000 kl_l:14991.1865 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:14,454][02269] KL-divergence is very high: 4143271.5000
[2023-08-29 14:05:14,457][02269] High loss value: l:6460.1050 pl:-0.0377 vl:4.4499 exp_l:0.0000 kl_l:6455.6929 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:14,458][02269] KL-divergence is very high: 2531784.5000
[2023-08-29 14:05:14,461][02269] High loss value: l:2033.2765 pl:-0.0321 vl:4.3982 exp_l:0.0000 kl_l:2028.9104 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:14,461][02269] KL-divergence is very high: 640539.0000
[2023-08-29 14:05:14,701][02269] High loss value: l:893.7085 pl:-0.0506 vl:4.3547 exp_l:0.0000 kl_l:889.4044 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:14,701][02269] KL-divergence is very high: 253178.2812
[2023-08-29 14:05:14,705][02269] High loss value: l:472.5727 pl:-0.0528 vl:4.2877 exp_l:0.0000 kl_l:468.3377 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:14,705][02269] KL-divergence is very high: 163275.8281
[2023-08-29 14:05:14,708][02269] High loss value: l:224.6534 pl:-0.0516 vl:4.3080 exp_l:0.0000 kl_l:220.3970 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:14,709][02269] KL-divergence is very high: 50059.8047
[2023-08-29 14:05:14,712][02269] High loss value: l:370.6410 pl:-0.0459 vl:4.2253 exp_l:0.0000 kl_l:366.4615 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:14,713][02269] KL-divergence is very high: 64321.3594
[2023-08-29 14:05:14,716][02269] High loss value: l:128.0340 pl:-0.0447 vl:4.2840 exp_l:0.0000 kl_l:123.7948 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:14,717][02269] KL-divergence is very high: 63043.6836
[2023-08-29 14:05:14,720][02269] High loss value: l:47.4225 pl:-0.0508 vl:4.2200 exp_l:0.0000 kl_l:43.2533 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:14,721][02269] KL-divergence is very high: 29278.1855
[2023-08-29 14:05:14,724][02269] High loss value: l:590.5286 pl:-0.0481 vl:4.2362 exp_l:0.0000 kl_l:586.3405 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:14,724][02269] KL-divergence is very high: 144142.8750
[2023-08-29 14:05:14,928][02269] KL-divergence is very high: 736.9821
[2023-08-29 14:05:14,930][02269] KL-divergence is very high: 7560.9546
[2023-08-29 14:05:14,933][02269] KL-divergence is very high: 2290.1033
[2023-08-29 14:05:14,936][02269] High loss value: l:133.8610 pl:-0.0503 vl:4.3907 exp_l:0.0000 kl_l:129.5206 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:14,936][02269] KL-divergence is very high: 59700.5664
[2023-08-29 14:05:14,940][02269] KL-divergence is very high: 33318.1562
[2023-08-29 14:05:14,943][02269] KL-divergence is very high: 7496.6411
[2023-08-29 14:05:14,946][02269] KL-divergence is very high: 7157.6777
[2023-08-29 14:05:15,151][02269] High loss value: l:49.0701 pl:-0.0319 vl:3.4836 exp_l:0.0000 kl_l:45.6184 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:15,151][02269] KL-divergence is very high: 46036.1328
[2023-08-29 14:05:15,155][02269] KL-divergence is very high: 5409.5376
[2023-08-29 14:05:15,157][02269] KL-divergence is very high: 1567.4900
[2023-08-29 14:05:15,160][02269] KL-divergence is very high: 876.9507
[2023-08-29 14:05:15,163][02269] High loss value: l:115.3207 pl:-0.0480 vl:2.8085 exp_l:0.0000 kl_l:112.5602 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:15,164][02269] KL-divergence is very high: 105313.7031
[2023-08-29 14:05:15,167][02270] Updated weights for policy 0, policy_version 9296 (0.0002)
[2023-08-29 14:05:15,366][02269] High loss value: l:130.8144 pl:-0.0517 vl:1.8811 exp_l:0.0000 kl_l:128.9850 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:15,366][02269] KL-divergence is very high: 38904.2109
[2023-08-29 14:05:15,369][02269] High loss value: l:82.8575 pl:-0.0513 vl:1.9565 exp_l:0.0000 kl_l:80.9524 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:15,370][02269] KL-divergence is very high: 31538.3535
[2023-08-29 14:05:15,373][02269] High loss value: l:65.4417 pl:-0.0288 vl:2.1814 exp_l:0.0000 kl_l:63.2891 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:15,373][02269] KL-divergence is very high: 46787.0781
[2023-08-29 14:05:15,376][02269] KL-divergence is very high: 6062.4580
[2023-08-29 14:05:15,379][02269] High loss value: l:49.6802 pl:-0.0480 vl:1.3815 exp_l:0.0000 kl_l:48.3467 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:15,379][02269] KL-divergence is very high: 25126.1738
[2023-08-29 14:05:15,383][02269] High loss value: l:110.6069 pl:-0.0506 vl:1.4360 exp_l:0.0000 kl_l:109.2215 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:15,383][02269] KL-divergence is very high: 32907.1328
[2023-08-29 14:05:15,387][02269] High loss value: l:68.9336 pl:-0.0407 vl:1.7472 exp_l:0.0000 kl_l:67.2271 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:15,387][02269] KL-divergence is very high: 34971.8711
[2023-08-29 14:05:15,587][02269] KL-divergence is very high: 25380.2656
[2023-08-29 14:05:15,590][02269] KL-divergence is very high: 167.9472
[2023-08-29 14:05:15,592][02269] High loss value: l:198.8770 pl:-0.0412 vl:1.3677 exp_l:0.0000 kl_l:197.5505 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:15,592][02269] KL-divergence is very high: 316202.0938
[2023-08-29 14:05:15,596][02269] KL-divergence is very high: 16972.0254
[2023-08-29 14:05:15,600][02269] High loss value: l:32.5674 pl:0.0444 vl:1.7712 exp_l:0.0000 kl_l:30.7518 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:15,600][02269] KL-divergence is very high: 91549.4219
[2023-08-29 14:05:15,603][02269] KL-divergence is very high: 1472.6411
[2023-08-29 14:05:15,606][02269] High loss value: l:225.0730 pl:0.0478 vl:1.1650 exp_l:0.0000 kl_l:223.8602 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:15,606][02269] KL-divergence is very high: 363651.7500
[2023-08-29 14:05:15,812][02269] KL-divergence is very high: 61563.9219
[2023-08-29 14:05:15,815][02269] KL-divergence is very high: 446.1510
[2023-08-29 14:05:15,818][02269] High loss value: l:100.0890 pl:-0.0524 vl:0.3076 exp_l:0.0000 kl_l:99.8339 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:15,818][02269] KL-divergence is very high: 58487.7383
[2023-08-29 14:05:15,822][02269] KL-divergence is very high: 709.1168
[2023-08-29 14:05:15,825][02269] KL-divergence is very high: 1015.5912
[2023-08-29 14:05:15,828][02269] High loss value: l:107.5457 pl:-0.0152 vl:1.1908 exp_l:0.0000 kl_l:106.3700 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:15,828][02269] KL-divergence is very high: 148800.7500
[2023-08-29 14:05:15,832][02269] High loss value: l:112.6151 pl:-0.0523 vl:0.2105 exp_l:0.0000 kl_l:112.4569 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:15,832][02269] KL-divergence is very high: 67104.9531
[2023-08-29 14:05:16,039][02269] High loss value: l:372.7328 pl:-0.0520 vl:0.6062 exp_l:0.0000 kl_l:372.1786 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:16,039][02269] KL-divergence is very high: 350204.9375
[2023-08-29 14:05:16,042][02269] High loss value: l:369.1877 pl:-0.0513 vl:0.9055 exp_l:0.0000 kl_l:368.3334 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:16,042][02269] KL-divergence is very high: 856987.5625
[2023-08-29 14:05:16,045][02269] High loss value: l:6428.5469 pl:-0.0523 vl:0.2354 exp_l:0.0000 kl_l:6428.3638 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:16,046][02269] KL-divergence is very high: 3192508.2500
[2023-08-29 14:05:16,049][02269] High loss value: l:293.9118 pl:-0.0511 vl:0.4038 exp_l:0.0000 kl_l:293.5591 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:16,049][02269] KL-divergence is very high: 253114.2500
[2023-08-29 14:05:16,052][02269] High loss value: l:103.1052 pl:-0.0512 vl:0.5501 exp_l:0.0000 kl_l:102.6063 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:16,053][02269] KL-divergence is very high: 163041.7812
[2023-08-29 14:05:16,056][02269] High loss value: l:118.3130 pl:-0.0511 vl:0.8339 exp_l:0.0000 kl_l:117.5303 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:16,056][02269] KL-divergence is very high: 306277.7812
[2023-08-29 14:05:16,060][02269] High loss value: l:1109.6511 pl:-0.0510 vl:0.2077 exp_l:0.0000 kl_l:1109.4945 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:16,060][02269] KL-divergence is very high: 746650.6875
[2023-08-29 14:05:16,259][02269] KL-divergence is very high: 369.7854
[2023-08-29 14:05:16,262][02269] High loss value: l:3424.4194 pl:-0.0519 vl:0.2052 exp_l:0.0000 kl_l:3424.2661 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:16,262][02269] KL-divergence is very high: 1527769.1250
[2023-08-29 14:05:16,265][02269] High loss value: l:7807.6001 pl:-0.0509 vl:0.1787 exp_l:0.0000 kl_l:7807.4722 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:16,265][02269] KL-divergence is very high: 3042960.0000
[2023-08-29 14:05:16,268][02269] High loss value: l:8860.4834 pl:-0.0517 vl:0.1496 exp_l:0.0000 kl_l:8860.3857 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:16,269][02269] KL-divergence is very high: 3066821.2500
[2023-08-29 14:05:16,272][02269] High loss value: l:1659.2850 pl:-0.0513 vl:0.1844 exp_l:0.0000 kl_l:1659.1520 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:16,272][02269] KL-divergence is very high: 799043.5000
[2023-08-29 14:05:16,276][02269] High loss value: l:352.2700 pl:-0.0522 vl:0.2133 exp_l:0.0000 kl_l:352.1089 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:16,276][02269] KL-divergence is very high: 197956.7969
[2023-08-29 14:05:16,279][02269] High loss value: l:2126.2944 pl:-0.0497 vl:0.1886 exp_l:0.0000 kl_l:2126.1555 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:16,279][02269] KL-divergence is very high: 912675.6250
[2023-08-29 14:05:16,282][02269] High loss value: l:2335.5825 pl:-0.0504 vl:0.1613 exp_l:0.0000 kl_l:2335.4714 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:16,283][02269] KL-divergence is very high: 874047.6250
[2023-08-29 14:05:16,486][02269] High loss value: l:169.5155 pl:-0.0514 vl:0.1352 exp_l:0.0000 kl_l:169.4316 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:16,486][02269] KL-divergence is very high: 31582.7949
[2023-08-29 14:05:16,490][02269] High loss value: l:456.6443 pl:-0.0517 vl:0.1316 exp_l:0.0000 kl_l:456.5644 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:16,490][02269] KL-divergence is very high: 63071.6797
[2023-08-29 14:05:16,493][02269] High loss value: l:154.9889 pl:-0.0507 vl:0.1265 exp_l:0.0000 kl_l:154.9131 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:16,493][02269] KL-divergence is very high: 26047.7539
[2023-08-29 14:05:16,497][02269] High loss value: l:2205.0767 pl:-0.0514 vl:0.1369 exp_l:0.0000 kl_l:2204.9910 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:16,497][02269] KL-divergence is very high: 440751.3125
[2023-08-29 14:05:16,500][02269] High loss value: l:2782.5188 pl:-0.0509 vl:0.1369 exp_l:0.0000 kl_l:2782.4326 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:16,500][02269] KL-divergence is very high: 502714.8750
[2023-08-29 14:05:16,504][02269] High loss value: l:285.0432 pl:-0.0508 vl:0.1416 exp_l:0.0000 kl_l:284.9523 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:16,504][02269] KL-divergence is very high: 58099.9844
[2023-08-29 14:05:16,508][02269] High loss value: l:3386.0911 pl:-0.0503 vl:0.1421 exp_l:0.0000 kl_l:3385.9993 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:16,508][02269] KL-divergence is very high: 595094.1250
[2023-08-29 14:05:16,745][02269] High loss value: l:1706.4659 pl:-0.0520 vl:0.1541 exp_l:0.0000 kl_l:1706.3639 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:16,745][02269] KL-divergence is very high: 289970.9375
[2023-08-29 14:05:16,748][02269] High loss value: l:2118.8088 pl:-0.0528 vl:0.1724 exp_l:0.0000 kl_l:2118.6892 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:16,748][02269] KL-divergence is very high: 353127.4688
[2023-08-29 14:05:16,752][02269] High loss value: l:590.7264 pl:-0.0516 vl:0.1871 exp_l:0.0000 kl_l:590.5909 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:16,752][02269] KL-divergence is very high: 78161.0234
[2023-08-29 14:05:16,756][02269] High loss value: l:2059.3809 pl:-0.0525 vl:0.1942 exp_l:0.0000 kl_l:2059.2393 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:16,756][02269] KL-divergence is very high: 268723.2812
[2023-08-29 14:05:16,760][02269] High loss value: l:3805.3315 pl:-0.0511 vl:0.1939 exp_l:0.0000 kl_l:3805.1887 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:16,760][02269] KL-divergence is very high: 551329.6875
[2023-08-29 14:05:16,763][02269] High loss value: l:2186.4109 pl:-0.0510 vl:0.2022 exp_l:0.0000 kl_l:2186.2598 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:16,763][02269] KL-divergence is very high: 296662.7812
[2023-08-29 14:05:16,767][02269] High loss value: l:335.2736 pl:-0.0521 vl:0.2027 exp_l:0.0000 kl_l:335.1230 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:16,767][02269] KL-divergence is very high: 43817.1133
[2023-08-29 14:05:16,969][02269] High loss value: l:575.1199 pl:-0.0517 vl:0.1879 exp_l:0.0000 kl_l:574.9836 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:16,969][02269] KL-divergence is very high: 101661.7031
[2023-08-29 14:05:16,972][02269] High loss value: l:369.5672 pl:-0.0524 vl:0.1939 exp_l:0.0000 kl_l:369.4257 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:16,972][02269] KL-divergence is very high: 72117.5000
[2023-08-29 14:05:16,976][02269] High loss value: l:163.3996 pl:-0.0517 vl:0.2084 exp_l:0.0000 kl_l:163.2429 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:16,976][02269] KL-divergence is very high: 23314.3613
[2023-08-29 14:05:16,980][02269] High loss value: l:207.2719 pl:-0.0517 vl:0.2212 exp_l:0.0000 kl_l:207.1023 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:16,980][02269] KL-divergence is very high: 31143.0762
[2023-08-29 14:05:16,983][02269] High loss value: l:194.3551 pl:-0.0506 vl:0.2184 exp_l:0.0000 kl_l:194.1873 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:16,984][02269] KL-divergence is very high: 39710.5039
[2023-08-29 14:05:16,987][02269] High loss value: l:129.0468 pl:-0.0507 vl:0.2242 exp_l:0.0000 kl_l:128.8733 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:16,987][02269] KL-divergence is very high: 24374.7520
[2023-08-29 14:05:16,990][02269] High loss value: l:392.5935 pl:-0.0502 vl:0.2374 exp_l:0.0000 kl_l:392.4062 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:16,991][02269] KL-divergence is very high: 73732.1328
[2023-08-29 14:05:17,216][02269] High loss value: l:491.7150 pl:-0.0504 vl:0.2494 exp_l:0.0000 kl_l:491.5160 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:17,216][02269] KL-divergence is very high: 78841.7734
[2023-08-29 14:05:17,219][02269] High loss value: l:383.3303 pl:-0.0517 vl:0.2651 exp_l:0.0000 kl_l:383.1169 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:17,219][02269] KL-divergence is very high: 59952.3672
[2023-08-29 14:05:17,223][02269] High loss value: l:88.8459 pl:-0.0495 vl:0.2582 exp_l:0.0000 kl_l:88.6372 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:17,223][02269] KL-divergence is very high: 12375.9150
[2023-08-29 14:05:17,226][02269] High loss value: l:102.3913 pl:-0.0499 vl:0.2623 exp_l:0.0000 kl_l:102.1789 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:17,227][02269] KL-divergence is very high: 16206.3242
[2023-08-29 14:05:17,230][02269] High loss value: l:126.6836 pl:-0.0494 vl:0.2647 exp_l:0.0000 kl_l:126.4683 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:17,230][02269] KL-divergence is very high: 27936.2832
[2023-08-29 14:05:17,233][02269] High loss value: l:52.2651 pl:-0.0502 vl:0.2682 exp_l:0.0000 kl_l:52.0472 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:17,233][02269] KL-divergence is very high: 13621.7549
[2023-08-29 14:05:17,237][02269] High loss value: l:408.2140 pl:-0.0472 vl:0.2550 exp_l:0.0000 kl_l:408.0062 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:17,237][02269] KL-divergence is very high: 59776.5391
[2023-08-29 14:05:17,438][02269] High loss value: l:189.2802 pl:-0.0516 vl:0.2637 exp_l:0.0000 kl_l:189.0681 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:17,438][02269] KL-divergence is very high: 25528.4727
[2023-08-29 14:05:17,441][02269] High loss value: l:56.8169 pl:-0.0469 vl:0.2728 exp_l:0.0000 kl_l:56.5909 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:17,441][02269] KL-divergence is very high: 7679.7427
[2023-08-29 14:05:17,444][02269] High loss value: l:377.9084 pl:-0.0503 vl:0.2879 exp_l:0.0000 kl_l:377.6709 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:17,444][02269] KL-divergence is very high: 84002.0156
[2023-08-29 14:05:17,448][02269] High loss value: l:501.4561 pl:-0.0468 vl:0.2693 exp_l:0.0000 kl_l:501.2336 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:17,448][02269] KL-divergence is very high: 116218.2422
[2023-08-29 14:05:17,451][02269] High loss value: l:60.3886 pl:-0.0425 vl:0.2632 exp_l:0.0000 kl_l:60.1679 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:17,451][02269] KL-divergence is very high: 24306.1602
[2023-08-29 14:05:17,454][02269] High loss value: l:758.8821 pl:-0.0323 vl:0.2647 exp_l:0.0000 kl_l:758.6497 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:17,454][02269] KL-divergence is very high: 103006.7812
[2023-08-29 14:05:17,458][02269] High loss value: l:1455.0745 pl:-0.0370 vl:0.2776 exp_l:0.0000 kl_l:1454.8339 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:17,458][02269] KL-divergence is very high: 204571.0000
[2023-08-29 14:05:17,462][02270] Updated weights for policy 0, policy_version 9376 (0.0003)
[2023-08-29 14:05:17,663][02257] Fps is (10 sec: 17202.7, 60 sec: 17544.5, 300 sec: 17612.7). Total num frames: 4800512. Throughput: 0: 17537.0. Samples: 4381442. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-29 14:05:17,663][02257] Avg episode reward: [(0, '-19021.244')]
[2023-08-29 14:05:17,687][02269] High loss value: l:520.5781 pl:-0.0492 vl:0.2589 exp_l:0.0000 kl_l:520.3685 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:17,688][02269] KL-divergence is very high: 84053.2109
[2023-08-29 14:05:17,691][02269] High loss value: l:725.3877 pl:-0.0500 vl:0.2562 exp_l:0.0000 kl_l:725.1815 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:17,691][02269] KL-divergence is very high: 118880.9297
[2023-08-29 14:05:17,694][02269] High loss value: l:234.8500 pl:-0.0519 vl:0.2589 exp_l:0.0000 kl_l:234.6430 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:17,694][02269] KL-divergence is very high: 38855.4688
[2023-08-29 14:05:17,699][02269] High loss value: l:141.6427 pl:-0.0495 vl:0.2736 exp_l:0.0000 kl_l:141.4186 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:17,699][02269] KL-divergence is very high: 28105.2832
[2023-08-29 14:05:17,702][02269] High loss value: l:388.3510 pl:-0.0478 vl:0.2632 exp_l:0.0000 kl_l:388.1356 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:17,703][02269] KL-divergence is very high: 71996.6875
[2023-08-29 14:05:17,706][02269] High loss value: l:127.9258 pl:-0.0463 vl:0.2624 exp_l:0.0000 kl_l:127.7096 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:17,706][02269] KL-divergence is very high: 26800.0352
[2023-08-29 14:05:17,710][02269] High loss value: l:170.4595 pl:-0.0497 vl:0.2671 exp_l:0.0000 kl_l:170.2422 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:17,710][02269] KL-divergence is very high: 31121.3457
[2023-08-29 14:05:17,913][02269] High loss value: l:376.0434 pl:-0.0472 vl:0.2560 exp_l:0.0000 kl_l:375.8346 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:17,913][02269] KL-divergence is very high: 62457.3047
[2023-08-29 14:05:17,916][02269] High loss value: l:461.7112 pl:-0.0490 vl:0.2492 exp_l:0.0000 kl_l:461.5111 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:17,916][02269] KL-divergence is very high: 78044.8125
[2023-08-29 14:05:17,919][02269] High loss value: l:90.7641 pl:-0.0385 vl:0.1402 exp_l:0.0000 kl_l:90.6625 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:17,919][02269] KL-divergence is very high: 12854.3477
[2023-08-29 14:05:17,923][02269] High loss value: l:368.9054 pl:-0.0466 vl:0.2681 exp_l:0.0000 kl_l:368.6839 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:17,923][02269] KL-divergence is very high: 57031.2617
[2023-08-29 14:05:17,926][02269] High loss value: l:762.7256 pl:-0.0468 vl:0.2687 exp_l:0.0000 kl_l:762.5037 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:17,926][02269] KL-divergence is very high: 120274.8203
[2023-08-29 14:05:17,930][02269] High loss value: l:411.8039 pl:-0.0468 vl:0.2548 exp_l:0.0000 kl_l:411.5959 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:17,930][02269] KL-divergence is very high: 64880.1094
[2023-08-29 14:05:17,933][02269] KL-divergence is very high: 1484.6018
[2023-08-29 14:05:18,136][02269] High loss value: l:306.2855 pl:0.0341 vl:0.0481 exp_l:0.0000 kl_l:306.2032 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:18,136][02269] KL-divergence is very high: 52264.1211
[2023-08-29 14:05:18,139][02269] High loss value: l:381.1845 pl:0.1138 vl:0.0620 exp_l:0.0000 kl_l:381.0086 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:18,139][02269] KL-divergence is very high: 64646.0078
[2023-08-29 14:05:18,142][02269] High loss value: l:60.6808 pl:0.1884 vl:0.1004 exp_l:0.0000 kl_l:60.3919 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:18,142][02269] KL-divergence is very high: 10505.3174
[2023-08-29 14:05:18,146][02269] High loss value: l:312.5222 pl:-0.0109 vl:0.0769 exp_l:0.0000 kl_l:312.4562 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:18,146][02269] KL-divergence is very high: 50160.9453
[2023-08-29 14:05:18,150][02269] High loss value: l:659.6641 pl:0.0337 vl:0.0487 exp_l:0.0000 kl_l:659.5818 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:18,150][02269] KL-divergence is very high: 107653.9766
[2023-08-29 14:05:18,153][02269] High loss value: l:383.9792 pl:0.1158 vl:0.0595 exp_l:0.0000 kl_l:383.8039 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:18,153][02269] KL-divergence is very high: 62011.5938
[2023-08-29 14:05:18,156][02269] KL-divergence is very high: 571.9940
[2023-08-29 14:05:18,355][02269] High loss value: l:1682.5554 pl:-0.0113 vl:0.0689 exp_l:0.0000 kl_l:1682.4977 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:18,355][02269] KL-divergence is very high: 281535.2188
[2023-08-29 14:05:18,358][02269] High loss value: l:4146.8945 pl:-0.0366 vl:0.1037 exp_l:0.0000 kl_l:4146.8276 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:18,358][02269] KL-divergence is very high: 682389.0625
[2023-08-29 14:05:18,361][02269] High loss value: l:5073.3965 pl:-0.0389 vl:0.1993 exp_l:0.0000 kl_l:5073.2363 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:18,361][02269] KL-divergence is very high: 835149.6250
[2023-08-29 14:05:18,365][02269] High loss value: l:4087.7625 pl:0.0965 vl:0.0754 exp_l:0.0000 kl_l:4087.5906 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:18,365][02269] KL-divergence is very high: 661120.9375
[2023-08-29 14:05:18,368][02269] High loss value: l:1797.2958 pl:-0.0120 vl:0.0753 exp_l:0.0000 kl_l:1797.2324 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:18,368][02269] KL-divergence is very high: 298603.9062
[2023-08-29 14:05:18,372][02269] High loss value: l:171.9984 pl:-0.0361 vl:0.1271 exp_l:0.0000 kl_l:171.9074 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:18,372][02269] KL-divergence is very high: 24753.3027
[2023-08-29 14:05:18,376][02269] High loss value: l:1035.6160 pl:-0.0463 vl:0.2403 exp_l:0.0000 kl_l:1035.4220 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:18,376][02269] KL-divergence is very high: 158499.2500
[2023-08-29 14:05:18,582][02269] KL-divergence is very high: 4334.1113
[2023-08-29 14:05:18,585][02269] KL-divergence is very high: 119.9567
[2023-08-29 14:05:18,588][02269] High loss value: l:126.8708 pl:-0.0519 vl:0.4685 exp_l:0.0000 kl_l:126.4543 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:18,588][02269] KL-divergence is very high: 20350.4004
[2023-08-29 14:05:18,591][02269] High loss value: l:180.9191 pl:-0.0456 vl:0.3320 exp_l:0.0000 kl_l:180.6327 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:18,591][02269] KL-divergence is very high: 26344.1797
[2023-08-29 14:05:18,594][02269] High loss value: l:52.2748 pl:-0.0484 vl:0.4396 exp_l:0.0000 kl_l:51.8836 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:18,595][02269] KL-divergence is very high: 6326.2422
[2023-08-29 14:05:18,597][02269] High loss value: l:103.1346 pl:-0.0523 vl:0.4886 exp_l:0.0000 kl_l:102.6982 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:18,598][02269] KL-divergence is very high: 16631.4629
[2023-08-29 14:05:18,601][02269] High loss value: l:199.0722 pl:-0.0507 vl:0.5008 exp_l:0.0000 kl_l:198.6220 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:18,602][02269] KL-divergence is very high: 33114.5977
[2023-08-29 14:05:18,858][02269] High loss value: l:84.2581 pl:-0.0526 vl:0.5158 exp_l:0.0000 kl_l:83.7948 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:18,858][02269] KL-divergence is very high: 13134.2461
[2023-08-29 14:05:18,861][02269] High loss value: l:105.1190 pl:-0.0525 vl:0.5299 exp_l:0.0000 kl_l:104.6416 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:18,861][02269] KL-divergence is very high: 15578.1387
[2023-08-29 14:05:18,864][02269] KL-divergence is very high: 2075.7217
[2023-08-29 14:05:18,868][02269] High loss value: l:81.1611 pl:-0.0514 vl:0.5252 exp_l:0.0000 kl_l:80.6873 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:18,868][02269] KL-divergence is very high: 14235.0186
[2023-08-29 14:05:18,871][02269] High loss value: l:167.7913 pl:-0.0524 vl:0.5320 exp_l:0.0000 kl_l:167.3117 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:18,871][02269] KL-divergence is very high: 29333.3828
[2023-08-29 14:05:18,875][02269] High loss value: l:93.7006 pl:-0.0521 vl:0.5351 exp_l:0.0000 kl_l:93.2175 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:18,875][02269] KL-divergence is very high: 16266.7832
[2023-08-29 14:05:18,879][02269] KL-divergence is very high: 612.9665
[2023-08-29 14:05:19,106][02269] High loss value: l:143.4451 pl:-0.0522 vl:0.5947 exp_l:0.0000 kl_l:142.9025 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:19,106][02269] KL-divergence is very high: 20228.3945
[2023-08-29 14:05:19,110][02269] High loss value: l:263.8923 pl:-0.0511 vl:0.6178 exp_l:0.0000 kl_l:263.3257 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:19,110][02269] KL-divergence is very high: 36057.2539
[2023-08-29 14:05:19,113][02269] High loss value: l:205.7218 pl:-0.0513 vl:0.6220 exp_l:0.0000 kl_l:205.1511 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:19,113][02269] KL-divergence is very high: 25632.9922
[2023-08-29 14:05:19,117][02269] High loss value: l:76.4154 pl:-0.0514 vl:0.6232 exp_l:0.0000 kl_l:75.8436 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:19,117][02269] KL-divergence is very high: 10614.7607
[2023-08-29 14:05:19,120][02269] High loss value: l:95.9235 pl:-0.0510 vl:0.6193 exp_l:0.0000 kl_l:95.3552 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:19,120][02269] KL-divergence is very high: 13292.2139
[2023-08-29 14:05:19,124][02269] High loss value: l:155.4202 pl:-0.0531 vl:0.5981 exp_l:0.0000 kl_l:154.8752 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:19,124][02269] KL-divergence is very high: 23675.0137
[2023-08-29 14:05:19,127][02269] High loss value: l:109.4649 pl:-0.0493 vl:0.5686 exp_l:0.0000 kl_l:108.9457 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:19,127][02269] KL-divergence is very high: 13524.7051
[2023-08-29 14:05:19,328][02269] High loss value: l:215.2463 pl:-0.0527 vl:0.5498 exp_l:0.0000 kl_l:214.7492 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:19,328][02269] KL-divergence is very high: 34468.6367
[2023-08-29 14:05:19,331][02269] High loss value: l:460.7997 pl:-0.0513 vl:0.5378 exp_l:0.0000 kl_l:460.3132 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:19,331][02269] KL-divergence is very high: 73829.7031
[2023-08-29 14:05:19,334][02269] High loss value: l:460.1409 pl:-0.0524 vl:0.5693 exp_l:0.0000 kl_l:459.6240 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:19,334][02269] KL-divergence is very high: 73199.2344
[2023-08-29 14:05:19,338][02269] High loss value: l:239.0587 pl:-0.0518 vl:0.5593 exp_l:0.0000 kl_l:238.5513 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:19,338][02269] KL-divergence is very high: 36906.3164
[2023-08-29 14:05:19,342][02269] KL-divergence is very high: 3044.0757
[2023-08-29 14:05:19,344][02269] High loss value: l:156.5869 pl:-0.0502 vl:0.5877 exp_l:0.0000 kl_l:156.0494 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:19,344][02269] KL-divergence is very high: 24929.6211
[2023-08-29 14:05:19,347][02269] High loss value: l:395.6743 pl:-0.0504 vl:0.6483 exp_l:0.0000 kl_l:395.0765 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:19,348][02269] KL-divergence is very high: 64310.9258
[2023-08-29 14:05:19,550][02269] KL-divergence is very high: 2970.4014
[2023-08-29 14:05:19,553][02269] High loss value: l:33.7955 pl:-0.0526 vl:0.7227 exp_l:0.0000 kl_l:33.1255 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:19,553][02269] KL-divergence is very high: 4044.8599
[2023-08-29 14:05:19,556][02269] KL-divergence is very high: 2293.2539
[2023-08-29 14:05:19,559][02269] KL-divergence is very high: 1528.1556
[2023-08-29 14:05:19,562][02269] KL-divergence is very high: 1341.7806
[2023-08-29 14:05:19,565][02269] KL-divergence is very high: 2142.8630
[2023-08-29 14:05:19,569][02269] KL-divergence is very high: 1065.0594
[2023-08-29 14:05:19,772][02269] KL-divergence is very high: 1510.8547
[2023-08-29 14:05:19,775][02269] KL-divergence is very high: 1581.3517
[2023-08-29 14:05:19,778][02269] KL-divergence is very high: 146.2796
[2023-08-29 14:05:19,782][02269] KL-divergence is very high: 2612.1406
[2023-08-29 14:05:19,785][02269] High loss value: l:38.4495 pl:-0.0482 vl:0.6743 exp_l:0.0000 kl_l:37.8234 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:19,785][02269] KL-divergence is very high: 5394.1118
[2023-08-29 14:05:19,789][02269] KL-divergence is very high: 3758.6990
[2023-08-29 14:05:19,792][02269] KL-divergence is very high: 415.7375
[2023-08-29 14:05:19,796][02270] Updated weights for policy 0, policy_version 9456 (0.0003)
[2023-08-29 14:05:20,030][02269] High loss value: l:60.3006 pl:-0.0513 vl:0.8328 exp_l:0.0000 kl_l:59.5191 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:20,030][02269] KL-divergence is very high: 7190.5381
[2023-08-29 14:05:20,034][02269] High loss value: l:132.7356 pl:-0.0515 vl:0.8555 exp_l:0.0000 kl_l:131.9316 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:20,034][02269] KL-divergence is very high: 16414.6465
[2023-08-29 14:05:20,038][02269] High loss value: l:142.4647 pl:-0.0520 vl:0.9013 exp_l:0.0000 kl_l:141.6154 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:20,038][02269] KL-divergence is very high: 17871.3398
[2023-08-29 14:05:20,041][02269] High loss value: l:90.9624 pl:-0.0512 vl:0.8822 exp_l:0.0000 kl_l:90.1315 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:20,041][02269] KL-divergence is very high: 12109.0244
[2023-08-29 14:05:20,045][02269] High loss value: l:38.7633 pl:-0.0531 vl:0.8497 exp_l:0.0000 kl_l:37.9667 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:20,045][02269] KL-divergence is very high: 4707.2217
[2023-08-29 14:05:20,049][02269] KL-divergence is very high: 3458.6038
[2023-08-29 14:05:20,052][02269] High loss value: l:32.5124 pl:-0.0436 vl:0.7760 exp_l:0.0000 kl_l:31.7800 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:20,052][02269] KL-divergence is very high: 3890.1707
[2023-08-29 14:05:20,267][02269] High loss value: l:44.4263 pl:-0.0530 vl:0.7416 exp_l:0.0000 kl_l:43.7377 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:20,267][02269] KL-divergence is very high: 7258.0649
[2023-08-29 14:05:20,271][02269] High loss value: l:84.8270 pl:-0.0518 vl:0.7331 exp_l:0.0000 kl_l:84.1456 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:20,271][02269] KL-divergence is very high: 13744.9482
[2023-08-29 14:05:20,275][02269] High loss value: l:64.5480 pl:-0.0503 vl:0.7136 exp_l:0.0000 kl_l:63.8846 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:20,275][02269] KL-divergence is very high: 10281.8594
[2023-08-29 14:05:20,279][02269] KL-divergence is very high: 2027.3120
[2023-08-29 14:05:20,282][02269] KL-divergence is very high: 2687.8794
[2023-08-29 14:05:20,285][02269] High loss value: l:49.4264 pl:-0.0504 vl:0.7745 exp_l:0.0000 kl_l:48.7022 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:20,286][02269] KL-divergence is very high: 8467.5020
[2023-08-29 14:05:20,290][02269] High loss value: l:40.4150 pl:-0.0485 vl:0.7705 exp_l:0.0000 kl_l:39.6930 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:20,290][02269] KL-divergence is very high: 7155.3364
[2023-08-29 14:05:20,504][02269] High loss value: l:35.3741 pl:-0.0522 vl:0.8082 exp_l:0.0000 kl_l:34.6181 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:20,504][02269] KL-divergence is very high: 5020.7842
[2023-08-29 14:05:20,507][02269] High loss value: l:70.3786 pl:-0.0512 vl:0.8265 exp_l:0.0000 kl_l:69.6033 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:20,507][02269] KL-divergence is very high: 9708.9092
[2023-08-29 14:05:20,511][02269] High loss value: l:59.9737 pl:-0.0517 vl:0.8193 exp_l:0.0000 kl_l:59.2061 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:20,511][02269] KL-divergence is very high: 7688.9600
[2023-08-29 14:05:20,514][02269] KL-divergence is very high: 2169.9265
[2023-08-29 14:05:20,518][02269] KL-divergence is very high: 1162.7036
[2023-08-29 14:05:20,520][02269] KL-divergence is very high: 3818.0767
[2023-08-29 14:05:20,523][02269] KL-divergence is very high: 3283.3643
[2023-08-29 14:05:21,046][02269] KL-divergence is very high: 4097.3809
[2023-08-29 14:05:21,050][02269] KL-divergence is very high: 7412.2759
[2023-08-29 14:05:21,056][02269] KL-divergence is very high: 3272.1499
[2023-08-29 14:05:21,059][02269] KL-divergence is very high: 275.7736
[2023-08-29 14:05:21,063][02269] KL-divergence is very high: 3976.3440
[2023-08-29 14:05:22,552][02270] Updated weights for policy 0, policy_version 9536 (0.0002)
[2023-08-29 14:05:22,662][02257] Fps is (10 sec: 16795.7, 60 sec: 17408.3, 300 sec: 17588.7). Total num frames: 4882432. Throughput: 0: 17389.8. Samples: 4481222. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-29 14:05:22,662][02257] Avg episode reward: [(0, '-39691.204')]
[2023-08-29 14:05:24,151][02269] KL-divergence is very high: 6866.9541
[2023-08-29 14:05:24,364][02269] KL-divergence is very high: 189.0965
[2023-08-29 14:05:24,367][02269] KL-divergence is very high: 331.8179
[2023-08-29 14:05:24,371][02269] KL-divergence is very high: 473.1398
[2023-08-29 14:05:24,373][02269] KL-divergence is very high: 970.7754
[2023-08-29 14:05:24,376][02269] KL-divergence is very high: 284.0141
[2023-08-29 14:05:24,379][02269] KL-divergence is very high: 2786.7534
[2023-08-29 14:05:24,382][02269] KL-divergence is very high: 4389.3628
[2023-08-29 14:05:24,622][02269] KL-divergence is very high: 4825.5503
[2023-08-29 14:05:24,625][02269] High loss value: l:30.4702 pl:0.0152 vl:0.0565 exp_l:0.0000 kl_l:30.3986 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:24,625][02269] KL-divergence is very high: 30281.1191
[2023-08-29 14:05:24,629][02269] KL-divergence is very high: 14106.5615
[2023-08-29 14:05:24,631][02269] KL-divergence is very high: 3556.4927
[2023-08-29 14:05:24,635][02269] KL-divergence is very high: 7255.5835
[2023-08-29 14:05:24,638][02269] KL-divergence is very high: 17607.6309
[2023-08-29 14:05:24,640][02269] KL-divergence is very high: 8962.6416
[2023-08-29 14:05:24,863][02270] Updated weights for policy 0, policy_version 9616 (0.0002)
[2023-08-29 14:05:26,043][02269] KL-divergence is very high: 3621.5627
[2023-08-29 14:05:26,046][02269] KL-divergence is very high: 2469.3547
[2023-08-29 14:05:26,049][02269] KL-divergence is very high: 2575.6992
[2023-08-29 14:05:26,052][02269] KL-divergence is very high: 7955.3716
[2023-08-29 14:05:26,056][02269] KL-divergence is very high: 880.5578
[2023-08-29 14:05:26,059][02269] KL-divergence is very high: 971.4490
[2023-08-29 14:05:26,063][02269] KL-divergence is very high: 7163.5176
[2023-08-29 14:05:26,291][02269] High loss value: l:51.0863 pl:-0.0470 vl:0.7724 exp_l:0.0000 kl_l:50.3609 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:26,292][02269] KL-divergence is very high: 84669.6562
[2023-08-29 14:05:26,295][02269] High loss value: l:50.7369 pl:-0.0340 vl:0.6219 exp_l:0.0000 kl_l:50.1490 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:05:26,295][02269] KL-divergence is very high: 115741.6484
[2023-08-29 14:05:26,298][02269] KL-divergence is very high: 15613.8662
[2023-08-29 14:05:26,301][02269] KL-divergence is very high: 18658.8184
[2023-08-29 14:05:26,304][02269] KL-divergence is very high: 48790.5703
[2023-08-29 14:05:26,307][02269] KL-divergence is very high: 13751.9131
[2023-08-29 14:05:26,310][02269] KL-divergence is very high: 8543.5195
[2023-08-29 14:05:26,549][02269] KL-divergence is very high: 1896.7792
[2023-08-29 14:05:26,559][02269] KL-divergence is very high: 4075.7878
[2023-08-29 14:05:26,561][02269] KL-divergence is very high: 751.1550
[2023-08-29 14:05:27,269][02270] Updated weights for policy 0, policy_version 9696 (0.0002)
[2023-08-29 14:05:27,663][02257] Fps is (10 sec: 16794.3, 60 sec: 17408.0, 300 sec: 17581.3). Total num frames: 4968448. Throughput: 0: 17219.1. Samples: 4584123. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2023-08-29 14:05:27,663][02257] Avg episode reward: [(0, '-39691.204')]
[2023-08-29 14:05:29,581][02270] Updated weights for policy 0, policy_version 9776 (0.0002)
[2023-08-29 14:05:31,990][02270] Updated weights for policy 0, policy_version 9856 (0.0002)
[2023-08-29 14:05:32,663][02257] Fps is (10 sec: 17201.6, 60 sec: 17339.6, 300 sec: 17574.1). Total num frames: 5054464. Throughput: 0: 17332.5. Samples: 4638059. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2023-08-29 14:05:32,663][02257] Avg episode reward: [(0, '-44431.631')]
[2023-08-29 14:05:34,252][02270] Updated weights for policy 0, policy_version 9936 (0.0002)
[2023-08-29 14:05:36,618][02270] Updated weights for policy 0, policy_version 10016 (0.0002)
[2023-08-29 14:05:37,663][02257] Fps is (10 sec: 17612.1, 60 sec: 17339.9, 300 sec: 17582.4). Total num frames: 5144576. Throughput: 0: 17221.8. Samples: 4741249. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-29 14:05:37,663][02257] Avg episode reward: [(0, '-44431.631')]
[2023-08-29 14:05:38,894][02270] Updated weights for policy 0, policy_version 10096 (0.0002)
[2023-08-29 14:05:41,431][02270] Updated weights for policy 0, policy_version 10176 (0.0002)
[2023-08-29 14:05:42,664][02257] Fps is (10 sec: 17610.7, 60 sec: 17271.1, 300 sec: 17575.4). Total num frames: 5230592. Throughput: 0: 17225.9. Samples: 4845554. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-29 14:05:42,664][02257] Avg episode reward: [(0, '-40006.113')]
[2023-08-29 14:05:43,513][02269] KL-divergence is very high: 538.7574
[2023-08-29 14:05:43,516][02269] KL-divergence is very high: 983.7418
[2023-08-29 14:05:43,519][02269] KL-divergence is very high: 525.2870
[2023-08-29 14:05:43,526][02269] KL-divergence is very high: 7335.5962
[2023-08-29 14:05:43,529][02269] KL-divergence is very high: 4546.9707
[2023-08-29 14:05:43,532][02269] KL-divergence is very high: 6680.5161
[2023-08-29 14:05:43,769][02269] KL-divergence is very high: 1349.5940
[2023-08-29 14:05:43,779][02270] Updated weights for policy 0, policy_version 10256 (0.0002)
[2023-08-29 14:05:46,149][02270] Updated weights for policy 0, policy_version 10336 (0.0002)
[2023-08-29 14:05:47,662][02257] Fps is (10 sec: 17205.7, 60 sec: 17340.1, 300 sec: 17568.9). Total num frames: 5316608. Throughput: 0: 17172.9. Samples: 4897444. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-29 14:05:47,662][02257] Avg episode reward: [(0, '-40006.113')]
[2023-08-29 14:05:48,421][02270] Updated weights for policy 0, policy_version 10416 (0.0002)
[2023-08-29 14:05:50,638][02269] KL-divergence is very high: 1691.7527
[2023-08-29 14:05:50,647][02269] KL-divergence is very high: 2053.0464
[2023-08-29 14:05:50,650][02269] KL-divergence is very high: 2561.4370
[2023-08-29 14:05:50,879][02269] KL-divergence is very high: 2242.7634
[2023-08-29 14:05:50,882][02269] KL-divergence is very high: 743.6378
[2023-08-29 14:05:50,885][02269] KL-divergence is very high: 459.2630
[2023-08-29 14:05:50,888][02269] KL-divergence is very high: 1253.5909
[2023-08-29 14:05:50,892][02269] KL-divergence is very high: 355.0304
[2023-08-29 14:05:50,894][02269] KL-divergence is very high: 160.7854
[2023-08-29 14:05:50,898][02269] KL-divergence is very high: 118.2320
[2023-08-29 14:05:50,900][02270] Updated weights for policy 0, policy_version 10496 (0.0002)
[2023-08-29 14:05:51,136][02269] KL-divergence is very high: 4122.2222
[2023-08-29 14:05:51,139][02269] KL-divergence is very high: 272.7761
[2023-08-29 14:05:51,374][02269] KL-divergence is very high: 627.3469
[2023-08-29 14:05:51,377][02269] KL-divergence is very high: 4086.2092
[2023-08-29 14:05:51,380][02269] KL-divergence is very high: 207.8328
[2023-08-29 14:05:51,383][02269] KL-divergence is very high: 117.1795
[2023-08-29 14:05:51,386][02269] KL-divergence is very high: 39908.9961
[2023-08-29 14:05:51,389][02269] KL-divergence is very high: 39271.3320
[2023-08-29 14:05:51,392][02269] KL-divergence is very high: 867.4716
[2023-08-29 14:05:51,596][02269] KL-divergence is very high: 1475.5148
[2023-08-29 14:05:51,601][02269] KL-divergence is very high: 3700.8511
[2023-08-29 14:05:51,604][02269] KL-divergence is very high: 317.2466
[2023-08-29 14:05:51,607][02269] KL-divergence is very high: 490.4350
[2023-08-29 14:05:51,613][02269] KL-divergence is very high: 5344.4854
[2023-08-29 14:05:51,845][02269] KL-divergence is very high: 225.5555
[2023-08-29 14:05:51,848][02269] KL-divergence is very high: 908.0386
[2023-08-29 14:05:51,851][02269] KL-divergence is very high: 735.7924
[2023-08-29 14:05:51,854][02269] KL-divergence is very high: 423.7685
[2023-08-29 14:05:51,857][02269] KL-divergence is very high: 243.7964
[2023-08-29 14:05:51,861][02269] KL-divergence is very high: 4935.4199
[2023-08-29 14:05:51,864][02269] KL-divergence is very high: 4497.6519
[2023-08-29 14:05:52,092][02269] KL-divergence is very high: 235.7561
[2023-08-29 14:05:52,095][02269] KL-divergence is very high: 503.3214
[2023-08-29 14:05:52,100][02269] KL-divergence is very high: 226.3194
[2023-08-29 14:05:52,103][02269] KL-divergence is very high: 208.9021
[2023-08-29 14:05:52,106][02269] KL-divergence is very high: 680.1140
[2023-08-29 14:05:52,110][02269] KL-divergence is very high: 4948.4302
[2023-08-29 14:05:52,338][02269] KL-divergence is very high: 449.7518
[2023-08-29 14:05:52,347][02269] KL-divergence is very high: 18386.6562
[2023-08-29 14:05:52,350][02269] KL-divergence is very high: 320.9675
[2023-08-29 14:05:52,353][02269] KL-divergence is very high: 789.4053
[2023-08-29 14:05:52,663][02257] Fps is (10 sec: 17205.0, 60 sec: 17203.2, 300 sec: 17562.4). Total num frames: 5402624. Throughput: 0: 17196.4. Samples: 5000931. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-29 14:05:52,663][02257] Avg episode reward: [(0, '-36670.979')]
[2023-08-29 14:05:53,309][02270] Updated weights for policy 0, policy_version 10576 (0.0002)
[2023-08-29 14:05:55,609][02270] Updated weights for policy 0, policy_version 10656 (0.0002)
[2023-08-29 14:05:57,663][02257] Fps is (10 sec: 17201.5, 60 sec: 17203.3, 300 sec: 17556.3). Total num frames: 5488640. Throughput: 0: 17266.1. Samples: 5105675. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-29 14:05:57,663][02257] Avg episode reward: [(0, '-36670.979')]
[2023-08-29 14:05:58,038][02270] Updated weights for policy 0, policy_version 10736 (0.0002)
[2023-08-29 14:06:00,479][02270] Updated weights for policy 0, policy_version 10816 (0.0002)
[2023-08-29 14:06:02,663][02257] Fps is (10 sec: 17202.9, 60 sec: 17202.7, 300 sec: 17550.3). Total num frames: 5574656. Throughput: 0: 17181.3. Samples: 5154600. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-29 14:06:02,663][02257] Avg episode reward: [(0, '-38262.171')]
[2023-08-29 14:06:02,666][02269] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000010888_5574656.pth...
[2023-08-29 14:06:02,668][02269] Removing /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000004072_2084864.pth
[2023-08-29 14:06:02,764][02270] Updated weights for policy 0, policy_version 10896 (0.0002)
[2023-08-29 14:06:05,056][02269] KL-divergence is very high: 1594.0121
[2023-08-29 14:06:05,058][02269] KL-divergence is very high: 117.0337
[2023-08-29 14:06:05,063][02270] Updated weights for policy 0, policy_version 10976 (0.0002)
[2023-08-29 14:06:05,286][02269] KL-divergence is very high: 156.2416
[2023-08-29 14:06:05,289][02269] KL-divergence is very high: 147.0213
[2023-08-29 14:06:05,768][02269] KL-divergence is very high: 314.9628
[2023-08-29 14:06:05,771][02269] KL-divergence is very high: 1210.6757
[2023-08-29 14:06:05,773][02269] KL-divergence is very high: 4230.5752
[2023-08-29 14:06:05,779][02269] KL-divergence is very high: 339.8400
[2023-08-29 14:06:05,782][02269] KL-divergence is very high: 1726.4797
[2023-08-29 14:06:06,008][02269] KL-divergence is very high: 270.1195
[2023-08-29 14:06:06,014][02269] KL-divergence is very high: 210.6634
[2023-08-29 14:06:06,020][02269] KL-divergence is very high: 3323.1047
[2023-08-29 14:06:06,026][02269] KL-divergence is very high: 3754.5769
[2023-08-29 14:06:06,255][02269] KL-divergence is very high: 486.4020
[2023-08-29 14:06:06,257][02269] KL-divergence is very high: 607.6324
[2023-08-29 14:06:06,260][02269] KL-divergence is very high: 489.9193
[2023-08-29 14:06:06,263][02269] KL-divergence is very high: 273.1667
[2023-08-29 14:06:06,266][02269] KL-divergence is very high: 1102.9561
[2023-08-29 14:06:06,269][02269] KL-divergence is very high: 410.6522
[2023-08-29 14:06:06,272][02269] KL-divergence is very high: 1023.3153
[2023-08-29 14:06:06,473][02269] KL-divergence is very high: 658.5802
[2023-08-29 14:06:06,476][02269] KL-divergence is very high: 206.7787
[2023-08-29 14:06:06,482][02269] KL-divergence is very high: 2414.4373
[2023-08-29 14:06:06,485][02269] KL-divergence is very high: 383.6399
[2023-08-29 14:06:06,488][02269] KL-divergence is very high: 411.8894
[2023-08-29 14:06:07,619][02270] Updated weights for policy 0, policy_version 11056 (0.0002)
[2023-08-29 14:06:07,663][02257] Fps is (10 sec: 17202.4, 60 sec: 17203.1, 300 sec: 17536.4). Total num frames: 5660672. Throughput: 0: 17312.3. Samples: 5260295. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2023-08-29 14:06:07,663][02257] Avg episode reward: [(0, '-38341.907')]
[2023-08-29 14:06:09,808][02270] Updated weights for policy 0, policy_version 11136 (0.0002)
[2023-08-29 14:06:12,045][02270] Updated weights for policy 0, policy_version 11216 (0.0002)
[2023-08-29 14:06:12,663][02257] Fps is (10 sec: 17613.1, 60 sec: 17271.5, 300 sec: 17536.4). Total num frames: 5750784. Throughput: 0: 17385.4. Samples: 5366471. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2023-08-29 14:06:12,663][02257] Avg episode reward: [(0, '-38341.907')]
[2023-08-29 14:06:14,299][02270] Updated weights for policy 0, policy_version 11296 (0.0002)
[2023-08-29 14:06:16,608][02269] KL-divergence is very high: 124.6645
[2023-08-29 14:06:16,611][02269] KL-divergence is very high: 349.3945
[2023-08-29 14:06:16,846][02269] KL-divergence is very high: 135.4873
[2023-08-29 14:06:16,851][02269] KL-divergence is very high: 243.1500
[2023-08-29 14:06:16,854][02269] KL-divergence is very high: 336.1958
[2023-08-29 14:06:16,857][02269] KL-divergence is very high: 601.9877
[2023-08-29 14:06:16,860][02270] Updated weights for policy 0, policy_version 11376 (0.0002)
[2023-08-29 14:06:17,064][02269] KL-divergence is very high: 16280.6299
[2023-08-29 14:06:17,663][02257] Fps is (10 sec: 17613.1, 60 sec: 17271.5, 300 sec: 17522.5). Total num frames: 5836800. Throughput: 0: 17394.0. Samples: 5420791. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[2023-08-29 14:06:17,663][02257] Avg episode reward: [(0, '-27851.606')]
[2023-08-29 14:06:19,108][02270] Updated weights for policy 0, policy_version 11456 (0.0002)
[2023-08-29 14:06:21,360][02269] KL-divergence is very high: 126.2598
[2023-08-29 14:06:21,362][02269] KL-divergence is very high: 190.4182
[2023-08-29 14:06:21,364][02270] Updated weights for policy 0, policy_version 11536 (0.0002)
[2023-08-29 14:06:22,664][02257] Fps is (10 sec: 17610.5, 60 sec: 17407.3, 300 sec: 17536.3). Total num frames: 5926912. Throughput: 0: 17403.5. Samples: 5524428. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[2023-08-29 14:06:22,665][02257] Avg episode reward: [(0, '-27851.606')]
[2023-08-29 14:06:23,638][02270] Updated weights for policy 0, policy_version 11616 (0.0002)
[2023-08-29 14:06:26,160][02270] Updated weights for policy 0, policy_version 11696 (0.0002)
[2023-08-29 14:06:27,663][02257] Fps is (10 sec: 17612.9, 60 sec: 17407.9, 300 sec: 17550.3). Total num frames: 6012928. Throughput: 0: 17397.1. Samples: 5628401. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-29 14:06:27,663][02257] Avg episode reward: [(0, '-18064.830')]
[2023-08-29 14:06:28,433][02270] Updated weights for policy 0, policy_version 11776 (0.0002)
[2023-08-29 14:06:30,761][02270] Updated weights for policy 0, policy_version 11856 (0.0002)
[2023-08-29 14:06:32,661][02257] Fps is (10 sec: 17618.2, 60 sec: 17476.8, 300 sec: 17564.4). Total num frames: 6103040. Throughput: 0: 17428.1. Samples: 5681702. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-29 14:06:32,661][02257] Avg episode reward: [(0, '-18064.830')]
[2023-08-29 14:06:32,996][02270] Updated weights for policy 0, policy_version 11936 (0.0002)
[2023-08-29 14:06:33,199][02269] KL-divergence is very high: 721.5854
[2023-08-29 14:06:33,211][02269] KL-divergence is very high: 323.6070
[2023-08-29 14:06:33,456][02269] KL-divergence is very high: 15349.9951
[2023-08-29 14:06:33,459][02269] KL-divergence is very high: 187.5093
[2023-08-29 14:06:33,465][02269] KL-divergence is very high: 67620.2734
[2023-08-29 14:06:33,469][02269] KL-divergence is very high: 2091.6724
[2023-08-29 14:06:33,472][02269] KL-divergence is very high: 912.6551
[2023-08-29 14:06:33,475][02269] KL-divergence is very high: 763.2825
[2023-08-29 14:06:33,712][02269] KL-divergence is very high: 244.7830
[2023-08-29 14:06:35,529][02270] Updated weights for policy 0, policy_version 12016 (0.0002)
[2023-08-29 14:06:37,663][02257] Fps is (10 sec: 17612.8, 60 sec: 17408.1, 300 sec: 17550.4). Total num frames: 6189056. Throughput: 0: 17434.6. Samples: 5785487. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-29 14:06:37,663][02257] Avg episode reward: [(0, '-15772.698')]
[2023-08-29 14:06:37,799][02270] Updated weights for policy 0, policy_version 12096 (0.0002)
[2023-08-29 14:06:39,183][02269] KL-divergence is very high: 1813.7976
[2023-08-29 14:06:40,153][02270] Updated weights for policy 0, policy_version 12176 (0.0002)
[2023-08-29 14:06:41,964][02269] KL-divergence is very high: 199.1216
[2023-08-29 14:06:42,426][02270] Updated weights for policy 0, policy_version 12256 (0.0002)
[2023-08-29 14:06:42,663][02257] Fps is (10 sec: 17200.3, 60 sec: 17408.3, 300 sec: 17536.4). Total num frames: 6275072. Throughput: 0: 17481.1. Samples: 5892330. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-29 14:06:42,663][02257] Avg episode reward: [(0, '-15772.698')]
[2023-08-29 14:06:42,896][02269] KL-divergence is very high: 297.5592
[2023-08-29 14:06:42,907][02269] KL-divergence is very high: 4158.7368
[2023-08-29 14:06:42,910][02269] KL-divergence is very high: 4899.7329
[2023-08-29 14:06:44,992][02270] Updated weights for policy 0, policy_version 12336 (0.0002)
[2023-08-29 14:06:47,286][02270] Updated weights for policy 0, policy_version 12416 (0.0002)
[2023-08-29 14:06:47,663][02257] Fps is (10 sec: 17203.0, 60 sec: 17407.6, 300 sec: 17536.5). Total num frames: 6361088. Throughput: 0: 17476.7. Samples: 5941048. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-29 14:06:47,663][02257] Avg episode reward: [(0, '-16113.299')]
[2023-08-29 14:06:49,587][02270] Updated weights for policy 0, policy_version 12496 (0.0002)
[2023-08-29 14:06:51,801][02270] Updated weights for policy 0, policy_version 12576 (0.0002)
[2023-08-29 14:06:52,664][02257] Fps is (10 sec: 17611.1, 60 sec: 17476.0, 300 sec: 17522.5). Total num frames: 6451200. Throughput: 0: 17522.7. Samples: 6048830. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-29 14:06:52,664][02257] Avg episode reward: [(0, '-16113.299')]
[2023-08-29 14:06:54,295][02270] Updated weights for policy 0, policy_version 12656 (0.0002)
[2023-08-29 14:06:54,959][02269] KL-divergence is very high: 89644.3750
[2023-08-29 14:06:54,970][02269] KL-divergence is very high: 32709.2246
[2023-08-29 14:06:55,194][02269] High loss value: l:164.7911 pl:-0.0365 vl:0.0629 exp_l:0.0000 kl_l:164.7647 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:06:55,194][02269] KL-divergence is very high: 92527.7812
[2023-08-29 14:06:55,198][02269] High loss value: l:137.3851 pl:-0.0224 vl:0.0876 exp_l:0.0000 kl_l:137.3199 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:06:55,198][02269] KL-divergence is very high: 122388.8047
[2023-08-29 14:06:55,204][02269] KL-divergence is very high: 5294.3330
[2023-08-29 14:06:55,207][02269] High loss value: l:168.6167 pl:-0.0365 vl:0.0482 exp_l:0.0000 kl_l:168.6050 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:06:55,207][02269] KL-divergence is very high: 97483.3750
[2023-08-29 14:06:55,210][02269] High loss value: l:184.1619 pl:-0.0189 vl:0.0654 exp_l:0.0000 kl_l:184.1154 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:06:55,211][02269] KL-divergence is very high: 173441.2031
[2023-08-29 14:06:55,880][02269] KL-divergence is very high: 597.7069
[2023-08-29 14:06:55,882][02269] KL-divergence is very high: 1919.9673
[2023-08-29 14:06:56,596][02270] Updated weights for policy 0, policy_version 12736 (0.0002)
[2023-08-29 14:06:56,826][02269] KL-divergence is very high: 2237.6328
[2023-08-29 14:06:56,829][02269] High loss value: l:39.9232 pl:0.0756 vl:0.0840 exp_l:0.0000 kl_l:39.7637 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:06:56,829][02269] KL-divergence is very high: 49821.8438
[2023-08-29 14:06:56,833][02269] KL-divergence is very high: 398.5371
[2023-08-29 14:06:56,836][02269] KL-divergence is very high: 37347.6523
[2023-08-29 14:06:56,839][02269] KL-divergence is very high: 9141.2197
[2023-08-29 14:06:56,842][02269] High loss value: l:86.2796 pl:0.0716 vl:0.0931 exp_l:0.0000 kl_l:86.1149 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:06:56,842][02269] KL-divergence is very high: 107826.1016
[2023-08-29 14:06:56,846][02269] KL-divergence is very high: 443.9901
[2023-08-29 14:06:57,056][02269] High loss value: l:3065.8691 pl:0.1120 vl:0.0938 exp_l:0.0000 kl_l:3065.6633 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:06:57,056][02269] KL-divergence is very high: 2641372.2500
[2023-08-29 14:06:57,304][02269] KL-divergence is very high: 319.9493
[2023-08-29 14:06:57,309][02269] KL-divergence is very high: 103.0979
[2023-08-29 14:06:57,546][02269] KL-divergence is very high: 690.9847
[2023-08-29 14:06:57,555][02269] KL-divergence is very high: 5081.0034
[2023-08-29 14:06:57,558][02269] KL-divergence is very high: 690.0901
[2023-08-29 14:06:57,663][02257] Fps is (10 sec: 17613.0, 60 sec: 17476.2, 300 sec: 17522.5). Total num frames: 6537216. Throughput: 0: 17465.9. Samples: 6152436. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-29 14:06:57,663][02257] Avg episode reward: [(0, '-17080.361')]
[2023-08-29 14:06:58,936][02270] Updated weights for policy 0, policy_version 12816 (0.0002)
[2023-08-29 14:07:01,187][02270] Updated weights for policy 0, policy_version 12896 (0.0002)
[2023-08-29 14:07:02,662][02257] Fps is (10 sec: 17206.2, 60 sec: 17476.6, 300 sec: 17494.8). Total num frames: 6623232. Throughput: 0: 17447.7. Samples: 6205923. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-29 14:07:02,662][02257] Avg episode reward: [(0, '-18930.824')]
[2023-08-29 14:07:02,840][02269] KL-divergence is very high: 539.4114
[2023-08-29 14:07:02,843][02269] KL-divergence is very high: 336.8919
[2023-08-29 14:07:02,849][02269] KL-divergence is very high: 2046.6466
[2023-08-29 14:07:02,853][02269] KL-divergence is very high: 1794.8438
[2023-08-29 14:07:02,855][02269] KL-divergence is very high: 214.1741
[2023-08-29 14:07:03,086][02269] High loss value: l:34.8308 pl:0.0145 vl:0.0605 exp_l:0.0000 kl_l:34.7558 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:03,086][02269] KL-divergence is very high: 26076.2812
[2023-08-29 14:07:03,089][02269] High loss value: l:37.2824 pl:-0.0370 vl:0.0614 exp_l:0.0000 kl_l:37.2581 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:03,089][02269] KL-divergence is very high: 9821.2822
[2023-08-29 14:07:03,098][02269] High loss value: l:167.5012 pl:0.0192 vl:0.0562 exp_l:0.0000 kl_l:167.4258 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:03,099][02269] KL-divergence is very high: 135771.3750
[2023-08-29 14:07:03,102][02269] High loss value: l:285.8097 pl:-0.0350 vl:0.0660 exp_l:0.0000 kl_l:285.7788 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:03,102][02269] KL-divergence is very high: 102851.6875
[2023-08-29 14:07:03,304][02269] KL-divergence is very high: 238.4485
[2023-08-29 14:07:03,309][02269] High loss value: l:849.9264 pl:-0.0377 vl:0.1064 exp_l:0.0000 kl_l:849.8576 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:03,309][02269] KL-divergence is very high: 362773.9062
[2023-08-29 14:07:03,556][02269] KL-divergence is very high: 9096.1494
[2023-08-29 14:07:03,564][02269] KL-divergence is very high: 3991.4880
[2023-08-29 14:07:03,568][02269] KL-divergence is very high: 4965.2886
[2023-08-29 14:07:03,779][02269] KL-divergence is very high: 273.7988
[2023-08-29 14:07:03,784][02269] KL-divergence is very high: 137.2400
[2023-08-29 14:07:03,791][02269] KL-divergence is very high: 213.7540
[2023-08-29 14:07:03,794][02270] Updated weights for policy 0, policy_version 12976 (0.0002)
[2023-08-29 14:07:04,022][02269] KL-divergence is very high: 1371.1837
[2023-08-29 14:07:04,031][02269] KL-divergence is very high: 3347.8457
[2023-08-29 14:07:04,034][02269] KL-divergence is very high: 1098.4897
[2023-08-29 14:07:04,264][02269] KL-divergence is very high: 141.2015
[2023-08-29 14:07:04,267][02269] KL-divergence is very high: 131.1198
[2023-08-29 14:07:04,269][02269] KL-divergence is very high: 501.8257
[2023-08-29 14:07:04,273][02269] KL-divergence is very high: 11334.7314
[2023-08-29 14:07:04,275][02269] KL-divergence is very high: 425.7415
[2023-08-29 14:07:04,278][02269] KL-divergence is very high: 949.5765
[2023-08-29 14:07:04,281][02269] KL-divergence is very high: 189.5012
[2023-08-29 14:07:04,493][02269] KL-divergence is very high: 121.9795
[2023-08-29 14:07:05,408][02269] KL-divergence is very high: 137.8764
[2023-08-29 14:07:05,643][02269] KL-divergence is very high: 418.8350
[2023-08-29 14:07:05,655][02269] KL-divergence is very high: 3033.9993
[2023-08-29 14:07:05,857][02269] High loss value: l:34.7866 pl:0.0690 vl:1.2742 exp_l:0.0000 kl_l:33.4434 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:05,857][02269] KL-divergence is very high: 19325.3965
[2023-08-29 14:07:05,861][02269] High loss value: l:62.3977 pl:0.0365 vl:0.9415 exp_l:0.0000 kl_l:61.4197 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:05,861][02269] KL-divergence is very high: 35836.7773
[2023-08-29 14:07:05,864][02269] High loss value: l:31.6173 pl:0.0920 vl:1.0934 exp_l:0.0000 kl_l:30.4319 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:05,864][02269] KL-divergence is very high: 14227.4150
[2023-08-29 14:07:05,868][02269] KL-divergence is very high: 818.2848
[2023-08-29 14:07:05,871][02269] High loss value: l:30.7259 pl:0.1180 vl:1.2610 exp_l:0.0000 kl_l:29.3468 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:05,871][02269] KL-divergence is very high: 21264.0996
[2023-08-29 14:07:05,875][02269] High loss value: l:36.3598 pl:0.0628 vl:1.0219 exp_l:0.0000 kl_l:35.2751 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:05,875][02269] KL-divergence is very high: 21311.1543
[2023-08-29 14:07:05,879][02269] KL-divergence is very high: 10214.6143
[2023-08-29 14:07:06,107][02269] KL-divergence is very high: 17502.9922
[2023-08-29 14:07:06,110][02269] High loss value: l:93.5536 pl:0.1219 vl:0.8442 exp_l:0.0000 kl_l:92.5876 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:06,110][02269] KL-divergence is very high: 64499.6367
[2023-08-29 14:07:06,114][02269] High loss value: l:120.2519 pl:0.1543 vl:0.7588 exp_l:0.0000 kl_l:119.3387 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:06,114][02269] KL-divergence is very high: 33409.0469
[2023-08-29 14:07:06,118][02269] KL-divergence is very high: 4861.8867
[2023-08-29 14:07:06,121][02269] KL-divergence is very high: 18893.2344
[2023-08-29 14:07:06,124][02269] KL-divergence is very high: 21028.2617
[2023-08-29 14:07:06,127][02269] High loss value: l:83.8711 pl:0.1969 vl:0.7651 exp_l:0.0000 kl_l:82.9091 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:06,127][02269] KL-divergence is very high: 25757.6465
[2023-08-29 14:07:06,131][02270] Updated weights for policy 0, policy_version 13056 (0.0002)
[2023-08-29 14:07:06,348][02269] KL-divergence is very high: 1382.5269
[2023-08-29 14:07:06,351][02269] High loss value: l:298.7619 pl:0.1694 vl:0.6379 exp_l:0.0000 kl_l:297.9545 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:06,352][02269] KL-divergence is very high: 167967.8750
[2023-08-29 14:07:06,355][02269] KL-divergence is very high: 21203.2090
[2023-08-29 14:07:06,359][02269] KL-divergence is very high: 71016.2109
[2023-08-29 14:07:06,362][02269] High loss value: l:97.9786 pl:0.0926 vl:0.8769 exp_l:0.0000 kl_l:97.0090 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:06,362][02269] KL-divergence is very high: 29494.3672
[2023-08-29 14:07:06,366][02269] High loss value: l:219.0503 pl:0.1846 vl:0.6363 exp_l:0.0000 kl_l:218.2295 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:06,366][02269] KL-divergence is very high: 121232.0625
[2023-08-29 14:07:06,369][02269] KL-divergence is very high: 16684.8262
[2023-08-29 14:07:06,372][02269] High loss value: l:33.5318 pl:0.1241 vl:0.7968 exp_l:0.0000 kl_l:32.6109 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:06,372][02269] KL-divergence is very high: 48938.6172
[2023-08-29 14:07:06,570][02269] KL-divergence is very high: 367.7357
[2023-08-29 14:07:06,572][02269] High loss value: l:132.9310 pl:0.0878 vl:1.1324 exp_l:0.0000 kl_l:131.7109 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:06,573][02269] KL-divergence is very high: 94396.5703
[2023-08-29 14:07:06,576][02269] High loss value: l:1166.8885 pl:0.0600 vl:1.1791 exp_l:0.0000 kl_l:1165.6494 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:06,576][02269] KL-divergence is very high: 426876.6875
[2023-08-29 14:07:06,580][02269] High loss value: l:337.7818 pl:0.0625 vl:1.0289 exp_l:0.0000 kl_l:336.6904 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:06,580][02269] KL-divergence is very high: 136059.0938
[2023-08-29 14:07:06,584][02269] High loss value: l:138.8877 pl:0.0949 vl:0.9334 exp_l:0.0000 kl_l:137.8594 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:06,584][02269] KL-divergence is very high: 64019.6523
[2023-08-29 14:07:06,587][02269] High loss value: l:225.3700 pl:0.1152 vl:1.1385 exp_l:0.0000 kl_l:224.1164 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:06,587][02269] KL-divergence is very high: 148473.0625
[2023-08-29 14:07:06,591][02269] High loss value: l:892.6998 pl:0.0633 vl:1.1802 exp_l:0.0000 kl_l:891.4562 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:06,591][02269] KL-divergence is very high: 273686.5000
[2023-08-29 14:07:06,595][02269] High loss value: l:94.9040 pl:0.0798 vl:1.0364 exp_l:0.0000 kl_l:93.7878 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:06,595][02269] KL-divergence is very high: 17658.8145
[2023-08-29 14:07:06,791][02269] KL-divergence is very high: 2093.5837
[2023-08-29 14:07:06,794][02269] High loss value: l:3365.5706 pl:0.0723 vl:1.0387 exp_l:0.0000 kl_l:3364.4595 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:06,794][02269] KL-divergence is very high: 608616.3125
[2023-08-29 14:07:06,797][02269] High loss value: l:5318.1729 pl:0.0746 vl:1.0676 exp_l:0.0000 kl_l:5317.0308 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:06,797][02269] KL-divergence is very high: 1168715.0000
[2023-08-29 14:07:06,801][02269] High loss value: l:3603.8770 pl:0.0214 vl:0.9806 exp_l:0.0000 kl_l:3602.8750 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:06,801][02269] KL-divergence is very high: 884923.5625
[2023-08-29 14:07:06,805][02269] High loss value: l:1718.3949 pl:0.1060 vl:0.8262 exp_l:0.0000 kl_l:1717.4628 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:06,805][02269] KL-divergence is very high: 354954.1250
[2023-08-29 14:07:06,808][02269] High loss value: l:126.0949 pl:0.0609 vl:1.0468 exp_l:0.0000 kl_l:124.9872 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:06,808][02269] KL-divergence is very high: 15345.3896
[2023-08-29 14:07:06,812][02269] High loss value: l:1468.2153 pl:0.0657 vl:1.0728 exp_l:0.0000 kl_l:1467.0768 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:06,812][02269] KL-divergence is very high: 287958.4688
[2023-08-29 14:07:06,816][02269] High loss value: l:1635.3838 pl:0.0120 vl:0.9911 exp_l:0.0000 kl_l:1634.3807 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:06,816][02269] KL-divergence is very high: 358372.6562
[2023-08-29 14:07:07,021][02269] KL-divergence is very high: 648.0622
[2023-08-29 14:07:07,024][02269] High loss value: l:658.9745 pl:-0.0181 vl:0.7718 exp_l:0.0000 kl_l:658.2208 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:07,024][02269] KL-divergence is very high: 245909.5000
[2023-08-29 14:07:07,027][02269] High loss value: l:112.8800 pl:0.0439 vl:1.9222 exp_l:0.0000 kl_l:110.9138 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:07,027][02269] KL-divergence is very high: 304862.6562
[2023-08-29 14:07:07,033][02269] High loss value: l:205.0291 pl:-0.0261 vl:0.6743 exp_l:0.0000 kl_l:204.3809 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:07,034][02269] KL-divergence is very high: 54814.1719
[2023-08-29 14:07:07,037][02269] High loss value: l:142.3768 pl:0.0043 vl:0.7517 exp_l:0.0000 kl_l:141.6208 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:07,037][02269] KL-divergence is very high: 50905.2500
[2023-08-29 14:07:07,041][02269] High loss value: l:36.1428 pl:0.0671 vl:1.8375 exp_l:0.0000 kl_l:34.2381 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:07,041][02269] KL-divergence is very high: 88889.1016
[2023-08-29 14:07:07,270][02269] High loss value: l:37.4102 pl:0.0203 vl:1.1593 exp_l:0.0000 kl_l:36.2307 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:07,270][02269] KL-divergence is very high: 17580.2891
[2023-08-29 14:07:07,274][02269] KL-divergence is very high: 325.2848
[2023-08-29 14:07:07,279][02269] KL-divergence is very high: 1780.2581
[2023-08-29 14:07:07,283][02269] High loss value: l:48.7619 pl:0.0532 vl:1.0089 exp_l:0.0000 kl_l:47.6998 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:07,283][02269] KL-divergence is very high: 23909.9316
[2023-08-29 14:07:07,286][02269] KL-divergence is very high: 943.5992
[2023-08-29 14:07:07,289][02269] KL-divergence is very high: 230.3802
[2023-08-29 14:07:07,493][02269] KL-divergence is very high: 21657.5312
[2023-08-29 14:07:07,496][02269] High loss value: l:69.3770 pl:0.0126 vl:0.8816 exp_l:0.0000 kl_l:68.4829 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:07,496][02269] KL-divergence is very high: 26251.6035
[2023-08-29 14:07:07,500][02269] KL-divergence is very high: 3024.6313
[2023-08-29 14:07:07,506][02269] High loss value: l:204.2420 pl:0.0507 vl:0.4757 exp_l:0.0000 kl_l:203.7156 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:07,506][02269] KL-divergence is very high: 198277.9531
[2023-08-29 14:07:07,510][02269] High loss value: l:654.4818 pl:0.0561 vl:0.8990 exp_l:0.0000 kl_l:653.5267 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:07,510][02269] KL-divergence is very high: 201454.0156
[2023-08-29 14:07:07,514][02269] High loss value: l:249.2777 pl:0.1305 vl:1.8369 exp_l:0.0000 kl_l:247.3103 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:07,514][02269] KL-divergence is very high: 137644.3906
[2023-08-29 14:07:07,661][02257] Fps is (10 sec: 17206.2, 60 sec: 17476.8, 300 sec: 17494.9). Total num frames: 6709248. Throughput: 0: 17410.7. Samples: 6307856. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-29 14:07:07,661][02257] Avg episode reward: [(0, '-18930.824')]
[2023-08-29 14:07:07,711][02269] KL-divergence is very high: 576.1398
[2023-08-29 14:07:07,714][02269] KL-divergence is very high: 3905.3645
[2023-08-29 14:07:07,717][02269] High loss value: l:164.4293 pl:0.0972 vl:2.1990 exp_l:0.0000 kl_l:162.1330 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:07,717][02269] KL-divergence is very high: 136064.0000
[2023-08-29 14:07:07,720][02269] KL-divergence is very high: 3173.2803
[2023-08-29 14:07:07,723][02269] KL-divergence is very high: 18431.4512
[2023-08-29 14:07:07,726][02269] High loss value: l:39.6067 pl:0.2437 vl:2.5271 exp_l:0.0000 kl_l:36.8359 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:07,726][02269] KL-divergence is very high: 15048.1777
[2023-08-29 14:07:07,730][02269] High loss value: l:215.2262 pl:0.1385 vl:2.0331 exp_l:0.0000 kl_l:213.0546 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:07,730][02269] KL-divergence is very high: 66163.5703
[2023-08-29 14:07:07,733][02269] High loss value: l:118.7838 pl:0.2075 vl:2.1758 exp_l:0.0000 kl_l:116.4006 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:07,733][02269] KL-divergence is very high: 34565.4375
[2023-08-29 14:07:07,925][02269] High loss value: l:78.5172 pl:0.1348 vl:2.0372 exp_l:0.0000 kl_l:76.3452 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:07,926][02269] KL-divergence is very high: 15918.8105
[2023-08-29 14:07:07,929][02269] High loss value: l:106.2610 pl:0.0942 vl:2.0501 exp_l:0.0000 kl_l:104.1167 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:07,929][02269] KL-divergence is very high: 33960.5039
[2023-08-29 14:07:07,932][02269] High loss value: l:83.0366 pl:0.1305 vl:2.0631 exp_l:0.0000 kl_l:80.8430 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:07,932][02269] KL-divergence is very high: 27218.7578
[2023-08-29 14:07:07,936][02269] High loss value: l:55.9516 pl:0.1157 vl:2.2609 exp_l:0.0000 kl_l:53.5750 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:07,936][02269] KL-divergence is very high: 11498.0293
[2023-08-29 14:07:07,940][02269] High loss value: l:63.5033 pl:0.1362 vl:1.9711 exp_l:0.0000 kl_l:61.3960 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:07,940][02269] KL-divergence is very high: 10834.4316
[2023-08-29 14:07:07,944][02269] High loss value: l:73.5139 pl:0.0980 vl:1.9776 exp_l:0.0000 kl_l:71.4383 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:07,944][02269] KL-divergence is very high: 31172.5469
[2023-08-29 14:07:07,948][02269] High loss value: l:64.3113 pl:0.1082 vl:2.0170 exp_l:0.0000 kl_l:62.1861 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:07,948][02269] KL-divergence is very high: 36893.0312
[2023-08-29 14:07:08,140][02269] KL-divergence is very high: 1037.2914
[2023-08-29 14:07:08,143][02269] High loss value: l:112.6028 pl:0.0532 vl:2.0354 exp_l:0.0000 kl_l:110.5142 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:08,143][02269] KL-divergence is very high: 54790.5898
[2023-08-29 14:07:08,146][02269] High loss value: l:411.1358 pl:0.0374 vl:1.8048 exp_l:0.0000 kl_l:409.2935 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:08,146][02269] KL-divergence is very high: 89907.8281
[2023-08-29 14:07:08,150][02269] High loss value: l:269.5577 pl:0.0468 vl:1.9242 exp_l:0.0000 kl_l:267.5867 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:08,150][02269] KL-divergence is very high: 58288.1562
[2023-08-29 14:07:08,153][02269] KL-divergence is very high: 18475.9785
[2023-08-29 14:07:08,156][02269] High loss value: l:234.4820 pl:0.0836 vl:2.0119 exp_l:0.0000 kl_l:232.3865 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:08,157][02269] KL-divergence is very high: 116730.6094
[2023-08-29 14:07:08,160][02269] High loss value: l:993.5223 pl:0.0483 vl:1.7781 exp_l:0.0000 kl_l:991.6959 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:08,160][02269] KL-divergence is very high: 205153.7344
[2023-08-29 14:07:08,163][02269] High loss value: l:1139.6086 pl:0.0601 vl:1.8990 exp_l:0.0000 kl_l:1137.6497 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:08,163][02269] KL-divergence is very high: 196164.7031
[2023-08-29 14:07:08,357][02269] KL-divergence is very high: 132.9570
[2023-08-29 14:07:08,360][02269] KL-divergence is very high: 34673.1914
[2023-08-29 14:07:08,362][02269] KL-divergence is very high: 13423.8486
[2023-08-29 14:07:08,365][02269] High loss value: l:40.9775 pl:0.0799 vl:0.8648 exp_l:0.0000 kl_l:40.0328 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:08,366][02269] KL-divergence is very high: 34710.6836
[2023-08-29 14:07:08,369][02269] High loss value: l:205.2534 pl:0.1306 vl:2.2486 exp_l:0.0000 kl_l:202.8742 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:08,369][02269] KL-divergence is very high: 250950.3125
[2023-08-29 14:07:08,373][02269] High loss value: l:57.9480 pl:0.1128 vl:1.8085 exp_l:0.0000 kl_l:56.0266 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:08,373][02269] KL-divergence is very high: 26319.4414
[2023-08-29 14:07:08,377][02269] High loss value: l:70.6270 pl:0.0621 vl:1.1664 exp_l:0.0000 kl_l:69.3985 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:08,377][02269] KL-divergence is very high: 59252.4492
[2023-08-29 14:07:08,380][02269] High loss value: l:218.7227 pl:0.0723 vl:0.8616 exp_l:0.0000 kl_l:217.7888 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:08,380][02269] KL-divergence is very high: 71047.0469
[2023-08-29 14:07:08,384][02270] Updated weights for policy 0, policy_version 13136 (0.0003)
[2023-08-29 14:07:08,580][02269] KL-divergence is very high: 7228.5293
[2023-08-29 14:07:08,583][02269] KL-divergence is very high: 102.6834
[2023-08-29 14:07:08,586][02269] KL-divergence is very high: 196.5097
[2023-08-29 14:07:08,590][02269] High loss value: l:135.7525 pl:0.0963 vl:0.9887 exp_l:0.0000 kl_l:134.6675 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:08,590][02269] KL-divergence is very high: 44830.9414
[2023-08-29 14:07:08,593][02269] High loss value: l:35.6425 pl:0.0321 vl:1.0471 exp_l:0.0000 kl_l:34.5632 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:08,594][02269] KL-divergence is very high: 23524.6211
[2023-08-29 14:07:08,597][02269] KL-divergence is very high: 653.9144
[2023-08-29 14:07:08,603][02269] KL-divergence is very high: 8653.4805
[2023-08-29 14:07:08,851][02269] KL-divergence is very high: 291.3439
[2023-08-29 14:07:08,854][02269] KL-divergence is very high: 308.3998
[2023-08-29 14:07:08,857][02269] KL-divergence is very high: 121.9036
[2023-08-29 14:07:08,860][02269] KL-divergence is very high: 170.5655
[2023-08-29 14:07:08,863][02269] KL-divergence is very high: 1029.0853
[2023-08-29 14:07:08,866][02269] KL-divergence is very high: 161.3455
[2023-08-29 14:07:09,072][02269] KL-divergence is very high: 694.0084
[2023-08-29 14:07:09,075][02269] KL-divergence is very high: 1946.8116
[2023-08-29 14:07:09,078][02269] KL-divergence is very high: 147.4969
[2023-08-29 14:07:09,084][02269] KL-divergence is very high: 871.6055
[2023-08-29 14:07:09,088][02269] KL-divergence is very high: 3250.9004
[2023-08-29 14:07:09,318][02269] High loss value: l:109.6974 pl:-0.0244 vl:0.7527 exp_l:0.0000 kl_l:108.9691 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:09,318][02269] KL-divergence is very high: 31828.7129
[2023-08-29 14:07:09,327][02269] KL-divergence is very high: 6711.8540
[2023-08-29 14:07:09,330][02269] High loss value: l:35.8481 pl:0.0112 vl:0.6272 exp_l:0.0000 kl_l:35.2097 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:09,330][02269] KL-divergence is very high: 24273.0293
[2023-08-29 14:07:09,566][02269] KL-divergence is very high: 2815.6138
[2023-08-29 14:07:09,568][02269] KL-divergence is very high: 4697.5444
[2023-08-29 14:07:09,571][02269] KL-divergence is very high: 17068.9941
[2023-08-29 14:07:09,577][02269] KL-divergence is very high: 1909.5962
[2023-08-29 14:07:09,580][02269] KL-divergence is very high: 61387.4375
[2023-08-29 14:07:09,780][02269] High loss value: l:406.3573 pl:0.0546 vl:0.6472 exp_l:0.0000 kl_l:405.6555 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:09,780][02269] KL-divergence is very high: 262716.0312
[2023-08-29 14:07:09,783][02269] KL-divergence is very high: 14378.9551
[2023-08-29 14:07:09,786][02269] KL-divergence is very high: 5231.5400
[2023-08-29 14:07:09,789][02269] High loss value: l:48.1527 pl:0.0163 vl:0.4875 exp_l:0.0000 kl_l:47.6489 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:09,789][02269] KL-divergence is very high: 34555.7383
[2023-08-29 14:07:09,792][02269] High loss value: l:244.1865 pl:0.0666 vl:0.6533 exp_l:0.0000 kl_l:243.4667 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:09,793][02269] KL-divergence is very high: 184583.1719
[2023-08-29 14:07:09,796][02269] KL-divergence is very high: 8031.9009
[2023-08-29 14:07:09,799][02269] KL-divergence is very high: 351.1533
[2023-08-29 14:07:10,028][02269] KL-divergence is very high: 309.2083
[2023-08-29 14:07:10,031][02269] KL-divergence is very high: 2492.0803
[2023-08-29 14:07:10,034][02269] High loss value: l:34.1615 pl:0.0968 vl:1.2074 exp_l:0.0000 kl_l:32.8574 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:10,034][02269] KL-divergence is very high: 202993.5938
[2023-08-29 14:07:10,037][02269] KL-divergence is very high: 953.2724
[2023-08-29 14:07:10,041][02269] KL-divergence is very high: 180.7247
[2023-08-29 14:07:10,043][02269] KL-divergence is very high: 2526.4419
[2023-08-29 14:07:10,046][02269] KL-divergence is very high: 12963.2676
[2023-08-29 14:07:10,242][02269] KL-divergence is very high: 2112.3086
[2023-08-29 14:07:10,245][02269] High loss value: l:277.4522 pl:0.1426 vl:1.4793 exp_l:0.0000 kl_l:275.8303 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:10,245][02269] KL-divergence is very high: 43441.8711
[2023-08-29 14:07:10,248][02269] High loss value: l:220.9173 pl:0.1726 vl:1.7244 exp_l:0.0000 kl_l:219.0203 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:10,248][02269] KL-divergence is very high: 28152.5000
[2023-08-29 14:07:10,252][02269] High loss value: l:88.4680 pl:0.1299 vl:1.5139 exp_l:0.0000 kl_l:86.8242 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:10,252][02269] KL-divergence is very high: 15572.8184
[2023-08-29 14:07:10,256][02269] High loss value: l:42.8063 pl:0.2071 vl:1.6115 exp_l:0.0000 kl_l:40.9877 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:10,256][02269] KL-divergence is very high: 16205.8291
[2023-08-29 14:07:10,260][02269] High loss value: l:49.4050 pl:0.1508 vl:1.4548 exp_l:0.0000 kl_l:47.7993 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:10,260][02269] KL-divergence is very high: 11705.8096
[2023-08-29 14:07:10,264][02269] High loss value: l:137.9516 pl:0.2059 vl:1.6936 exp_l:0.0000 kl_l:136.0520 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:10,264][02269] KL-divergence is very high: 16208.3584
[2023-08-29 14:07:10,267][02269] High loss value: l:131.0056 pl:0.1264 vl:1.4870 exp_l:0.0000 kl_l:129.3923 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:10,268][02269] KL-divergence is very high: 19903.5703
[2023-08-29 14:07:10,489][02269] KL-divergence is very high: 554.2827
[2023-08-29 14:07:10,492][02269] High loss value: l:1492.1917 pl:0.0579 vl:1.6826 exp_l:0.0000 kl_l:1490.4512 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:10,492][02269] KL-divergence is very high: 201368.0156
[2023-08-29 14:07:10,495][02269] High loss value: l:2946.8306 pl:0.0679 vl:1.3334 exp_l:0.0000 kl_l:2945.4292 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:10,495][02269] KL-divergence is very high: 398787.5312
[2023-08-29 14:07:10,499][02269] High loss value: l:2429.4934 pl:0.0044 vl:1.8720 exp_l:0.0000 kl_l:2427.6169 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:10,499][02269] KL-divergence is very high: 313515.0938
[2023-08-29 14:07:10,502][02269] High loss value: l:625.5206 pl:0.1099 vl:1.1816 exp_l:0.0000 kl_l:624.2292 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:10,502][02269] KL-divergence is very high: 92829.1562
[2023-08-29 14:07:10,506][02269] High loss value: l:299.1374 pl:0.1296 vl:1.6524 exp_l:0.0000 kl_l:297.3553 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:10,507][02269] KL-divergence is very high: 39629.0977
[2023-08-29 14:07:10,510][02269] High loss value: l:1143.6257 pl:0.0520 vl:1.2976 exp_l:0.0000 kl_l:1142.2761 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:10,511][02269] KL-divergence is very high: 151177.2500
[2023-08-29 14:07:10,514][02269] High loss value: l:928.8061 pl:-0.0047 vl:1.8380 exp_l:0.0000 kl_l:926.9728 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:10,514][02269] KL-divergence is very high: 117406.8203
[2023-08-29 14:07:10,740][02269] High loss value: l:154.9445 pl:0.0069 vl:1.3615 exp_l:0.0000 kl_l:153.5762 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:10,740][02269] KL-divergence is very high: 14226.1074
[2023-08-29 14:07:10,744][02269] High loss value: l:112.6402 pl:0.0667 vl:1.4826 exp_l:0.0000 kl_l:111.0909 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:10,744][02269] KL-divergence is very high: 10725.2676
[2023-08-29 14:07:10,747][02269] KL-divergence is very high: 1591.3981
[2023-08-29 14:07:10,751][02269] KL-divergence is very high: 3394.7156
[2023-08-29 14:07:10,754][02269] High loss value: l:80.6311 pl:0.0050 vl:1.3583 exp_l:0.0000 kl_l:79.2678 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:10,754][02269] KL-divergence is very high: 8589.7285
[2023-08-29 14:07:10,758][02269] High loss value: l:46.0053 pl:0.0596 vl:1.4799 exp_l:0.0000 kl_l:44.4658 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:10,758][02269] KL-divergence is very high: 4956.7139
[2023-08-29 14:07:10,762][02269] High loss value: l:92.9815 pl:0.0223 vl:1.5242 exp_l:0.0000 kl_l:91.4350 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:10,762][02269] KL-divergence is very high: 11404.0713
[2023-08-29 14:07:10,765][02270] Updated weights for policy 0, policy_version 13216 (0.0002)
[2023-08-29 14:07:10,963][02269] High loss value: l:115.7470 pl:0.0320 vl:1.9561 exp_l:0.0000 kl_l:113.7589 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:10,963][02269] KL-divergence is very high: 13125.3496
[2023-08-29 14:07:10,966][02269] High loss value: l:111.3140 pl:-0.0009 vl:1.5007 exp_l:0.0000 kl_l:109.8142 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:10,966][02269] KL-divergence is very high: 14266.4316
[2023-08-29 14:07:10,970][02269] High loss value: l:310.8131 pl:0.0153 vl:1.6626 exp_l:0.0000 kl_l:309.1352 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:10,970][02269] KL-divergence is very high: 41941.8594
[2023-08-29 14:07:10,973][02269] High loss value: l:273.4856 pl:0.0177 vl:1.3931 exp_l:0.0000 kl_l:272.0748 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:10,973][02269] KL-divergence is very high: 30970.9023
[2023-08-29 14:07:10,977][02269] High loss value: l:59.6588 pl:0.0295 vl:1.9473 exp_l:0.0000 kl_l:57.6821 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:10,977][02269] KL-divergence is very high: 5206.2451
[2023-08-29 14:07:10,980][02269] High loss value: l:378.3316 pl:0.0060 vl:1.5118 exp_l:0.0000 kl_l:376.8137 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:10,980][02269] KL-divergence is very high: 40695.4609
[2023-08-29 14:07:10,984][02269] High loss value: l:789.9119 pl:0.0127 vl:1.6899 exp_l:0.0000 kl_l:788.2093 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:10,984][02269] KL-divergence is very high: 83410.8984
[2023-08-29 14:07:11,186][02269] KL-divergence is very high: 1971.9344
[2023-08-29 14:07:11,189][02269] High loss value: l:724.2115 pl:0.0311 vl:1.7322 exp_l:0.0000 kl_l:722.4482 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:11,189][02269] KL-divergence is very high: 128727.7578
[2023-08-29 14:07:11,192][02269] High loss value: l:669.5386 pl:0.0468 vl:1.9782 exp_l:0.0000 kl_l:667.5136 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:11,192][02269] KL-divergence is very high: 121095.0312
[2023-08-29 14:07:11,196][02269] High loss value: l:72.4357 pl:0.0387 vl:1.7258 exp_l:0.0000 kl_l:70.6713 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:11,196][02269] KL-divergence is very high: 18894.4980
[2023-08-29 14:07:11,200][02269] High loss value: l:411.4669 pl:0.0533 vl:1.5644 exp_l:0.0000 kl_l:409.8492 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:11,200][02269] KL-divergence is very high: 39938.5781
[2023-08-29 14:07:11,203][02269] High loss value: l:386.4980 pl:0.0338 vl:1.6870 exp_l:0.0000 kl_l:384.7772 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:11,203][02269] KL-divergence is very high: 30210.6211
[2023-08-29 14:07:11,207][02269] High loss value: l:139.9270 pl:0.0435 vl:1.9273 exp_l:0.0000 kl_l:137.9562 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:11,207][02269] KL-divergence is very high: 46933.4609
[2023-08-29 14:07:11,211][02269] High loss value: l:320.3650 pl:0.0394 vl:1.6870 exp_l:0.0000 kl_l:318.6386 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:11,211][02269] KL-divergence is very high: 37496.1992
[2023-08-29 14:07:11,641][02269] KL-divergence is very high: 123.9593
[2023-08-29 14:07:11,644][02269] High loss value: l:71.6658 pl:0.0049 vl:2.4880 exp_l:0.0000 kl_l:69.1730 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:11,644][02269] KL-divergence is very high: 10964.4209
[2023-08-29 14:07:11,654][02269] High loss value: l:86.2440 pl:-0.0029 vl:1.9908 exp_l:0.0000 kl_l:84.2561 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:11,654][02269] KL-divergence is very high: 12207.7842
[2023-08-29 14:07:11,658][02269] High loss value: l:32.9371 pl:-0.0000 vl:2.3419 exp_l:0.0000 kl_l:30.5953 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:11,658][02269] KL-divergence is very high: 5960.4868
[2023-08-29 14:07:12,663][02257] Fps is (10 sec: 17201.7, 60 sec: 17408.0, 300 sec: 17467.1). Total num frames: 6795264. Throughput: 0: 17365.1. Samples: 6409830. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-29 14:07:12,663][02257] Avg episode reward: [(0, '-45907.110')]
[2023-08-29 14:07:13,280][02270] Updated weights for policy 0, policy_version 13296 (0.0002)
[2023-08-29 14:07:15,553][02270] Updated weights for policy 0, policy_version 13376 (0.0002)
[2023-08-29 14:07:17,662][02257] Fps is (10 sec: 17611.2, 60 sec: 17476.5, 300 sec: 17481.0). Total num frames: 6885376. Throughput: 0: 17377.6. Samples: 6463709. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-29 14:07:17,662][02257] Avg episode reward: [(0, '-45907.110')]
[2023-08-29 14:07:17,801][02270] Updated weights for policy 0, policy_version 13456 (0.0002)
[2023-08-29 14:07:20,039][02270] Updated weights for policy 0, policy_version 13536 (0.0002)
[2023-08-29 14:07:22,598][02270] Updated weights for policy 0, policy_version 13616 (0.0002)
[2023-08-29 14:07:22,663][02257] Fps is (10 sec: 17612.9, 60 sec: 17408.4, 300 sec: 17467.1). Total num frames: 6971392. Throughput: 0: 17371.9. Samples: 6567221. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-29 14:07:22,663][02257] Avg episode reward: [(0, '-41693.643')]
[2023-08-29 14:07:24,208][02269] KL-divergence is very high: 1545.3812
[2023-08-29 14:07:24,442][02269] KL-divergence is very high: 820.0391
[2023-08-29 14:07:24,936][02270] Updated weights for policy 0, policy_version 13696 (0.0002)
[2023-08-29 14:07:26,978][02269] KL-divergence is very high: 15787.1406
[2023-08-29 14:07:27,176][02269] KL-divergence is very high: 10636.9717
[2023-08-29 14:07:27,179][02269] KL-divergence is very high: 6271.6562
[2023-08-29 14:07:27,182][02269] KL-divergence is very high: 2462.8784
[2023-08-29 14:07:27,185][02269] KL-divergence is very high: 7307.7944
[2023-08-29 14:07:27,188][02269] KL-divergence is very high: 6905.0903
[2023-08-29 14:07:27,192][02269] KL-divergence is very high: 6041.2954
[2023-08-29 14:07:27,195][02269] KL-divergence is very high: 569.9950
[2023-08-29 14:07:27,198][02270] Updated weights for policy 0, policy_version 13776 (0.0002)
[2023-08-29 14:07:27,394][02269] KL-divergence is very high: 364.7785
[2023-08-29 14:07:27,402][02269] KL-divergence is very high: 4060.6416
[2023-08-29 14:07:27,405][02269] KL-divergence is very high: 1925.4886
[2023-08-29 14:07:27,619][02269] KL-divergence is very high: 6634.2446
[2023-08-29 14:07:27,631][02269] KL-divergence is very high: 2733.0740
[2023-08-29 14:07:27,663][02257] Fps is (10 sec: 17610.9, 60 sec: 17476.2, 300 sec: 17467.0). Total num frames: 7061504. Throughput: 0: 17382.1. Samples: 6674530. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-29 14:07:27,663][02257] Avg episode reward: [(0, '-41693.643')]
[2023-08-29 14:07:27,833][02269] KL-divergence is very high: 2714.1946
[2023-08-29 14:07:27,841][02269] KL-divergence is very high: 571.3431
[2023-08-29 14:07:27,844][02269] KL-divergence is very high: 2735.8098
[2023-08-29 14:07:27,847][02269] KL-divergence is very high: 234.4427
[2023-08-29 14:07:28,064][02269] High loss value: l:64.3932 pl:0.2266 vl:0.0445 exp_l:0.0000 kl_l:64.1221 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:28,064][02269] KL-divergence is very high: 36360.7773
[2023-08-29 14:07:28,076][02269] KL-divergence is very high: 7401.7798
[2023-08-29 14:07:28,283][02269] High loss value: l:47.6915 pl:0.2074 vl:0.0895 exp_l:0.0000 kl_l:47.3946 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:28,283][02269] KL-divergence is very high: 46037.4180
[2023-08-29 14:07:29,446][02269] KL-divergence is very high: 126.1420
[2023-08-29 14:07:29,448][02270] Updated weights for policy 0, policy_version 13856 (0.0002)
[2023-08-29 14:07:31,928][02270] Updated weights for policy 0, policy_version 13936 (0.0002)
[2023-08-29 14:07:32,661][02257] Fps is (10 sec: 17616.1, 60 sec: 17408.0, 300 sec: 17467.1). Total num frames: 7147520. Throughput: 0: 17433.9. Samples: 6725541. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-29 14:07:32,661][02257] Avg episode reward: [(0, '-45711.216')]
[2023-08-29 14:07:34,021][02269] KL-divergence is very high: 1989.0743
[2023-08-29 14:07:34,257][02269] KL-divergence is very high: 738.2981
[2023-08-29 14:07:34,267][02270] Updated weights for policy 0, policy_version 14016 (0.0002)
[2023-08-29 14:07:35,179][02269] KL-divergence is very high: 159.9797
[2023-08-29 14:07:35,182][02269] KL-divergence is very high: 196.9583
[2023-08-29 14:07:35,191][02269] KL-divergence is very high: 534.4442
[2023-08-29 14:07:35,194][02269] KL-divergence is very high: 348.6779
[2023-08-29 14:07:35,196][02269] KL-divergence is very high: 444.9312
[2023-08-29 14:07:35,405][02269] High loss value: l:58.4030 pl:0.2039 vl:0.0770 exp_l:0.0000 kl_l:58.1221 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:35,405][02269] KL-divergence is very high: 45199.7578
[2023-08-29 14:07:35,417][02269] High loss value: l:903.4162 pl:0.2082 vl:0.0734 exp_l:0.0000 kl_l:903.1346 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:35,417][02269] KL-divergence is very high: 666488.0000
[2023-08-29 14:07:35,622][02269] KL-divergence is very high: 578.7803
[2023-08-29 14:07:35,625][02269] KL-divergence is very high: 3302.1611
[2023-08-29 14:07:35,628][02269] KL-divergence is very high: 291.8220
[2023-08-29 14:07:35,634][02269] KL-divergence is very high: 3001.8308
[2023-08-29 14:07:35,845][02269] KL-divergence is very high: 226.6030
[2023-08-29 14:07:35,850][02269] KL-divergence is very high: 820.8433
[2023-08-29 14:07:35,853][02269] KL-divergence is very high: 545.4387
[2023-08-29 14:07:35,856][02269] KL-divergence is very high: 1144.6479
[2023-08-29 14:07:36,549][02269] KL-divergence is very high: 2947.8704
[2023-08-29 14:07:36,552][02269] KL-divergence is very high: 522.1161
[2023-08-29 14:07:36,561][02269] KL-divergence is very high: 33614.2031
[2023-08-29 14:07:36,564][02269] KL-divergence is very high: 1179.4773
[2023-08-29 14:07:36,567][02270] Updated weights for policy 0, policy_version 14096 (0.0002)
[2023-08-29 14:07:36,764][02269] KL-divergence is very high: 3662.9319
[2023-08-29 14:07:36,767][02269] KL-divergence is very high: 29906.7227
[2023-08-29 14:07:36,769][02269] KL-divergence is very high: 187.8395
[2023-08-29 14:07:36,772][02269] KL-divergence is very high: 3702.2410
[2023-08-29 14:07:36,775][02269] KL-divergence is very high: 5309.1450
[2023-08-29 14:07:36,778][02269] KL-divergence is very high: 755.1548
[2023-08-29 14:07:36,781][02269] KL-divergence is very high: 621.4516
[2023-08-29 14:07:37,016][02269] KL-divergence is very high: 168.4981
[2023-08-29 14:07:37,266][02269] KL-divergence is very high: 780.7217
[2023-08-29 14:07:37,277][02269] KL-divergence is very high: 9949.2344
[2023-08-29 14:07:37,486][02269] High loss value: l:110.0362 pl:0.0858 vl:0.0854 exp_l:0.0000 kl_l:109.8649 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:37,486][02269] KL-divergence is very high: 90486.4922
[2023-08-29 14:07:37,490][02269] High loss value: l:67.8517 pl:0.1127 vl:0.0800 exp_l:0.0000 kl_l:67.6590 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:37,490][02269] KL-divergence is very high: 13787.9990
[2023-08-29 14:07:37,500][02269] High loss value: l:1001.4010 pl:0.0830 vl:0.0825 exp_l:0.0000 kl_l:1001.2355 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:37,500][02269] KL-divergence is very high: 981588.6875
[2023-08-29 14:07:37,504][02269] High loss value: l:1819.6992 pl:0.1143 vl:0.0837 exp_l:0.0000 kl_l:1819.5012 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:37,504][02269] KL-divergence is very high: 559350.8750
[2023-08-29 14:07:37,663][02257] Fps is (10 sec: 17203.0, 60 sec: 17407.9, 300 sec: 17453.1). Total num frames: 7233536. Throughput: 0: 17407.2. Samples: 6832144. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-29 14:07:37,664][02257] Avg episode reward: [(0, '-45711.216')]
[2023-08-29 14:07:37,731][02269] High loss value: l:34.4757 pl:0.0743 vl:0.0981 exp_l:0.0000 kl_l:34.3033 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:37,731][02269] KL-divergence is very high: 61169.2500
[2023-08-29 14:07:37,734][02269] KL-divergence is very high: 74844.6953
[2023-08-29 14:07:37,737][02269] KL-divergence is very high: 19463.4707
[2023-08-29 14:07:37,740][02269] High loss value: l:43.0611 pl:0.1015 vl:0.0859 exp_l:0.0000 kl_l:42.8737 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:37,740][02269] KL-divergence is very high: 25312.8301
[2023-08-29 14:07:37,744][02269] KL-divergence is very high: 28754.2773
[2023-08-29 14:07:37,747][02269] KL-divergence is very high: 62016.3867
[2023-08-29 14:07:37,750][02269] KL-divergence is very high: 11891.5488
[2023-08-29 14:07:37,981][02269] KL-divergence is very high: 3297.5798
[2023-08-29 14:07:37,983][02269] KL-divergence is very high: 307.8429
[2023-08-29 14:07:37,986][02269] KL-divergence is very high: 327.5798
[2023-08-29 14:07:37,992][02269] KL-divergence is very high: 724.8161
[2023-08-29 14:07:37,996][02269] KL-divergence is very high: 160.5533
[2023-08-29 14:07:38,222][02269] KL-divergence is very high: 565.3522
[2023-08-29 14:07:38,233][02269] KL-divergence is very high: 561.7212
[2023-08-29 14:07:39,168][02269] KL-divergence is very high: 150.1015
[2023-08-29 14:07:39,176][02270] Updated weights for policy 0, policy_version 14176 (0.0002)
[2023-08-29 14:07:41,382][02270] Updated weights for policy 0, policy_version 14256 (0.0002)
[2023-08-29 14:07:41,622][02269] KL-divergence is very high: 276.9124
[2023-08-29 14:07:42,528][02269] KL-divergence is very high: 2231.6013
[2023-08-29 14:07:42,534][02269] KL-divergence is very high: 247.6217
[2023-08-29 14:07:42,540][02269] KL-divergence is very high: 15964.4717
[2023-08-29 14:07:42,664][02257] Fps is (10 sec: 17198.4, 60 sec: 17407.7, 300 sec: 17453.1). Total num frames: 7319552. Throughput: 0: 17380.0. Samples: 6934551. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-29 14:07:42,664][02257] Avg episode reward: [(0, '-48243.066')]
[2023-08-29 14:07:42,667][02269] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000014296_7319552.pth...
[2023-08-29 14:07:42,668][02269] Removing /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000007496_3837952.pth
[2023-08-29 14:07:42,780][02269] KL-divergence is very high: 6824.2432
[2023-08-29 14:07:42,783][02269] KL-divergence is very high: 974.2292
[2023-08-29 14:07:42,785][02269] High loss value: l:63.8907 pl:0.2196 vl:0.0625 exp_l:0.0000 kl_l:63.6085 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:42,785][02269] KL-divergence is very high: 17906.7871
[2023-08-29 14:07:42,789][02269] High loss value: l:54.1686 pl:0.1627 vl:0.2657 exp_l:0.0000 kl_l:53.7401 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:42,789][02269] KL-divergence is very high: 25276.9668
[2023-08-29 14:07:42,793][02269] KL-divergence is very high: 7499.9756
[2023-08-29 14:07:42,795][02269] High loss value: l:42.6164 pl:0.1667 vl:0.1335 exp_l:0.0000 kl_l:42.3162 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:42,796][02269] KL-divergence is very high: 17042.2637
[2023-08-29 14:07:42,800][02269] High loss value: l:111.1779 pl:0.2316 vl:0.0558 exp_l:0.0000 kl_l:110.8905 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:42,800][02269] KL-divergence is very high: 37086.5352
[2023-08-29 14:07:43,010][02269] High loss value: l:66.7343 pl:0.0565 vl:0.1374 exp_l:0.0000 kl_l:66.5404 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:43,011][02269] KL-divergence is very high: 72278.7344
[2023-08-29 14:07:43,014][02269] KL-divergence is very high: 34155.2695
[2023-08-29 14:07:43,017][02269] KL-divergence is very high: 2105.7261
[2023-08-29 14:07:43,023][02269] High loss value: l:86.6422 pl:0.0530 vl:0.1358 exp_l:0.0000 kl_l:86.4535 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:43,023][02269] KL-divergence is very high: 97951.9141
[2023-08-29 14:07:43,027][02269] High loss value: l:37.6673 pl:0.1911 vl:0.1163 exp_l:0.0000 kl_l:37.3599 (recommended to adjust the --reward_scale parameter)
[2023-08-29 14:07:43,027][02269] KL-divergence is very high: 69067.1406
[2023-08-29 14:07:43,527][02269] KL-divergence is very high: 132.3494
[2023-08-29 14:07:43,762][02269] KL-divergence is very high: 34862.4922
[2023-08-29 14:07:43,773][02270] Updated weights for policy 0, policy_version 14336 (0.0002)
[2023-08-29 14:07:44,039][02269] KL-divergence is very high: 450.8875
[2023-08-29 14:07:44,048][02269] KL-divergence is very high: 103.4223
[2023-08-29 14:07:44,052][02269] KL-divergence is very high: 6731.7192
[2023-08-29 14:07:44,055][02269] KL-divergence is very high: 420.2974
[2023-08-29 14:07:44,728][02269] KL-divergence is very high: 243.7616
[2023-08-29 14:07:44,739][02269] KL-divergence is very high: 876.9836
[2023-08-29 14:07:44,742][02269] KL-divergence is very high: 158.3471
[2023-08-29 14:07:44,945][02269] KL-divergence is very high: 119.8564
[2023-08-29 14:07:46,044][02269] KL-divergence is very high: 112.7863
[2023-08-29 14:07:46,052][02269] KL-divergence is very high: 105.5768
[2023-08-29 14:07:46,056][02269] KL-divergence is very high: 185.1767
[2023-08-29 14:07:46,058][02270] Updated weights for policy 0, policy_version 14416 (0.0002)
[2023-08-29 14:07:47,663][02257] Fps is (10 sec: 17203.5, 60 sec: 17408.0, 300 sec: 17439.2). Total num frames: 7405568. Throughput: 0: 17340.2. Samples: 6986251. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-29 14:07:47,663][02257] Avg episode reward: [(0, '-48243.066')]
[2023-08-29 14:07:47,679][02269] KL-divergence is very high: 232.8849
[2023-08-29 14:07:47,886][02269] KL-divergence is very high: 3383.6025
[2023-08-29 14:07:48,612][02270] Updated weights for policy 0, policy_version 14496 (0.0002)
[2023-08-29 14:07:49,495][02269] KL-divergence is very high: 1358.8883
[2023-08-29 14:07:49,503][02269] KL-divergence is very high: 100.3594
[2023-08-29 14:07:49,506][02269] KL-divergence is very high: 2707.3401
[2023-08-29 14:07:49,972][02269] KL-divergence is very high: 1471.1527
[2023-08-29 14:07:49,975][02269] KL-divergence is very high: 529.0118
[2023-08-29 14:07:49,983][02269] KL-divergence is very high: 1196.6912
[2023-08-29 14:07:49,986][02269] KL-divergence is very high: 442.6955
[2023-08-29 14:07:50,188][02269] KL-divergence is very high: 580.2992
[2023-08-29 14:07:50,199][02269] KL-divergence is very high: 112.2373
[2023-08-29 14:07:50,647][02269] KL-divergence is very high: 280.8906
[2023-08-29 14:07:50,658][02269] KL-divergence is very high: 219.2920
[2023-08-29 14:07:50,879][02270] Updated weights for policy 0, policy_version 14576 (0.0002)
[2023-08-29 14:07:51,093][02269] KL-divergence is very high: 309.1498
[2023-08-29 14:07:51,324][02269] KL-divergence is very high: 143.0033
[2023-08-29 14:07:51,333][02269] KL-divergence is very high: 8156.0273
[2023-08-29 14:07:51,336][02269] KL-divergence is very high: 292.1244
[2023-08-29 14:07:51,542][02269] KL-divergence is very high: 115.0383
[2023-08-29 14:07:51,545][02269] KL-divergence is very high: 378.9860
[2023-08-29 14:07:51,548][02269] KL-divergence is very high: 204.5343
[2023-08-29 14:07:51,553][02269] KL-divergence is very high: 341.0117
[2023-08-29 14:07:51,557][02269] KL-divergence is very high: 1256.6940
[2023-08-29 14:07:52,663][02257] Fps is (10 sec: 17204.5, 60 sec: 17340.0, 300 sec: 17439.2). Total num frames: 7491584. Throughput: 0: 17384.7. Samples: 7090201. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-29 14:07:52,663][02257] Avg episode reward: [(0, '-50133.942')]
[2023-08-29 14:07:53,184][02270] Updated weights for policy 0, policy_version 14656 (0.0002)
[2023-08-29 14:07:54,335][02269] KL-divergence is very high: 175.2237
[2023-08-29 14:07:54,347][02269] KL-divergence is very high: 2130.0256
[2023-08-29 14:07:55,505][02270] Updated weights for policy 0, policy_version 14736 (0.0002)
[2023-08-29 14:07:55,960][02269] KL-divergence is very high: 155.3420
[2023-08-29 14:07:55,963][02269] KL-divergence is very high: 2222.6243
[2023-08-29 14:07:55,971][02269] KL-divergence is very high: 318.4874
[2023-08-29 14:07:55,975][02269] KL-divergence is very high: 5769.2329
[2023-08-29 14:07:56,180][02269] KL-divergence is very high: 3364.4924
[2023-08-29 14:07:57,584][02269] KL-divergence is very high: 385.6371
[2023-08-29 14:07:57,663][02257] Fps is (10 sec: 17203.4, 60 sec: 17339.7, 300 sec: 17425.4). Total num frames: 7577600. Throughput: 0: 17485.8. Samples: 7196691. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-29 14:07:57,663][02257] Avg episode reward: [(0, '-55153.702')]
[2023-08-29 14:07:58,069][02270] Updated weights for policy 0, policy_version 14816 (0.0002)
[2023-08-29 14:07:58,958][02269] KL-divergence is very high: 303.0348
[2023-08-29 14:08:00,344][02270] Updated weights for policy 0, policy_version 14896 (0.0002)
[2023-08-29 14:08:01,760][02269] KL-divergence is very high: 278.9695
[2023-08-29 14:08:02,648][02270] Updated weights for policy 0, policy_version 14976 (0.0002)
[2023-08-29 14:08:02,662][02257] Fps is (10 sec: 17614.1, 60 sec: 17407.9, 300 sec: 17439.3). Total num frames: 7667712. Throughput: 0: 17380.5. Samples: 7245836. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-29 14:08:02,663][02257] Avg episode reward: [(0, '-55153.702')]
[2023-08-29 14:08:03,512][02269] KL-divergence is very high: 590.2270
[2023-08-29 14:08:03,521][02269] KL-divergence is very high: 158.2572
[2023-08-29 14:08:03,524][02269] KL-divergence is very high: 309.8405
[2023-08-29 14:08:04,914][02270] Updated weights for policy 0, policy_version 15056 (0.0002)
[2023-08-29 14:08:07,398][02270] Updated weights for policy 0, policy_version 15136 (0.0002)
[2023-08-29 14:08:07,664][02257] Fps is (10 sec: 17610.9, 60 sec: 17407.2, 300 sec: 17439.2). Total num frames: 7753728. Throughput: 0: 17466.9. Samples: 7353250. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-29 14:08:07,664][02257] Avg episode reward: [(0, '-37206.633')]
[2023-08-29 14:08:09,658][02270] Updated weights for policy 0, policy_version 15216 (0.0002)
[2023-08-29 14:08:10,322][02269] KL-divergence is very high: 101.6827
[2023-08-29 14:08:10,330][02269] KL-divergence is very high: 477.4763
[2023-08-29 14:08:10,333][02269] KL-divergence is very high: 392.9258
[2023-08-29 14:08:11,863][02270] Updated weights for policy 0, policy_version 15296 (0.0002)
[2023-08-29 14:08:12,663][02257] Fps is (10 sec: 17611.7, 60 sec: 17476.3, 300 sec: 17453.2). Total num frames: 7843840. Throughput: 0: 17429.1. Samples: 7458834. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-29 14:08:12,663][02257] Avg episode reward: [(0, '-37206.633')]
[2023-08-29 14:08:14,157][02270] Updated weights for policy 0, policy_version 15376 (0.0002)
[2023-08-29 14:08:14,629][02269] KL-divergence is very high: 317.0595
[2023-08-29 14:08:15,299][02269] KL-divergence is very high: 125.8953
[2023-08-29 14:08:16,643][02270] Updated weights for policy 0, policy_version 15456 (0.0002)
[2023-08-29 14:08:17,663][02257] Fps is (10 sec: 17614.8, 60 sec: 17407.8, 300 sec: 17467.0). Total num frames: 7929856. Throughput: 0: 17485.4. Samples: 7512415. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2023-08-29 14:08:17,663][02257] Avg episode reward: [(0, '-30395.484')]
[2023-08-29 14:08:18,845][02270] Updated weights for policy 0, policy_version 15536 (0.0002)
[2023-08-29 14:08:19,488][02269] KL-divergence is very high: 581.6305
[2023-08-29 14:08:19,491][02269] KL-divergence is very high: 684.9551
[2023-08-29 14:08:19,497][02269] KL-divergence is very high: 664.5197
[2023-08-29 14:08:19,500][02269] KL-divergence is very high: 183.0240
[2023-08-29 14:08:19,504][02269] KL-divergence is very high: 307.3160
[2023-08-29 14:08:20,883][02269] KL-divergence is very high: 175.5180
[2023-08-29 14:08:20,894][02269] KL-divergence is very high: 1270.6976
[2023-08-29 14:08:21,114][02270] Updated weights for policy 0, policy_version 15616 (0.0002)
[2023-08-29 14:08:22,664][02257] Fps is (10 sec: 17610.7, 60 sec: 17475.9, 300 sec: 17467.0). Total num frames: 8019968. Throughput: 0: 17472.2. Samples: 7618409. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2023-08-29 14:08:22,664][02257] Avg episode reward: [(0, '-30395.484')]
[2023-08-29 14:08:23,381][02270] Updated weights for policy 0, policy_version 15696 (0.0002)
[2023-08-29 14:08:23,584][02269] KL-divergence is very high: 152.4288
[2023-08-29 14:08:25,813][02270] Updated weights for policy 0, policy_version 15776 (0.0002)
[2023-08-29 14:08:27,448][02269] KL-divergence is very high: 16217.2861
[2023-08-29 14:08:27,654][02269] KL-divergence is very high: 3452.8691
[2023-08-29 14:08:27,661][02257] Fps is (10 sec: 17615.7, 60 sec: 17408.6, 300 sec: 17467.1). Total num frames: 8105984. Throughput: 0: 17530.5. Samples: 7723380. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-29 14:08:27,661][02257] Avg episode reward: [(0, '-30157.055')]
[2023-08-29 14:08:28,116][02270] Updated weights for policy 0, policy_version 15856 (0.0002)
[2023-08-29 14:08:30,347][02270] Updated weights for policy 0, policy_version 15936 (0.0002)
[2023-08-29 14:08:30,788][02269] KL-divergence is very high: 136.4673
[2023-08-29 14:08:32,663][02257] Fps is (10 sec: 18024.9, 60 sec: 17544.0, 300 sec: 17480.9). Total num frames: 8200192. Throughput: 0: 17601.4. Samples: 7778309. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-29 14:08:32,663][02257] Avg episode reward: [(0, '-30157.055')]
[2023-08-29 14:08:32,663][02270] Updated weights for policy 0, policy_version 16016 (0.0002)
[2023-08-29 14:08:35,159][02270] Updated weights for policy 0, policy_version 16096 (0.0002)
[2023-08-29 14:08:37,458][02270] Updated weights for policy 0, policy_version 16176 (0.0002)
[2023-08-29 14:08:37,663][02257] Fps is (10 sec: 17609.9, 60 sec: 17476.4, 300 sec: 17467.0). Total num frames: 8282112. Throughput: 0: 17567.1. Samples: 7880720. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-29 14:08:37,663][02257] Avg episode reward: [(0, '-28447.756')]
[2023-08-29 14:08:39,750][02270] Updated weights for policy 0, policy_version 16256 (0.0002)
[2023-08-29 14:08:41,795][02269] KL-divergence is very high: 113.7350
[2023-08-29 14:08:42,014][02270] Updated weights for policy 0, policy_version 16336 (0.0002)
[2023-08-29 14:08:42,663][02257] Fps is (10 sec: 17202.9, 60 sec: 17544.8, 300 sec: 17467.0). Total num frames: 8372224. Throughput: 0: 17598.3. Samples: 7988613. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-29 14:08:42,663][02257] Avg episode reward: [(0, '-28447.756')]
[2023-08-29 14:08:43,103][02269] KL-divergence is very high: 115.7423
[2023-08-29 14:08:43,764][02269] KL-divergence is very high: 201.4993
[2023-08-29 14:08:43,979][02269] KL-divergence is very high: 635.2693
[2023-08-29 14:08:44,467][02270] Updated weights for policy 0, policy_version 16416 (0.0002)
[2023-08-29 14:08:46,717][02270] Updated weights for policy 0, policy_version 16496 (0.0002)
[2023-08-29 14:08:47,663][02257] Fps is (10 sec: 18022.0, 60 sec: 17612.8, 300 sec: 17480.9). Total num frames: 8462336. Throughput: 0: 17648.0. Samples: 8040011. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-29 14:08:47,663][02257] Avg episode reward: [(0, '-25523.786')]
[2023-08-29 14:08:48,976][02270] Updated weights for policy 0, policy_version 16576 (0.0002)
[2023-08-29 14:08:51,294][02270] Updated weights for policy 0, policy_version 16656 (0.0002)
[2023-08-29 14:08:52,663][02257] Fps is (10 sec: 17613.5, 60 sec: 17612.9, 300 sec: 17466.9). Total num frames: 8548352. Throughput: 0: 17645.1. Samples: 8147253. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-29 14:08:52,663][02257] Avg episode reward: [(0, '-19712.826')]
[2023-08-29 14:08:53,763][02270] Updated weights for policy 0, policy_version 16736 (0.0002)
[2023-08-29 14:08:54,189][02269] KL-divergence is very high: 108.3029
[2023-08-29 14:08:54,617][02269] KL-divergence is very high: 121.3802
[2023-08-29 14:08:55,287][02269] KL-divergence is very high: 102.8893
[2023-08-29 14:08:55,995][02270] Updated weights for policy 0, policy_version 16816 (0.0002)
[2023-08-29 14:08:57,367][02269] KL-divergence is very high: 622.2882
[2023-08-29 14:08:57,604][02269] KL-divergence is very high: 773.8061
[2023-08-29 14:08:57,613][02269] KL-divergence is very high: 190.5741
[2023-08-29 14:08:57,663][02257] Fps is (10 sec: 17613.0, 60 sec: 17681.0, 300 sec: 17480.9). Total num frames: 8638464. Throughput: 0: 17642.5. Samples: 8252749. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-29 14:08:57,663][02257] Avg episode reward: [(0, '-19712.826')]
[2023-08-29 14:08:58,262][02270] Updated weights for policy 0, policy_version 16896 (0.0002)
[2023-08-29 14:09:00,273][02269] KL-divergence is very high: 991.2599
[2023-08-29 14:09:00,284][02269] KL-divergence is very high: 679.9507
[2023-08-29 14:09:00,484][02269] KL-divergence is very high: 1110.5978
[2023-08-29 14:09:00,487][02269] KL-divergence is very high: 436.0970
[2023-08-29 14:09:00,493][02269] KL-divergence is very high: 145.4747
[2023-08-29 14:09:00,496][02269] KL-divergence is very high: 414.0157
[2023-08-29 14:09:00,500][02269] KL-divergence is very high: 252.2464
[2023-08-29 14:09:00,506][02270] Updated weights for policy 0, policy_version 16976 (0.0002)
[2023-08-29 14:09:02,663][02257] Fps is (10 sec: 17611.9, 60 sec: 17612.6, 300 sec: 17467.0). Total num frames: 8724480. Throughput: 0: 17651.9. Samples: 8306752. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[2023-08-29 14:09:02,664][02257] Avg episode reward: [(0, '-16945.831')]
[2023-08-29 14:09:03,006][02270] Updated weights for policy 0, policy_version 17056 (0.0002)
[2023-08-29 14:09:05,082][02269] KL-divergence is very high: 179.9186
[2023-08-29 14:09:05,330][02270] Updated weights for policy 0, policy_version 17136 (0.0002)
[2023-08-29 14:09:06,203][02269] KL-divergence is very high: 333.6711
[2023-08-29 14:09:06,206][02269] KL-divergence is very high: 325.7532
[2023-08-29 14:09:06,410][02269] KL-divergence is very high: 131.1154
[2023-08-29 14:09:06,418][02269] KL-divergence is very high: 185.2010
[2023-08-29 14:09:06,631][02269] KL-divergence is very high: 350.7987
[2023-08-29 14:09:06,644][02269] KL-divergence is very high: 792.3060
[2023-08-29 14:09:06,868][02269] KL-divergence is very high: 365.7035
[2023-08-29 14:09:06,879][02269] KL-divergence is very high: 114.1643
[2023-08-29 14:09:07,570][02269] KL-divergence is very high: 493.8705
[2023-08-29 14:09:07,577][02270] Updated weights for policy 0, policy_version 17216 (0.0003)
[2023-08-29 14:09:07,664][02257] Fps is (10 sec: 17610.8, 60 sec: 17681.0, 300 sec: 17480.8). Total num frames: 8814592. Throughput: 0: 17611.9. Samples: 8410946. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[2023-08-29 14:09:07,664][02257] Avg episode reward: [(0, '-16945.831')]
[2023-08-29 14:09:09,631][02269] KL-divergence is very high: 954.4609
[2023-08-29 14:09:09,875][02270] Updated weights for policy 0, policy_version 17296 (0.0002)
[2023-08-29 14:09:12,329][02270] Updated weights for policy 0, policy_version 17376 (0.0002)
[2023-08-29 14:09:12,663][02257] Fps is (10 sec: 17612.8, 60 sec: 17612.8, 300 sec: 17467.0). Total num frames: 8900608. Throughput: 0: 17598.4. Samples: 8515341. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[2023-08-29 14:09:12,663][02257] Avg episode reward: [(0, '-15373.723')]
[2023-08-29 14:09:14,593][02270] Updated weights for policy 0, policy_version 17456 (0.0002)
[2023-08-29 14:09:16,885][02270] Updated weights for policy 0, policy_version 17536 (0.0002)
[2023-08-29 14:09:17,663][02257] Fps is (10 sec: 17614.9, 60 sec: 17681.0, 300 sec: 17467.0). Total num frames: 8990720. Throughput: 0: 17567.4. Samples: 8568848. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-29 14:09:17,663][02257] Avg episode reward: [(0, '-15373.723')]
[2023-08-29 14:09:19,400][02270] Updated weights for policy 0, policy_version 17616 (0.0002)
[2023-08-29 14:09:21,730][02270] Updated weights for policy 0, policy_version 17696 (0.0002)
[2023-08-29 14:09:22,663][02257] Fps is (10 sec: 17612.6, 60 sec: 17613.1, 300 sec: 17467.0). Total num frames: 9076736. Throughput: 0: 17600.3. Samples: 8672739. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-29 14:09:22,663][02257] Avg episode reward: [(0, '-13983.978')]
[2023-08-29 14:09:22,666][02269] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000017728_9076736.pth...
[2023-08-29 14:09:22,668][02269] Removing /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000010888_5574656.pth
[2023-08-29 14:09:23,976][02270] Updated weights for policy 0, policy_version 17776 (0.0002)
[2023-08-29 14:09:26,308][02270] Updated weights for policy 0, policy_version 17856 (0.0002)
[2023-08-29 14:09:27,664][02257] Fps is (10 sec: 17201.4, 60 sec: 17612.0, 300 sec: 17453.0). Total num frames: 9162752. Throughput: 0: 17573.7. Samples: 8779449. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2023-08-29 14:09:27,664][02257] Avg episode reward: [(0, '-13983.978')]
[2023-08-29 14:09:28,735][02270] Updated weights for policy 0, policy_version 17936 (0.0002)
[2023-08-29 14:09:31,037][02270] Updated weights for policy 0, policy_version 18016 (0.0002)
[2023-08-29 14:09:32,662][02257] Fps is (10 sec: 17614.7, 60 sec: 17544.7, 300 sec: 17453.2). Total num frames: 9252864. Throughput: 0: 17570.1. Samples: 8830649. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2023-08-29 14:09:32,662][02257] Avg episode reward: [(0, '-13791.767')]
[2023-08-29 14:09:33,261][02270] Updated weights for policy 0, policy_version 18096 (0.0002)
[2023-08-29 14:09:35,634][02270] Updated weights for policy 0, policy_version 18176 (0.0002)
[2023-08-29 14:09:37,664][02257] Fps is (10 sec: 17203.3, 60 sec: 17544.2, 300 sec: 17425.3). Total num frames: 9334784. Throughput: 0: 17564.5. Samples: 8937681. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2023-08-29 14:09:37,664][02257] Avg episode reward: [(0, '-14257.273')]
[2023-08-29 14:09:38,174][02270] Updated weights for policy 0, policy_version 18256 (0.0002)
[2023-08-29 14:09:40,379][02270] Updated weights for policy 0, policy_version 18336 (0.0002)
[2023-08-29 14:09:42,663][02257] Fps is (10 sec: 17202.0, 60 sec: 17544.6, 300 sec: 17453.1). Total num frames: 9424896. Throughput: 0: 17521.0. Samples: 9041190. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[2023-08-29 14:09:42,663][02257] Avg episode reward: [(0, '-14257.273')]
[2023-08-29 14:09:42,721][02270] Updated weights for policy 0, policy_version 18416 (0.0002)
[2023-08-29 14:09:44,952][02270] Updated weights for policy 0, policy_version 18496 (0.0002)
[2023-08-29 14:09:47,403][02270] Updated weights for policy 0, policy_version 18576 (0.0002)
[2023-08-29 14:09:47,664][02257] Fps is (10 sec: 18022.1, 60 sec: 17544.2, 300 sec: 17439.2). Total num frames: 9515008. Throughput: 0: 17535.4. Samples: 9095863. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[2023-08-29 14:09:47,664][02257] Avg episode reward: [(0, '-11892.660')]
[2023-08-29 14:09:49,598][02270] Updated weights for policy 0, policy_version 18656 (0.0002)
[2023-08-29 14:09:51,867][02270] Updated weights for policy 0, policy_version 18736 (0.0002)
[2023-08-29 14:09:52,662][02257] Fps is (10 sec: 18024.5, 60 sec: 17613.1, 300 sec: 17453.2). Total num frames: 9605120. Throughput: 0: 17580.9. Samples: 9202042. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[2023-08-29 14:09:52,662][02257] Avg episode reward: [(0, '-11892.660')]
[2023-08-29 14:09:54,090][02270] Updated weights for policy 0, policy_version 18816 (0.0002)
[2023-08-29 14:09:56,702][02270] Updated weights for policy 0, policy_version 18896 (0.0002)
[2023-08-29 14:09:57,664][02257] Fps is (10 sec: 17613.4, 60 sec: 17544.3, 300 sec: 17453.0). Total num frames: 9691136. Throughput: 0: 17559.2. Samples: 9305518. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-29 14:09:57,664][02257] Avg episode reward: [(0, '-11891.927')]
[2023-08-29 14:09:58,993][02270] Updated weights for policy 0, policy_version 18976 (0.0002)
[2023-08-29 14:10:01,308][02270] Updated weights for policy 0, policy_version 19056 (0.0002)
[2023-08-29 14:10:02,662][02257] Fps is (10 sec: 17203.4, 60 sec: 17545.0, 300 sec: 17453.2). Total num frames: 9777152. Throughput: 0: 17567.9. Samples: 9359376. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-29 14:10:02,662][02257] Avg episode reward: [(0, '-11891.927')]
[2023-08-29 14:10:03,529][02270] Updated weights for policy 0, policy_version 19136 (0.0002)
[2023-08-29 14:10:06,029][02270] Updated weights for policy 0, policy_version 19216 (0.0002)
[2023-08-29 14:10:07,663][02257] Fps is (10 sec: 17204.7, 60 sec: 17476.6, 300 sec: 17453.1). Total num frames: 9863168. Throughput: 0: 17557.7. Samples: 9462834. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-29 14:10:07,663][02257] Avg episode reward: [(0, '-11534.683')]
[2023-08-29 14:10:08,409][02270] Updated weights for policy 0, policy_version 19296 (0.0002)
[2023-08-29 14:10:10,710][02270] Updated weights for policy 0, policy_version 19376 (0.0002)
[2023-08-29 14:10:12,662][02257] Fps is (10 sec: 17612.6, 60 sec: 17544.9, 300 sec: 17467.1). Total num frames: 9953280. Throughput: 0: 17529.5. Samples: 9568235. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-29 14:10:12,662][02257] Avg episode reward: [(0, '-11534.683')]
[2023-08-29 14:10:13,053][02270] Updated weights for policy 0, policy_version 19456 (0.0002)
[2023-08-29 14:10:15,571][02270] Updated weights for policy 0, policy_version 19536 (0.0002)
[2023-08-29 14:10:15,784][02275] Stopping RolloutWorker_w5...
[2023-08-29 14:10:15,784][02257] Component RolloutWorker_w5 stopped!
[2023-08-29 14:10:15,784][02274] Stopping RolloutWorker_w4...
[2023-08-29 14:10:15,784][02269] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000019544_10006528.pth...
[2023-08-29 14:10:15,784][02278] Stopping RolloutWorker_w3...
[2023-08-29 14:10:15,784][02275] Loop rollout_proc5_evt_loop terminating...
[2023-08-29 14:10:15,784][02257] Component RolloutWorker_w3 stopped!
[2023-08-29 14:10:15,784][02257] Component RolloutWorker_w4 stopped!
[2023-08-29 14:10:15,784][02278] Loop rollout_proc3_evt_loop terminating...
[2023-08-29 14:10:15,784][02274] Loop rollout_proc4_evt_loop terminating...
[2023-08-29 14:10:15,784][02277] Stopping RolloutWorker_w7...
[2023-08-29 14:10:15,784][02272] Stopping RolloutWorker_w1...
[2023-08-29 14:10:15,784][02257] Component RolloutWorker_w1 stopped!
[2023-08-29 14:10:15,784][02277] Loop rollout_proc7_evt_loop terminating...
[2023-08-29 14:10:15,784][02276] Stopping RolloutWorker_w6...
[2023-08-29 14:10:15,784][02273] Stopping RolloutWorker_w2...
[2023-08-29 14:10:15,785][02276] Loop rollout_proc6_evt_loop terminating...
[2023-08-29 14:10:15,785][02273] Loop rollout_proc2_evt_loop terminating...
[2023-08-29 14:10:15,785][02272] Loop rollout_proc1_evt_loop terminating...
[2023-08-29 14:10:15,785][02257] Component RolloutWorker_w6 stopped!
[2023-08-29 14:10:15,785][02257] Component RolloutWorker_w7 stopped!
[2023-08-29 14:10:15,785][02257] Component RolloutWorker_w2 stopped!
[2023-08-29 14:10:15,785][02257] Component RolloutWorker_w0 stopped!
[2023-08-29 14:10:15,784][02271] Stopping RolloutWorker_w0...
[2023-08-29 14:10:15,786][02269] Removing /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000014296_7319552.pth
[2023-08-29 14:10:15,786][02271] Loop rollout_proc0_evt_loop terminating...
[2023-08-29 14:10:15,787][02269] Saving new best policy, reward=-10330.609!
[2023-08-29 14:10:15,790][02269] Stopping Batcher_0...
[2023-08-29 14:10:15,790][02269] Loop batcher_evt_loop terminating...
[2023-08-29 14:10:15,790][02257] Component Batcher_0 stopped!
[2023-08-29 14:10:15,790][02269] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000019544_10006528.pth...
[2023-08-29 14:10:15,793][02269] Stopping LearnerWorker_p0...
[2023-08-29 14:10:15,793][02269] Loop learner_proc0_evt_loop terminating...
[2023-08-29 14:10:15,794][02257] Component LearnerWorker_p0 stopped!
[2023-08-29 14:10:15,872][02270] Weights refcount: 2 0
[2023-08-29 14:10:15,872][02270] Stopping InferenceWorker_p0-w0...
[2023-08-29 14:10:15,873][02270] Loop inference_proc0-0_evt_loop terminating...
[2023-08-29 14:10:15,880][02257] Component InferenceWorker_p0-w0 stopped!
[2023-08-29 14:10:15,880][02257] Waiting for process learner_proc0 to stop...
[2023-08-29 14:10:16,237][02257] Waiting for process inference_proc0-0 to join...
[2023-08-29 14:10:16,245][02257] Waiting for process rollout_proc0 to join...
[2023-08-29 14:10:16,273][02257] Waiting for process rollout_proc1 to join...
[2023-08-29 14:10:16,273][02257] Waiting for process rollout_proc2 to join...
[2023-08-29 14:10:16,275][02257] Waiting for process rollout_proc3 to join...
[2023-08-29 14:10:16,275][02257] Waiting for process rollout_proc4 to join...
[2023-08-29 14:10:16,275][02257] Waiting for process rollout_proc5 to join...
[2023-08-29 14:10:16,276][02257] Waiting for process rollout_proc6 to join...
[2023-08-29 14:10:16,276][02257] Waiting for process rollout_proc7 to join...
[2023-08-29 14:10:16,276][02257] Batcher 0 profile tree view:
batching: 2.7798, releasing_batches: 0.7744
[2023-08-29 14:10:16,276][02257] InferenceWorker_p0-w0 profile tree view:
wait_policy: 0.0063
  wait_policy_total: 111.7105
update_model: 6.2085
  weight_update: 0.0002
one_step: 0.0004
  handle_policy_step: 382.6014
    deserialize: 12.7581, stack: 3.6665, obs_to_device_normalize: 62.9801, forward: 164.5476, send_messages: 71.3895
    prepare_outputs: 33.3811
      to_cpu: 4.6354
[2023-08-29 14:10:16,276][02257] Learner 0 profile tree view:
misc: 0.0036, prepare_batch: 5.4253
train: 50.5547
  epoch_init: 0.0216, minibatch_init: 0.5366, losses_postprocess: 0.7788, kl_divergence: 0.2874, after_optimizer: 0.3886
  calculate_losses: 22.0665
    losses_init: 0.0250, forward_head: 9.9836, bptt_initial: 0.0565, bptt: 0.0619, tail: 5.6179, advantages_returns: 0.5238, losses: 5.1515
  update: 25.7374
    clip: 2.3725
[2023-08-29 14:10:16,276][02257] RolloutWorker_w0 profile tree view:
wait_for_trajectories: 0.3376, enqueue_policy_requests: 22.5950, env_step: 117.5242, overhead: 16.5223, complete_rollouts: 0.9106
save_policy_outputs: 48.0349
  split_output_tensors: 16.7151
[2023-08-29 14:10:16,276][02257] RolloutWorker_w7 profile tree view:
wait_for_trajectories: 0.3140, enqueue_policy_requests: 22.7185, env_step: 117.8189, overhead: 16.0891, complete_rollouts: 0.9002
save_policy_outputs: 47.8100
  split_output_tensors: 16.5837
[2023-08-29 14:10:16,277][02257] Loop Runner_EvtLoop terminating...
[2023-08-29 14:10:16,277][02257] Runner profile tree view:
main_loop: 552.3791
[2023-08-29 14:10:16,277][02257] Collected {0: 10006528}, FPS: 17433.1
[2023-08-31 21:31:15,941][25909] Saving configuration to /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/config.json...
[2023-08-31 21:31:15,964][25909] Rollout worker 0 uses device cpu
[2023-08-31 21:31:15,964][25909] Rollout worker 1 uses device cpu
[2023-08-31 21:31:15,964][25909] Rollout worker 2 uses device cpu
[2023-08-31 21:31:15,964][25909] Rollout worker 3 uses device cpu
[2023-08-31 21:31:15,964][25909] Rollout worker 4 uses device cpu
[2023-08-31 21:31:15,964][25909] Rollout worker 5 uses device cpu
[2023-08-31 21:31:15,965][25909] Rollout worker 6 uses device cpu
[2023-08-31 21:31:15,965][25909] Rollout worker 7 uses device cpu
[2023-08-31 21:31:15,965][25909] In synchronous mode, we only accumulate one batch. Setting num_batches_to_accumulate to 1
[2023-08-31 21:31:16,185][25909] InferenceWorker_p0-w0: min num requests: 2
[2023-08-31 21:31:16,222][25909] Starting all processes...
[2023-08-31 21:31:16,222][25909] Starting process learner_proc0
[2023-08-31 21:31:16,285][25909] Starting all processes...
[2023-08-31 21:31:16,369][25909] Starting process inference_proc0-0
[2023-08-31 21:31:16,369][25909] Starting process rollout_proc0
[2023-08-31 21:31:16,369][25909] Starting process rollout_proc1
[2023-08-31 21:31:16,370][25909] Starting process rollout_proc2
[2023-08-31 21:31:16,370][25909] Starting process rollout_proc3
[2023-08-31 21:31:16,370][25909] Starting process rollout_proc4
[2023-08-31 21:31:16,370][25909] Starting process rollout_proc5
[2023-08-31 21:31:16,373][25909] Starting process rollout_proc6
[2023-08-31 21:31:16,373][25909] Starting process rollout_proc7
[2023-08-31 21:31:18,961][25923] Starting seed is not provided
[2023-08-31 21:31:18,962][25923] Initializing actor-critic model on device cpu
[2023-08-31 21:31:18,962][25923] RunningMeanStd input shape: (8,)
[2023-08-31 21:31:18,963][25923] RunningMeanStd input shape: (1,)
[2023-08-31 21:31:18,971][25931] On MacOS, not setting affinity
[2023-08-31 21:31:19,005][25932] On MacOS, not setting affinity
[2023-08-31 21:31:19,072][25929] On MacOS, not setting affinity
[2023-08-31 21:31:19,076][25923] Created Actor Critic model with architecture:
[2023-08-31 21:31:19,076][25923] ActorCriticSharedWeights(
  (obs_normalizer): ObservationNormalizer(
    (running_mean_std): RunningMeanStdDictInPlace(
      (running_mean_std): ModuleDict(
        (obs): RunningMeanStdInPlace()
      )
    )
  )
  (returns_normalizer): RecursiveScriptModule(original_name=RunningMeanStdInPlace)
  (encoder): MultiInputEncoder(
    (encoders): ModuleDict(
      (obs): MlpEncoder(
        (mlp_head): RecursiveScriptModule(
          original_name=Sequential
          (0): RecursiveScriptModule(original_name=Linear)
          (1): RecursiveScriptModule(original_name=ELU)
          (2): RecursiveScriptModule(original_name=Linear)
          (3): RecursiveScriptModule(original_name=ELU)
        )
      )
    )
  )
  (core): ModelCoreIdentity()
  (decoder): MlpDecoder(
    (mlp): Identity()
  )
  (critic_linear): Linear(in_features=64, out_features=1, bias=True)
  (action_parameterization): ActionParameterizationDefault(
    (distribution_linear): Linear(in_features=64, out_features=18, bias=True)
  )
)
[2023-08-31 21:31:19,077][25923] Using optimizer <class 'torch.optim.adam.Adam'>
[2023-08-31 21:31:19,078][25923] Loading state from checkpoint /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000019544_10006528.pth...
[2023-08-31 21:31:19,080][25923] Loading model from checkpoint
[2023-08-31 21:31:19,081][25923] Loaded experiment state at self.train_step=19544, self.env_steps=10006528
[2023-08-31 21:31:19,081][25923] Initialized policy 0 weights for model version 19544
[2023-08-31 21:31:19,082][25923] LearnerWorker_p0 finished initialization!
[2023-08-31 21:31:19,085][25925] RunningMeanStd input shape: (8,)
[2023-08-31 21:31:19,086][25925] RunningMeanStd input shape: (1,)
[2023-08-31 21:31:19,100][25926] On MacOS, not setting affinity
[2023-08-31 21:31:19,100][25924] On MacOS, not setting affinity
[2023-08-31 21:31:19,100][25930] On MacOS, not setting affinity
[2023-08-31 21:31:19,100][25927] On MacOS, not setting affinity
[2023-08-31 21:31:19,104][25928] On MacOS, not setting affinity
[2023-08-31 21:31:19,136][25909] Inference worker 0-0 is ready!
[2023-08-31 21:31:19,137][25909] All inference workers are ready! Signal rollout workers to start!
[2023-08-31 21:31:19,443][25929] Decorrelating experience for 0 frames...
[2023-08-31 21:31:19,446][25932] Decorrelating experience for 0 frames...
[2023-08-31 21:31:19,447][25931] Decorrelating experience for 0 frames...
[2023-08-31 21:31:19,456][25926] Decorrelating experience for 0 frames...
[2023-08-31 21:31:19,475][25928] Decorrelating experience for 0 frames...
[2023-08-31 21:31:19,495][25924] Decorrelating experience for 0 frames...
[2023-08-31 21:31:19,500][25930] Decorrelating experience for 0 frames...
[2023-08-31 21:31:19,506][25927] Decorrelating experience for 0 frames...
[2023-08-31 21:31:19,602][25932] Decorrelating experience for 64 frames...
[2023-08-31 21:31:19,624][25931] Decorrelating experience for 64 frames...
[2023-08-31 21:31:19,656][25929] Decorrelating experience for 64 frames...
[2023-08-31 21:31:19,673][25928] Decorrelating experience for 64 frames...
[2023-08-31 21:31:19,687][25926] Decorrelating experience for 64 frames...
[2023-08-31 21:31:19,687][25927] Decorrelating experience for 64 frames...
[2023-08-31 21:31:19,704][25930] Decorrelating experience for 64 frames...
[2023-08-31 21:31:19,710][25924] Decorrelating experience for 64 frames...
[2023-08-31 21:31:19,716][25909] Fps is (10 sec: nan, 60 sec: nan, 300 sec: nan). Total num frames: 10006528. Throughput: 0: nan. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2023-08-31 21:31:20,141][25930] Stopping RolloutWorker_w6...
[2023-08-31 21:31:20,141][25929] Stopping RolloutWorker_w5...
[2023-08-31 21:31:20,141][25932] Stopping RolloutWorker_w3...
[2023-08-31 21:31:20,141][25931] Stopping RolloutWorker_w7...
[2023-08-31 21:31:20,141][25930] Loop rollout_proc6_evt_loop terminating...
[2023-08-31 21:31:20,141][25932] Loop rollout_proc3_evt_loop terminating...
[2023-08-31 21:31:20,141][25931] Loop rollout_proc7_evt_loop terminating...
[2023-08-31 21:31:20,141][25923] Stopping Batcher_0...
[2023-08-31 21:31:20,141][25924] Stopping RolloutWorker_w1...
[2023-08-31 21:31:20,141][25923] Loop batcher_evt_loop terminating...
[2023-08-31 21:31:20,141][25924] Loop rollout_proc1_evt_loop terminating...
[2023-08-31 21:31:20,141][25928] Stopping RolloutWorker_w4...
[2023-08-31 21:31:20,142][25928] Loop rollout_proc4_evt_loop terminating...
[2023-08-31 21:31:20,141][25929] Loop rollout_proc5_evt_loop terminating...
[2023-08-31 21:31:20,142][25927] Stopping RolloutWorker_w2...
[2023-08-31 21:31:20,144][25927] Loop rollout_proc2_evt_loop terminating...
[2023-08-31 21:31:20,142][25926] Stopping RolloutWorker_w0...
[2023-08-31 21:31:20,143][25923] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000019552_10010624.pth...
[2023-08-31 21:31:20,145][25926] Loop rollout_proc0_evt_loop terminating...
[2023-08-31 21:31:20,158][25923] Removing /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000017728_9076736.pth
[2023-08-31 21:31:20,159][25923] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000019552_10010624.pth...
[2023-08-31 21:31:20,161][25923] Stopping LearnerWorker_p0...
[2023-08-31 21:31:20,161][25923] Loop learner_proc0_evt_loop terminating...
[2023-08-31 21:31:20,215][25925] Weights refcount: 2 0
[2023-08-31 21:31:20,216][25925] Stopping InferenceWorker_p0-w0...
[2023-08-31 21:31:20,216][25925] Loop inference_proc0-0_evt_loop terminating...
[2023-08-31 21:31:20,222][25909] Component RolloutWorker_w6 stopped!
[2023-08-31 21:31:20,222][25909] Component RolloutWorker_w3 stopped!
[2023-08-31 21:31:20,222][25909] Component RolloutWorker_w5 stopped!
[2023-08-31 21:31:20,222][25909] Component RolloutWorker_w7 stopped!
[2023-08-31 21:31:20,222][25909] Component RolloutWorker_w1 stopped!
[2023-08-31 21:31:20,223][25909] Component Batcher_0 stopped!
[2023-08-31 21:31:20,223][25909] Component RolloutWorker_w4 stopped!
[2023-08-31 21:31:20,223][25909] Component RolloutWorker_w2 stopped!
[2023-08-31 21:31:20,224][25909] Component RolloutWorker_w0 stopped!
[2023-08-31 21:31:20,224][25909] Component LearnerWorker_p0 stopped!
[2023-08-31 21:31:20,224][25909] Component InferenceWorker_p0-w0 stopped!
[2023-08-31 21:31:20,224][25909] Waiting for process learner_proc0 to stop...
[2023-08-31 21:31:20,612][25909] Waiting for process inference_proc0-0 to join...
[2023-08-31 21:31:20,699][25909] Waiting for process rollout_proc0 to join...
[2023-08-31 21:31:20,699][25909] Waiting for process rollout_proc1 to join...
[2023-08-31 21:31:20,699][25909] Waiting for process rollout_proc2 to join...
[2023-08-31 21:31:20,699][25909] Waiting for process rollout_proc3 to join...
[2023-08-31 21:31:20,699][25909] Waiting for process rollout_proc4 to join...
[2023-08-31 21:31:20,699][25909] Waiting for process rollout_proc5 to join...
[2023-08-31 21:31:20,699][25909] Waiting for process rollout_proc6 to join...
[2023-08-31 21:31:20,699][25909] Waiting for process rollout_proc7 to join...
[2023-08-31 21:31:20,699][25909] Batcher 0 profile tree view:
batching: 0.0016, releasing_batches: 0.0004
[2023-08-31 21:31:20,699][25909] InferenceWorker_p0-w0 profile tree view:
update_model: 0.0056
wait_policy: 0.0124
  wait_policy_total: 0.6341
one_step: 0.0006
  handle_policy_step: 0.3489
    deserialize: 0.0093, stack: 0.0032, obs_to_device_normalize: 0.0608, forward: 0.1817, send_messages: 0.0383
    prepare_outputs: 0.0300
      to_cpu: 0.0032
[2023-08-31 21:31:20,699][25909] Learner 0 profile tree view:
misc: 0.0000, prepare_batch: 0.0214
train: 0.0568
  epoch_init: 0.0000, minibatch_init: 0.0003, losses_postprocess: 0.0010, kl_divergence: 0.0002, after_optimizer: 0.0026
  calculate_losses: 0.0155
    losses_init: 0.0000, forward_head: 0.0047, bptt_initial: 0.0000, bptt: 0.0001, tail: 0.0050, advantages_returns: 0.0009, losses: 0.0044
  update: 0.0360
    clip: 0.0029
[2023-08-31 21:31:20,699][25909] RolloutWorker_w0 profile tree view:
wait_for_trajectories: 0.0002, enqueue_policy_requests: 0.0135, env_step: 0.0642, overhead: 0.0123, complete_rollouts: 0.0004
save_policy_outputs: 0.0226
  split_output_tensors: 0.0080
[2023-08-31 21:31:20,700][25909] RolloutWorker_w7 profile tree view:
wait_for_trajectories: 0.0002, enqueue_policy_requests: 0.0143, env_step: 0.0679, overhead: 0.0106, complete_rollouts: 0.0007
save_policy_outputs: 0.0222
  split_output_tensors: 0.0076
[2023-08-31 21:31:20,700][25909] Loop Runner_EvtLoop terminating...
[2023-08-31 21:31:20,700][25909] Runner profile tree view:
main_loop: 4.4786
[2023-08-31 21:31:20,700][25909] Collected {0: 10010624}, FPS: 914.6
[2023-08-31 21:31:45,871][26005] Saving configuration to /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/config.json...
[2023-08-31 21:31:45,892][26005] Rollout worker 0 uses device cpu
[2023-08-31 21:31:45,893][26005] Rollout worker 1 uses device cpu
[2023-08-31 21:31:45,893][26005] Rollout worker 2 uses device cpu
[2023-08-31 21:31:45,893][26005] Rollout worker 3 uses device cpu
[2023-08-31 21:31:45,893][26005] Rollout worker 4 uses device cpu
[2023-08-31 21:31:45,893][26005] Rollout worker 5 uses device cpu
[2023-08-31 21:31:45,893][26005] Rollout worker 6 uses device cpu
[2023-08-31 21:31:45,893][26005] Rollout worker 7 uses device cpu
[2023-08-31 21:31:45,893][26005] In synchronous mode, we only accumulate one batch. Setting num_batches_to_accumulate to 1
[2023-08-31 21:31:46,077][26005] InferenceWorker_p0-w0: min num requests: 2
[2023-08-31 21:31:46,122][26005] Starting all processes...
[2023-08-31 21:31:46,122][26005] Starting process learner_proc0
[2023-08-31 21:31:46,175][26005] Starting all processes...
[2023-08-31 21:31:46,207][26005] Starting process inference_proc0-0
[2023-08-31 21:31:46,215][26005] Starting process rollout_proc0
[2023-08-31 21:31:46,231][26005] Starting process rollout_proc1
[2023-08-31 21:31:46,234][26005] Starting process rollout_proc2
[2023-08-31 21:31:46,250][26005] Starting process rollout_proc3
[2023-08-31 21:31:46,261][26005] Starting process rollout_proc4
[2023-08-31 21:31:46,267][26005] Starting process rollout_proc5
[2023-08-31 21:31:46,270][26005] Starting process rollout_proc6
[2023-08-31 21:31:46,276][26005] Starting process rollout_proc7
[2023-08-31 21:31:48,626][26019] On MacOS, not setting affinity
[2023-08-31 21:31:48,706][26018] On MacOS, not setting affinity
[2023-08-31 21:31:48,733][26016] Starting seed is not provided
[2023-08-31 21:31:48,733][26016] Initializing actor-critic model on device cpu
[2023-08-31 21:31:48,734][26016] RunningMeanStd input shape: (8,)
[2023-08-31 21:31:48,735][26016] RunningMeanStd input shape: (1,)
[2023-08-31 21:31:48,758][26020] On MacOS, not setting affinity
[2023-08-31 21:31:48,758][26025] On MacOS, not setting affinity
[2023-08-31 21:31:48,798][26022] On MacOS, not setting affinity
[2023-08-31 21:31:48,798][26021] On MacOS, not setting affinity
[2023-08-31 21:31:48,805][26023] On MacOS, not setting affinity
[2023-08-31 21:31:48,841][26016] Created Actor Critic model with architecture:
[2023-08-31 21:31:48,841][26016] ActorCriticSharedWeights(
  (obs_normalizer): ObservationNormalizer(
    (running_mean_std): RunningMeanStdDictInPlace(
      (running_mean_std): ModuleDict(
        (obs): RunningMeanStdInPlace()
      )
    )
  )
  (returns_normalizer): RecursiveScriptModule(original_name=RunningMeanStdInPlace)
  (encoder): MultiInputEncoder(
    (encoders): ModuleDict(
      (obs): MlpEncoder(
        (mlp_head): RecursiveScriptModule(
          original_name=Sequential
          (0): RecursiveScriptModule(original_name=Linear)
          (1): RecursiveScriptModule(original_name=ELU)
          (2): RecursiveScriptModule(original_name=Linear)
          (3): RecursiveScriptModule(original_name=ELU)
        )
      )
    )
  )
  (core): ModelCoreIdentity()
  (decoder): MlpDecoder(
    (mlp): Identity()
  )
  (critic_linear): Linear(in_features=64, out_features=1, bias=True)
  (action_parameterization): ActionParameterizationDefault(
    (distribution_linear): Linear(in_features=64, out_features=18, bias=True)
  )
)
[2023-08-31 21:31:48,847][26016] Using optimizer <class 'torch.optim.adam.Adam'>
[2023-08-31 21:31:48,850][26016] Loading state from checkpoint /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000019552_10010624.pth...
[2023-08-31 21:31:48,850][26024] On MacOS, not setting affinity
[2023-08-31 21:31:48,852][26016] Loading model from checkpoint
[2023-08-31 21:31:48,854][26016] Loaded experiment state at self.train_step=19552, self.env_steps=10010624
[2023-08-31 21:31:48,854][26016] Initialized policy 0 weights for model version 19552
[2023-08-31 21:31:48,855][26016] LearnerWorker_p0 finished initialization!
[2023-08-31 21:31:48,856][26017] RunningMeanStd input shape: (8,)
[2023-08-31 21:31:48,859][26017] RunningMeanStd input shape: (1,)
[2023-08-31 21:31:48,908][26005] Inference worker 0-0 is ready!
[2023-08-31 21:31:48,908][26005] All inference workers are ready! Signal rollout workers to start!
[2023-08-31 21:31:49,134][26023] Decorrelating experience for 0 frames...
[2023-08-31 21:31:49,134][26020] Decorrelating experience for 0 frames...
[2023-08-31 21:31:49,147][26021] Decorrelating experience for 0 frames...
[2023-08-31 21:31:49,148][26018] Decorrelating experience for 0 frames...
[2023-08-31 21:31:49,149][26019] Decorrelating experience for 0 frames...
[2023-08-31 21:31:49,151][26025] Decorrelating experience for 0 frames...
[2023-08-31 21:31:49,171][26022] Decorrelating experience for 0 frames...
[2023-08-31 21:31:49,172][26024] Decorrelating experience for 0 frames...
[2023-08-31 21:31:49,300][26020] Decorrelating experience for 64 frames...
[2023-08-31 21:31:49,304][26019] Decorrelating experience for 64 frames...
[2023-08-31 21:31:49,315][26018] Decorrelating experience for 64 frames...
[2023-08-31 21:31:49,315][26025] Decorrelating experience for 64 frames...
[2023-08-31 21:31:49,323][26023] Decorrelating experience for 64 frames...
[2023-08-31 21:31:49,325][26022] Decorrelating experience for 64 frames...
[2023-08-31 21:31:49,327][26021] Decorrelating experience for 64 frames...
[2023-08-31 21:31:49,336][26024] Decorrelating experience for 64 frames...
[2023-08-31 21:31:49,737][26005] Fps is (10 sec: nan, 60 sec: nan, 300 sec: nan). Total num frames: 10014720. Throughput: 0: nan. Samples: 0. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:31:52,075][26017] Updated weights for policy 0, policy_version 19632 (0.0003)
[2023-08-31 21:31:54,628][26017] Updated weights for policy 0, policy_version 19712 (0.0003)
[2023-08-31 21:31:54,735][26005] Fps is (10 sec: 15570.4, 60 sec: 15570.4, 300 sec: 15570.4). Total num frames: 10092544. Throughput: 0: 7833.2. Samples: 39152. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:31:57,294][26017] Updated weights for policy 0, policy_version 19792 (0.0003)
[2023-08-31 21:31:59,736][26005] Fps is (10 sec: 14747.1, 60 sec: 14747.1, 300 sec: 14747.1). Total num frames: 10162176. Throughput: 0: 13110.2. Samples: 131088. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:32:00,676][26017] Updated weights for policy 0, policy_version 19872 (0.0003)
[2023-08-31 21:32:03,546][26017] Updated weights for policy 0, policy_version 19952 (0.0003)
[2023-08-31 21:32:04,737][26005] Fps is (10 sec: 13924.9, 60 sec: 14473.2, 300 sec: 14473.2). Total num frames: 10231808. Throughput: 0: 14066.9. Samples: 210993. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[2023-08-31 21:32:04,737][26005] Avg episode reward: [(0, '-10316.262')]
[2023-08-31 21:32:04,738][26016] Saving new best policy, reward=-10316.262!
[2023-08-31 21:32:06,065][26005] Heartbeat connected on Batcher_0
[2023-08-31 21:32:06,067][26005] Heartbeat connected on LearnerWorker_p0
[2023-08-31 21:32:06,077][26005] Heartbeat connected on InferenceWorker_p0-w0
[2023-08-31 21:32:06,082][26005] Heartbeat connected on RolloutWorker_w0
[2023-08-31 21:32:06,087][26005] Heartbeat connected on RolloutWorker_w1
[2023-08-31 21:32:06,092][26005] Heartbeat connected on RolloutWorker_w2
[2023-08-31 21:32:06,097][26005] Heartbeat connected on RolloutWorker_w3
[2023-08-31 21:32:06,100][26005] Heartbeat connected on RolloutWorker_w4
[2023-08-31 21:32:06,105][26005] Heartbeat connected on RolloutWorker_w5
[2023-08-31 21:32:06,118][26005] Heartbeat connected on RolloutWorker_w6
[2023-08-31 21:32:06,122][26005] Heartbeat connected on RolloutWorker_w7
[2023-08-31 21:32:06,237][26017] Updated weights for policy 0, policy_version 20032 (0.0003)
[2023-08-31 21:32:07,503][26016] KL-divergence is very high: 125.1986
[2023-08-31 21:32:08,019][26016] KL-divergence is very high: 193.2574
[2023-08-31 21:32:08,815][26017] Updated weights for policy 0, policy_version 20112 (0.0003)
[2023-08-31 21:32:09,735][26005] Fps is (10 sec: 14748.0, 60 sec: 14747.6, 300 sec: 14747.6). Total num frames: 10309632. Throughput: 0: 12862.5. Samples: 257215. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[2023-08-31 21:32:09,735][26005] Avg episode reward: [(0, '-10316.262')]
[2023-08-31 21:32:12,132][26017] Updated weights for policy 0, policy_version 20192 (0.0003)
[2023-08-31 21:32:12,406][26016] KL-divergence is very high: 136.7137
[2023-08-31 21:32:14,735][26005] Fps is (10 sec: 14338.2, 60 sec: 14419.2, 300 sec: 14419.2). Total num frames: 10375168. Throughput: 0: 13600.6. Samples: 339984. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[2023-08-31 21:32:14,735][26005] Avg episode reward: [(0, '-11568.545')]
[2023-08-31 21:32:14,765][26017] Updated weights for policy 0, policy_version 20272 (0.0003)
[2023-08-31 21:32:17,331][26017] Updated weights for policy 0, policy_version 20352 (0.0002)
[2023-08-31 21:32:19,712][26016] KL-divergence is very high: 121.9458
[2023-08-31 21:32:19,714][26017] Updated weights for policy 0, policy_version 20432 (0.0002)
[2023-08-31 21:32:19,737][26005] Fps is (10 sec: 15151.9, 60 sec: 14882.4, 300 sec: 14882.4). Total num frames: 10461184. Throughput: 0: 14579.1. Samples: 437365. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:32:19,737][26005] Avg episode reward: [(0, '-11568.545')]
[2023-08-31 21:32:22,837][26017] Updated weights for policy 0, policy_version 20512 (0.0003)
[2023-08-31 21:32:24,735][26005] Fps is (10 sec: 15155.5, 60 sec: 14629.6, 300 sec: 14629.6). Total num frames: 10526720. Throughput: 0: 13719.6. Samples: 480152. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:32:24,735][26005] Avg episode reward: [(0, '-9213.608')]
[2023-08-31 21:32:24,735][26016] Saving new best policy, reward=-9213.608!
[2023-08-31 21:32:25,484][26017] Updated weights for policy 0, policy_version 20592 (0.0003)
[2023-08-31 21:32:28,100][26017] Updated weights for policy 0, policy_version 20672 (0.0003)
[2023-08-31 21:32:29,737][26005] Fps is (10 sec: 14745.2, 60 sec: 14848.1, 300 sec: 14848.1). Total num frames: 10608640. Throughput: 0: 14281.2. Samples: 571246. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:32:29,737][26005] Avg episode reward: [(0, '-9213.608')]
[2023-08-31 21:32:30,688][26017] Updated weights for policy 0, policy_version 20752 (0.0002)
[2023-08-31 21:32:33,494][26017] Updated weights for policy 0, policy_version 20832 (0.0002)
[2023-08-31 21:32:34,511][26016] KL-divergence is very high: 137.8809
[2023-08-31 21:32:34,737][26005] Fps is (10 sec: 15561.8, 60 sec: 14836.8, 300 sec: 14836.8). Total num frames: 10682368. Throughput: 0: 14705.1. Samples: 661722. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:32:34,737][26005] Avg episode reward: [(0, '-8001.997')]
[2023-08-31 21:32:34,738][26016] Saving new best policy, reward=-8001.997!
[2023-08-31 21:32:36,079][26017] Updated weights for policy 0, policy_version 20912 (0.0003)
[2023-08-31 21:32:38,508][26017] Updated weights for policy 0, policy_version 20992 (0.0002)
[2023-08-31 21:32:39,736][26005] Fps is (10 sec: 15566.8, 60 sec: 14991.8, 300 sec: 14991.8). Total num frames: 10764288. Throughput: 0: 14912.5. Samples: 710220. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:32:39,736][26005] Avg episode reward: [(0, '-8001.997')]
[2023-08-31 21:32:41,044][26017] Updated weights for policy 0, policy_version 21072 (0.0002)
[2023-08-31 21:32:43,840][26017] Updated weights for policy 0, policy_version 21152 (0.0002)
[2023-08-31 21:32:44,737][26005] Fps is (10 sec: 15974.3, 60 sec: 15043.6, 300 sec: 15043.6). Total num frames: 10842112. Throughput: 0: 14952.0. Samples: 803937. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:32:44,737][26005] Avg episode reward: [(0, '-7977.126')]
[2023-08-31 21:32:44,737][26016] Saving new best policy, reward=-7977.126!
[2023-08-31 21:32:46,346][26017] Updated weights for policy 0, policy_version 21232 (0.0003)
[2023-08-31 21:32:48,888][26017] Updated weights for policy 0, policy_version 21312 (0.0003)
[2023-08-31 21:32:49,736][26005] Fps is (10 sec: 15974.0, 60 sec: 15155.5, 300 sec: 15155.5). Total num frames: 10924032. Throughput: 0: 15344.0. Samples: 901465. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:32:49,736][26005] Avg episode reward: [(0, '-7977.126')]
[2023-08-31 21:32:51,498][26017] Updated weights for policy 0, policy_version 21392 (0.0003)
[2023-08-31 21:32:54,423][26017] Updated weights for policy 0, policy_version 21472 (0.0003)
[2023-08-31 21:32:54,736][26005] Fps is (10 sec: 15565.2, 60 sec: 15086.7, 300 sec: 15123.9). Total num frames: 10997760. Throughput: 0: 15379.5. Samples: 949322. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:32:54,737][26005] Avg episode reward: [(0, '-7017.920')]
[2023-08-31 21:32:54,737][26016] Saving new best policy, reward=-7017.920!
[2023-08-31 21:32:57,062][26017] Updated weights for policy 0, policy_version 21552 (0.0003)
[2023-08-31 21:32:59,735][26005] Fps is (10 sec: 14336.8, 60 sec: 15087.1, 300 sec: 15038.6). Total num frames: 11067392. Throughput: 0: 15507.3. Samples: 1037819. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:32:59,736][26005] Avg episode reward: [(0, '-7017.920')]
[2023-08-31 21:33:00,179][26017] Updated weights for policy 0, policy_version 21632 (0.0003)
[2023-08-31 21:33:03,208][26017] Updated weights for policy 0, policy_version 21712 (0.0003)
[2023-08-31 21:33:04,736][26005] Fps is (10 sec: 13107.4, 60 sec: 14950.5, 300 sec: 14855.0). Total num frames: 11128832. Throughput: 0: 15043.8. Samples: 1114328. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:33:04,737][26005] Avg episode reward: [(0, '-6334.574')]
[2023-08-31 21:33:04,755][26016] Saving new best policy, reward=-6334.574!
[2023-08-31 21:33:06,547][26017] Updated weights for policy 0, policy_version 21792 (0.0003)
[2023-08-31 21:33:09,474][26017] Updated weights for policy 0, policy_version 21872 (0.0003)
[2023-08-31 21:33:09,737][26005] Fps is (10 sec: 13514.9, 60 sec: 14881.6, 300 sec: 14848.1). Total num frames: 11202560. Throughput: 0: 14908.2. Samples: 1151054. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:33:09,737][26005] Avg episode reward: [(0, '-6334.574')]
[2023-08-31 21:33:12,146][26017] Updated weights for policy 0, policy_version 21952 (0.0003)
[2023-08-31 21:33:14,736][26005] Fps is (10 sec: 14745.6, 60 sec: 15018.3, 300 sec: 14842.1). Total num frames: 11276288. Throughput: 0: 14870.0. Samples: 1240384. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:33:14,736][26005] Avg episode reward: [(0, '-6334.574')]
[2023-08-31 21:33:14,972][26017] Updated weights for policy 0, policy_version 22032 (0.0002)
[2023-08-31 21:33:18,047][26017] Updated weights for policy 0, policy_version 22112 (0.0003)
[2023-08-31 21:33:19,735][26005] Fps is (10 sec: 14338.5, 60 sec: 14746.0, 300 sec: 14791.5). Total num frames: 11345920. Throughput: 0: 14703.4. Samples: 1323353. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:33:19,735][26005] Avg episode reward: [(0, '-4526.619')]
[2023-08-31 21:33:19,736][26016] Saving new best policy, reward=-4526.619!
[2023-08-31 21:33:20,766][26017] Updated weights for policy 0, policy_version 22192 (0.0003)
[2023-08-31 21:33:23,401][26017] Updated weights for policy 0, policy_version 22272 (0.0003)
[2023-08-31 21:33:24,735][26005] Fps is (10 sec: 14338.0, 60 sec: 14882.1, 300 sec: 14789.1). Total num frames: 11419648. Throughput: 0: 14665.7. Samples: 1370165. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:33:24,735][26005] Avg episode reward: [(0, '-4526.619')]
[2023-08-31 21:33:24,738][26016] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000022304_11419648.pth...
[2023-08-31 21:33:24,740][26016] Removing /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000019544_10006528.pth
[2023-08-31 21:33:26,371][26017] Updated weights for policy 0, policy_version 22352 (0.0003)
[2023-08-31 21:33:29,425][26017] Updated weights for policy 0, policy_version 22432 (0.0003)
[2023-08-31 21:33:29,737][26005] Fps is (10 sec: 14333.7, 60 sec: 14677.4, 300 sec: 14745.7). Total num frames: 11489280. Throughput: 0: 14381.3. Samples: 1451096. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:33:29,737][26005] Avg episode reward: [(0, '-3991.432')]
[2023-08-31 21:33:29,737][26016] Saving new best policy, reward=-3991.432!
[2023-08-31 21:33:32,106][26017] Updated weights for policy 0, policy_version 22512 (0.0003)
[2023-08-31 21:33:34,736][26005] Fps is (10 sec: 13925.1, 60 sec: 14609.3, 300 sec: 14706.8). Total num frames: 11558912. Throughput: 0: 14191.1. Samples: 1540059. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[2023-08-31 21:33:34,736][26005] Avg episode reward: [(0, '-3991.432')]
[2023-08-31 21:33:35,122][26017] Updated weights for policy 0, policy_version 22592 (0.0003)
[2023-08-31 21:33:38,084][26017] Updated weights for policy 0, policy_version 22672 (0.0003)
[2023-08-31 21:33:39,735][26005] Fps is (10 sec: 13109.4, 60 sec: 14267.9, 300 sec: 14596.9). Total num frames: 11620352. Throughput: 0: 14068.1. Samples: 1582366. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[2023-08-31 21:33:39,736][26005] Avg episode reward: [(0, '-4414.125')]
[2023-08-31 21:33:42,030][26017] Updated weights for policy 0, policy_version 22752 (0.0003)
[2023-08-31 21:33:44,740][26005] Fps is (10 sec: 12691.7, 60 sec: 14062.1, 300 sec: 14531.5). Total num frames: 11685888. Throughput: 0: 13618.3. Samples: 1650708. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[2023-08-31 21:33:44,741][26005] Avg episode reward: [(0, '-4414.125')]
[2023-08-31 21:33:44,899][26017] Updated weights for policy 0, policy_version 22832 (0.0002)
[2023-08-31 21:33:47,630][26017] Updated weights for policy 0, policy_version 22912 (0.0003)
[2023-08-31 21:33:49,736][26005] Fps is (10 sec: 14334.2, 60 sec: 13994.6, 300 sec: 14575.0). Total num frames: 11763712. Throughput: 0: 13922.1. Samples: 1740821. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[2023-08-31 21:33:49,736][26005] Avg episode reward: [(0, '-4414.125')]
[2023-08-31 21:33:50,549][26017] Updated weights for policy 0, policy_version 22992 (0.0002)
[2023-08-31 21:33:53,099][26017] Updated weights for policy 0, policy_version 23072 (0.0002)
[2023-08-31 21:33:54,735][26005] Fps is (10 sec: 14753.6, 60 sec: 13926.7, 300 sec: 14549.3). Total num frames: 11833344. Throughput: 0: 14036.7. Samples: 1782679. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[2023-08-31 21:33:54,735][26005] Avg episode reward: [(0, '-3530.495')]
[2023-08-31 21:33:54,762][26016] Saving new best policy, reward=-3530.495!
[2023-08-31 21:33:56,241][26017] Updated weights for policy 0, policy_version 23152 (0.0003)
[2023-08-31 21:33:58,951][26017] Updated weights for policy 0, policy_version 23232 (0.0003)
[2023-08-31 21:33:59,737][26005] Fps is (10 sec: 13926.0, 60 sec: 13926.1, 300 sec: 14525.1). Total num frames: 11902976. Throughput: 0: 13942.3. Samples: 1867794. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[2023-08-31 21:33:59,737][26005] Avg episode reward: [(0, '-3530.495')]
[2023-08-31 21:34:00,527][26005] Keyboard interrupt detected in the event loop EvtLoop [Runner_EvtLoop, process=main process 26005], exiting...
[2023-08-31 21:34:00,527][26005] Runner profile tree view:
main_loop: 134.4053
[2023-08-31 21:34:00,527][26005] Collected {0: 11915264}, FPS: 14170.9
[2023-08-31 21:34:00,528][26021] Stopping RolloutWorker_w3...
[2023-08-31 21:34:00,528][26019] Stopping RolloutWorker_w1...
[2023-08-31 21:34:00,528][26024] Stopping RolloutWorker_w6...
[2023-08-31 21:34:00,528][26023] Stopping RolloutWorker_w5...
[2023-08-31 21:34:00,528][26022] Stopping RolloutWorker_w4...
[2023-08-31 21:34:00,528][26019] Loop rollout_proc1_evt_loop terminating...
[2023-08-31 21:34:00,528][26021] Loop rollout_proc3_evt_loop terminating...
[2023-08-31 21:34:00,528][26023] Loop rollout_proc5_evt_loop terminating...
[2023-08-31 21:34:00,528][26022] Loop rollout_proc4_evt_loop terminating...
[2023-08-31 21:34:00,528][26024] Loop rollout_proc6_evt_loop terminating...
[2023-08-31 21:34:00,529][26016] Stopping Batcher_0...
[2023-08-31 21:34:00,531][26016] Loop batcher_evt_loop terminating...
[2023-08-31 21:34:00,529][26018] Stopping RolloutWorker_w0...
[2023-08-31 21:34:00,528][26020] Stopping RolloutWorker_w2...
[2023-08-31 21:34:00,531][26025] Stopping RolloutWorker_w7...
[2023-08-31 21:34:00,532][26025] Loop rollout_proc7_evt_loop terminating...
[2023-08-31 21:34:00,530][26016] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000023272_11915264.pth...
[2023-08-31 21:34:00,532][26020] Loop rollout_proc2_evt_loop terminating...
[2023-08-31 21:34:00,533][26018] Loop rollout_proc0_evt_loop terminating...
[2023-08-31 21:34:00,534][26016] Removing /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000019552_10010624.pth
[2023-08-31 21:34:00,537][26016] Stopping LearnerWorker_p0...
[2023-08-31 21:34:00,538][26016] Loop learner_proc0_evt_loop terminating...
[2023-08-31 21:34:00,703][26017] Weights refcount: 2 0
[2023-08-31 21:34:00,704][26017] Stopping InferenceWorker_p0-w0...
[2023-08-31 21:34:00,704][26017] Loop inference_proc0-0_evt_loop terminating...
[2023-08-31 21:34:04,174][26276] Saving configuration to /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/config.json...
[2023-08-31 21:34:04,196][26276] Rollout worker 0 uses device cpu
[2023-08-31 21:34:04,196][26276] Rollout worker 1 uses device cpu
[2023-08-31 21:34:04,196][26276] Rollout worker 2 uses device cpu
[2023-08-31 21:34:04,196][26276] Rollout worker 3 uses device cpu
[2023-08-31 21:34:04,196][26276] Rollout worker 4 uses device cpu
[2023-08-31 21:34:04,196][26276] Rollout worker 5 uses device cpu
[2023-08-31 21:34:04,196][26276] Rollout worker 6 uses device cpu
[2023-08-31 21:34:04,196][26276] Rollout worker 7 uses device cpu
[2023-08-31 21:34:04,196][26276] In synchronous mode, we only accumulate one batch. Setting num_batches_to_accumulate to 1
[2023-08-31 21:34:04,385][26276] InferenceWorker_p0-w0: min num requests: 2
[2023-08-31 21:34:04,425][26276] Starting all processes...
[2023-08-31 21:34:04,425][26276] Starting process learner_proc0
[2023-08-31 21:34:04,484][26276] Starting all processes...
[2023-08-31 21:34:04,497][26276] Starting process inference_proc0-0
[2023-08-31 21:34:04,517][26276] Starting process rollout_proc0
[2023-08-31 21:34:04,526][26276] Starting process rollout_proc1
[2023-08-31 21:34:04,537][26276] Starting process rollout_proc2
[2023-08-31 21:34:04,537][26276] Starting process rollout_proc3
[2023-08-31 21:34:04,543][26276] Starting process rollout_proc4
[2023-08-31 21:34:04,561][26276] Starting process rollout_proc7
[2023-08-31 21:34:04,556][26276] Starting process rollout_proc5
[2023-08-31 21:34:04,556][26276] Starting process rollout_proc6
[2023-08-31 21:34:07,089][26287] Starting seed is not provided
[2023-08-31 21:34:07,089][26287] Initializing actor-critic model on device cpu
[2023-08-31 21:34:07,091][26287] RunningMeanStd input shape: (8,)
[2023-08-31 21:34:07,091][26287] RunningMeanStd input shape: (1,)
[2023-08-31 21:34:07,191][26287] Created Actor Critic model with architecture:
[2023-08-31 21:34:07,192][26287] ActorCriticSharedWeights(
  (obs_normalizer): ObservationNormalizer(
    (running_mean_std): RunningMeanStdDictInPlace(
      (running_mean_std): ModuleDict(
        (obs): RunningMeanStdInPlace()
      )
    )
  )
  (returns_normalizer): RecursiveScriptModule(original_name=RunningMeanStdInPlace)
  (encoder): MultiInputEncoder(
    (encoders): ModuleDict(
      (obs): MlpEncoder(
        (mlp_head): RecursiveScriptModule(
          original_name=Sequential
          (0): RecursiveScriptModule(original_name=Linear)
          (1): RecursiveScriptModule(original_name=ELU)
          (2): RecursiveScriptModule(original_name=Linear)
          (3): RecursiveScriptModule(original_name=ELU)
        )
      )
    )
  )
  (core): ModelCoreIdentity()
  (decoder): MlpDecoder(
    (mlp): Identity()
  )
  (critic_linear): Linear(in_features=64, out_features=1, bias=True)
  (action_parameterization): ActionParameterizationDefault(
    (distribution_linear): Linear(in_features=64, out_features=18, bias=True)
  )
)
[2023-08-31 21:34:07,197][26287] Using optimizer <class 'torch.optim.adam.Adam'>
[2023-08-31 21:34:07,201][26287] Loading state from checkpoint /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000023272_11915264.pth...
[2023-08-31 21:34:07,205][26290] On MacOS, not setting affinity
[2023-08-31 21:34:07,207][26291] On MacOS, not setting affinity
[2023-08-31 21:34:07,207][26287] Loading model from checkpoint
[2023-08-31 21:34:07,208][26287] Loaded experiment state at self.train_step=23272, self.env_steps=11915264
[2023-08-31 21:34:07,208][26287] Initialized policy 0 weights for model version 23272
[2023-08-31 21:34:07,208][26287] LearnerWorker_p0 finished initialization!
[2023-08-31 21:34:07,209][26288] RunningMeanStd input shape: (8,)
[2023-08-31 21:34:07,211][26288] RunningMeanStd input shape: (1,)
[2023-08-31 21:34:07,258][26293] On MacOS, not setting affinity
[2023-08-31 21:34:07,267][26295] On MacOS, not setting affinity
[2023-08-31 21:34:07,299][26289] On MacOS, not setting affinity
[2023-08-31 21:34:07,299][26294] On MacOS, not setting affinity
[2023-08-31 21:34:07,300][26276] Inference worker 0-0 is ready!
[2023-08-31 21:34:07,302][26276] All inference workers are ready! Signal rollout workers to start!
[2023-08-31 21:34:07,306][26296] On MacOS, not setting affinity
[2023-08-31 21:34:07,358][26292] On MacOS, not setting affinity
[2023-08-31 21:34:07,591][26290] Decorrelating experience for 0 frames...
[2023-08-31 21:34:07,638][26291] Decorrelating experience for 0 frames...
[2023-08-31 21:34:07,644][26292] Decorrelating experience for 0 frames...
[2023-08-31 21:34:07,652][26294] Decorrelating experience for 0 frames...
[2023-08-31 21:34:07,660][26293] Decorrelating experience for 0 frames...
[2023-08-31 21:34:07,662][26289] Decorrelating experience for 0 frames...
[2023-08-31 21:34:07,667][26296] Decorrelating experience for 0 frames...
[2023-08-31 21:34:07,669][26295] Decorrelating experience for 0 frames...
[2023-08-31 21:34:07,889][26295] Decorrelating experience for 64 frames...
[2023-08-31 21:34:07,899][26290] Decorrelating experience for 64 frames...
[2023-08-31 21:34:07,917][26289] Decorrelating experience for 64 frames...
[2023-08-31 21:34:07,922][26292] Decorrelating experience for 64 frames...
[2023-08-31 21:34:07,922][26294] Decorrelating experience for 64 frames...
[2023-08-31 21:34:07,923][26296] Decorrelating experience for 64 frames...
[2023-08-31 21:34:07,939][26291] Decorrelating experience for 64 frames...
[2023-08-31 21:34:07,941][26293] Decorrelating experience for 64 frames...
[2023-08-31 21:34:08,164][26276] Fps is (10 sec: nan, 60 sec: nan, 300 sec: nan). Total num frames: 11915264. Throughput: 0: nan. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2023-08-31 21:34:11,435][26288] Updated weights for policy 0, policy_version 23352 (0.0003)
[2023-08-31 21:34:13,108][26276] Fps is (10 sec: 12421.0, 60 sec: 12421.0, 300 sec: 12421.0). Total num frames: 11976704. Throughput: 0: 5027.4. Samples: 24868. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 21:34:14,559][26288] Updated weights for policy 0, policy_version 23432 (0.0003)
[2023-08-31 21:34:17,411][26288] Updated weights for policy 0, policy_version 23512 (0.0002)
[2023-08-31 21:34:18,108][26276] Fps is (10 sec: 13177.6, 60 sec: 13177.6, 300 sec: 13177.6). Total num frames: 12046336. Throughput: 0: 10784.4. Samples: 107268. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 21:34:20,219][26288] Updated weights for policy 0, policy_version 23592 (0.0002)
[2023-08-31 21:34:22,748][26288] Updated weights for policy 0, policy_version 23672 (0.0002)
[2023-08-31 21:34:23,107][26276] Fps is (10 sec: 14746.8, 60 sec: 13977.0, 300 sec: 13977.0). Total num frames: 12124160. Throughput: 0: 13194.7. Samples: 197203. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 21:34:23,107][26276] Avg episode reward: [(0, '-9758.918')]
[2023-08-31 21:34:24,375][26276] Heartbeat connected on Batcher_0
[2023-08-31 21:34:24,379][26276] Heartbeat connected on LearnerWorker_p0
[2023-08-31 21:34:24,396][26276] Heartbeat connected on RolloutWorker_w0
[2023-08-31 21:34:24,401][26276] Heartbeat connected on RolloutWorker_w1
[2023-08-31 21:34:24,406][26276] Heartbeat connected on RolloutWorker_w2
[2023-08-31 21:34:24,408][26276] Heartbeat connected on RolloutWorker_w3
[2023-08-31 21:34:24,413][26276] Heartbeat connected on RolloutWorker_w4
[2023-08-31 21:34:24,420][26276] Heartbeat connected on RolloutWorker_w5
[2023-08-31 21:34:24,421][26276] Heartbeat connected on RolloutWorker_w6
[2023-08-31 21:34:24,427][26276] Heartbeat connected on RolloutWorker_w7
[2023-08-31 21:34:24,447][26276] Heartbeat connected on InferenceWorker_p0-w0
[2023-08-31 21:34:25,295][26288] Updated weights for policy 0, policy_version 23752 (0.0002)
[2023-08-31 21:34:27,986][26288] Updated weights for policy 0, policy_version 23832 (0.0002)
[2023-08-31 21:34:28,106][26276] Fps is (10 sec: 15567.1, 60 sec: 14375.5, 300 sec: 14375.5). Total num frames: 12201984. Throughput: 0: 12322.8. Samples: 245779. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[2023-08-31 21:34:28,106][26276] Avg episode reward: [(0, '-9758.918')]
[2023-08-31 21:34:30,892][26288] Updated weights for policy 0, policy_version 23912 (0.0002)
[2023-08-31 21:34:33,107][26276] Fps is (10 sec: 15154.4, 60 sec: 14449.0, 300 sec: 14449.0). Total num frames: 12275712. Throughput: 0: 13392.3. Samples: 334087. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[2023-08-31 21:34:33,108][26276] Avg episode reward: [(0, '-9017.887')]
[2023-08-31 21:34:33,467][26288] Updated weights for policy 0, policy_version 23992 (0.0002)
[2023-08-31 21:34:35,927][26288] Updated weights for policy 0, policy_version 24072 (0.0002)
[2023-08-31 21:34:38,107][26276] Fps is (10 sec: 15564.1, 60 sec: 14772.4, 300 sec: 14772.4). Total num frames: 12357632. Throughput: 0: 14404.5. Samples: 431349. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[2023-08-31 21:34:38,108][26276] Avg episode reward: [(0, '-9017.887')]
[2023-08-31 21:34:38,439][26288] Updated weights for policy 0, policy_version 24152 (0.0002)
[2023-08-31 21:34:41,231][26288] Updated weights for policy 0, policy_version 24232 (0.0002)
[2023-08-31 21:34:43,107][26276] Fps is (10 sec: 15565.3, 60 sec: 14768.4, 300 sec: 14768.4). Total num frames: 12431360. Throughput: 0: 13714.0. Samples: 479248. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 21:34:43,107][26276] Avg episode reward: [(0, '-7548.199')]
[2023-08-31 21:34:43,999][26288] Updated weights for policy 0, policy_version 24312 (0.0002)
[2023-08-31 21:34:46,916][26288] Updated weights for policy 0, policy_version 24392 (0.0003)
[2023-08-31 21:34:48,107][26276] Fps is (10 sec: 14335.5, 60 sec: 14663.0, 300 sec: 14663.0). Total num frames: 12500992. Throughput: 0: 14150.7. Samples: 565264. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 21:34:48,107][26276] Avg episode reward: [(0, '-7548.199')]
[2023-08-31 21:34:49,748][26288] Updated weights for policy 0, policy_version 24472 (0.0003)
[2023-08-31 21:34:52,756][26288] Updated weights for policy 0, policy_version 24552 (0.0003)
[2023-08-31 21:34:53,106][26276] Fps is (10 sec: 14337.0, 60 sec: 14672.4, 300 sec: 14672.4). Total num frames: 12574720. Throughput: 0: 14431.2. Samples: 648614. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 21:34:53,107][26276] Avg episode reward: [(0, '-6991.753')]
[2023-08-31 21:34:55,701][26288] Updated weights for policy 0, policy_version 24632 (0.0002)
[2023-08-31 21:34:58,110][26276] Fps is (10 sec: 14331.5, 60 sec: 14596.6, 300 sec: 14596.6). Total num frames: 12644352. Throughput: 0: 14793.3. Samples: 690604. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:34:58,110][26276] Avg episode reward: [(0, '-6991.753')]
[2023-08-31 21:34:58,825][26288] Updated weights for policy 0, policy_version 24712 (0.0002)
[2023-08-31 21:35:01,807][26288] Updated weights for policy 0, policy_version 24792 (0.0003)
[2023-08-31 21:35:03,109][26276] Fps is (10 sec: 13513.7, 60 sec: 14461.5, 300 sec: 14461.5). Total num frames: 12709888. Throughput: 0: 14743.8. Samples: 770755. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:35:03,109][26276] Avg episode reward: [(0, '-6991.753')]
[2023-08-31 21:35:05,071][26288] Updated weights for policy 0, policy_version 24872 (0.0002)
[2023-08-31 21:35:07,821][26288] Updated weights for policy 0, policy_version 24952 (0.0002)
[2023-08-31 21:35:08,108][26276] Fps is (10 sec: 13520.3, 60 sec: 14417.1, 300 sec: 14417.1). Total num frames: 12779520. Throughput: 0: 14569.9. Samples: 852859. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:35:08,108][26276] Avg episode reward: [(0, '-6471.714')]
[2023-08-31 21:35:10,601][26288] Updated weights for policy 0, policy_version 25032 (0.0003)
[2023-08-31 21:35:13,107][26276] Fps is (10 sec: 13929.0, 60 sec: 14541.0, 300 sec: 14379.5). Total num frames: 12849152. Throughput: 0: 14472.3. Samples: 897043. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:35:13,107][26276] Avg episode reward: [(0, '-6471.714')]
[2023-08-31 21:35:13,574][26288] Updated weights for policy 0, policy_version 25112 (0.0003)
[2023-08-31 21:35:16,934][26288] Updated weights for policy 0, policy_version 25192 (0.0002)
[2023-08-31 21:35:18,110][26276] Fps is (10 sec: 13513.5, 60 sec: 14472.0, 300 sec: 14287.9). Total num frames: 12914688. Throughput: 0: 14221.8. Samples: 974107. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:35:18,110][26276] Avg episode reward: [(0, '-6144.422')]
[2023-08-31 21:35:19,533][26288] Updated weights for policy 0, policy_version 25272 (0.0002)
[2023-08-31 21:35:22,264][26288] Updated weights for policy 0, policy_version 25352 (0.0002)
[2023-08-31 21:35:23,108][26276] Fps is (10 sec: 14333.9, 60 sec: 14472.2, 300 sec: 14373.4). Total num frames: 12992512. Throughput: 0: 14088.5. Samples: 1065355. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:35:23,108][26276] Avg episode reward: [(0, '-6144.422')]
[2023-08-31 21:35:24,966][26288] Updated weights for policy 0, policy_version 25432 (0.0002)
[2023-08-31 21:35:28,106][26276] Fps is (10 sec: 14342.0, 60 sec: 14267.8, 300 sec: 14294.7). Total num frames: 13058048. Throughput: 0: 14010.4. Samples: 1109700. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:35:28,108][26276] Avg episode reward: [(0, '-5552.842')]
[2023-08-31 21:35:28,255][26288] Updated weights for policy 0, policy_version 25512 (0.0002)
[2023-08-31 21:35:31,075][26288] Updated weights for policy 0, policy_version 25592 (0.0003)
[2023-08-31 21:35:33,108][26276] Fps is (10 sec: 13927.1, 60 sec: 14267.6, 300 sec: 14320.9). Total num frames: 13131776. Throughput: 0: 13908.4. Samples: 1191152. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:35:33,108][26276] Avg episode reward: [(0, '-5552.842')]
[2023-08-31 21:35:33,829][26288] Updated weights for policy 0, policy_version 25672 (0.0002)
[2023-08-31 21:35:36,320][26288] Updated weights for policy 0, policy_version 25752 (0.0002)
[2023-08-31 21:35:38,107][26276] Fps is (10 sec: 14743.9, 60 sec: 14131.1, 300 sec: 14344.6). Total num frames: 13205504. Throughput: 0: 14056.4. Samples: 1281163. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:35:38,108][26276] Avg episode reward: [(0, '-4858.351')]
[2023-08-31 21:35:39,169][26288] Updated weights for policy 0, policy_version 25832 (0.0002)
[2023-08-31 21:35:41,701][26288] Updated weights for policy 0, policy_version 25912 (0.0002)
[2023-08-31 21:35:43,110][26276] Fps is (10 sec: 15561.1, 60 sec: 14267.0, 300 sec: 14451.6). Total num frames: 13287424. Throughput: 0: 14194.5. Samples: 1329354. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:35:43,110][26276] Avg episode reward: [(0, '-4858.351')]
[2023-08-31 21:35:43,113][26287] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000025952_13287424.pth...
[2023-08-31 21:35:43,116][26287] Removing /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000022304_11419648.pth
[2023-08-31 21:35:44,214][26288] Updated weights for policy 0, policy_version 25992 (0.0002)
[2023-08-31 21:35:46,863][26288] Updated weights for policy 0, policy_version 26072 (0.0003)
[2023-08-31 21:35:48,105][26276] Fps is (10 sec: 15567.2, 60 sec: 14336.4, 300 sec: 14466.9). Total num frames: 13361152. Throughput: 0: 14514.6. Samples: 1423867. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:35:48,106][26276] Avg episode reward: [(0, '-5210.796')]
[2023-08-31 21:35:49,992][26288] Updated weights for policy 0, policy_version 26152 (0.0002)
[2023-08-31 21:35:52,921][26288] Updated weights for policy 0, policy_version 26232 (0.0003)
[2023-08-31 21:35:53,106][26276] Fps is (10 sec: 14342.4, 60 sec: 14267.9, 300 sec: 14441.2). Total num frames: 13430784. Throughput: 0: 14516.6. Samples: 1506079. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:35:53,106][26276] Avg episode reward: [(0, '-5210.796')]
[2023-08-31 21:35:55,451][26288] Updated weights for policy 0, policy_version 26312 (0.0002)
[2023-08-31 21:35:57,938][26288] Updated weights for policy 0, policy_version 26392 (0.0002)
[2023-08-31 21:35:58,110][26276] Fps is (10 sec: 15148.2, 60 sec: 14472.5, 300 sec: 14528.9). Total num frames: 13512704. Throughput: 0: 14603.9. Samples: 1554269. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:35:58,110][26276] Avg episode reward: [(0, '-5210.796')]
[2023-08-31 21:36:00,754][26288] Updated weights for policy 0, policy_version 26472 (0.0002)
[2023-08-31 21:36:03,108][26276] Fps is (10 sec: 15969.9, 60 sec: 14677.4, 300 sec: 14574.2). Total num frames: 13590528. Throughput: 0: 14972.4. Samples: 1647841. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:36:03,109][26276] Avg episode reward: [(0, '-5597.864')]
[2023-08-31 21:36:03,257][26288] Updated weights for policy 0, policy_version 26552 (0.0002)
[2023-08-31 21:36:05,938][26288] Updated weights for policy 0, policy_version 26632 (0.0002)
[2023-08-31 21:36:08,106][26276] Fps is (10 sec: 15571.5, 60 sec: 14814.3, 300 sec: 14615.8). Total num frames: 13668352. Throughput: 0: 15051.7. Samples: 1742644. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:36:08,106][26276] Avg episode reward: [(0, '-5597.864')]
[2023-08-31 21:36:08,722][26288] Updated weights for policy 0, policy_version 26712 (0.0002)
[2023-08-31 21:36:11,308][26288] Updated weights for policy 0, policy_version 26792 (0.0002)
[2023-08-31 21:36:13,108][26276] Fps is (10 sec: 15155.7, 60 sec: 14881.8, 300 sec: 14620.7). Total num frames: 13742080. Throughput: 0: 15025.4. Samples: 1785877. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:36:13,108][26276] Avg episode reward: [(0, '-5810.133')]
[2023-08-31 21:36:13,909][26288] Updated weights for policy 0, policy_version 26872 (0.0003)
[2023-08-31 21:36:16,488][26288] Updated weights for policy 0, policy_version 26952 (0.0002)
[2023-08-31 21:36:18,110][26276] Fps is (10 sec: 15558.3, 60 sec: 15155.2, 300 sec: 14688.4). Total num frames: 13824000. Throughput: 0: 15335.8. Samples: 1881296. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:36:18,110][26276] Avg episode reward: [(0, '-5810.133')]
[2023-08-31 21:36:19,381][26288] Updated weights for policy 0, policy_version 27032 (0.0002)
[2023-08-31 21:36:21,999][26288] Updated weights for policy 0, policy_version 27112 (0.0002)
[2023-08-31 21:36:23,109][26276] Fps is (10 sec: 15563.8, 60 sec: 15086.8, 300 sec: 14690.6). Total num frames: 13897728. Throughput: 0: 15327.3. Samples: 1970918. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:36:23,109][26276] Avg episode reward: [(0, '-5923.866')]
[2023-08-31 21:36:24,547][26288] Updated weights for policy 0, policy_version 27192 (0.0002)
[2023-08-31 21:36:27,109][26288] Updated weights for policy 0, policy_version 27272 (0.0002)
[2023-08-31 21:36:28,105][26276] Fps is (10 sec: 15572.5, 60 sec: 15360.2, 300 sec: 14751.5). Total num frames: 13979648. Throughput: 0: 15339.2. Samples: 2019539. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:36:28,105][26276] Avg episode reward: [(0, '-5923.866')]
[2023-08-31 21:36:29,761][26288] Updated weights for policy 0, policy_version 27352 (0.0002)
[2023-08-31 21:36:32,318][26288] Updated weights for policy 0, policy_version 27432 (0.0002)
[2023-08-31 21:36:33,110][26276] Fps is (10 sec: 15972.3, 60 sec: 15427.7, 300 sec: 14779.1). Total num frames: 14057472. Throughput: 0: 15331.9. Samples: 2113873. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:36:33,110][26276] Avg episode reward: [(0, '-5722.001')]
[2023-08-31 21:36:34,753][26288] Updated weights for policy 0, policy_version 27512 (0.0002)
[2023-08-31 21:36:37,157][26288] Updated weights for policy 0, policy_version 27592 (0.0002)
[2023-08-31 21:36:38,106][26276] Fps is (10 sec: 15973.4, 60 sec: 15565.1, 300 sec: 14833.0). Total num frames: 14139392. Throughput: 0: 15735.1. Samples: 2214158. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:36:38,106][26276] Avg episode reward: [(0, '-5722.001')]
[2023-08-31 21:36:39,935][26288] Updated weights for policy 0, policy_version 27672 (0.0002)
[2023-08-31 21:36:42,332][26288] Updated weights for policy 0, policy_version 27752 (0.0002)
[2023-08-31 21:36:43,109][26276] Fps is (10 sec: 15976.8, 60 sec: 15496.9, 300 sec: 14856.3). Total num frames: 14217216. Throughput: 0: 15669.4. Samples: 2259365. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 21:36:43,109][26276] Avg episode reward: [(0, '-5457.362')]
[2023-08-31 21:36:44,866][26288] Updated weights for policy 0, policy_version 27832 (0.0002)
[2023-08-31 21:36:47,247][26288] Updated weights for policy 0, policy_version 27912 (0.0002)
[2023-08-31 21:36:48,110][26276] Fps is (10 sec: 16376.5, 60 sec: 15700.1, 300 sec: 14929.5). Total num frames: 14303232. Throughput: 0: 15809.9. Samples: 2359316. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 21:36:48,111][26276] Avg episode reward: [(0, '-5457.362')]
[2023-08-31 21:36:50,041][26288] Updated weights for policy 0, policy_version 27992 (0.0002)
[2023-08-31 21:36:52,360][26288] Updated weights for policy 0, policy_version 28072 (0.0002)
[2023-08-31 21:36:53,105][26276] Fps is (10 sec: 16389.4, 60 sec: 15838.0, 300 sec: 14949.3). Total num frames: 14381056. Throughput: 0: 15865.7. Samples: 2456593. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 21:36:53,105][26276] Avg episode reward: [(0, '-4640.532')]
[2023-08-31 21:36:54,736][26288] Updated weights for policy 0, policy_version 28152 (0.0002)
[2023-08-31 21:36:57,225][26288] Updated weights for policy 0, policy_version 28232 (0.0002)
[2023-08-31 21:36:58,107][26276] Fps is (10 sec: 16389.1, 60 sec: 15906.9, 300 sec: 15015.4). Total num frames: 14467072. Throughput: 0: 16039.8. Samples: 2507654. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 21:36:58,107][26276] Avg episode reward: [(0, '-4640.532')]
[2023-08-31 21:36:59,901][26288] Updated weights for policy 0, policy_version 28312 (0.0002)
[2023-08-31 21:37:02,388][26288] Updated weights for policy 0, policy_version 28392 (0.0002)
[2023-08-31 21:37:03,110][26276] Fps is (10 sec: 16376.9, 60 sec: 15905.8, 300 sec: 15030.9). Total num frames: 14544896. Throughput: 0: 16069.4. Samples: 2604412. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[2023-08-31 21:37:03,110][26276] Avg episode reward: [(0, '-4199.152')]
[2023-08-31 21:37:05,119][26288] Updated weights for policy 0, policy_version 28472 (0.0002)
[2023-08-31 21:37:07,742][26288] Updated weights for policy 0, policy_version 28552 (0.0003)
[2023-08-31 21:37:08,109][26276] Fps is (10 sec: 15561.5, 60 sec: 15905.2, 300 sec: 15045.8). Total num frames: 14622720. Throughput: 0: 16118.3. Samples: 2696249. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[2023-08-31 21:37:08,109][26276] Avg episode reward: [(0, '-4199.152')]
[2023-08-31 21:37:10,480][26288] Updated weights for policy 0, policy_version 28632 (0.0002)
[2023-08-31 21:37:13,003][26288] Updated weights for policy 0, policy_version 28712 (0.0002)
[2023-08-31 21:37:13,108][26276] Fps is (10 sec: 15567.9, 60 sec: 15974.5, 300 sec: 15059.9). Total num frames: 14700544. Throughput: 0: 16042.8. Samples: 2741507. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[2023-08-31 21:37:13,108][26276] Avg episode reward: [(0, '-3730.628')]
[2023-08-31 21:37:15,483][26288] Updated weights for policy 0, policy_version 28792 (0.0002)
[2023-08-31 21:37:18,020][26288] Updated weights for policy 0, policy_version 28872 (0.0002)
[2023-08-31 21:37:18,109][26276] Fps is (10 sec: 15974.4, 60 sec: 15974.6, 300 sec: 15094.6). Total num frames: 14782464. Throughput: 0: 16144.9. Samples: 2840380. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[2023-08-31 21:37:18,109][26276] Avg episode reward: [(0, '-3730.628')]
[2023-08-31 21:37:20,828][26288] Updated weights for policy 0, policy_version 28952 (0.0002)
[2023-08-31 21:37:23,106][26276] Fps is (10 sec: 15976.7, 60 sec: 16043.4, 300 sec: 15106.9). Total num frames: 14860288. Throughput: 0: 15976.1. Samples: 2933090. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:37:23,106][26276] Avg episode reward: [(0, '-3239.516')]
[2023-08-31 21:37:23,110][26287] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000029024_14860288.pth...
[2023-08-31 21:37:23,112][26287] Removing /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000023272_11915264.pth
[2023-08-31 21:37:23,113][26287] Saving new best policy, reward=-3239.516!
[2023-08-31 21:37:23,227][26288] Updated weights for policy 0, policy_version 29032 (0.0002)
[2023-08-31 21:37:25,770][26288] Updated weights for policy 0, policy_version 29112 (0.0002)
[2023-08-31 21:37:28,106][26276] Fps is (10 sec: 15980.0, 60 sec: 16042.5, 300 sec: 15138.9). Total num frames: 14942208. Throughput: 0: 16057.4. Samples: 2981904. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:37:28,106][26276] Avg episode reward: [(0, '-3239.516')]
[2023-08-31 21:37:28,344][26288] Updated weights for policy 0, policy_version 29192 (0.0002)
[2023-08-31 21:37:31,111][26288] Updated weights for policy 0, policy_version 29272 (0.0002)
[2023-08-31 21:37:33,107][26276] Fps is (10 sec: 15563.3, 60 sec: 15975.2, 300 sec: 15129.2). Total num frames: 15015936. Throughput: 0: 15915.6. Samples: 3075466. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:37:33,107][26276] Avg episode reward: [(0, '-2947.195')]
[2023-08-31 21:37:33,108][26287] Saving new best policy, reward=-2947.195!
[2023-08-31 21:37:33,755][26288] Updated weights for policy 0, policy_version 29352 (0.0002)
[2023-08-31 21:37:36,271][26288] Updated weights for policy 0, policy_version 29432 (0.0002)
[2023-08-31 21:37:38,105][26276] Fps is (10 sec: 15565.5, 60 sec: 15974.5, 300 sec: 15159.2). Total num frames: 15097856. Throughput: 0: 15871.0. Samples: 3170786. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:37:38,105][26276] Avg episode reward: [(0, '-2947.195')]
[2023-08-31 21:37:38,903][26288] Updated weights for policy 0, policy_version 29512 (0.0002)
[2023-08-31 21:37:41,923][26288] Updated weights for policy 0, policy_version 29592 (0.0002)
[2023-08-31 21:37:43,107][26276] Fps is (10 sec: 15155.7, 60 sec: 15838.3, 300 sec: 15130.4). Total num frames: 15167488. Throughput: 0: 15649.9. Samples: 3211896. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:37:43,107][26276] Avg episode reward: [(0, '-2846.540')]
[2023-08-31 21:37:43,107][26287] Saving new best policy, reward=-2846.540!
[2023-08-31 21:37:44,870][26288] Updated weights for policy 0, policy_version 29672 (0.0002)
[2023-08-31 21:37:47,725][26288] Updated weights for policy 0, policy_version 29752 (0.0003)
[2023-08-31 21:37:48,108][26276] Fps is (10 sec: 13922.2, 60 sec: 15565.3, 300 sec: 15103.0). Total num frames: 15237120. Throughput: 0: 15414.9. Samples: 3298064. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:37:48,109][26276] Avg episode reward: [(0, '-2846.540')]
[2023-08-31 21:37:50,575][26288] Updated weights for policy 0, policy_version 29832 (0.0002)
[2023-08-31 21:37:53,108][26276] Fps is (10 sec: 13925.4, 60 sec: 15427.7, 300 sec: 15076.9). Total num frames: 15306752. Throughput: 0: 15213.8. Samples: 3380844. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:37:53,109][26276] Avg episode reward: [(0, '-2888.878')]
[2023-08-31 21:37:53,534][26288] Updated weights for policy 0, policy_version 29912 (0.0002)
[2023-08-31 21:37:56,451][26288] Updated weights for policy 0, policy_version 29992 (0.0003)
[2023-08-31 21:37:58,107][26276] Fps is (10 sec: 14337.7, 60 sec: 15223.5, 300 sec: 15069.7). Total num frames: 15380480. Throughput: 0: 15161.9. Samples: 3423785. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:37:58,107][26276] Avg episode reward: [(0, '-2888.878')]
[2023-08-31 21:37:58,996][26288] Updated weights for policy 0, policy_version 30072 (0.0002)
[2023-08-31 21:38:01,899][26288] Updated weights for policy 0, policy_version 30152 (0.0002)
[2023-08-31 21:38:03,110][26276] Fps is (10 sec: 14741.9, 60 sec: 15155.1, 300 sec: 15062.6). Total num frames: 15454208. Throughput: 0: 15068.6. Samples: 3518480. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:38:03,110][26276] Avg episode reward: [(0, '-2597.860')]
[2023-08-31 21:38:03,110][26287] Saving new best policy, reward=-2597.860!
[2023-08-31 21:38:04,343][26288] Updated weights for policy 0, policy_version 30232 (0.0002)
[2023-08-31 21:38:07,067][26288] Updated weights for policy 0, policy_version 30312 (0.0002)
[2023-08-31 21:38:08,106][26276] Fps is (10 sec: 15566.7, 60 sec: 15224.3, 300 sec: 15090.4). Total num frames: 15536128. Throughput: 0: 15011.2. Samples: 3608592. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:38:08,106][26276] Avg episode reward: [(0, '-2597.860')]
[2023-08-31 21:38:09,502][26288] Updated weights for policy 0, policy_version 30392 (0.0002)
[2023-08-31 21:38:12,378][26288] Updated weights for policy 0, policy_version 30472 (0.0002)
[2023-08-31 21:38:13,106][26276] Fps is (10 sec: 15980.7, 60 sec: 15223.9, 300 sec: 15100.1). Total num frames: 15613952. Throughput: 0: 15018.8. Samples: 3657756. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:38:13,106][26276] Avg episode reward: [(0, '-2473.300')]
[2023-08-31 21:38:13,107][26287] Saving new best policy, reward=-2473.300!
[2023-08-31 21:38:14,837][26288] Updated weights for policy 0, policy_version 30552 (0.0002)
[2023-08-31 21:38:17,351][26288] Updated weights for policy 0, policy_version 30632 (0.0002)
[2023-08-31 21:38:18,107][26276] Fps is (10 sec: 15562.6, 60 sec: 15155.7, 300 sec: 15109.3). Total num frames: 15691776. Throughput: 0: 15019.5. Samples: 3751348. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:38:18,108][26276] Avg episode reward: [(0, '-2473.300')]
[2023-08-31 21:38:19,912][26288] Updated weights for policy 0, policy_version 30712 (0.0002)
[2023-08-31 21:38:22,603][26288] Updated weights for policy 0, policy_version 30792 (0.0002)
[2023-08-31 21:38:23,107][26276] Fps is (10 sec: 15563.8, 60 sec: 15155.1, 300 sec: 15118.3). Total num frames: 15769600. Throughput: 0: 14981.7. Samples: 3844985. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:38:23,107][26276] Avg episode reward: [(0, '-2431.111')]
[2023-08-31 21:38:23,107][26287] Saving new best policy, reward=-2431.111!
[2023-08-31 21:38:25,229][26288] Updated weights for policy 0, policy_version 30872 (0.0002)
[2023-08-31 21:38:27,816][26288] Updated weights for policy 0, policy_version 30952 (0.0002)
[2023-08-31 21:38:28,109][26276] Fps is (10 sec: 15972.3, 60 sec: 15154.5, 300 sec: 15142.5). Total num frames: 15851520. Throughput: 0: 15119.8. Samples: 3892316. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:38:28,109][26276] Avg episode reward: [(0, '-2431.111')]
[2023-08-31 21:38:30,355][26288] Updated weights for policy 0, policy_version 31032 (0.0002)
[2023-08-31 21:38:33,107][26276] Fps is (10 sec: 15565.0, 60 sec: 15155.3, 300 sec: 15135.1). Total num frames: 15925248. Throughput: 0: 15347.2. Samples: 3988664. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:38:33,107][26276] Avg episode reward: [(0, '-2457.647')]
[2023-08-31 21:38:33,241][26288] Updated weights for policy 0, policy_version 31112 (0.0002)
[2023-08-31 21:38:35,694][26288] Updated weights for policy 0, policy_version 31192 (0.0002)
[2023-08-31 21:38:38,109][26276] Fps is (10 sec: 15564.3, 60 sec: 15154.3, 300 sec: 15158.1). Total num frames: 16007168. Throughput: 0: 15529.5. Samples: 4079693. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:38:38,109][26276] Avg episode reward: [(0, '-2457.647')]
[2023-08-31 21:38:38,318][26288] Updated weights for policy 0, policy_version 31272 (0.0002)
[2023-08-31 21:38:40,840][26288] Updated weights for policy 0, policy_version 31352 (0.0002)
[2023-08-31 21:38:43,108][26276] Fps is (10 sec: 15562.6, 60 sec: 15223.2, 300 sec: 15150.7). Total num frames: 16080896. Throughput: 0: 15665.5. Samples: 4128747. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:38:43,110][26276] Avg episode reward: [(0, '-2470.606')]
[2023-08-31 21:38:43,690][26288] Updated weights for policy 0, policy_version 31432 (0.0002)
[2023-08-31 21:38:46,194][26288] Updated weights for policy 0, policy_version 31512 (0.0002)
[2023-08-31 21:38:48,110][26276] Fps is (10 sec: 15562.8, 60 sec: 15427.8, 300 sec: 15172.6). Total num frames: 16162816. Throughput: 0: 15599.5. Samples: 4220460. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:38:48,110][26276] Avg episode reward: [(0, '-2470.606')]
[2023-08-31 21:38:48,782][26288] Updated weights for policy 0, policy_version 31592 (0.0002)
[2023-08-31 21:38:51,362][26288] Updated weights for policy 0, policy_version 31672 (0.0002)
[2023-08-31 21:38:53,109][26276] Fps is (10 sec: 15972.1, 60 sec: 15564.3, 300 sec: 15179.5). Total num frames: 16240640. Throughput: 0: 15733.2. Samples: 4316642. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:38:53,110][26276] Avg episode reward: [(0, '-2480.666')]
[2023-08-31 21:38:54,114][26288] Updated weights for policy 0, policy_version 31752 (0.0002)
[2023-08-31 21:38:56,587][26288] Updated weights for policy 0, policy_version 31832 (0.0002)
[2023-08-31 21:38:58,109][26276] Fps is (10 sec: 15567.4, 60 sec: 15632.7, 300 sec: 15186.2). Total num frames: 16318464. Throughput: 0: 15636.6. Samples: 4361443. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:38:58,109][26276] Avg episode reward: [(0, '-2480.666')]
[2023-08-31 21:38:59,221][26288] Updated weights for policy 0, policy_version 31912 (0.0002)
[2023-08-31 21:39:01,715][26288] Updated weights for policy 0, policy_version 31992 (0.0002)
[2023-08-31 21:39:03,106][26276] Fps is (10 sec: 15570.4, 60 sec: 15702.4, 300 sec: 15192.8). Total num frames: 16396288. Throughput: 0: 15698.3. Samples: 4457748. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[2023-08-31 21:39:03,106][26276] Avg episode reward: [(0, '-2580.236')]
[2023-08-31 21:39:03,109][26287] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000032024_16396288.pth...
[2023-08-31 21:39:03,111][26287] Removing /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000025952_13287424.pth
[2023-08-31 21:39:04,601][26288] Updated weights for policy 0, policy_version 32072 (0.0002)
[2023-08-31 21:39:07,242][26288] Updated weights for policy 0, policy_version 32152 (0.0002)
[2023-08-31 21:39:08,110][26276] Fps is (10 sec: 15563.0, 60 sec: 15632.1, 300 sec: 15245.3). Total num frames: 16474112. Throughput: 0: 15607.6. Samples: 4547373. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[2023-08-31 21:39:08,110][26276] Avg episode reward: [(0, '-2580.236')]
[2023-08-31 21:39:10,107][26288] Updated weights for policy 0, policy_version 32232 (0.0002)
[2023-08-31 21:39:12,938][26288] Updated weights for policy 0, policy_version 32312 (0.0002)
[2023-08-31 21:39:13,110][26276] Fps is (10 sec: 14739.5, 60 sec: 15495.5, 300 sec: 15245.3). Total num frames: 16543744. Throughput: 0: 15498.8. Samples: 4589783. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[2023-08-31 21:39:13,110][26276] Avg episode reward: [(0, '-2580.236')]
[2023-08-31 21:39:16,226][26288] Updated weights for policy 0, policy_version 32392 (0.0002)
[2023-08-31 21:39:18,109][26276] Fps is (10 sec: 13517.8, 60 sec: 15291.3, 300 sec: 15203.7). Total num frames: 16609280. Throughput: 0: 15151.4. Samples: 4670515. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[2023-08-31 21:39:18,109][26276] Avg episode reward: [(0, '-2679.317')]
[2023-08-31 21:39:18,906][26288] Updated weights for policy 0, policy_version 32472 (0.0002)
[2023-08-31 21:39:21,685][26288] Updated weights for policy 0, policy_version 32552 (0.0002)
[2023-08-31 21:39:23,107][26276] Fps is (10 sec: 14340.1, 60 sec: 15291.6, 300 sec: 15203.7). Total num frames: 16687104. Throughput: 0: 15141.6. Samples: 4761036. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:39:23,107][26276] Avg episode reward: [(0, '-2679.317')]
[2023-08-31 21:39:24,307][26288] Updated weights for policy 0, policy_version 32632 (0.0002)
[2023-08-31 21:39:27,307][26288] Updated weights for policy 0, policy_version 32712 (0.0002)
[2023-08-31 21:39:28,106][26276] Fps is (10 sec: 15159.2, 60 sec: 15155.8, 300 sec: 15203.8). Total num frames: 16760832. Throughput: 0: 14947.3. Samples: 4801351. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:39:28,107][26276] Avg episode reward: [(0, '-2689.137')]
[2023-08-31 21:39:29,766][26288] Updated weights for policy 0, policy_version 32792 (0.0002)
[2023-08-31 21:39:32,225][26288] Updated weights for policy 0, policy_version 32872 (0.0002)
[2023-08-31 21:39:33,108][26276] Fps is (10 sec: 15562.9, 60 sec: 15291.3, 300 sec: 15203.7). Total num frames: 16842752. Throughput: 0: 15106.6. Samples: 4900229. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:39:33,109][26276] Avg episode reward: [(0, '-2689.137')]
[2023-08-31 21:39:34,810][26288] Updated weights for policy 0, policy_version 32952 (0.0002)
[2023-08-31 21:39:37,719][26288] Updated weights for policy 0, policy_version 33032 (0.0002)
[2023-08-31 21:39:38,106][26276] Fps is (10 sec: 15566.0, 60 sec: 15156.1, 300 sec: 15203.9). Total num frames: 16916480. Throughput: 0: 14976.4. Samples: 4990524. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:39:38,106][26276] Avg episode reward: [(0, '-2829.554')]
[2023-08-31 21:39:40,144][26288] Updated weights for policy 0, policy_version 33112 (0.0002)
[2023-08-31 21:39:42,680][26288] Updated weights for policy 0, policy_version 33192 (0.0002)
[2023-08-31 21:39:43,106][26276] Fps is (10 sec: 15569.0, 60 sec: 15292.3, 300 sec: 15245.5). Total num frames: 16998400. Throughput: 0: 15099.1. Samples: 5040858. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:39:43,106][26276] Avg episode reward: [(0, '-2829.554')]
[2023-08-31 21:39:45,282][26288] Updated weights for policy 0, policy_version 33272 (0.0002)
[2023-08-31 21:39:48,007][26288] Updated weights for policy 0, policy_version 33352 (0.0002)
[2023-08-31 21:39:48,110][26276] Fps is (10 sec: 15968.2, 60 sec: 15223.7, 300 sec: 15259.2). Total num frames: 17076224. Throughput: 0: 15047.1. Samples: 5134923. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:39:48,110][26276] Avg episode reward: [(0, '-3051.780')]
[2023-08-31 21:39:50,542][26288] Updated weights for policy 0, policy_version 33432 (0.0002)
[2023-08-31 21:39:53,110][26276] Fps is (10 sec: 15558.0, 60 sec: 15223.3, 300 sec: 15287.1). Total num frames: 17154048. Throughput: 0: 15175.6. Samples: 5230280. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:39:53,110][26276] Avg episode reward: [(0, '-3051.780')]
[2023-08-31 21:39:53,124][26288] Updated weights for policy 0, policy_version 33512 (0.0002)
[2023-08-31 21:39:55,818][26288] Updated weights for policy 0, policy_version 33592 (0.0002)
[2023-08-31 21:39:58,108][26276] Fps is (10 sec: 15977.5, 60 sec: 15292.0, 300 sec: 15342.7). Total num frames: 17235968. Throughput: 0: 15325.0. Samples: 5279370. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:39:58,108][26276] Avg episode reward: [(0, '-3261.823')]
[2023-08-31 21:39:58,234][26288] Updated weights for policy 0, policy_version 33672 (0.0002)
[2023-08-31 21:40:00,749][26288] Updated weights for policy 0, policy_version 33752 (0.0002)
[2023-08-31 21:40:03,107][26276] Fps is (10 sec: 16389.0, 60 sec: 15359.7, 300 sec: 15384.3). Total num frames: 17317888. Throughput: 0: 15650.5. Samples: 5374754. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:40:03,107][26276] Avg episode reward: [(0, '-3261.823')]
[2023-08-31 21:40:03,242][26288] Updated weights for policy 0, policy_version 33832 (0.0002)
[2023-08-31 21:40:05,984][26288] Updated weights for policy 0, policy_version 33912 (0.0002)
[2023-08-31 21:40:08,107][26276] Fps is (10 sec: 15975.1, 60 sec: 15360.7, 300 sec: 15412.0). Total num frames: 17395712. Throughput: 0: 15743.7. Samples: 5469504. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:40:08,107][26276] Avg episode reward: [(0, '-3386.252')]
[2023-08-31 21:40:08,573][26288] Updated weights for policy 0, policy_version 33992 (0.0002)
[2023-08-31 21:40:11,174][26288] Updated weights for policy 0, policy_version 34072 (0.0002)
[2023-08-31 21:40:13,109][26276] Fps is (10 sec: 15560.9, 60 sec: 15496.7, 300 sec: 15453.8). Total num frames: 17473536. Throughput: 0: 15876.1. Samples: 5515825. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:40:13,110][26276] Avg episode reward: [(0, '-3386.252')]
[2023-08-31 21:40:13,758][26288] Updated weights for policy 0, policy_version 34152 (0.0002)
[2023-08-31 21:40:16,480][26288] Updated weights for policy 0, policy_version 34232 (0.0002)
[2023-08-31 21:40:18,109][26276] Fps is (10 sec: 15152.5, 60 sec: 15633.1, 300 sec: 15439.8). Total num frames: 17547264. Throughput: 0: 15730.4. Samples: 5608108. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:40:18,110][26276] Avg episode reward: [(0, '-3383.557')]
[2023-08-31 21:40:19,079][26288] Updated weights for policy 0, policy_version 34312 (0.0002)
[2023-08-31 21:40:21,646][26288] Updated weights for policy 0, policy_version 34392 (0.0002)
[2023-08-31 21:40:23,105][26276] Fps is (10 sec: 15980.7, 60 sec: 15770.0, 300 sec: 15509.3). Total num frames: 17633280. Throughput: 0: 15879.6. Samples: 5705102. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:40:23,106][26276] Avg episode reward: [(0, '-3383.557')]
[2023-08-31 21:40:24,078][26288] Updated weights for policy 0, policy_version 34472 (0.0002)
[2023-08-31 21:40:25,996][26287] KL-divergence is very high: 44924.5898
[2023-08-31 21:40:26,002][26287] High loss value: l:2450.2158 pl:0.0060 vl:0.0304 exp_l:0.0000 kl_l:2450.1792 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:40:26,002][26287] KL-divergence is very high: 1298249.2500
[2023-08-31 21:40:26,006][26287] KL-divergence is very high: 4825.1782
[2023-08-31 21:40:26,009][26287] KL-divergence is very high: 74745.3516
[2023-08-31 21:40:26,015][26287] High loss value: l:28796.0273 pl:0.0448 vl:0.0415 exp_l:0.0000 kl_l:28795.9414 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:40:26,015][26287] KL-divergence is very high: 11036314.0000
[2023-08-31 21:40:26,268][26287] KL-divergence is very high: 1039.9370
[2023-08-31 21:40:26,273][26287] KL-divergence is very high: 342.9218
[2023-08-31 21:40:26,276][26287] High loss value: l:861.9007 pl:-0.0216 vl:0.2047 exp_l:0.0000 kl_l:861.7176 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:40:26,276][26287] KL-divergence is very high: 465046.3125
[2023-08-31 21:40:26,279][26287] KL-divergence is very high: 20049.5000
[2023-08-31 21:40:26,284][26287] KL-divergence is very high: 104.2886
[2023-08-31 21:40:26,526][26287] KL-divergence is very high: 105.8485
[2023-08-31 21:40:26,535][26287] KL-divergence is very high: 6274.4824
[2023-08-31 21:40:26,762][26287] High loss value: l:3000.9150 pl:-0.0155 vl:3.8884 exp_l:0.0000 kl_l:2997.0420 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:40:26,762][26287] KL-divergence is very high: 1756769.6250
[2023-08-31 21:40:26,765][26287] High loss value: l:132.3323 pl:0.0315 vl:2.9002 exp_l:0.0000 kl_l:129.4006 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:40:26,765][26287] KL-divergence is very high: 127660.6484
[2023-08-31 21:40:26,768][26287] KL-divergence is very high: 3087.7590
[2023-08-31 21:40:26,771][26287] High loss value: l:5079.3882 pl:0.0949 vl:2.3204 exp_l:0.0000 kl_l:5076.9731 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:40:26,771][26287] KL-divergence is very high: 1884509.8750
[2023-08-31 21:40:26,775][26287] High loss value: l:1913.3523 pl:0.0925 vl:3.2316 exp_l:0.0000 kl_l:1910.0283 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:40:26,775][26287] KL-divergence is very high: 700894.8125
[2023-08-31 21:40:26,778][26287] High loss value: l:261.7207 pl:0.0934 vl:2.1976 exp_l:0.0000 kl_l:259.4297 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:40:26,778][26287] KL-divergence is very high: 134142.4688
[2023-08-31 21:40:26,781][26287] High loss value: l:45.7021 pl:0.0916 vl:2.1198 exp_l:0.0000 kl_l:43.4907 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:40:26,782][26287] KL-divergence is very high: 24953.9863
[2023-08-31 21:40:26,785][26288] Updated weights for policy 0, policy_version 34552 (0.0002)
[2023-08-31 21:40:27,025][26287] KL-divergence is very high: 871.3832
[2023-08-31 21:40:27,028][26287] KL-divergence is very high: 835.1633
[2023-08-31 21:40:27,031][26287] KL-divergence is very high: 505.5967
[2023-08-31 21:40:27,034][26287] KL-divergence is very high: 1326.9554
[2023-08-31 21:40:27,036][26287] KL-divergence is very high: 827.0404
[2023-08-31 21:40:27,039][26287] KL-divergence is very high: 208.2408
[2023-08-31 21:40:27,042][26287] KL-divergence is very high: 180.1686
[2023-08-31 21:40:27,292][26287] KL-divergence is very high: 254.7101
[2023-08-31 21:40:27,295][26287] KL-divergence is very high: 371.2607
[2023-08-31 21:40:27,298][26287] KL-divergence is very high: 267.3712
[2023-08-31 21:40:27,301][26287] KL-divergence is very high: 942.2936
[2023-08-31 21:40:27,304][26287] KL-divergence is very high: 426.0852
[2023-08-31 21:40:27,307][26287] KL-divergence is very high: 589.7308
[2023-08-31 21:40:27,310][26287] KL-divergence is very high: 453.7514
[2023-08-31 21:40:27,523][26287] KL-divergence is very high: 1274.5863
[2023-08-31 21:40:27,525][26287] KL-divergence is very high: 1802.8154
[2023-08-31 21:40:27,529][26287] KL-divergence is very high: 699.5053
[2023-08-31 21:40:27,531][26287] KL-divergence is very high: 321.3572
[2023-08-31 21:40:27,534][26287] KL-divergence is very high: 647.1086
[2023-08-31 21:40:27,537][26287] KL-divergence is very high: 323.2336
[2023-08-31 21:40:27,539][26287] KL-divergence is very high: 240.7922
[2023-08-31 21:40:27,794][26287] KL-divergence is very high: 171.9521
[2023-08-31 21:40:27,799][26287] KL-divergence is very high: 272.3795
[2023-08-31 21:40:27,802][26287] KL-divergence is very high: 378.8112
[2023-08-31 21:40:27,807][26287] KL-divergence is very high: 317.8959
[2023-08-31 21:40:27,810][26287] KL-divergence is very high: 414.4712
[2023-08-31 21:40:28,054][26287] KL-divergence is very high: 319.7784
[2023-08-31 21:40:28,057][26287] KL-divergence is very high: 400.1347
[2023-08-31 21:40:28,060][26287] KL-divergence is very high: 209.7270
[2023-08-31 21:40:28,063][26287] KL-divergence is very high: 193.0887
[2023-08-31 21:40:28,066][26287] KL-divergence is very high: 111.9463
[2023-08-31 21:40:28,107][26276] Fps is (10 sec: 16386.4, 60 sec: 15837.6, 300 sec: 15523.2). Total num frames: 17711104. Throughput: 0: 15878.4. Samples: 5755414. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:40:28,108][26276] Avg episode reward: [(0, '-3475.161')]
[2023-08-31 21:40:28,303][26287] KL-divergence is very high: 550.5793
[2023-08-31 21:40:28,305][26287] KL-divergence is very high: 1066.4229
[2023-08-31 21:40:28,308][26287] KL-divergence is very high: 967.9100
[2023-08-31 21:40:28,311][26287] KL-divergence is very high: 471.4187
[2023-08-31 21:40:28,313][26287] KL-divergence is very high: 362.8134
[2023-08-31 21:40:28,316][26287] KL-divergence is very high: 414.8945
[2023-08-31 21:40:28,319][26287] KL-divergence is very high: 194.6758
[2023-08-31 21:40:28,528][26287] KL-divergence is very high: 300.6579
[2023-08-31 21:40:28,530][26287] KL-divergence is very high: 567.1871
[2023-08-31 21:40:28,533][26287] KL-divergence is very high: 425.0752
[2023-08-31 21:40:28,536][26287] KL-divergence is very high: 114.7815
[2023-08-31 21:40:28,539][26287] KL-divergence is very high: 135.6573
[2023-08-31 21:40:28,542][26287] KL-divergence is very high: 371.1676
[2023-08-31 21:40:28,545][26287] KL-divergence is very high: 281.9615
[2023-08-31 21:40:29,025][26287] KL-divergence is very high: 116.7959
[2023-08-31 21:40:29,028][26287] KL-divergence is very high: 190.3008
[2023-08-31 21:40:29,030][26287] KL-divergence is very high: 133.4874
[2023-08-31 21:40:29,038][26287] KL-divergence is very high: 145.3493
[2023-08-31 21:40:29,255][26287] KL-divergence is very high: 133.5468
[2023-08-31 21:40:29,257][26287] KL-divergence is very high: 245.6845
[2023-08-31 21:40:29,260][26287] KL-divergence is very high: 163.7270
[2023-08-31 21:40:29,268][26287] KL-divergence is very high: 185.3728
[2023-08-31 21:40:29,271][26287] KL-divergence is very high: 156.8565
[2023-08-31 21:40:29,273][26288] Updated weights for policy 0, policy_version 34632 (0.0002)
[2023-08-31 21:40:29,510][26287] KL-divergence is very high: 151.4837
[2023-08-31 21:40:29,513][26287] KL-divergence is very high: 233.7181
[2023-08-31 21:40:29,515][26287] KL-divergence is very high: 159.4882
[2023-08-31 21:40:29,523][26287] KL-divergence is very high: 152.9796
[2023-08-31 21:40:29,526][26287] KL-divergence is very high: 104.8295
[2023-08-31 21:40:30,020][26287] KL-divergence is very high: 110.2084
[2023-08-31 21:40:30,023][26287] KL-divergence is very high: 155.5636
[2023-08-31 21:40:31,288][26287] KL-divergence is very high: 108.0827
[2023-08-31 21:40:31,292][26287] KL-divergence is very high: 142.5220
[2023-08-31 21:40:31,295][26287] KL-divergence is very high: 100.2219
[2023-08-31 21:40:31,576][26287] KL-divergence is very high: 160.2532
[2023-08-31 21:40:31,579][26287] KL-divergence is very high: 110.3047
[2023-08-31 21:40:31,834][26287] KL-divergence is very high: 129.9994
[2023-08-31 21:40:31,850][26288] Updated weights for policy 0, policy_version 34712 (0.0002)
[2023-08-31 21:40:32,331][26287] KL-divergence is very high: 103.8950
[2023-08-31 21:40:32,822][26287] KL-divergence is very high: 219.0341
[2023-08-31 21:40:32,825][26287] KL-divergence is very high: 162.2137
[2023-08-31 21:40:32,832][26287] KL-divergence is very high: 140.0852
[2023-08-31 21:40:32,836][26287] KL-divergence is very high: 127.0106
[2023-08-31 21:40:33,090][26287] KL-divergence is very high: 122.8398
[2023-08-31 21:40:33,105][26276] Fps is (10 sec: 15974.6, 60 sec: 15838.7, 300 sec: 15551.0). Total num frames: 17793024. Throughput: 0: 15872.2. Samples: 5849108. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:40:33,106][26276] Avg episode reward: [(0, '-3475.161')]
[2023-08-31 21:40:33,843][26287] KL-divergence is very high: 108.3376
[2023-08-31 21:40:34,121][26287] KL-divergence is very high: 156.9679
[2023-08-31 21:40:34,124][26287] KL-divergence is very high: 270.6866
[2023-08-31 21:40:34,359][26288] Updated weights for policy 0, policy_version 34792 (0.0002)
[2023-08-31 21:40:35,645][26287] KL-divergence is very high: 166.2014
[2023-08-31 21:40:35,648][26287] KL-divergence is very high: 139.1133
[2023-08-31 21:40:36,143][26287] KL-divergence is very high: 159.4923
[2023-08-31 21:40:36,149][26287] KL-divergence is very high: 202.2336
[2023-08-31 21:40:37,226][26288] Updated weights for policy 0, policy_version 34872 (0.0003)
[2023-08-31 21:40:38,107][26276] Fps is (10 sec: 15565.1, 60 sec: 15837.4, 300 sec: 15523.3). Total num frames: 17866752. Throughput: 0: 15779.0. Samples: 5940290. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:40:38,108][26276] Avg episode reward: [(0, '-14160.166')]
[2023-08-31 21:40:39,759][26288] Updated weights for policy 0, policy_version 34952 (0.0002)
[2023-08-31 21:40:42,367][26288] Updated weights for policy 0, policy_version 35032 (0.0002)
[2023-08-31 21:40:43,106][26276] Fps is (10 sec: 15563.6, 60 sec: 15837.7, 300 sec: 15550.9). Total num frames: 17948672. Throughput: 0: 15766.3. Samples: 5988832. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:40:43,106][26276] Avg episode reward: [(0, '-14160.166')]
[2023-08-31 21:40:43,110][26287] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000035056_17948672.pth...
[2023-08-31 21:40:43,112][26287] Removing /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000029024_14860288.pth
[2023-08-31 21:40:44,856][26288] Updated weights for policy 0, policy_version 35112 (0.0002)
[2023-08-31 21:40:47,550][26288] Updated weights for policy 0, policy_version 35192 (0.0003)
[2023-08-31 21:40:48,110][26276] Fps is (10 sec: 15969.9, 60 sec: 15837.7, 300 sec: 15578.4). Total num frames: 18026496. Throughput: 0: 15723.7. Samples: 6082368. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:40:48,110][26276] Avg episode reward: [(0, '-14121.168')]
[2023-08-31 21:40:50,068][26288] Updated weights for policy 0, policy_version 35272 (0.0002)
[2023-08-31 21:40:52,483][26288] Updated weights for policy 0, policy_version 35352 (0.0002)
[2023-08-31 21:40:53,107][26276] Fps is (10 sec: 15973.7, 60 sec: 15907.0, 300 sec: 15578.9). Total num frames: 18108416. Throughput: 0: 15822.6. Samples: 6181510. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:40:53,107][26276] Avg episode reward: [(0, '-14121.168')]
[2023-08-31 21:40:54,933][26288] Updated weights for policy 0, policy_version 35432 (0.0002)
[2023-08-31 21:40:56,160][26287] KL-divergence is very high: 566.7412
[2023-08-31 21:40:56,169][26287] KL-divergence is very high: 186.6763
[2023-08-31 21:40:56,171][26287] KL-divergence is very high: 3223.1611
[2023-08-31 21:40:56,416][26287] KL-divergence is very high: 23079.4609
[2023-08-31 21:40:56,662][26287] KL-divergence is very high: 107.1433
[2023-08-31 21:40:56,666][26287] KL-divergence is very high: 585.8299
[2023-08-31 21:40:56,668][26287] KL-divergence is very high: 107.4636
[2023-08-31 21:40:56,673][26287] KL-divergence is very high: 115.5261
[2023-08-31 21:40:56,887][26287] KL-divergence is very high: 3172.4507
[2023-08-31 21:40:56,889][26287] KL-divergence is very high: 552.2877
[2023-08-31 21:40:56,892][26287] KL-divergence is very high: 2962.9414
[2023-08-31 21:40:56,898][26287] KL-divergence is very high: 6471.5459
[2023-08-31 21:40:56,901][26287] KL-divergence is very high: 10251.8096
[2023-08-31 21:40:57,105][26287] KL-divergence is very high: 187.4744
[2023-08-31 21:40:57,108][26287] KL-divergence is very high: 374.3694
[2023-08-31 21:40:57,111][26287] KL-divergence is very high: 191.0694
[2023-08-31 21:40:57,114][26287] KL-divergence is very high: 749.1256
[2023-08-31 21:40:57,117][26287] KL-divergence is very high: 151.7489
[2023-08-31 21:40:57,120][26287] KL-divergence is very high: 218.8932
[2023-08-31 21:40:57,123][26287] KL-divergence is very high: 175.1783
[2023-08-31 21:40:57,330][26287] KL-divergence is very high: 397.3231
[2023-08-31 21:40:57,333][26287] KL-divergence is very high: 218.5518
[2023-08-31 21:40:57,335][26287] KL-divergence is very high: 118.2060
[2023-08-31 21:40:57,338][26287] KL-divergence is very high: 605.5130
[2023-08-31 21:40:57,340][26287] KL-divergence is very high: 810.2439
[2023-08-31 21:40:57,343][26287] KL-divergence is very high: 2312.4211
[2023-08-31 21:40:57,346][26287] KL-divergence is very high: 3730.5149
[2023-08-31 21:40:57,588][26287] KL-divergence is very high: 1437.5415
[2023-08-31 21:40:57,599][26287] KL-divergence is very high: 5425.7490
[2023-08-31 21:40:57,602][26287] KL-divergence is very high: 481.7138
[2023-08-31 21:40:57,604][26288] Updated weights for policy 0, policy_version 35512 (0.0002)
[2023-08-31 21:40:57,847][26287] KL-divergence is very high: 1404.5769
[2023-08-31 21:40:58,110][26276] Fps is (10 sec: 16384.2, 60 sec: 15905.5, 300 sec: 15592.5). Total num frames: 18190336. Throughput: 0: 15907.6. Samples: 6231676. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:40:58,110][26276] Avg episode reward: [(0, '-14121.095')]
[2023-08-31 21:41:00,029][26288] Updated weights for policy 0, policy_version 35592 (0.0002)
[2023-08-31 21:41:00,258][26287] KL-divergence is very high: 136.4963
[2023-08-31 21:41:02,400][26288] Updated weights for policy 0, policy_version 35672 (0.0002)
[2023-08-31 21:41:03,108][26276] Fps is (10 sec: 16382.3, 60 sec: 15906.0, 300 sec: 15606.4). Total num frames: 18272256. Throughput: 0: 16032.5. Samples: 6329548. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:41:03,108][26276] Avg episode reward: [(0, '-14121.095')]
[2023-08-31 21:41:04,861][26288] Updated weights for policy 0, policy_version 35752 (0.0002)
[2023-08-31 21:41:07,522][26288] Updated weights for policy 0, policy_version 35832 (0.0002)
[2023-08-31 21:41:07,766][26287] KL-divergence is very high: 145.4160
[2023-08-31 21:41:08,107][26276] Fps is (10 sec: 16389.5, 60 sec: 15974.5, 300 sec: 15634.3). Total num frames: 18354176. Throughput: 0: 16040.8. Samples: 6426959. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:41:08,107][26276] Avg episode reward: [(0, '-32571.117')]
[2023-08-31 21:41:08,751][26287] KL-divergence is very high: 226.2016
[2023-08-31 21:41:08,982][26287] KL-divergence is very high: 2719.7385
[2023-08-31 21:41:08,984][26287] KL-divergence is very high: 22492.8730
[2023-08-31 21:41:08,993][26287] KL-divergence is very high: 7949.8638
[2023-08-31 21:41:08,996][26287] High loss value: l:1489.9222 pl:0.1306 vl:0.2008 exp_l:0.0000 kl_l:1489.5908 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:41:08,996][26287] KL-divergence is very high: 4097688.2500
[2023-08-31 21:41:09,239][26287] KL-divergence is very high: 134.3094
[2023-08-31 21:41:09,243][26287] KL-divergence is very high: 3641.0950
[2023-08-31 21:41:09,246][26287] KL-divergence is very high: 5644.9312
[2023-08-31 21:41:09,252][26287] KL-divergence is very high: 5201.4536
[2023-08-31 21:41:09,255][26287] High loss value: l:51.7649 pl:0.1451 vl:0.7145 exp_l:0.0000 kl_l:50.9053 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:41:09,255][26287] KL-divergence is very high: 25853.0312
[2023-08-31 21:41:09,472][26287] KL-divergence is very high: 2166.4963
[2023-08-31 21:41:09,475][26287] KL-divergence is very high: 631.8268
[2023-08-31 21:41:09,478][26287] KL-divergence is very high: 2644.3645
[2023-08-31 21:41:09,481][26287] KL-divergence is very high: 2899.5549
[2023-08-31 21:41:09,484][26287] KL-divergence is very high: 1442.3395
[2023-08-31 21:41:09,487][26287] KL-divergence is very high: 2263.4260
[2023-08-31 21:41:09,491][26287] KL-divergence is very high: 9089.0371
[2023-08-31 21:41:09,712][26287] KL-divergence is very high: 4604.6489
[2023-08-31 21:41:09,715][26287] KL-divergence is very high: 10826.4189
[2023-08-31 21:41:09,718][26287] KL-divergence is very high: 308.6287
[2023-08-31 21:41:09,721][26287] High loss value: l:94.7188 pl:0.1534 vl:0.2481 exp_l:0.0000 kl_l:94.3174 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:41:09,722][26287] KL-divergence is very high: 87252.3828
[2023-08-31 21:41:09,725][26287] KL-divergence is very high: 1605.6221
[2023-08-31 21:41:09,728][26287] KL-divergence is very high: 8115.1284
[2023-08-31 21:41:09,731][26287] KL-divergence is very high: 6360.8789
[2023-08-31 21:41:09,960][26287] KL-divergence is very high: 3548.0237
[2023-08-31 21:41:09,963][26287] KL-divergence is very high: 4948.4155
[2023-08-31 21:41:09,966][26287] KL-divergence is very high: 9149.3613
[2023-08-31 21:41:09,969][26287] KL-divergence is very high: 8341.8340
[2023-08-31 21:41:09,971][26287] KL-divergence is very high: 217.2154
[2023-08-31 21:41:09,974][26287] KL-divergence is very high: 209.2729
[2023-08-31 21:41:09,977][26287] KL-divergence is very high: 2334.2212
[2023-08-31 21:41:09,979][26288] Updated weights for policy 0, policy_version 35912 (0.0002)
[2023-08-31 21:41:10,179][26287] KL-divergence is very high: 321.8802
[2023-08-31 21:41:10,188][26287] KL-divergence is very high: 761.8527
[2023-08-31 21:41:10,190][26287] KL-divergence is very high: 768.7032
[2023-08-31 21:41:10,193][26287] KL-divergence is very high: 156.4444
[2023-08-31 21:41:10,432][26287] KL-divergence is very high: 902.9617
[2023-08-31 21:41:10,442][26287] KL-divergence is very high: 13842.7393
[2023-08-31 21:41:10,946][26287] KL-divergence is very high: 2541.2068
[2023-08-31 21:41:10,956][26287] High loss value: l:90.8727 pl:0.1348 vl:0.2430 exp_l:0.0000 kl_l:90.4949 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:41:10,956][26287] KL-divergence is very high: 67838.5625
[2023-08-31 21:41:11,170][26287] KL-divergence is very high: 8966.8408
[2023-08-31 21:41:11,173][26287] KL-divergence is very high: 1175.3223
[2023-08-31 21:41:11,176][26287] KL-divergence is very high: 171.9436
[2023-08-31 21:41:11,179][26287] KL-divergence is very high: 123.5029
[2023-08-31 21:41:11,418][26287] KL-divergence is very high: 185.4600
[2023-08-31 21:41:11,421][26287] KL-divergence is very high: 146.3728
[2023-08-31 21:41:11,428][26287] KL-divergence is very high: 1209.3120
[2023-08-31 21:41:11,430][26287] KL-divergence is very high: 1522.2152
[2023-08-31 21:41:11,675][26287] KL-divergence is very high: 954.9514
[2023-08-31 21:41:11,678][26287] KL-divergence is very high: 1511.9570
[2023-08-31 21:41:11,684][26287] KL-divergence is very high: 841.6061
[2023-08-31 21:41:11,687][26287] KL-divergence is very high: 938.4427
[2023-08-31 21:41:11,689][26287] KL-divergence is very high: 932.7198
[2023-08-31 21:41:11,922][26287] KL-divergence is very high: 230.9576
[2023-08-31 21:41:11,925][26287] KL-divergence is very high: 216.7300
[2023-08-31 21:41:11,928][26287] KL-divergence is very high: 1208.4448
[2023-08-31 21:41:11,931][26287] KL-divergence is very high: 310.5713
[2023-08-31 21:41:11,934][26287] KL-divergence is very high: 486.1263
[2023-08-31 21:41:11,937][26287] KL-divergence is very high: 1396.4808
[2023-08-31 21:41:12,168][26287] KL-divergence is very high: 104.3496
[2023-08-31 21:41:12,175][26287] KL-divergence is very high: 1155.5652
[2023-08-31 21:41:12,178][26287] KL-divergence is very high: 115.1448
[2023-08-31 21:41:12,395][26287] KL-divergence is very high: 229.3121
[2023-08-31 21:41:12,401][26287] KL-divergence is very high: 474.4002
[2023-08-31 21:41:12,404][26287] KL-divergence is very high: 199.5064
[2023-08-31 21:41:12,407][26287] KL-divergence is very high: 234.6824
[2023-08-31 21:41:12,413][26288] Updated weights for policy 0, policy_version 35992 (0.0002)
[2023-08-31 21:41:13,106][26276] Fps is (10 sec: 16386.0, 60 sec: 16043.5, 300 sec: 15634.4). Total num frames: 18436096. Throughput: 0: 16048.2. Samples: 6477564. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:41:13,107][26276] Avg episode reward: [(0, '-32571.117')]
[2023-08-31 21:41:14,098][26287] KL-divergence is very high: 116.3943
[2023-08-31 21:41:14,823][26288] Updated weights for policy 0, policy_version 36072 (0.0002)
[2023-08-31 21:41:15,523][26287] High loss value: l:52.2636 pl:0.1357 vl:3.2437 exp_l:0.0000 kl_l:48.8842 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:41:15,523][26287] KL-divergence is very high: 32442.3379
[2023-08-31 21:41:15,527][26287] High loss value: l:53.4996 pl:0.1451 vl:0.8627 exp_l:0.0000 kl_l:52.4918 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:41:15,527][26287] KL-divergence is very high: 19455.6172
[2023-08-31 21:41:15,535][26287] High loss value: l:1258.0549 pl:0.1899 vl:2.7615 exp_l:0.0000 kl_l:1255.1035 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:41:15,536][26287] KL-divergence is very high: 803527.0000
[2023-08-31 21:41:15,540][26287] KL-divergence is very high: 5542.8940
[2023-08-31 21:41:15,754][26287] High loss value: l:222.4290 pl:0.0305 vl:2.0482 exp_l:0.0000 kl_l:220.3502 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:41:15,754][26287] KL-divergence is very high: 83022.7188
[2023-08-31 21:41:15,757][26287] High loss value: l:130.0812 pl:0.0275 vl:2.8846 exp_l:0.0000 kl_l:127.1692 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:41:15,757][26287] KL-divergence is very high: 179857.7188
[2023-08-31 21:41:15,761][26287] KL-divergence is very high: 6776.3706
[2023-08-31 21:41:15,764][26287] High loss value: l:2065.4629 pl:0.2328 vl:2.2863 exp_l:0.0000 kl_l:2062.9438 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:41:15,764][26287] KL-divergence is very high: 627115.8125
[2023-08-31 21:41:15,768][26287] High loss value: l:579.6219 pl:0.0583 vl:2.0475 exp_l:0.0000 kl_l:577.5161 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:41:15,768][26287] KL-divergence is very high: 197381.8750
[2023-08-31 21:41:15,771][26287] High loss value: l:195.9787 pl:0.0611 vl:3.0266 exp_l:0.0000 kl_l:192.8910 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:41:15,771][26287] KL-divergence is very high: 263986.4375
[2023-08-31 21:41:15,774][26287] KL-divergence is very high: 5964.6919
[2023-08-31 21:41:15,982][26287] High loss value: l:48.5216 pl:-0.0223 vl:1.4775 exp_l:0.0000 kl_l:47.0664 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:41:15,982][26287] KL-divergence is very high: 22869.2168
[2023-08-31 21:41:15,985][26287] High loss value: l:88.6644 pl:0.0619 vl:2.1999 exp_l:0.0000 kl_l:86.4026 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:41:15,985][26287] KL-divergence is very high: 21221.5176
[2023-08-31 21:41:15,988][26287] High loss value: l:51.3519 pl:0.0880 vl:3.0088 exp_l:0.0000 kl_l:48.2551 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:41:15,988][26287] KL-divergence is very high: 42070.5117
[2023-08-31 21:41:15,991][26287] High loss value: l:97.2402 pl:0.0460 vl:0.8187 exp_l:0.0000 kl_l:96.3755 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:41:15,992][26287] KL-divergence is very high: 46008.4492
[2023-08-31 21:41:15,995][26287] High loss value: l:36.6573 pl:0.0799 vl:1.7922 exp_l:0.0000 kl_l:34.7851 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:41:15,995][26287] KL-divergence is very high: 9828.9336
[2023-08-31 21:41:15,998][26287] High loss value: l:143.4780 pl:0.0629 vl:3.3079 exp_l:0.0000 kl_l:140.1073 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:41:15,998][26287] KL-divergence is very high: 22497.3926
[2023-08-31 21:41:16,001][26287] High loss value: l:236.4046 pl:0.1334 vl:4.3383 exp_l:0.0000 kl_l:231.9329 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:41:16,001][26287] KL-divergence is very high: 67917.1953
[2023-08-31 21:41:16,235][26287] High loss value: l:237.1096 pl:0.0640 vl:3.7633 exp_l:0.0000 kl_l:233.2822 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:41:16,235][26287] KL-divergence is very high: 85959.7422
[2023-08-31 21:41:16,238][26287] High loss value: l:518.4819 pl:0.1243 vl:3.1014 exp_l:0.0000 kl_l:515.2563 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:41:16,238][26287] KL-divergence is very high: 165356.0469
[2023-08-31 21:41:16,241][26287] High loss value: l:421.4949 pl:0.1203 vl:2.3808 exp_l:0.0000 kl_l:418.9939 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:41:16,241][26287] KL-divergence is very high: 126379.1172
[2023-08-31 21:41:16,244][26287] High loss value: l:257.3800 pl:0.0852 vl:3.3990 exp_l:0.0000 kl_l:253.8958 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:41:16,244][26287] KL-divergence is very high: 73618.3047
[2023-08-31 21:41:16,248][26287] High loss value: l:45.7448 pl:0.0451 vl:3.4478 exp_l:0.0000 kl_l:42.2519 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:41:16,248][26287] KL-divergence is very high: 6951.0132
[2023-08-31 21:41:16,252][26287] High loss value: l:157.1566 pl:0.0266 vl:2.9572 exp_l:0.0000 kl_l:154.1728 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:41:16,252][26287] KL-divergence is very high: 81687.0000
[2023-08-31 21:41:16,255][26287] High loss value: l:412.8164 pl:0.0348 vl:2.2743 exp_l:0.0000 kl_l:410.5073 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:41:16,255][26287] KL-divergence is very high: 156655.2188
[2023-08-31 21:41:16,468][26287] High loss value: l:39.2635 pl:-0.0089 vl:1.7072 exp_l:0.0000 kl_l:37.5652 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:41:16,468][26287] KL-divergence is very high: 7494.6572
[2023-08-31 21:41:16,471][26287] KL-divergence is very high: 8352.9697
[2023-08-31 21:41:16,474][26287] KL-divergence is very high: 1337.5718
[2023-08-31 21:41:16,477][26287] KL-divergence is very high: 1845.1379
[2023-08-31 21:41:16,480][26287] KL-divergence is very high: 1833.6147
[2023-08-31 21:41:16,482][26287] KL-divergence is very high: 2853.6899
[2023-08-31 21:41:16,485][26287] KL-divergence is very high: 3699.4287
[2023-08-31 21:41:16,701][26287] KL-divergence is very high: 1435.8717
[2023-08-31 21:41:16,704][26287] KL-divergence is very high: 702.1136
[2023-08-31 21:41:16,707][26287] KL-divergence is very high: 1562.6309
[2023-08-31 21:41:16,710][26287] KL-divergence is very high: 1617.0958
[2023-08-31 21:41:16,713][26287] KL-divergence is very high: 504.0643
[2023-08-31 21:41:16,715][26287] KL-divergence is very high: 12049.9727
[2023-08-31 21:41:16,718][26287] KL-divergence is very high: 4610.5952
[2023-08-31 21:41:16,959][26287] KL-divergence is very high: 5817.3809
[2023-08-31 21:41:16,962][26287] High loss value: l:37.7969 pl:0.0671 vl:1.5621 exp_l:0.0000 kl_l:36.1677 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:41:16,962][26287] KL-divergence is very high: 9234.9834
[2023-08-31 21:41:16,966][26287] KL-divergence is very high: 3297.1499
[2023-08-31 21:41:16,969][26287] KL-divergence is very high: 3517.6973
[2023-08-31 21:41:16,971][26287] KL-divergence is very high: 6175.0186
[2023-08-31 21:41:16,974][26287] KL-divergence is very high: 4618.4912
[2023-08-31 21:41:16,977][26287] KL-divergence is very high: 5516.9575
[2023-08-31 21:41:17,213][26287] KL-divergence is very high: 2801.2820
[2023-08-31 21:41:17,216][26287] KL-divergence is very high: 8034.7344
[2023-08-31 21:41:17,219][26287] KL-divergence is very high: 1849.4379
[2023-08-31 21:41:17,222][26287] KL-divergence is very high: 2333.5837
[2023-08-31 21:41:17,225][26287] KL-divergence is very high: 1909.2493
[2023-08-31 21:41:17,228][26287] KL-divergence is very high: 2585.0637
[2023-08-31 21:41:17,230][26287] KL-divergence is very high: 9973.7295
[2023-08-31 21:41:17,498][26287] KL-divergence is very high: 1104.0723
[2023-08-31 21:41:17,500][26287] KL-divergence is very high: 665.3709
[2023-08-31 21:41:17,503][26287] KL-divergence is very high: 576.3234
[2023-08-31 21:41:17,506][26287] KL-divergence is very high: 4930.5415
[2023-08-31 21:41:17,508][26288] Updated weights for policy 0, policy_version 36152 (0.0002)
[2023-08-31 21:41:17,756][26287] KL-divergence is very high: 8592.5342
[2023-08-31 21:41:17,759][26287] KL-divergence is very high: 921.1464
[2023-08-31 21:41:17,762][26287] KL-divergence is very high: 4724.4434
[2023-08-31 21:41:17,765][26287] KL-divergence is very high: 28731.0020
[2023-08-31 21:41:17,768][26287] KL-divergence is very high: 7324.0835
[2023-08-31 21:41:17,771][26287] High loss value: l:56.5105 pl:0.1738 vl:1.1417 exp_l:0.0000 kl_l:55.1949 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:41:17,771][26287] KL-divergence is very high: 8917.0156
[2023-08-31 21:41:17,774][26287] High loss value: l:49.7667 pl:0.1425 vl:1.1665 exp_l:0.0000 kl_l:48.4577 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:41:17,774][26287] KL-divergence is very high: 22626.8047
[2023-08-31 21:41:17,983][26287] KL-divergence is very high: 597.2063
[2023-08-31 21:41:17,986][26287] KL-divergence is very high: 186.6264
[2023-08-31 21:41:17,991][26287] KL-divergence is very high: 419.4028
[2023-08-31 21:41:17,994][26287] KL-divergence is very high: 293.6956
[2023-08-31 21:41:17,997][26287] KL-divergence is very high: 104.7912
[2023-08-31 21:41:18,106][26276] Fps is (10 sec: 16385.8, 60 sec: 16180.1, 300 sec: 15662.2). Total num frames: 18518016. Throughput: 0: 16121.0. Samples: 6574558. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:41:18,106][26276] Avg episode reward: [(0, '-38895.114')]
[2023-08-31 21:41:18,460][26287] KL-divergence is very high: 157.9155
[2023-08-31 21:41:18,468][26287] KL-divergence is very high: 389.1481
[2023-08-31 21:41:18,473][26287] KL-divergence is very high: 509.1943
[2023-08-31 21:41:18,476][26287] KL-divergence is very high: 181.3181
[2023-08-31 21:41:19,429][26287] KL-divergence is very high: 4134.1763
[2023-08-31 21:41:19,437][26287] KL-divergence is very high: 3796.2422
[2023-08-31 21:41:19,440][26287] KL-divergence is very high: 932.6100
[2023-08-31 21:41:19,649][26287] KL-divergence is very high: 169.3168
[2023-08-31 21:41:19,657][26287] KL-divergence is very high: 118.2936
[2023-08-31 21:41:19,942][26287] KL-divergence is very high: 420.4165
[2023-08-31 21:41:19,945][26288] Updated weights for policy 0, policy_version 36232 (0.0002)
[2023-08-31 21:41:20,155][26287] KL-divergence is very high: 101.5808
[2023-08-31 21:41:20,157][26287] KL-divergence is very high: 232.9451
[2023-08-31 21:41:20,164][26287] KL-divergence is very high: 274.0596
[2023-08-31 21:41:20,432][26287] KL-divergence is very high: 169.9864
[2023-08-31 21:41:20,435][26287] KL-divergence is very high: 190.9589
[2023-08-31 21:41:20,924][26287] KL-divergence is very high: 106.6247
[2023-08-31 21:41:21,161][26287] KL-divergence is very high: 150.0225
[2023-08-31 21:41:21,164][26287] KL-divergence is very high: 169.1331
[2023-08-31 21:41:21,166][26287] KL-divergence is very high: 181.5327
[2023-08-31 21:41:21,169][26287] KL-divergence is very high: 224.7003
[2023-08-31 21:41:21,172][26287] KL-divergence is very high: 125.7622
[2023-08-31 21:41:21,177][26287] KL-divergence is very high: 752.7650
[2023-08-31 21:41:21,404][26287] KL-divergence is very high: 137.8256
[2023-08-31 21:41:21,409][26287] KL-divergence is very high: 246.9874
[2023-08-31 21:41:21,631][26287] KL-divergence is very high: 112.9114
[2023-08-31 21:41:21,634][26287] KL-divergence is very high: 154.2659
[2023-08-31 21:41:21,641][26287] KL-divergence is very high: 187.3661
[2023-08-31 21:41:21,902][26287] KL-divergence is very high: 155.8197
[2023-08-31 21:41:21,905][26287] KL-divergence is very high: 1589.2289
[2023-08-31 21:41:21,907][26287] KL-divergence is very high: 384.8959
[2023-08-31 21:41:21,915][26287] KL-divergence is very high: 1066.3939
[2023-08-31 21:41:22,176][26287] KL-divergence is very high: 114.1429
[2023-08-31 21:41:22,181][26287] KL-divergence is very high: 145.5502
[2023-08-31 21:41:22,448][26288] Updated weights for policy 0, policy_version 36312 (0.0002)
[2023-08-31 21:41:22,714][26287] KL-divergence is very high: 597.5314
[2023-08-31 21:41:23,107][26276] Fps is (10 sec: 16383.2, 60 sec: 16110.6, 300 sec: 15661.9). Total num frames: 18599936. Throughput: 0: 16308.8. Samples: 6674179. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:41:23,107][26276] Avg episode reward: [(0, '-38895.114')]
[2023-08-31 21:41:23,790][26287] KL-divergence is very high: 868.6734
[2023-08-31 21:41:23,793][26287] KL-divergence is very high: 799.9989
[2023-08-31 21:41:24,045][26287] KL-divergence is very high: 612.8939
[2023-08-31 21:41:24,048][26287] KL-divergence is very high: 576.5898
[2023-08-31 21:41:24,051][26287] KL-divergence is very high: 252.1152
[2023-08-31 21:41:24,053][26287] KL-divergence is very high: 189.7978
[2023-08-31 21:41:24,509][26287] KL-divergence is very high: 474.3026
[2023-08-31 21:41:24,512][26287] KL-divergence is very high: 376.1076
[2023-08-31 21:41:24,515][26287] KL-divergence is very high: 109.9721
[2023-08-31 21:41:24,518][26287] KL-divergence is very high: 157.7057
[2023-08-31 21:41:24,521][26287] KL-divergence is very high: 257.2321
[2023-08-31 21:41:24,524][26287] KL-divergence is very high: 328.2025
[2023-08-31 21:41:24,791][26287] KL-divergence is very high: 646.4330
[2023-08-31 21:41:24,797][26287] KL-divergence is very high: 175.6764
[2023-08-31 21:41:24,799][26287] KL-divergence is very high: 134.4571
[2023-08-31 21:41:25,019][26287] KL-divergence is very high: 123.9097
[2023-08-31 21:41:25,032][26287] KL-divergence is very high: 123.8178
[2023-08-31 21:41:25,034][26288] Updated weights for policy 0, policy_version 36392 (0.0002)
[2023-08-31 21:41:27,653][26288] Updated weights for policy 0, policy_version 36472 (0.0002)
[2023-08-31 21:41:28,109][26276] Fps is (10 sec: 15969.5, 60 sec: 16110.6, 300 sec: 15662.1). Total num frames: 18677760. Throughput: 0: 16252.0. Samples: 6720211. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:41:28,109][26276] Avg episode reward: [(0, '-58024.304')]
[2023-08-31 21:41:30,097][26288] Updated weights for policy 0, policy_version 36552 (0.0002)
[2023-08-31 21:41:32,467][26288] Updated weights for policy 0, policy_version 36632 (0.0002)
[2023-08-31 21:41:33,106][26276] Fps is (10 sec: 16385.8, 60 sec: 16179.1, 300 sec: 15675.9). Total num frames: 18763776. Throughput: 0: 16390.2. Samples: 6819859. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:41:33,106][26276] Avg episode reward: [(0, '-58024.304')]
[2023-08-31 21:41:35,098][26288] Updated weights for policy 0, policy_version 36712 (0.0002)
[2023-08-31 21:41:37,509][26288] Updated weights for policy 0, policy_version 36792 (0.0002)
[2023-08-31 21:41:38,107][26276] Fps is (10 sec: 16796.2, 60 sec: 16315.8, 300 sec: 15689.8). Total num frames: 18845696. Throughput: 0: 16384.8. Samples: 6918834. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:41:38,107][26276] Avg episode reward: [(0, '-52523.107')]
[2023-08-31 21:41:40,021][26288] Updated weights for policy 0, policy_version 36872 (0.0002)
[2023-08-31 21:41:42,463][26288] Updated weights for policy 0, policy_version 36952 (0.0002)
[2023-08-31 21:41:43,110][26276] Fps is (10 sec: 16377.2, 60 sec: 16314.7, 300 sec: 15675.9). Total num frames: 18927616. Throughput: 0: 16347.7. Samples: 6967322. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:41:43,110][26276] Avg episode reward: [(0, '-52523.107')]
[2023-08-31 21:41:44,305][26287] KL-divergence is very high: 534.8354
[2023-08-31 21:41:45,057][26288] Updated weights for policy 0, policy_version 37032 (0.0002)
[2023-08-31 21:41:47,478][26288] Updated weights for policy 0, policy_version 37112 (0.0002)
[2023-08-31 21:41:48,106][26276] Fps is (10 sec: 16386.1, 60 sec: 16385.2, 300 sec: 15689.7). Total num frames: 19009536. Throughput: 0: 16376.5. Samples: 7066461. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:41:48,106][26276] Avg episode reward: [(0, '-47265.224')]
[2023-08-31 21:41:50,001][26288] Updated weights for policy 0, policy_version 37192 (0.0002)
[2023-08-31 21:41:52,381][26288] Updated weights for policy 0, policy_version 37272 (0.0002)
[2023-08-31 21:41:53,108][26276] Fps is (10 sec: 16387.9, 60 sec: 16383.7, 300 sec: 15675.9). Total num frames: 19091456. Throughput: 0: 16448.2. Samples: 7167142. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:41:53,108][26276] Avg episode reward: [(0, '-47265.224')]
[2023-08-31 21:41:54,952][26288] Updated weights for policy 0, policy_version 37352 (0.0002)
[2023-08-31 21:41:57,340][26288] Updated weights for policy 0, policy_version 37432 (0.0002)
[2023-08-31 21:41:58,106][26276] Fps is (10 sec: 16793.9, 60 sec: 16453.5, 300 sec: 15703.9). Total num frames: 19177472. Throughput: 0: 16378.4. Samples: 7214579. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:41:58,106][26276] Avg episode reward: [(0, '-47350.255')]
[2023-08-31 21:41:59,773][26288] Updated weights for policy 0, policy_version 37512 (0.0002)
[2023-08-31 21:42:02,265][26288] Updated weights for policy 0, policy_version 37592 (0.0002)
[2023-08-31 21:42:03,109][26276] Fps is (10 sec: 16792.1, 60 sec: 16452.0, 300 sec: 15717.6). Total num frames: 19259392. Throughput: 0: 16477.0. Samples: 7316070. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:42:03,109][26276] Avg episode reward: [(0, '-47350.255')]
[2023-08-31 21:42:05,034][26288] Updated weights for policy 0, policy_version 37672 (0.0002)
[2023-08-31 21:42:07,521][26288] Updated weights for policy 0, policy_version 37752 (0.0002)
[2023-08-31 21:42:08,110][26276] Fps is (10 sec: 15967.4, 60 sec: 16383.1, 300 sec: 15717.4). Total num frames: 19337216. Throughput: 0: 16352.9. Samples: 7410112. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[2023-08-31 21:42:08,110][26276] Avg episode reward: [(0, '-38025.151')]
[2023-08-31 21:42:10,146][26287] KL-divergence is very high: 5508.9902
[2023-08-31 21:42:10,149][26288] Updated weights for policy 0, policy_version 37832 (0.0002)
[2023-08-31 21:42:10,384][26287] KL-divergence is very high: 1520.4709
[2023-08-31 21:42:10,387][26287] KL-divergence is very high: 944.3821
[2023-08-31 21:42:10,393][26287] KL-divergence is very high: 169.4739
[2023-08-31 21:42:10,396][26287] KL-divergence is very high: 620.7026
[2023-08-31 21:42:10,398][26287] KL-divergence is very high: 268.9792
[2023-08-31 21:42:10,620][26287] KL-divergence is very high: 436.1029
[2023-08-31 21:42:12,644][26288] Updated weights for policy 0, policy_version 37912 (0.0002)
[2023-08-31 21:42:13,107][26276] Fps is (10 sec: 15976.7, 60 sec: 16383.8, 300 sec: 15717.6). Total num frames: 19419136. Throughput: 0: 16385.9. Samples: 7457551. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[2023-08-31 21:42:13,107][26276] Avg episode reward: [(0, '-38025.151')]
[2023-08-31 21:42:15,218][26288] Updated weights for policy 0, policy_version 37992 (0.0002)
[2023-08-31 21:42:17,732][26288] Updated weights for policy 0, policy_version 38072 (0.0003)
[2023-08-31 21:42:18,110][26276] Fps is (10 sec: 15974.2, 60 sec: 16314.5, 300 sec: 15717.3). Total num frames: 19496960. Throughput: 0: 16313.5. Samples: 7554036. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[2023-08-31 21:42:18,110][26276] Avg episode reward: [(0, '-24232.552')]
[2023-08-31 21:42:20,164][26288] Updated weights for policy 0, policy_version 38152 (0.0002)
[2023-08-31 21:42:22,560][26288] Updated weights for policy 0, policy_version 38232 (0.0002)
[2023-08-31 21:42:23,106][26276] Fps is (10 sec: 16386.4, 60 sec: 16384.4, 300 sec: 15731.4). Total num frames: 19582976. Throughput: 0: 16358.3. Samples: 7654935. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[2023-08-31 21:42:23,106][26276] Avg episode reward: [(0, '-24232.552')]
[2023-08-31 21:42:23,109][26287] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000038248_19582976.pth...
[2023-08-31 21:42:23,111][26287] Removing /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000032024_16396288.pth
[2023-08-31 21:42:25,220][26288] Updated weights for policy 0, policy_version 38312 (0.0002)
[2023-08-31 21:42:27,698][26288] Updated weights for policy 0, policy_version 38392 (0.0002)
[2023-08-31 21:42:28,105][26276] Fps is (10 sec: 16391.9, 60 sec: 16384.9, 300 sec: 15745.4). Total num frames: 19660800. Throughput: 0: 16324.1. Samples: 7701832. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[2023-08-31 21:42:28,105][26276] Avg episode reward: [(0, '-5070.645')]
[2023-08-31 21:42:30,083][26288] Updated weights for policy 0, policy_version 38472 (0.0002)
[2023-08-31 21:42:32,467][26288] Updated weights for policy 0, policy_version 38552 (0.0002)
[2023-08-31 21:42:33,105][26276] Fps is (10 sec: 16384.3, 60 sec: 16384.1, 300 sec: 15759.2). Total num frames: 19746816. Throughput: 0: 16365.5. Samples: 7802901. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:42:33,106][26276] Avg episode reward: [(0, '-5070.645')]
[2023-08-31 21:42:33,967][26287] KL-divergence is very high: 6217.9111
[2023-08-31 21:42:33,970][26287] KL-divergence is very high: 1004.0583
[2023-08-31 21:42:33,976][26287] High loss value: l:30.3996 pl:0.1206 vl:0.1283 exp_l:0.0000 kl_l:30.1507 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:33,976][26287] KL-divergence is very high: 6901.3926
[2023-08-31 21:42:33,979][26287] High loss value: l:72.3263 pl:0.0835 vl:0.3396 exp_l:0.0000 kl_l:71.9032 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:33,979][26287] KL-divergence is very high: 33449.8008
[2023-08-31 21:42:33,982][26287] KL-divergence is very high: 4827.8340
[2023-08-31 21:42:34,222][26287] KL-divergence is very high: 131.4175
[2023-08-31 21:42:34,227][26287] KL-divergence is very high: 182.2543
[2023-08-31 21:42:34,233][26287] KL-divergence is very high: 232.4782
[2023-08-31 21:42:34,480][26287] KL-divergence is very high: 212.9963
[2023-08-31 21:42:34,489][26287] KL-divergence is very high: 1101.0173
[2023-08-31 21:42:34,493][26287] KL-divergence is very high: 651.6414
[2023-08-31 21:42:34,496][26287] KL-divergence is very high: 230.9363
[2023-08-31 21:42:35,238][26288] Updated weights for policy 0, policy_version 38632 (0.0002)
[2023-08-31 21:42:35,711][26287] KL-divergence is very high: 320.9615
[2023-08-31 21:42:36,484][26287] KL-divergence is very high: 181.4943
[2023-08-31 21:42:36,487][26287] KL-divergence is very high: 318.6832
[2023-08-31 21:42:36,753][26287] KL-divergence is very high: 119.4258
[2023-08-31 21:42:36,756][26287] KL-divergence is very high: 142.8084
[2023-08-31 21:42:37,238][26287] KL-divergence is very high: 157.2666
[2023-08-31 21:42:37,243][26287] KL-divergence is very high: 165.4450
[2023-08-31 21:42:37,246][26287] KL-divergence is very high: 192.4826
[2023-08-31 21:42:37,249][26287] KL-divergence is very high: 3574.8513
[2023-08-31 21:42:37,486][26287] KL-divergence is very high: 2504.5208
[2023-08-31 21:42:37,488][26287] KL-divergence is very high: 2638.4702
[2023-08-31 21:42:37,491][26287] KL-divergence is very high: 21915.3730
[2023-08-31 21:42:37,494][26287] KL-divergence is very high: 18074.2891
[2023-08-31 21:42:37,497][26287] High loss value: l:32.9126 pl:0.0485 vl:4.2575 exp_l:0.0000 kl_l:28.6066 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:37,497][26287] KL-divergence is very high: 8557.1426
[2023-08-31 21:42:37,501][26287] KL-divergence is very high: 9482.7646
[2023-08-31 21:42:37,504][26287] High loss value: l:53.2624 pl:0.0400 vl:4.4234 exp_l:0.0000 kl_l:48.7990 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:37,504][26287] KL-divergence is very high: 20378.3828
[2023-08-31 21:42:37,755][26287] High loss value: l:44.0154 pl:0.0209 vl:4.6635 exp_l:0.0000 kl_l:39.3310 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:37,755][26287] KL-divergence is very high: 103516.8828
[2023-08-31 21:42:37,759][26287] High loss value: l:747.8834 pl:0.1541 vl:7.2170 exp_l:0.0000 kl_l:740.5123 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:37,759][26287] KL-divergence is very high: 340007.0938
[2023-08-31 21:42:37,763][26287] High loss value: l:579.4944 pl:0.0177 vl:7.4343 exp_l:0.0000 kl_l:572.0424 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:37,763][26287] KL-divergence is very high: 238771.8906
[2023-08-31 21:42:37,766][26287] High loss value: l:81.8118 pl:0.0356 vl:2.1519 exp_l:0.0000 kl_l:79.6244 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:37,767][26287] KL-divergence is very high: 26578.0859
[2023-08-31 21:42:37,770][26287] KL-divergence is very high: 12938.6934
[2023-08-31 21:42:37,773][26287] High loss value: l:203.3932 pl:0.1526 vl:6.3091 exp_l:0.0000 kl_l:196.9315 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:37,773][26287] KL-divergence is very high: 135043.5312
[2023-08-31 21:42:37,776][26287] High loss value: l:228.1812 pl:0.0183 vl:7.6255 exp_l:0.0000 kl_l:220.5375 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:37,776][26287] KL-divergence is very high: 166279.5000
[2023-08-31 21:42:37,780][26288] Updated weights for policy 0, policy_version 38712 (0.0002)
[2023-08-31 21:42:37,990][26287] High loss value: l:30.9453 pl:-0.0295 vl:1.3871 exp_l:0.0000 kl_l:29.5876 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:37,991][26287] KL-divergence is very high: 8537.1738
[2023-08-31 21:42:37,994][26287] KL-divergence is very high: 6971.4551
[2023-08-31 21:42:37,996][26287] KL-divergence is very high: 4217.8472
[2023-08-31 21:42:37,999][26287] KL-divergence is very high: 7151.2368
[2023-08-31 21:42:38,003][26287] High loss value: l:50.7447 pl:-0.0422 vl:1.2844 exp_l:0.0000 kl_l:49.5025 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:38,003][26287] KL-divergence is very high: 11603.2188
[2023-08-31 21:42:38,006][26287] High loss value: l:37.0738 pl:-0.0425 vl:1.4079 exp_l:0.0000 kl_l:35.7084 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:38,006][26287] KL-divergence is very high: 7843.0337
[2023-08-31 21:42:38,009][26287] KL-divergence is very high: 12733.7178
[2023-08-31 21:42:38,106][26276] Fps is (10 sec: 16383.0, 60 sec: 16316.1, 300 sec: 15787.0). Total num frames: 19824640. Throughput: 0: 16236.4. Samples: 7897753. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[2023-08-31 21:42:38,106][26276] Avg episode reward: [(0, '-4824.605')]
[2023-08-31 21:42:38,221][26287] High loss value: l:79.8561 pl:0.0170 vl:1.8323 exp_l:0.0000 kl_l:78.0068 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:38,221][26287] KL-divergence is very high: 52365.4609
[2023-08-31 21:42:38,224][26287] High loss value: l:222.8700 pl:-0.0261 vl:1.5272 exp_l:0.0000 kl_l:221.3689 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:38,225][26287] KL-divergence is very high: 112979.4766
[2023-08-31 21:42:38,228][26287] High loss value: l:278.5393 pl:0.0266 vl:10.3309 exp_l:0.0000 kl_l:268.1818 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:38,228][26287] KL-divergence is very high: 93705.4844
[2023-08-31 21:42:38,231][26287] High loss value: l:106.5602 pl:-0.0026 vl:4.3831 exp_l:0.0000 kl_l:102.1796 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:38,232][26287] KL-divergence is very high: 38972.3633
[2023-08-31 21:42:38,235][26287] High loss value: l:30.8573 pl:0.0483 vl:1.8962 exp_l:0.0000 kl_l:28.9128 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:38,235][26287] KL-divergence is very high: 37103.2773
[2023-08-31 21:42:38,239][26287] High loss value: l:148.8845 pl:0.0472 vl:1.4442 exp_l:0.0000 kl_l:147.3931 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:38,239][26287] KL-divergence is very high: 108816.2656
[2023-08-31 21:42:38,242][26287] High loss value: l:99.6931 pl:0.0403 vl:10.2143 exp_l:0.0000 kl_l:89.4385 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:38,242][26287] KL-divergence is very high: 55637.4609
[2023-08-31 21:42:38,472][26287] KL-divergence is very high: 2063.7380
[2023-08-31 21:42:38,475][26287] KL-divergence is very high: 14684.6240
[2023-08-31 21:42:38,479][26287] High loss value: l:55.8675 pl:0.0048 vl:16.1179 exp_l:0.0000 kl_l:39.7448 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:38,479][26287] KL-divergence is very high: 11834.9658
[2023-08-31 21:42:38,483][26287] KL-divergence is very high: 7557.2734
[2023-08-31 21:42:38,485][26287] KL-divergence is very high: 2183.0525
[2023-08-31 21:42:38,488][26287] High loss value: l:47.7568 pl:-0.0043 vl:17.9253 exp_l:0.0000 kl_l:29.8358 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:38,488][26287] KL-divergence is very high: 25794.1777
[2023-08-31 21:42:38,491][26287] High loss value: l:254.7652 pl:0.0280 vl:15.8824 exp_l:0.0000 kl_l:238.8547 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:38,492][26287] KL-divergence is very high: 89025.1172
[2023-08-31 21:42:38,697][26287] KL-divergence is very high: 3446.0276
[2023-08-31 21:42:38,700][26287] KL-divergence is very high: 552.6014
[2023-08-31 21:42:38,703][26287] High loss value: l:46.1546 pl:0.0368 vl:1.6227 exp_l:0.0000 kl_l:44.4951 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:38,703][26287] KL-divergence is very high: 8637.1953
[2023-08-31 21:42:38,706][26287] High loss value: l:60.5762 pl:-0.0323 vl:23.1039 exp_l:0.0000 kl_l:37.5047 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:38,706][26287] KL-divergence is very high: 16828.4824
[2023-08-31 21:42:38,709][26287] KL-divergence is very high: 3040.1785
[2023-08-31 21:42:38,711][26287] High loss value: l:33.3321 pl:-0.0396 vl:5.0604 exp_l:0.0000 kl_l:28.3113 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:38,712][26287] KL-divergence is very high: 8398.4453
[2023-08-31 21:42:38,714][26287] High loss value: l:62.0342 pl:0.0367 vl:1.5872 exp_l:0.0000 kl_l:60.4104 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:38,715][26287] KL-divergence is very high: 10667.5264
[2023-08-31 21:42:38,947][26287] High loss value: l:50.0033 pl:-0.0483 vl:2.7100 exp_l:0.0000 kl_l:47.3416 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:38,947][26287] KL-divergence is very high: 6328.1997
[2023-08-31 21:42:38,950][26287] High loss value: l:50.5871 pl:-0.0387 vl:1.8121 exp_l:0.0000 kl_l:48.8137 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:38,950][26287] KL-divergence is very high: 24025.7930
[2023-08-31 21:42:38,953][26287] High loss value: l:48.0828 pl:-0.0254 vl:1.2735 exp_l:0.0000 kl_l:46.8348 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:38,954][26287] KL-divergence is very high: 8503.7178
[2023-08-31 21:42:38,957][26287] High loss value: l:38.0348 pl:-0.0518 vl:1.0810 exp_l:0.0000 kl_l:37.0055 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:38,957][26287] KL-divergence is very high: 10980.4131
[2023-08-31 21:42:38,960][26287] High loss value: l:100.0258 pl:-0.0468 vl:2.5693 exp_l:0.0000 kl_l:97.5034 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:38,960][26287] KL-divergence is very high: 19359.3242
[2023-08-31 21:42:38,964][26287] High loss value: l:81.7991 pl:-0.0385 vl:1.6593 exp_l:0.0000 kl_l:80.1783 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:38,964][26287] KL-divergence is very high: 17792.9668
[2023-08-31 21:42:38,967][26287] KL-divergence is very high: 7408.5225
[2023-08-31 21:42:39,201][26287] KL-divergence is very high: 2533.1897
[2023-08-31 21:42:39,204][26287] KL-divergence is very high: 4259.9863
[2023-08-31 21:42:39,207][26287] High loss value: l:35.9784 pl:-0.0569 vl:1.4811 exp_l:0.0000 kl_l:34.5543 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:39,207][26287] KL-divergence is very high: 11832.5732
[2023-08-31 21:42:39,211][26287] High loss value: l:33.1399 pl:-0.0504 vl:1.2430 exp_l:0.0000 kl_l:31.9474 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:39,211][26287] KL-divergence is very high: 4821.5513
[2023-08-31 21:42:39,214][26287] KL-divergence is very high: 4307.0176
[2023-08-31 21:42:39,217][26287] KL-divergence is very high: 4892.2720
[2023-08-31 21:42:39,220][26287] High loss value: l:55.9348 pl:-0.0580 vl:1.2558 exp_l:0.0000 kl_l:54.7370 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:39,220][26287] KL-divergence is very high: 7072.8242
[2023-08-31 21:42:39,450][26287] High loss value: l:43.8026 pl:-0.0602 vl:1.2235 exp_l:0.0000 kl_l:42.6394 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:39,450][26287] KL-divergence is very high: 7777.2495
[2023-08-31 21:42:39,453][26287] High loss value: l:54.2808 pl:-0.0565 vl:0.9857 exp_l:0.0000 kl_l:53.3515 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:39,454][26287] KL-divergence is very high: 7335.0366
[2023-08-31 21:42:39,457][26287] KL-divergence is very high: 1008.7773
[2023-08-31 21:42:39,460][26287] High loss value: l:81.2937 pl:-0.0614 vl:0.8643 exp_l:0.0000 kl_l:80.4908 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:39,460][26287] KL-divergence is very high: 14506.5566
[2023-08-31 21:42:39,464][26287] High loss value: l:114.9276 pl:-0.0592 vl:1.0836 exp_l:0.0000 kl_l:113.9032 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:39,464][26287] KL-divergence is very high: 23046.5820
[2023-08-31 21:42:39,467][26287] High loss value: l:77.8424 pl:-0.0561 vl:0.8650 exp_l:0.0000 kl_l:77.0335 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:39,467][26287] KL-divergence is very high: 11321.3232
[2023-08-31 21:42:39,470][26287] KL-divergence is very high: 834.9146
[2023-08-31 21:42:39,705][26287] High loss value: l:48.4507 pl:-0.0601 vl:1.6030 exp_l:0.0000 kl_l:46.9079 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:39,705][26287] KL-divergence is very high: 7733.1792
[2023-08-31 21:42:39,708][26287] High loss value: l:52.0674 pl:-0.0175 vl:4.4435 exp_l:0.0000 kl_l:47.6415 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:39,708][26287] KL-divergence is very high: 9912.0547
[2023-08-31 21:42:39,712][26287] KL-divergence is very high: 2579.6121
[2023-08-31 21:42:39,715][26287] KL-divergence is very high: 2405.4214
[2023-08-31 21:42:39,718][26287] High loss value: l:49.1567 pl:-0.0603 vl:1.3368 exp_l:0.0000 kl_l:47.8802 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:39,718][26287] KL-divergence is very high: 8562.8789
[2023-08-31 21:42:39,722][26287] KL-divergence is very high: 3371.1558
[2023-08-31 21:42:39,725][26287] KL-divergence is very high: 3821.7468
[2023-08-31 21:42:39,937][26287] KL-divergence is very high: 5403.9229
[2023-08-31 21:42:39,939][26287] KL-divergence is very high: 3918.3145
[2023-08-31 21:42:39,942][26287] KL-divergence is very high: 4068.6648
[2023-08-31 21:42:39,945][26287] KL-divergence is very high: 771.0693
[2023-08-31 21:42:39,947][26287] KL-divergence is very high: 9615.9629
[2023-08-31 21:42:39,951][26287] KL-divergence is very high: 7177.2642
[2023-08-31 21:42:39,954][26287] KL-divergence is very high: 5517.6655
[2023-08-31 21:42:40,187][26287] KL-divergence is very high: 6857.7446
[2023-08-31 21:42:40,190][26287] KL-divergence is very high: 3468.8591
[2023-08-31 21:42:40,193][26287] High loss value: l:36.9189 pl:-0.0500 vl:6.2831 exp_l:0.0000 kl_l:30.6858 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:40,193][26287] KL-divergence is very high: 7787.2573
[2023-08-31 21:42:40,197][26287] KL-divergence is very high: 9290.5322
[2023-08-31 21:42:40,200][26287] KL-divergence is very high: 2046.4825
[2023-08-31 21:42:40,202][26287] High loss value: l:59.5921 pl:-0.0360 vl:6.4900 exp_l:0.0000 kl_l:53.1381 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:40,202][26287] KL-divergence is very high: 25067.2988
[2023-08-31 21:42:40,206][26287] High loss value: l:100.7894 pl:-0.0477 vl:6.5998 exp_l:0.0000 kl_l:94.2374 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:40,206][26287] KL-divergence is very high: 24467.1895
[2023-08-31 21:42:40,210][26288] Updated weights for policy 0, policy_version 38792 (0.0002)
[2023-08-31 21:42:40,413][26287] KL-divergence is very high: 5369.6685
[2023-08-31 21:42:40,416][26287] KL-divergence is very high: 1862.8201
[2023-08-31 21:42:40,418][26287] High loss value: l:205.1485 pl:0.1021 vl:14.6897 exp_l:0.0000 kl_l:190.3567 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:40,418][26287] KL-divergence is very high: 814686.4375
[2023-08-31 21:42:40,421][26287] High loss value: l:252.1961 pl:-0.0516 vl:1.0452 exp_l:0.0000 kl_l:251.2025 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:40,422][26287] KL-divergence is very high: 272425.8125
[2023-08-31 21:42:40,425][26287] High loss value: l:153.0589 pl:-0.0335 vl:3.0021 exp_l:0.0000 kl_l:150.0903 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:40,425][26287] KL-divergence is very high: 182187.2188
[2023-08-31 21:42:40,428][26287] High loss value: l:126.8672 pl:-0.0359 vl:25.5625 exp_l:0.0000 kl_l:101.3406 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:40,429][26287] KL-divergence is very high: 100532.1953
[2023-08-31 21:42:40,432][26287] High loss value: l:163.1550 pl:-0.0298 vl:13.5223 exp_l:0.0000 kl_l:149.6626 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:40,432][26287] KL-divergence is very high: 843096.7500
[2023-08-31 21:42:40,665][26287] KL-divergence is very high: 322.5585
[2023-08-31 21:42:40,668][26287] KL-divergence is very high: 378.6861
[2023-08-31 21:42:40,671][26287] High loss value: l:75.8106 pl:-0.0347 vl:6.2501 exp_l:0.0000 kl_l:69.5952 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:40,671][26287] KL-divergence is very high: 74648.7734
[2023-08-31 21:42:40,675][26287] KL-divergence is very high: 724.5021
[2023-08-31 21:42:40,678][26287] KL-divergence is very high: 938.1270
[2023-08-31 21:42:40,681][26287] KL-divergence is very high: 552.0199
[2023-08-31 21:42:40,683][26287] High loss value: l:48.9765 pl:-0.0487 vl:6.3545 exp_l:0.0000 kl_l:42.6707 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:40,683][26287] KL-divergence is very high: 53437.1406
[2023-08-31 21:42:40,928][26287] KL-divergence is very high: 16306.9668
[2023-08-31 21:42:40,930][26287] High loss value: l:64.7815 pl:-0.0435 vl:5.8592 exp_l:0.0000 kl_l:58.9659 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:40,931][26287] KL-divergence is very high: 32938.5312
[2023-08-31 21:42:40,934][26287] High loss value: l:45.5458 pl:-0.0362 vl:9.5070 exp_l:0.0000 kl_l:36.0750 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:40,934][26287] KL-divergence is very high: 21639.0898
[2023-08-31 21:42:40,937][26287] High loss value: l:32.3832 pl:-0.0482 vl:0.9584 exp_l:0.0000 kl_l:31.4730 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:40,937][26287] KL-divergence is very high: 11881.8770
[2023-08-31 21:42:40,941][26287] High loss value: l:49.0576 pl:-0.0456 vl:2.9129 exp_l:0.0000 kl_l:46.1903 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:40,941][26287] KL-divergence is very high: 42082.0391
[2023-08-31 21:42:40,944][26287] High loss value: l:56.9010 pl:-0.0392 vl:6.5009 exp_l:0.0000 kl_l:50.4393 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:40,944][26287] KL-divergence is very high: 47263.9336
[2023-08-31 21:42:40,948][26287] KL-divergence is very high: 12406.3193
[2023-08-31 21:42:41,153][26287] KL-divergence is very high: 2561.2302
[2023-08-31 21:42:41,156][26287] KL-divergence is very high: 1032.3969
[2023-08-31 21:42:41,161][26287] High loss value: l:83.4639 pl:0.1082 vl:6.5201 exp_l:0.0000 kl_l:76.8356 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:41,161][26287] KL-divergence is very high: 49588.7812
[2023-08-31 21:42:41,164][26287] High loss value: l:31.6886 pl:-0.0560 vl:5.4850 exp_l:0.0000 kl_l:26.2597 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:41,164][26287] KL-divergence is very high: 8065.0103
[2023-08-31 21:42:41,168][26287] KL-divergence is very high: 4971.8223
[2023-08-31 21:42:41,171][26287] KL-divergence is very high: 1618.1495
[2023-08-31 21:42:41,418][26287] KL-divergence is very high: 3245.6882
[2023-08-31 21:42:41,422][26287] KL-divergence is very high: 1879.8870
[2023-08-31 21:42:41,425][26287] KL-divergence is very high: 283.3524
[2023-08-31 21:42:41,428][26287] KL-divergence is very high: 567.1121
[2023-08-31 21:42:41,431][26287] High loss value: l:31.9648 pl:-0.0335 vl:2.4670 exp_l:0.0000 kl_l:29.5313 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:41,431][26287] KL-divergence is very high: 11289.0889
[2023-08-31 21:42:41,435][26287] KL-divergence is very high: 2367.9194
[2023-08-31 21:42:41,438][26287] KL-divergence is very high: 1600.3308
[2023-08-31 21:42:41,655][26287] KL-divergence is very high: 3011.3018
[2023-08-31 21:42:41,658][26287] KL-divergence is very high: 222.9487
[2023-08-31 21:42:41,660][26287] KL-divergence is very high: 10550.0117
[2023-08-31 21:42:41,663][26287] KL-divergence is very high: 934.1686
[2023-08-31 21:42:41,666][26287] KL-divergence is very high: 8962.3574
[2023-08-31 21:42:41,669][26287] KL-divergence is very high: 2773.9001
[2023-08-31 21:42:41,672][26287] High loss value: l:79.3142 pl:-0.0458 vl:0.6951 exp_l:0.0000 kl_l:78.6649 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:41,672][26287] KL-divergence is very high: 47168.7070
[2023-08-31 21:42:41,881][26287] KL-divergence is very high: 570.4815
[2023-08-31 21:42:41,884][26287] KL-divergence is very high: 153.9091
[2023-08-31 21:42:41,886][26287] KL-divergence is very high: 4398.0430
[2023-08-31 21:42:41,889][26287] KL-divergence is very high: 212.5515
[2023-08-31 21:42:41,892][26287] KL-divergence is very high: 386.9788
[2023-08-31 21:42:41,895][26287] KL-divergence is very high: 111.8183
[2023-08-31 21:42:41,899][26287] KL-divergence is very high: 7666.9478
[2023-08-31 21:42:42,115][26287] KL-divergence is very high: 1902.2267
[2023-08-31 21:42:42,118][26287] High loss value: l:30.8682 pl:-0.0389 vl:1.1975 exp_l:0.0000 kl_l:29.7096 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:42,118][26287] KL-divergence is very high: 11657.8359
[2023-08-31 21:42:42,121][26287] KL-divergence is very high: 4621.1021
[2023-08-31 21:42:42,125][26287] KL-divergence is very high: 15575.5850
[2023-08-31 21:42:42,127][26287] High loss value: l:55.9945 pl:-0.0479 vl:0.5146 exp_l:0.0000 kl_l:55.5278 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:42,127][26287] KL-divergence is very high: 23749.9277
[2023-08-31 21:42:42,131][26287] KL-divergence is very high: 2227.7700
[2023-08-31 21:42:42,134][26287] High loss value: l:58.7801 pl:-0.0229 vl:0.7303 exp_l:0.0000 kl_l:58.0726 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:42,134][26287] KL-divergence is very high: 22928.1328
[2023-08-31 21:42:42,388][26287] KL-divergence is very high: 6795.4956
[2023-08-31 21:42:42,391][26287] KL-divergence is very high: 8950.6523
[2023-08-31 21:42:42,394][26287] KL-divergence is very high: 1209.4285
[2023-08-31 21:42:42,397][26287] KL-divergence is very high: 2274.5515
[2023-08-31 21:42:42,399][26287] KL-divergence is very high: 220.5175
[2023-08-31 21:42:42,402][26287] KL-divergence is very high: 10859.2910
[2023-08-31 21:42:42,405][26287] KL-divergence is very high: 3976.4575
[2023-08-31 21:42:42,643][26287] KL-divergence is very high: 380.7218
[2023-08-31 21:42:42,646][26287] KL-divergence is very high: 562.9899
[2023-08-31 21:42:42,649][26287] KL-divergence is very high: 894.2342
[2023-08-31 21:42:42,652][26287] KL-divergence is very high: 263.6996
[2023-08-31 21:42:42,654][26287] KL-divergence is very high: 890.9112
[2023-08-31 21:42:42,657][26287] KL-divergence is very high: 258.5213
[2023-08-31 21:42:42,660][26287] KL-divergence is very high: 517.9005
[2023-08-31 21:42:42,662][26288] Updated weights for policy 0, policy_version 38872 (0.0002)
[2023-08-31 21:42:42,893][26287] KL-divergence is very high: 12068.1416
[2023-08-31 21:42:42,895][26287] KL-divergence is very high: 15030.6787
[2023-08-31 21:42:42,898][26287] KL-divergence is very high: 13619.2510
[2023-08-31 21:42:42,901][26287] KL-divergence is very high: 1283.1470
[2023-08-31 21:42:42,905][26287] KL-divergence is very high: 5472.6929
[2023-08-31 21:42:42,907][26287] KL-divergence is very high: 1559.2205
[2023-08-31 21:42:42,910][26287] KL-divergence is very high: 4898.7212
[2023-08-31 21:42:43,105][26276] Fps is (10 sec: 15974.5, 60 sec: 16317.0, 300 sec: 15828.8). Total num frames: 19906560. Throughput: 0: 16293.6. Samples: 7947785. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:42:43,106][26276] Avg episode reward: [(0, '-4824.605')]
[2023-08-31 21:42:43,152][26287] KL-divergence is very high: 3709.6841
[2023-08-31 21:42:43,155][26287] KL-divergence is very high: 2387.7173
[2023-08-31 21:42:43,158][26287] KL-divergence is very high: 115.6761
[2023-08-31 21:42:43,161][26287] KL-divergence is very high: 569.7150
[2023-08-31 21:42:43,164][26287] KL-divergence is very high: 1126.0116
[2023-08-31 21:42:43,167][26287] KL-divergence is very high: 653.8491
[2023-08-31 21:42:43,170][26287] KL-divergence is very high: 4360.0879
[2023-08-31 21:42:43,406][26287] KL-divergence is very high: 4833.4609
[2023-08-31 21:42:43,408][26287] KL-divergence is very high: 3553.0110
[2023-08-31 21:42:43,411][26287] KL-divergence is very high: 4692.0259
[2023-08-31 21:42:43,414][26287] KL-divergence is very high: 1953.6456
[2023-08-31 21:42:43,416][26287] KL-divergence is very high: 1082.1741
[2023-08-31 21:42:43,419][26287] KL-divergence is very high: 1770.8293
[2023-08-31 21:42:43,422][26287] KL-divergence is very high: 978.3228
[2023-08-31 21:42:43,895][26287] KL-divergence is very high: 4829.4014
[2023-08-31 21:42:43,898][26287] KL-divergence is very high: 6426.6709
[2023-08-31 21:42:43,901][26287] High loss value: l:40.3622 pl:0.1279 vl:2.2342 exp_l:0.0000 kl_l:38.0001 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:43,901][26287] KL-divergence is very high: 6188.8574
[2023-08-31 21:42:43,904][26287] KL-divergence is very high: 14825.4580
[2023-08-31 21:42:43,907][26287] KL-divergence is very high: 11041.7891
[2023-08-31 21:42:43,911][26287] High loss value: l:56.0298 pl:0.0855 vl:1.5728 exp_l:0.0000 kl_l:54.3716 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:43,911][26287] KL-divergence is very high: 18697.8066
[2023-08-31 21:42:43,914][26287] High loss value: l:34.9750 pl:0.1506 vl:2.1635 exp_l:0.0000 kl_l:32.6609 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:43,914][26287] KL-divergence is very high: 15135.3809
[2023-08-31 21:42:44,150][26287] KL-divergence is very high: 323.4288
[2023-08-31 21:42:44,153][26287] KL-divergence is very high: 713.5016
[2023-08-31 21:42:44,156][26287] KL-divergence is very high: 1178.3804
[2023-08-31 21:42:44,159][26287] KL-divergence is very high: 2335.7681
[2023-08-31 21:42:44,162][26287] KL-divergence is very high: 1242.8290
[2023-08-31 21:42:44,165][26287] High loss value: l:43.7952 pl:0.0686 vl:0.6624 exp_l:0.0000 kl_l:43.0642 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:44,165][26287] KL-divergence is very high: 11119.4014
[2023-08-31 21:42:44,168][26287] High loss value: l:59.7829 pl:0.0318 vl:1.0398 exp_l:0.0000 kl_l:58.7113 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:44,169][26287] KL-divergence is very high: 19289.6680
[2023-08-31 21:42:44,397][26287] KL-divergence is very high: 116.4669
[2023-08-31 21:42:44,400][26287] KL-divergence is very high: 1476.9203
[2023-08-31 21:42:44,403][26287] KL-divergence is very high: 1599.0088
[2023-08-31 21:42:44,405][26287] KL-divergence is very high: 2259.0447
[2023-08-31 21:42:44,408][26287] KL-divergence is very high: 3759.0103
[2023-08-31 21:42:44,411][26287] KL-divergence is very high: 1316.8757
[2023-08-31 21:42:44,414][26287] KL-divergence is very high: 8846.0762
[2023-08-31 21:42:44,616][26287] KL-divergence is very high: 3120.4751
[2023-08-31 21:42:44,618][26287] KL-divergence is very high: 1319.0039
[2023-08-31 21:42:44,621][26287] KL-divergence is very high: 2162.9902
[2023-08-31 21:42:44,624][26287] KL-divergence is very high: 2920.2769
[2023-08-31 21:42:44,627][26287] KL-divergence is very high: 234.6069
[2023-08-31 21:42:44,629][26287] KL-divergence is very high: 3245.4719
[2023-08-31 21:42:44,632][26287] KL-divergence is very high: 5710.3198
[2023-08-31 21:42:44,836][26287] High loss value: l:34.5435 pl:-0.0201 vl:1.9455 exp_l:0.0000 kl_l:32.6182 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:44,836][26287] KL-divergence is very high: 10573.0156
[2023-08-31 21:42:44,840][26287] KL-divergence is very high: 3096.3535
[2023-08-31 21:42:44,843][26287] KL-divergence is very high: 431.3332
[2023-08-31 21:42:44,845][26287] High loss value: l:58.0140 pl:-0.0175 vl:1.8179 exp_l:0.0000 kl_l:56.2136 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:44,846][26287] KL-divergence is very high: 12054.5615
[2023-08-31 21:42:44,849][26287] High loss value: l:557.9894 pl:-0.0152 vl:1.8330 exp_l:0.0000 kl_l:556.1716 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:44,849][26287] KL-divergence is very high: 233059.5156
[2023-08-31 21:42:44,852][26287] High loss value: l:110.5449 pl:-0.0276 vl:2.1988 exp_l:0.0000 kl_l:108.3737 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:44,852][26287] KL-divergence is very high: 21516.0820
[2023-08-31 21:42:44,856][26287] High loss value: l:30.5598 pl:0.0444 vl:2.6373 exp_l:0.0000 kl_l:27.8782 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:44,856][26287] KL-divergence is very high: 6678.6372
[2023-08-31 21:42:45,061][26287] KL-divergence is very high: 6356.7549
[2023-08-31 21:42:45,063][26287] KL-divergence is very high: 6277.0493
[2023-08-31 21:42:45,066][26287] High loss value: l:153.7085 pl:-0.0107 vl:1.3651 exp_l:0.0000 kl_l:152.3541 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:45,066][26287] KL-divergence is very high: 150563.4531
[2023-08-31 21:42:45,070][26287] KL-divergence is very high: 1902.9656
[2023-08-31 21:42:45,073][26287] KL-divergence is very high: 5222.0996
[2023-08-31 21:42:45,076][26287] KL-divergence is very high: 5691.8506
[2023-08-31 21:42:45,079][26287] High loss value: l:174.6709 pl:-0.0265 vl:1.3336 exp_l:0.0000 kl_l:173.3638 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:45,079][26287] KL-divergence is very high: 165920.1562
[2023-08-31 21:42:45,292][26287] KL-divergence is very high: 8534.0537
[2023-08-31 21:42:45,294][26287] KL-divergence is very high: 1117.5331
[2023-08-31 21:42:45,297][26287] KL-divergence is very high: 1201.5243
[2023-08-31 21:42:45,300][26287] High loss value: l:56.7264 pl:0.0223 vl:1.1421 exp_l:0.0000 kl_l:55.5621 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:45,300][26287] KL-divergence is very high: 54930.6367
[2023-08-31 21:42:45,303][26287] KL-divergence is very high: 4410.2896
[2023-08-31 21:42:45,306][26287] High loss value: l:37.8870 pl:-0.0099 vl:1.6293 exp_l:0.0000 kl_l:36.2676 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:45,307][26287] KL-divergence is very high: 5639.4092
[2023-08-31 21:42:45,310][26287] KL-divergence is very high: 5221.4243
[2023-08-31 21:42:45,313][26288] Updated weights for policy 0, policy_version 38952 (0.0002)
[2023-08-31 21:42:45,523][26287] KL-divergence is very high: 480.7356
[2023-08-31 21:42:45,526][26287] KL-divergence is very high: 451.5940
[2023-08-31 21:42:45,532][26287] KL-divergence is very high: 777.1975
[2023-08-31 21:42:45,534][26287] KL-divergence is very high: 404.9533
[2023-08-31 21:42:45,537][26287] KL-divergence is very high: 438.1442
[2023-08-31 21:42:45,772][26287] KL-divergence is very high: 747.3772
[2023-08-31 21:42:45,774][26287] KL-divergence is very high: 754.6079
[2023-08-31 21:42:45,777][26287] KL-divergence is very high: 510.7791
[2023-08-31 21:42:45,783][26287] KL-divergence is very high: 701.1492
[2023-08-31 21:42:45,786][26287] KL-divergence is very high: 357.6670
[2023-08-31 21:42:45,789][26287] KL-divergence is very high: 287.1835
[2023-08-31 21:42:45,998][26287] KL-divergence is very high: 200.2260
[2023-08-31 21:42:46,003][26287] KL-divergence is very high: 409.0847
[2023-08-31 21:42:46,005][26287] KL-divergence is very high: 140.9597
[2023-08-31 21:42:46,008][26287] KL-divergence is very high: 514.3314
[2023-08-31 21:42:46,011][26287] KL-divergence is very high: 602.4340
[2023-08-31 21:42:46,226][26287] KL-divergence is very high: 1355.6436
[2023-08-31 21:42:46,228][26287] KL-divergence is very high: 1700.5753
[2023-08-31 21:42:46,231][26287] KL-divergence is very high: 1227.4009
[2023-08-31 21:42:46,234][26287] KL-divergence is very high: 206.2784
[2023-08-31 21:42:46,236][26287] KL-divergence is very high: 485.5443
[2023-08-31 21:42:46,240][26287] KL-divergence is very high: 985.3261
[2023-08-31 21:42:46,243][26287] KL-divergence is very high: 867.6931
[2023-08-31 21:42:46,454][26287] KL-divergence is very high: 2643.5322
[2023-08-31 21:42:46,456][26287] KL-divergence is very high: 4785.5889
[2023-08-31 21:42:46,460][26287] KL-divergence is very high: 8066.7847
[2023-08-31 21:42:46,463][26287] KL-divergence is very high: 28854.0938
[2023-08-31 21:42:46,466][26287] High loss value: l:32.0577 pl:0.0441 vl:2.0248 exp_l:0.0000 kl_l:29.9888 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:46,466][26287] KL-divergence is very high: 18165.9219
[2023-08-31 21:42:46,470][26287] KL-divergence is very high: 2161.5398
[2023-08-31 21:42:46,473][26287] High loss value: l:54.5907 pl:0.0663 vl:2.2257 exp_l:0.0000 kl_l:52.2987 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:46,473][26287] KL-divergence is very high: 14661.8447
[2023-08-31 21:42:46,707][26287] KL-divergence is very high: 4381.1079
[2023-08-31 21:42:46,710][26287] KL-divergence is very high: 7714.2124
[2023-08-31 21:42:46,714][26287] KL-divergence is very high: 16929.8145
[2023-08-31 21:42:46,716][26287] High loss value: l:146.5563 pl:0.0568 vl:2.0669 exp_l:0.0000 kl_l:144.4327 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:46,717][26287] KL-divergence is very high: 44703.7969
[2023-08-31 21:42:46,720][26287] High loss value: l:117.0538 pl:0.0505 vl:2.0231 exp_l:0.0000 kl_l:114.9802 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:46,720][26287] KL-divergence is very high: 25726.0098
[2023-08-31 21:42:46,723][26287] High loss value: l:30.5493 pl:0.0408 vl:2.7848 exp_l:0.0000 kl_l:27.7237 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:46,723][26287] KL-divergence is very high: 39037.5352
[2023-08-31 21:42:46,727][26287] High loss value: l:93.9129 pl:0.0689 vl:2.0786 exp_l:0.0000 kl_l:91.7654 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:46,727][26287] KL-divergence is very high: 77377.6641
[2023-08-31 21:42:46,957][26287] KL-divergence is very high: 8049.8818
[2023-08-31 21:42:46,960][26287] KL-divergence is very high: 4474.7749
[2023-08-31 21:42:46,962][26287] High loss value: l:44.1566 pl:0.0842 vl:1.8324 exp_l:0.0000 kl_l:42.2400 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:46,962][26287] KL-divergence is very high: 17141.3027
[2023-08-31 21:42:46,966][26287] KL-divergence is very high: 6047.5835
[2023-08-31 21:42:46,969][26287] KL-divergence is very high: 7221.2583
[2023-08-31 21:42:46,972][26287] KL-divergence is very high: 266.2412
[2023-08-31 21:42:46,974][26287] KL-divergence is very high: 14626.5283
[2023-08-31 21:42:47,178][26287] KL-divergence is very high: 30442.9473
[2023-08-31 21:42:47,181][26287] KL-divergence is very high: 3548.3716
[2023-08-31 21:42:47,183][26287] KL-divergence is very high: 5242.6548
[2023-08-31 21:42:47,187][26287] KL-divergence is very high: 22938.9590
[2023-08-31 21:42:47,189][26287] KL-divergence is very high: 7045.9536
[2023-08-31 21:42:47,193][26287] KL-divergence is very high: 1796.7311
[2023-08-31 21:42:47,196][26287] KL-divergence is very high: 5872.5835
[2023-08-31 21:42:47,444][26287] KL-divergence is very high: 2419.5527
[2023-08-31 21:42:47,448][26287] KL-divergence is very high: 1058.8307
[2023-08-31 21:42:47,451][26287] KL-divergence is very high: 1593.2407
[2023-08-31 21:42:47,454][26287] KL-divergence is very high: 9378.8193
[2023-08-31 21:42:47,457][26287] KL-divergence is very high: 1849.2668
[2023-08-31 21:42:47,460][26287] KL-divergence is very high: 923.9514
[2023-08-31 21:42:47,464][26287] KL-divergence is very high: 593.7692
[2023-08-31 21:42:47,712][26287] KL-divergence is very high: 436.1931
[2023-08-31 21:42:47,715][26287] KL-divergence is very high: 519.5289
[2023-08-31 21:42:47,719][26287] KL-divergence is very high: 572.9140
[2023-08-31 21:42:47,722][26287] KL-divergence is very high: 821.8198
[2023-08-31 21:42:47,725][26287] KL-divergence is very high: 1508.4684
[2023-08-31 21:42:47,729][26287] KL-divergence is very high: 393.0468
[2023-08-31 21:42:47,732][26287] KL-divergence is very high: 715.3924
[2023-08-31 21:42:47,734][26288] Updated weights for policy 0, policy_version 39032 (0.0002)
[2023-08-31 21:42:47,947][26287] KL-divergence is very high: 223.0297
[2023-08-31 21:42:47,950][26287] KL-divergence is very high: 174.5404
[2023-08-31 21:42:47,953][26287] KL-divergence is very high: 178.3810
[2023-08-31 21:42:47,956][26287] KL-divergence is very high: 655.1791
[2023-08-31 21:42:47,959][26287] KL-divergence is very high: 662.6985
[2023-08-31 21:42:47,962][26287] KL-divergence is very high: 376.8146
[2023-08-31 21:42:47,965][26287] KL-divergence is very high: 178.5524
[2023-08-31 21:42:48,106][26276] Fps is (10 sec: 16384.0, 60 sec: 16315.7, 300 sec: 15870.4). Total num frames: 19988480. Throughput: 0: 16208.1. Samples: 8045393. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 21:42:48,106][26276] Avg episode reward: [(0, '-29673.125')]
[2023-08-31 21:42:48,169][26287] KL-divergence is very high: 1013.0722
[2023-08-31 21:42:48,171][26287] KL-divergence is very high: 1780.4622
[2023-08-31 21:42:48,174][26287] KL-divergence is very high: 1945.8755
[2023-08-31 21:42:48,177][26287] KL-divergence is very high: 897.7971
[2023-08-31 21:42:48,180][26287] KL-divergence is very high: 118.6853
[2023-08-31 21:42:48,182][26287] KL-divergence is very high: 743.6169
[2023-08-31 21:42:48,185][26287] KL-divergence is very high: 2218.1118
[2023-08-31 21:42:48,396][26287] KL-divergence is very high: 7175.9399
[2023-08-31 21:42:48,399][26287] KL-divergence is very high: 9719.8057
[2023-08-31 21:42:48,402][26287] KL-divergence is very high: 559.7089
[2023-08-31 21:42:48,408][26287] High loss value: l:44.4495 pl:0.0901 vl:0.9397 exp_l:0.0000 kl_l:43.4197 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:48,408][26287] KL-divergence is very high: 50575.4336
[2023-08-31 21:42:48,411][26287] High loss value: l:150.7948 pl:0.0761 vl:0.6295 exp_l:0.0000 kl_l:150.0893 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:48,411][26287] KL-divergence is very high: 80780.2500
[2023-08-31 21:42:48,414][26287] KL-divergence is very high: 2708.3704
[2023-08-31 21:42:48,616][26287] High loss value: l:76.1892 pl:0.1613 vl:1.3050 exp_l:0.0000 kl_l:74.7229 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:48,616][26287] KL-divergence is very high: 25617.2109
[2023-08-31 21:42:48,620][26287] High loss value: l:231.3042 pl:0.1315 vl:0.9004 exp_l:0.0000 kl_l:230.2723 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:48,620][26287] KL-divergence is very high: 108208.9531
[2023-08-31 21:42:48,623][26287] High loss value: l:111.0105 pl:0.1882 vl:0.7748 exp_l:0.0000 kl_l:110.0475 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:48,624][26287] KL-divergence is very high: 42871.3594
[2023-08-31 21:42:48,627][26287] High loss value: l:42.2608 pl:0.1736 vl:0.9919 exp_l:0.0000 kl_l:41.0954 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:48,627][26287] KL-divergence is very high: 18485.0312
[2023-08-31 21:42:48,630][26287] High loss value: l:57.6465 pl:0.1899 vl:1.0181 exp_l:0.0000 kl_l:56.4384 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:48,630][26287] KL-divergence is very high: 30443.2324
[2023-08-31 21:42:48,634][26287] High loss value: l:203.9658 pl:0.1337 vl:0.7051 exp_l:0.0000 kl_l:203.1270 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:48,634][26287] KL-divergence is very high: 114514.5859
[2023-08-31 21:42:48,637][26287] High loss value: l:64.3971 pl:0.1817 vl:0.6138 exp_l:0.0000 kl_l:63.6016 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:48,637][26287] KL-divergence is very high: 22649.0781
[2023-08-31 21:42:48,879][26287] KL-divergence is very high: 425.4595
[2023-08-31 21:42:48,881][26287] KL-divergence is very high: 457.4813
[2023-08-31 21:42:48,884][26287] KL-divergence is very high: 132.4535
[2023-08-31 21:42:48,887][26287] KL-divergence is very high: 265.1544
[2023-08-31 21:42:48,890][26287] KL-divergence is very high: 309.6358
[2023-08-31 21:42:48,892][26287] KL-divergence is very high: 223.3159
[2023-08-31 21:42:48,895][26287] KL-divergence is very high: 151.7771
[2023-08-31 21:42:49,094][26287] KL-divergence is very high: 8647.2168
[2023-08-31 21:42:49,097][26287] KL-divergence is very high: 6524.3042
[2023-08-31 21:42:49,099][26287] KL-divergence is very high: 1844.9015
[2023-08-31 21:42:49,102][26287] KL-divergence is very high: 1435.9254
[2023-08-31 21:42:49,104][26287] High loss value: l:37.8359 pl:0.1935 vl:0.2749 exp_l:0.0000 kl_l:37.3675 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:49,105][26287] KL-divergence is very high: 41606.0039
[2023-08-31 21:42:49,108][26287] KL-divergence is very high: 18229.2129
[2023-08-31 21:42:49,110][26287] KL-divergence is very high: 680.1654
[2023-08-31 21:42:49,309][26287] KL-divergence is very high: 673.2397
[2023-08-31 21:42:49,312][26287] KL-divergence is very high: 740.9316
[2023-08-31 21:42:49,315][26287] KL-divergence is very high: 528.4473
[2023-08-31 21:42:49,317][26287] KL-divergence is very high: 878.0273
[2023-08-31 21:42:49,320][26287] KL-divergence is very high: 299.0958
[2023-08-31 21:42:49,323][26287] KL-divergence is very high: 614.0824
[2023-08-31 21:42:49,325][26287] KL-divergence is very high: 716.4835
[2023-08-31 21:42:49,566][26287] KL-divergence is very high: 9372.7266
[2023-08-31 21:42:49,569][26287] KL-divergence is very high: 5344.0864
[2023-08-31 21:42:49,572][26287] KL-divergence is very high: 20826.3984
[2023-08-31 21:42:49,575][26287] KL-divergence is very high: 42107.1172
[2023-08-31 21:42:49,578][26287] KL-divergence is very high: 30489.5684
[2023-08-31 21:42:49,581][26287] KL-divergence is very high: 4187.8335
[2023-08-31 21:42:49,584][26287] KL-divergence is very high: 3037.2998
[2023-08-31 21:42:49,814][26287] KL-divergence is very high: 2341.3479
[2023-08-31 21:42:49,816][26287] KL-divergence is very high: 7657.6934
[2023-08-31 21:42:49,819][26287] KL-divergence is very high: 6007.2944
[2023-08-31 21:42:49,822][26287] High loss value: l:36.8636 pl:0.1875 vl:0.4052 exp_l:0.0000 kl_l:36.2710 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:49,822][26287] KL-divergence is very high: 11465.0459
[2023-08-31 21:42:49,826][26287] KL-divergence is very high: 6293.4307
[2023-08-31 21:42:49,828][26287] KL-divergence is very high: 389.6399
[2023-08-31 21:42:49,831][26287] KL-divergence is very high: 413.6204
[2023-08-31 21:42:50,028][26287] KL-divergence is very high: 2304.6042
[2023-08-31 21:42:50,031][26287] KL-divergence is very high: 1274.0461
[2023-08-31 21:42:50,034][26287] KL-divergence is very high: 683.9468
[2023-08-31 21:42:50,036][26287] KL-divergence is very high: 401.2034
[2023-08-31 21:42:50,039][26287] KL-divergence is very high: 3777.4778
[2023-08-31 21:42:50,042][26287] KL-divergence is very high: 3202.6816
[2023-08-31 21:42:50,044][26287] KL-divergence is very high: 1405.4677
[2023-08-31 21:42:50,047][26288] Updated weights for policy 0, policy_version 39112 (0.0002)
[2023-08-31 21:42:50,278][26287] KL-divergence is very high: 428.5927
[2023-08-31 21:42:50,281][26287] KL-divergence is very high: 172.1864
[2023-08-31 21:42:50,283][26287] KL-divergence is very high: 101.2915
[2023-08-31 21:42:50,286][26287] KL-divergence is very high: 163.7961
[2023-08-31 21:42:50,292][26287] KL-divergence is very high: 114.0758
[2023-08-31 21:42:50,295][26287] KL-divergence is very high: 394.0944
[2023-08-31 21:42:50,496][26287] KL-divergence is very high: 2720.0034
[2023-08-31 21:42:50,499][26287] KL-divergence is very high: 215.3317
[2023-08-31 21:42:50,501][26287] KL-divergence is very high: 1264.9044
[2023-08-31 21:42:50,504][26287] KL-divergence is very high: 2368.1570
[2023-08-31 21:42:50,507][26287] KL-divergence is very high: 1952.2491
[2023-08-31 21:42:50,509][26287] KL-divergence is very high: 372.7774
[2023-08-31 21:42:50,512][26287] KL-divergence is very high: 2972.2754
[2023-08-31 21:42:50,716][26287] KL-divergence is very high: 372.8909
[2023-08-31 21:42:50,719][26287] KL-divergence is very high: 735.8538
[2023-08-31 21:42:50,722][26287] KL-divergence is very high: 2685.9148
[2023-08-31 21:42:50,725][26287] KL-divergence is very high: 7110.5186
[2023-08-31 21:42:50,728][26287] KL-divergence is very high: 1251.3818
[2023-08-31 21:42:50,731][26287] KL-divergence is very high: 6541.0400
[2023-08-31 21:42:50,733][26287] KL-divergence is very high: 3657.9153
[2023-08-31 21:42:50,953][26287] KL-divergence is very high: 112.6742
[2023-08-31 21:42:50,956][26287] KL-divergence is very high: 127.8076
[2023-08-31 21:42:50,958][26287] KL-divergence is very high: 445.7542
[2023-08-31 21:42:50,961][26287] KL-divergence is very high: 421.4500
[2023-08-31 21:42:50,966][26287] KL-divergence is very high: 626.0756
[2023-08-31 21:42:50,969][26287] KL-divergence is very high: 214.1498
[2023-08-31 21:42:51,164][26287] KL-divergence is very high: 13393.1758
[2023-08-31 21:42:51,167][26287] KL-divergence is very high: 10044.4863
[2023-08-31 21:42:51,170][26287] KL-divergence is very high: 743.7739
[2023-08-31 21:42:51,173][26287] KL-divergence is very high: 2261.0229
[2023-08-31 21:42:51,175][26287] High loss value: l:34.2368 pl:0.0748 vl:0.4276 exp_l:0.0000 kl_l:33.7344 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:51,175][26287] KL-divergence is very high: 32076.3984
[2023-08-31 21:42:51,178][26287] KL-divergence is very high: 9425.5322
[2023-08-31 21:42:51,181][26287] KL-divergence is very high: 5523.4712
[2023-08-31 21:42:51,379][26287] KL-divergence is very high: 6558.9604
[2023-08-31 21:42:51,382][26287] KL-divergence is very high: 3807.2314
[2023-08-31 21:42:51,385][26287] KL-divergence is very high: 8239.2627
[2023-08-31 21:42:51,387][26287] KL-divergence is very high: 3647.2764
[2023-08-31 21:42:51,390][26287] KL-divergence is very high: 5421.5923
[2023-08-31 21:42:51,393][26287] KL-divergence is very high: 1360.2637
[2023-08-31 21:42:51,396][26287] KL-divergence is very high: 1839.6497
[2023-08-31 21:42:51,624][26287] KL-divergence is very high: 923.6015
[2023-08-31 21:42:51,627][26287] KL-divergence is very high: 2018.7303
[2023-08-31 21:42:51,631][26287] KL-divergence is very high: 2555.3164
[2023-08-31 21:42:51,634][26287] KL-divergence is very high: 1048.5026
[2023-08-31 21:42:51,639][26287] KL-divergence is very high: 6661.3105
[2023-08-31 21:42:51,642][26287] KL-divergence is very high: 8071.6729
[2023-08-31 21:42:51,839][26287] KL-divergence is very high: 163.9441
[2023-08-31 21:42:51,842][26287] KL-divergence is very high: 335.5558
[2023-08-31 21:42:51,847][26287] KL-divergence is very high: 201.8014
[2023-08-31 21:42:51,850][26287] KL-divergence is very high: 282.7240
[2023-08-31 21:42:51,852][26287] KL-divergence is very high: 402.7841
[2023-08-31 21:42:52,052][26287] KL-divergence is very high: 204.8557
[2023-08-31 21:42:52,055][26287] KL-divergence is very high: 185.8727
[2023-08-31 21:42:52,058][26287] KL-divergence is very high: 146.9686
[2023-08-31 21:42:52,060][26287] KL-divergence is very high: 552.1730
[2023-08-31 21:42:52,063][26287] KL-divergence is very high: 158.7790
[2023-08-31 21:42:52,066][26287] KL-divergence is very high: 103.7954
[2023-08-31 21:42:52,069][26287] KL-divergence is very high: 102.3266
[2023-08-31 21:42:52,265][26287] KL-divergence is very high: 196.8429
[2023-08-31 21:42:52,267][26287] KL-divergence is very high: 117.1834
[2023-08-31 21:42:52,273][26287] KL-divergence is very high: 163.4021
[2023-08-31 21:42:52,278][26287] KL-divergence is very high: 136.9341
[2023-08-31 21:42:52,280][26287] KL-divergence is very high: 196.8744
[2023-08-31 21:42:52,283][26288] Updated weights for policy 0, policy_version 39192 (0.0002)
[2023-08-31 21:42:52,506][26287] KL-divergence is very high: 243.6219
[2023-08-31 21:42:52,513][26287] KL-divergence is very high: 159.6273
[2023-08-31 21:42:52,516][26287] KL-divergence is very high: 187.4900
[2023-08-31 21:42:52,519][26287] KL-divergence is very high: 164.2411
[2023-08-31 21:42:52,522][26287] KL-divergence is very high: 376.5975
[2023-08-31 21:42:52,525][26287] KL-divergence is very high: 592.5449
[2023-08-31 21:42:52,761][26287] KL-divergence is very high: 380.3966
[2023-08-31 21:42:52,767][26287] KL-divergence is very high: 265.8518
[2023-08-31 21:42:52,769][26287] KL-divergence is very high: 147.1875
[2023-08-31 21:42:52,775][26287] KL-divergence is very high: 339.5651
[2023-08-31 21:42:52,778][26287] KL-divergence is very high: 856.7864
[2023-08-31 21:42:53,110][26276] Fps is (10 sec: 16785.8, 60 sec: 16383.3, 300 sec: 15911.8). Total num frames: 20074496. Throughput: 0: 16466.1. Samples: 8151088. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 21:42:53,111][26276] Avg episode reward: [(0, '-82258.557')]
[2023-08-31 21:42:53,263][26287] KL-divergence is very high: 138.4342
[2023-08-31 21:42:53,267][26287] KL-divergence is very high: 2835.0793
[2023-08-31 21:42:53,270][26287] KL-divergence is very high: 192.1602
[2023-08-31 21:42:53,273][26287] KL-divergence is very high: 558.6948
[2023-08-31 21:42:53,277][26287] KL-divergence is very high: 8147.6421
[2023-08-31 21:42:53,280][26287] KL-divergence is very high: 3460.5322
[2023-08-31 21:42:53,283][26287] KL-divergence is very high: 4124.1021
[2023-08-31 21:42:53,491][26287] KL-divergence is very high: 2668.5090
[2023-08-31 21:42:53,494][26287] KL-divergence is very high: 1104.0261
[2023-08-31 21:42:53,497][26287] High loss value: l:30.1721 pl:0.0566 vl:0.5893 exp_l:0.0000 kl_l:29.5263 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:53,497][26287] KL-divergence is very high: 14325.6455
[2023-08-31 21:42:53,500][26287] High loss value: l:67.6685 pl:0.1342 vl:0.5520 exp_l:0.0000 kl_l:66.9823 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:53,500][26287] KL-divergence is very high: 34289.7031
[2023-08-31 21:42:53,503][26287] KL-divergence is very high: 4676.6260
[2023-08-31 21:42:53,506][26287] High loss value: l:55.5507 pl:0.1097 vl:0.4706 exp_l:0.0000 kl_l:54.9704 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:53,506][26287] KL-divergence is very high: 26701.4082
[2023-08-31 21:42:53,509][26287] High loss value: l:80.8398 pl:0.0760 vl:0.6020 exp_l:0.0000 kl_l:80.1618 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:53,509][26287] KL-divergence is very high: 26258.9512
[2023-08-31 21:42:53,748][26287] KL-divergence is very high: 3098.7434
[2023-08-31 21:42:53,752][26287] High loss value: l:34.3750 pl:0.0486 vl:0.5666 exp_l:0.0000 kl_l:33.7598 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:53,753][26287] KL-divergence is very high: 7798.1421
[2023-08-31 21:42:53,756][26287] KL-divergence is very high: 3164.3813
[2023-08-31 21:42:53,759][26287] KL-divergence is very high: 1150.9084
[2023-08-31 21:42:53,762][26287] High loss value: l:53.7610 pl:0.0686 vl:0.4871 exp_l:0.0000 kl_l:53.2053 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:53,762][26287] KL-divergence is very high: 12839.3926
[2023-08-31 21:42:53,765][26287] KL-divergence is very high: 9634.7168
[2023-08-31 21:42:53,768][26287] High loss value: l:65.2708 pl:0.1435 vl:0.3808 exp_l:0.0000 kl_l:64.7465 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:53,768][26287] KL-divergence is very high: 14112.2178
[2023-08-31 21:42:53,999][26287] High loss value: l:105.1117 pl:0.0528 vl:0.4891 exp_l:0.0000 kl_l:104.5699 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:53,999][26287] KL-divergence is very high: 20792.2773
[2023-08-31 21:42:54,002][26287] High loss value: l:62.5948 pl:0.1458 vl:0.3890 exp_l:0.0000 kl_l:62.0600 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:54,003][26287] KL-divergence is very high: 11967.9043
[2023-08-31 21:42:54,006][26287] High loss value: l:48.3837 pl:0.0901 vl:0.4467 exp_l:0.0000 kl_l:47.8468 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:54,006][26287] KL-divergence is very high: 13304.8857
[2023-08-31 21:42:54,010][26287] High loss value: l:77.6770 pl:0.0182 vl:0.4619 exp_l:0.0000 kl_l:77.1970 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:54,010][26287] KL-divergence is very high: 22939.6191
[2023-08-31 21:42:54,013][26287] KL-divergence is very high: 2211.7898
[2023-08-31 21:42:54,016][26287] KL-divergence is very high: 2680.3623
[2023-08-31 21:42:54,019][26287] High loss value: l:36.2381 pl:0.0883 vl:0.4609 exp_l:0.0000 kl_l:35.6889 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:54,019][26287] KL-divergence is very high: 7766.0122
[2023-08-31 21:42:54,252][26287] KL-divergence is very high: 4276.8008
[2023-08-31 21:42:54,255][26287] KL-divergence is very high: 594.1522
[2023-08-31 21:42:54,257][26287] KL-divergence is very high: 2324.8057
[2023-08-31 21:42:54,260][26287] High loss value: l:148.9819 pl:0.1255 vl:0.1810 exp_l:0.0000 kl_l:148.6753 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:54,260][26287] KL-divergence is very high: 28578.3184
[2023-08-31 21:42:54,264][26287] KL-divergence is very high: 5857.6670
[2023-08-31 21:42:54,266][26287] High loss value: l:47.3374 pl:0.0696 vl:0.1977 exp_l:0.0000 kl_l:47.0701 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:54,266][26287] KL-divergence is very high: 14125.2246
[2023-08-31 21:42:54,269][26287] High loss value: l:65.2991 pl:0.0915 vl:0.3350 exp_l:0.0000 kl_l:64.8725 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:54,270][26287] KL-divergence is very high: 21840.9746
[2023-08-31 21:42:54,469][26287] KL-divergence is very high: 785.2248
[2023-08-31 21:42:54,471][26287] KL-divergence is very high: 451.3767
[2023-08-31 21:42:54,474][26287] KL-divergence is very high: 4069.4697
[2023-08-31 21:42:54,477][26287] KL-divergence is very high: 2295.1409
[2023-08-31 21:42:54,479][26287] KL-divergence is very high: 3125.5198
[2023-08-31 21:42:54,482][26287] KL-divergence is very high: 9745.6680
[2023-08-31 21:42:54,485][26287] High loss value: l:32.9497 pl:0.0872 vl:1.0251 exp_l:0.0000 kl_l:31.8374 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:54,485][26287] KL-divergence is very high: 17144.2285
[2023-08-31 21:42:54,692][26287] KL-divergence is very high: 2407.5312
[2023-08-31 21:42:54,695][26287] KL-divergence is very high: 7963.9614
[2023-08-31 21:42:54,699][26287] KL-divergence is very high: 7664.6382
[2023-08-31 21:42:54,702][26287] KL-divergence is very high: 960.8030
[2023-08-31 21:42:54,705][26287] KL-divergence is very high: 2598.6372
[2023-08-31 21:42:54,708][26287] High loss value: l:41.1462 pl:0.2351 vl:0.6027 exp_l:0.0000 kl_l:40.3084 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:54,708][26287] KL-divergence is very high: 30325.5586
[2023-08-31 21:42:54,711][26287] High loss value: l:74.3753 pl:0.2598 vl:0.3642 exp_l:0.0000 kl_l:73.7513 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:54,711][26287] KL-divergence is very high: 17754.1777
[2023-08-31 21:42:54,927][26287] KL-divergence is very high: 170.5121
[2023-08-31 21:42:54,930][26287] KL-divergence is very high: 4233.6401
[2023-08-31 21:42:54,933][26287] KL-divergence is very high: 1087.6299
[2023-08-31 21:42:54,936][26287] KL-divergence is very high: 2819.2854
[2023-08-31 21:42:54,939][26287] KL-divergence is very high: 3008.0881
[2023-08-31 21:42:54,941][26287] KL-divergence is very high: 1761.4874
[2023-08-31 21:42:54,944][26287] KL-divergence is very high: 626.2969
[2023-08-31 21:42:54,947][26288] Updated weights for policy 0, policy_version 39272 (0.0002)
[2023-08-31 21:42:55,171][26287] KL-divergence is very high: 463.6401
[2023-08-31 21:42:55,177][26287] KL-divergence is very high: 348.0942
[2023-08-31 21:42:55,179][26287] KL-divergence is very high: 470.6941
[2023-08-31 21:42:55,182][26287] KL-divergence is very high: 354.3509
[2023-08-31 21:42:55,184][26287] KL-divergence is very high: 264.3438
[2023-08-31 21:42:55,187][26287] KL-divergence is very high: 116.3203
[2023-08-31 21:42:55,418][26287] KL-divergence is very high: 1002.4001
[2023-08-31 21:42:55,421][26287] KL-divergence is very high: 4121.4209
[2023-08-31 21:42:55,424][26287] KL-divergence is very high: 4007.4856
[2023-08-31 21:42:55,427][26287] KL-divergence is very high: 138.8938
[2023-08-31 21:42:55,429][26287] KL-divergence is very high: 224.7523
[2023-08-31 21:42:55,432][26287] KL-divergence is very high: 3091.2014
[2023-08-31 21:42:55,435][26287] KL-divergence is very high: 3295.4285
[2023-08-31 21:42:55,670][26287] KL-divergence is very high: 2090.6431
[2023-08-31 21:42:55,673][26287] KL-divergence is very high: 4283.0278
[2023-08-31 21:42:55,676][26287] KL-divergence is very high: 2191.1643
[2023-08-31 21:42:55,678][26287] KL-divergence is very high: 191.1353
[2023-08-31 21:42:55,682][26287] KL-divergence is very high: 1434.6539
[2023-08-31 21:42:55,685][26287] KL-divergence is very high: 3262.2930
[2023-08-31 21:42:55,687][26287] High loss value: l:35.0809 pl:0.3271 vl:0.2154 exp_l:0.0000 kl_l:34.5384 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:55,687][26287] KL-divergence is very high: 12154.4473
[2023-08-31 21:42:55,900][26287] KL-divergence is very high: 10288.5869
[2023-08-31 21:42:55,903][26287] KL-divergence is very high: 1163.4951
[2023-08-31 21:42:55,908][26287] KL-divergence is very high: 15187.6729
[2023-08-31 21:42:55,911][26287] High loss value: l:46.8929 pl:0.1863 vl:0.1098 exp_l:0.0000 kl_l:46.5968 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:55,911][26287] KL-divergence is very high: 36362.9180
[2023-08-31 21:42:55,914][26287] KL-divergence is very high: 2614.5776
[2023-08-31 21:42:55,917][26287] KL-divergence is very high: 385.6808
[2023-08-31 21:42:56,123][26287] KL-divergence is very high: 7871.9985
[2023-08-31 21:42:56,125][26287] High loss value: l:47.0562 pl:0.2411 vl:0.2797 exp_l:0.0000 kl_l:46.5354 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:56,126][26287] KL-divergence is very high: 22335.1191
[2023-08-31 21:42:56,129][26287] High loss value: l:41.1288 pl:0.2148 vl:0.1752 exp_l:0.0000 kl_l:40.7387 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:56,129][26287] KL-divergence is very high: 79828.9141
[2023-08-31 21:42:56,132][26287] KL-divergence is very high: 8878.5723
[2023-08-31 21:42:56,135][26287] KL-divergence is very high: 4336.3906
[2023-08-31 21:42:56,138][26287] KL-divergence is very high: 1000.7661
[2023-08-31 21:42:56,140][26287] KL-divergence is very high: 16022.9814
[2023-08-31 21:42:56,370][26287] KL-divergence is very high: 589.4406
[2023-08-31 21:42:56,372][26287] KL-divergence is very high: 604.8275
[2023-08-31 21:42:56,375][26287] KL-divergence is very high: 649.6606
[2023-08-31 21:42:56,377][26287] KL-divergence is very high: 551.9365
[2023-08-31 21:42:56,380][26287] KL-divergence is very high: 6198.3286
[2023-08-31 21:42:56,382][26287] KL-divergence is very high: 4629.0269
[2023-08-31 21:42:56,385][26287] KL-divergence is very high: 908.5989
[2023-08-31 21:42:56,607][26287] High loss value: l:58.2955 pl:0.3060 vl:0.1482 exp_l:0.0000 kl_l:57.8413 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:56,607][26287] KL-divergence is very high: 10360.0898
[2023-08-31 21:42:56,610][26287] High loss value: l:44.6819 pl:0.2408 vl:0.2302 exp_l:0.0000 kl_l:44.2108 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:56,610][26287] KL-divergence is very high: 10557.0254
[2023-08-31 21:42:56,614][26287] KL-divergence is very high: 3027.0405
[2023-08-31 21:42:56,616][26287] High loss value: l:95.6078 pl:0.3304 vl:0.2016 exp_l:0.0000 kl_l:95.0759 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:56,616][26287] KL-divergence is very high: 41365.4336
[2023-08-31 21:42:56,619][26287] High loss value: l:162.5921 pl:0.2630 vl:0.1540 exp_l:0.0000 kl_l:162.1752 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:56,619][26287] KL-divergence is very high: 35486.3672
[2023-08-31 21:42:56,623][26287] High loss value: l:67.8441 pl:0.2999 vl:0.2312 exp_l:0.0000 kl_l:67.3129 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:56,623][26287] KL-divergence is very high: 16992.4902
[2023-08-31 21:42:56,626][26287] KL-divergence is very high: 3042.6519
[2023-08-31 21:42:56,829][26287] KL-divergence is very high: 1043.7189
[2023-08-31 21:42:56,832][26287] KL-divergence is very high: 666.4382
[2023-08-31 21:42:56,835][26287] KL-divergence is very high: 143.3435
[2023-08-31 21:42:56,838][26287] KL-divergence is very high: 3977.0417
[2023-08-31 21:42:56,841][26287] KL-divergence is very high: 2240.7209
[2023-08-31 21:42:56,844][26287] KL-divergence is very high: 2950.0911
[2023-08-31 21:42:56,846][26287] KL-divergence is very high: 468.2061
[2023-08-31 21:42:57,084][26287] KL-divergence is very high: 6136.2471
[2023-08-31 21:42:57,087][26287] KL-divergence is very high: 2911.6265
[2023-08-31 21:42:57,090][26287] KL-divergence is very high: 111.8295
[2023-08-31 21:42:57,093][26287] KL-divergence is very high: 282.0971
[2023-08-31 21:42:57,095][26287] KL-divergence is very high: 1821.4008
[2023-08-31 21:42:57,101][26287] KL-divergence is very high: 360.1688
[2023-08-31 21:42:57,328][26287] KL-divergence is very high: 1815.7618
[2023-08-31 21:42:57,336][26287] High loss value: l:33.2454 pl:0.2286 vl:0.1975 exp_l:0.0000 kl_l:32.8193 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:57,336][26287] KL-divergence is very high: 15866.8594
[2023-08-31 21:42:57,339][26287] KL-divergence is very high: 7846.0137
[2023-08-31 21:42:57,345][26287] KL-divergence is very high: 205.7134
[2023-08-31 21:42:57,347][26288] Updated weights for policy 0, policy_version 39352 (0.0002)
[2023-08-31 21:42:57,548][26287] KL-divergence is very high: 126.6259
[2023-08-31 21:42:57,559][26287] KL-divergence is very high: 187.0918
[2023-08-31 21:42:57,562][26287] KL-divergence is very high: 189.5659
[2023-08-31 21:42:57,791][26287] KL-divergence is very high: 506.3942
[2023-08-31 21:42:57,794][26287] KL-divergence is very high: 5597.1470
[2023-08-31 21:42:57,797][26287] KL-divergence is very high: 1373.5002
[2023-08-31 21:42:57,800][26287] KL-divergence is very high: 174.1490
[2023-08-31 21:42:57,802][26287] KL-divergence is very high: 742.9149
[2023-08-31 21:42:57,806][26287] KL-divergence is very high: 6133.0801
[2023-08-31 21:42:57,809][26287] KL-divergence is very high: 6122.3511
[2023-08-31 21:42:58,021][26287] KL-divergence is very high: 229.1934
[2023-08-31 21:42:58,023][26287] KL-divergence is very high: 3799.3796
[2023-08-31 21:42:58,027][26287] KL-divergence is very high: 547.9875
[2023-08-31 21:42:58,030][26287] KL-divergence is very high: 260.5475
[2023-08-31 21:42:58,032][26287] KL-divergence is very high: 496.2938
[2023-08-31 21:42:58,035][26287] KL-divergence is very high: 1039.8824
[2023-08-31 21:42:58,038][26287] KL-divergence is very high: 114.9436
[2023-08-31 21:42:58,106][26276] Fps is (10 sec: 17203.6, 60 sec: 16384.0, 300 sec: 15953.8). Total num frames: 20160512. Throughput: 0: 16457.6. Samples: 8198120. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 21:42:58,106][26276] Avg episode reward: [(0, '-67140.701')]
[2023-08-31 21:42:58,236][26287] High loss value: l:33.9256 pl:0.1903 vl:0.4053 exp_l:0.0000 kl_l:33.3300 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:58,236][26287] KL-divergence is very high: 9285.3027
[2023-08-31 21:42:58,239][26287] KL-divergence is very high: 11028.6572
[2023-08-31 21:42:58,242][26287] KL-divergence is very high: 2625.8428
[2023-08-31 21:42:58,245][26287] KL-divergence is very high: 3082.5544
[2023-08-31 21:42:58,247][26287] High loss value: l:31.4124 pl:0.2334 vl:0.3324 exp_l:0.0000 kl_l:30.8466 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:58,247][26287] KL-divergence is very high: 11224.8037
[2023-08-31 21:42:58,250][26287] KL-divergence is very high: 4229.8403
[2023-08-31 21:42:58,253][26287] KL-divergence is very high: 5551.1689
[2023-08-31 21:42:58,479][26287] KL-divergence is very high: 2006.8822
[2023-08-31 21:42:58,481][26287] KL-divergence is very high: 2154.7185
[2023-08-31 21:42:58,484][26287] KL-divergence is very high: 17135.6191
[2023-08-31 21:42:58,488][26287] KL-divergence is very high: 5061.6587
[2023-08-31 21:42:58,491][26287] KL-divergence is very high: 6020.8994
[2023-08-31 21:42:58,493][26287] KL-divergence is very high: 2158.4536
[2023-08-31 21:42:58,496][26287] KL-divergence is very high: 8344.0234
[2023-08-31 21:42:58,708][26287] KL-divergence is very high: 158.0967
[2023-08-31 21:42:58,711][26287] KL-divergence is very high: 438.4934
[2023-08-31 21:42:58,714][26287] KL-divergence is very high: 3428.4910
[2023-08-31 21:42:58,716][26287] KL-divergence is very high: 4102.7861
[2023-08-31 21:42:58,719][26287] KL-divergence is very high: 3000.0625
[2023-08-31 21:42:58,722][26287] KL-divergence is very high: 4671.4629
[2023-08-31 21:42:58,724][26287] KL-divergence is very high: 10037.7207
[2023-08-31 21:42:58,964][26287] KL-divergence is very high: 3161.8721
[2023-08-31 21:42:58,967][26287] KL-divergence is very high: 209.8658
[2023-08-31 21:42:58,970][26287] KL-divergence is very high: 7469.2261
[2023-08-31 21:42:58,973][26287] KL-divergence is very high: 6100.2275
[2023-08-31 21:42:58,976][26287] KL-divergence is very high: 2785.1960
[2023-08-31 21:42:58,979][26287] KL-divergence is very high: 7305.4775
[2023-08-31 21:42:58,982][26287] KL-divergence is very high: 265.7680
[2023-08-31 21:42:59,240][26287] High loss value: l:102.1015 pl:0.1961 vl:0.1395 exp_l:0.0000 kl_l:101.7659 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:59,240][26287] KL-divergence is very high: 39298.2500
[2023-08-31 21:42:59,243][26287] High loss value: l:76.8291 pl:0.2400 vl:0.1712 exp_l:0.0000 kl_l:76.4179 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:59,243][26287] KL-divergence is very high: 24522.8730
[2023-08-31 21:42:59,246][26287] High loss value: l:56.1008 pl:0.2462 vl:0.1886 exp_l:0.0000 kl_l:55.6660 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:59,246][26287] KL-divergence is very high: 27419.1641
[2023-08-31 21:42:59,249][26287] KL-divergence is very high: 10201.0938
[2023-08-31 21:42:59,252][26287] KL-divergence is very high: 8551.2510
[2023-08-31 21:42:59,254][26287] High loss value: l:41.0573 pl:0.1568 vl:0.1588 exp_l:0.0000 kl_l:40.7418 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:59,254][26287] KL-divergence is very high: 14343.3262
[2023-08-31 21:42:59,257][26287] High loss value: l:41.0498 pl:0.1921 vl:0.1430 exp_l:0.0000 kl_l:40.7147 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:59,257][26287] KL-divergence is very high: 14066.8525
[2023-08-31 21:42:59,485][26287] KL-divergence is very high: 1092.1801
[2023-08-31 21:42:59,487][26287] KL-divergence is very high: 1421.3875
[2023-08-31 21:42:59,490][26287] KL-divergence is very high: 826.5370
[2023-08-31 21:42:59,493][26287] KL-divergence is very high: 21040.8301
[2023-08-31 21:42:59,496][26287] KL-divergence is very high: 696.3816
[2023-08-31 21:42:59,498][26287] KL-divergence is very high: 1252.8427
[2023-08-31 21:42:59,501][26287] KL-divergence is very high: 852.2701
[2023-08-31 21:42:59,701][26287] KL-divergence is very high: 553.5673
[2023-08-31 21:42:59,704][26287] High loss value: l:60.4823 pl:0.1467 vl:0.3063 exp_l:0.0000 kl_l:60.0293 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:59,704][26287] KL-divergence is very high: 44528.0625
[2023-08-31 21:42:59,707][26287] KL-divergence is very high: 7318.3545
[2023-08-31 21:42:59,709][26287] KL-divergence is very high: 316.6238
[2023-08-31 21:42:59,712][26287] KL-divergence is very high: 440.6743
[2023-08-31 21:42:59,715][26287] High loss value: l:120.3645 pl:0.2792 vl:0.2847 exp_l:0.0000 kl_l:119.8006 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:59,715][26287] KL-divergence is very high: 84897.3750
[2023-08-31 21:42:59,718][26287] KL-divergence is very high: 15449.5469
[2023-08-31 21:42:59,721][26288] Updated weights for policy 0, policy_version 39432 (0.0002)
[2023-08-31 21:42:59,953][26287] KL-divergence is very high: 1825.6339
[2023-08-31 21:42:59,956][26287] High loss value: l:110.0817 pl:0.2962 vl:0.2336 exp_l:0.0000 kl_l:109.5519 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:59,956][26287] KL-divergence is very high: 67345.4531
[2023-08-31 21:42:59,959][26287] KL-divergence is very high: 4170.0610
[2023-08-31 21:42:59,962][26287] High loss value: l:77.5103 pl:0.2523 vl:0.1561 exp_l:0.0000 kl_l:77.1019 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:42:59,962][26287] KL-divergence is very high: 28054.4844
[2023-08-31 21:42:59,965][26287] KL-divergence is very high: 527.0178
[2023-08-31 21:42:59,968][26287] KL-divergence is very high: 8288.8809
[2023-08-31 21:42:59,971][26287] KL-divergence is very high: 1500.0709
[2023-08-31 21:43:00,227][26287] KL-divergence is very high: 1290.6713
[2023-08-31 21:43:00,230][26287] KL-divergence is very high: 327.3906
[2023-08-31 21:43:00,434][26287] KL-divergence is very high: 1657.9619
[2023-08-31 21:43:00,436][26287] KL-divergence is very high: 1224.5145
[2023-08-31 21:43:00,439][26287] KL-divergence is very high: 107.8956
[2023-08-31 21:43:00,442][26287] KL-divergence is very high: 2345.1187
[2023-08-31 21:43:00,444][26287] KL-divergence is very high: 4141.4585
[2023-08-31 21:43:00,447][26287] KL-divergence is very high: 2011.2070
[2023-08-31 21:43:00,449][26287] KL-divergence is very high: 1012.8548
[2023-08-31 21:43:00,937][26287] KL-divergence is very high: 108.8605
[2023-08-31 21:43:01,155][26287] KL-divergence is very high: 130.0217
[2023-08-31 21:43:01,158][26287] KL-divergence is very high: 230.0665
[2023-08-31 21:43:01,161][26287] KL-divergence is very high: 296.5343
[2023-08-31 21:43:01,173][26287] KL-divergence is very high: 134.0103
[2023-08-31 21:43:01,378][26287] KL-divergence is very high: 110.6156
[2023-08-31 21:43:01,381][26287] KL-divergence is very high: 124.8616
[2023-08-31 21:43:01,840][26287] KL-divergence is very high: 148.9053
[2023-08-31 21:43:01,843][26287] KL-divergence is very high: 143.9232
[2023-08-31 21:43:02,071][26288] Updated weights for policy 0, policy_version 39512 (0.0002)
[2023-08-31 21:43:02,314][26287] KL-divergence is very high: 113.6299
[2023-08-31 21:43:02,774][26287] KL-divergence is very high: 753.2319
[2023-08-31 21:43:02,777][26287] KL-divergence is very high: 790.8638
[2023-08-31 21:43:02,783][26287] KL-divergence is very high: 3984.8333
[2023-08-31 21:43:02,786][26287] High loss value: l:31.4487 pl:0.1967 vl:0.4207 exp_l:0.0000 kl_l:30.8313 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:43:02,786][26287] KL-divergence is very high: 11832.1553
[2023-08-31 21:43:02,790][26287] KL-divergence is very high: 9755.5244
[2023-08-31 21:43:03,020][26287] KL-divergence is very high: 2465.3970
[2023-08-31 21:43:03,023][26287] KL-divergence is very high: 13642.6582
[2023-08-31 21:43:03,026][26287] High loss value: l:37.1688 pl:0.1878 vl:0.8024 exp_l:0.0000 kl_l:36.1786 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:43:03,026][26287] KL-divergence is very high: 12866.2871
[2023-08-31 21:43:03,029][26287] KL-divergence is very high: 2485.7991
[2023-08-31 21:43:03,032][26287] KL-divergence is very high: 214.2306
[2023-08-31 21:43:03,034][26287] KL-divergence is very high: 4405.6011
[2023-08-31 21:43:03,038][26287] High loss value: l:31.8603 pl:0.3710 vl:1.1622 exp_l:0.0000 kl_l:30.3271 (recommended to adjust the --reward_scale parameter)
[2023-08-31 21:43:03,038][26287] KL-divergence is very high: 10225.5664
[2023-08-31 21:43:03,110][26276] Fps is (10 sec: 16793.6, 60 sec: 16383.6, 300 sec: 15953.4). Total num frames: 20242432. Throughput: 0: 16595.7. Samples: 8300841. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:43:03,110][26276] Avg episode reward: [(0, '-136008.472')]
[2023-08-31 21:43:03,241][26287] KL-divergence is very high: 477.2361
[2023-08-31 21:43:03,244][26287] KL-divergence is very high: 375.9846
[2023-08-31 21:43:03,247][26287] KL-divergence is very high: 303.8971
[2023-08-31 21:43:03,250][26287] KL-divergence is very high: 570.4790
[2023-08-31 21:43:03,253][26287] KL-divergence is very high: 186.8834
[2023-08-31 21:43:03,259][26287] KL-divergence is very high: 237.2254
[2023-08-31 21:43:03,489][26287] KL-divergence is very high: 289.0980
[2023-08-31 21:43:03,491][26287] KL-divergence is very high: 284.8382
[2023-08-31 21:43:03,497][26287] KL-divergence is very high: 164.5128
[2023-08-31 21:43:03,499][26287] KL-divergence is very high: 435.2912
[2023-08-31 21:43:03,743][26287] KL-divergence is very high: 101.3940
[2023-08-31 21:43:03,750][26287] KL-divergence is very high: 101.4519
[2023-08-31 21:43:04,061][26287] KL-divergence is very high: 296.5930
[2023-08-31 21:43:04,069][26287] KL-divergence is very high: 1345.3448
[2023-08-31 21:43:04,072][26287] KL-divergence is very high: 294.3947
[2023-08-31 21:43:04,869][26288] Updated weights for policy 0, policy_version 39592 (0.0002)
[2023-08-31 21:43:05,132][26287] KL-divergence is very high: 147.5073
[2023-08-31 21:43:07,362][26288] Updated weights for policy 0, policy_version 39672 (0.0002)
[2023-08-31 21:43:08,108][26276] Fps is (10 sec: 15970.2, 60 sec: 16384.5, 300 sec: 15953.5). Total num frames: 20320256. Throughput: 0: 16460.7. Samples: 8395710. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:43:08,109][26276] Avg episode reward: [(0, '-136008.472')]
[2023-08-31 21:43:10,127][26288] Updated weights for policy 0, policy_version 39752 (0.0002)
[2023-08-31 21:43:12,762][26288] Updated weights for policy 0, policy_version 39832 (0.0002)
[2023-08-31 21:43:13,105][26276] Fps is (10 sec: 15162.1, 60 sec: 16247.9, 300 sec: 15939.8). Total num frames: 20393984. Throughput: 0: 16426.0. Samples: 8441003. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:43:13,106][26276] Avg episode reward: [(0, '-163408.447')]
[2023-08-31 21:43:15,829][26288] Updated weights for policy 0, policy_version 39912 (0.0003)
[2023-08-31 21:43:18,109][26276] Fps is (10 sec: 14744.0, 60 sec: 16179.4, 300 sec: 15925.7). Total num frames: 20467712. Throughput: 0: 16064.9. Samples: 8525886. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:43:18,110][26276] Avg episode reward: [(0, '-183499.959')]
[2023-08-31 21:43:18,524][26288] Updated weights for policy 0, policy_version 39992 (0.0002)
[2023-08-31 21:43:21,255][26288] Updated weights for policy 0, policy_version 40072 (0.0002)
[2023-08-31 21:43:21,525][26287] KL-divergence is very high: 116.0767
[2023-08-31 21:43:23,108][26276] Fps is (10 sec: 14741.3, 60 sec: 15973.7, 300 sec: 15898.0). Total num frames: 20541440. Throughput: 0: 15987.7. Samples: 8617240. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:43:23,109][26276] Avg episode reward: [(0, '-183499.959')]
[2023-08-31 21:43:24,292][26288] Updated weights for policy 0, policy_version 40152 (0.0002)
[2023-08-31 21:43:26,777][26287] KL-divergence is very high: 151.3879
[2023-08-31 21:43:27,064][26288] Updated weights for policy 0, policy_version 40232 (0.0002)
[2023-08-31 21:43:28,107][26276] Fps is (10 sec: 14749.5, 60 sec: 15905.8, 300 sec: 15898.0). Total num frames: 20615168. Throughput: 0: 15764.9. Samples: 8657227. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:43:28,107][26276] Avg episode reward: [(0, '-191858.961')]
[2023-08-31 21:43:29,998][26288] Updated weights for policy 0, policy_version 40312 (0.0002)
[2023-08-31 21:43:32,417][26288] Updated weights for policy 0, policy_version 40392 (0.0002)
[2023-08-31 21:43:33,106][26276] Fps is (10 sec: 14748.5, 60 sec: 15701.1, 300 sec: 15870.4). Total num frames: 20688896. Throughput: 0: 15571.8. Samples: 8746133. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:43:33,107][26276] Avg episode reward: [(0, '-191858.961')]
[2023-08-31 21:43:35,002][26288] Updated weights for policy 0, policy_version 40472 (0.0002)
[2023-08-31 21:43:37,529][26288] Updated weights for policy 0, policy_version 40552 (0.0003)
[2023-08-31 21:43:38,109][26276] Fps is (10 sec: 15561.4, 60 sec: 15768.8, 300 sec: 15898.0). Total num frames: 20770816. Throughput: 0: 15382.5. Samples: 8843284. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:43:38,109][26276] Avg episode reward: [(0, '-349516.451')]
[2023-08-31 21:43:39,916][26288] Updated weights for policy 0, policy_version 40632 (0.0002)
[2023-08-31 21:43:42,331][26288] Updated weights for policy 0, policy_version 40712 (0.0002)
[2023-08-31 21:43:43,110][26276] Fps is (10 sec: 16787.4, 60 sec: 15836.6, 300 sec: 15911.9). Total num frames: 20856832. Throughput: 0: 15477.6. Samples: 8894683. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:43:43,110][26276] Avg episode reward: [(0, '-349516.451')]
[2023-08-31 21:43:44,921][26288] Updated weights for policy 0, policy_version 40792 (0.0002)
[2023-08-31 21:43:47,316][26288] Updated weights for policy 0, policy_version 40872 (0.0002)
[2023-08-31 21:43:48,105][26276] Fps is (10 sec: 16390.1, 60 sec: 15769.8, 300 sec: 15912.1). Total num frames: 20934656. Throughput: 0: 15408.1. Samples: 8994132. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:43:48,105][26276] Avg episode reward: [(0, '-324928.922')]
[2023-08-31 21:43:49,808][26288] Updated weights for policy 0, policy_version 40952 (0.0002)
[2023-08-31 21:43:52,232][26288] Updated weights for policy 0, policy_version 41032 (0.0002)
[2023-08-31 21:43:53,107][26276] Fps is (10 sec: 16389.8, 60 sec: 15770.5, 300 sec: 15939.8). Total num frames: 21020672. Throughput: 0: 15522.2. Samples: 9094184. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:43:53,107][26276] Avg episode reward: [(0, '-324928.922')]
[2023-08-31 21:43:54,978][26288] Updated weights for policy 0, policy_version 41112 (0.0002)
[2023-08-31 21:43:57,427][26288] Updated weights for policy 0, policy_version 41192 (0.0002)
[2023-08-31 21:43:58,106][26276] Fps is (10 sec: 16382.5, 60 sec: 15632.9, 300 sec: 15939.7). Total num frames: 21098496. Throughput: 0: 15530.9. Samples: 9139903. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:43:58,106][26276] Avg episode reward: [(0, '-293142.643')]
[2023-08-31 21:43:59,902][26288] Updated weights for policy 0, policy_version 41272 (0.0002)
[2023-08-31 21:44:02,355][26288] Updated weights for policy 0, policy_version 41352 (0.0002)
[2023-08-31 21:44:03,108][26276] Fps is (10 sec: 16381.1, 60 sec: 15701.8, 300 sec: 15967.5). Total num frames: 21184512. Throughput: 0: 15855.5. Samples: 9239367. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:44:03,109][26276] Avg episode reward: [(0, '-293142.643')]
[2023-08-31 21:44:03,112][26287] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000041376_21184512.pth...
[2023-08-31 21:44:03,114][26287] Removing /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000035056_17948672.pth
[2023-08-31 21:44:05,081][26288] Updated weights for policy 0, policy_version 41432 (0.0002)
[2023-08-31 21:44:07,533][26288] Updated weights for policy 0, policy_version 41512 (0.0002)
[2023-08-31 21:44:08,105][26276] Fps is (10 sec: 16385.3, 60 sec: 15702.1, 300 sec: 15995.5). Total num frames: 21262336. Throughput: 0: 15951.6. Samples: 9335014. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:44:08,106][26276] Avg episode reward: [(0, '-245164.524')]
[2023-08-31 21:44:09,981][26288] Updated weights for policy 0, policy_version 41592 (0.0002)
[2023-08-31 21:44:12,468][26288] Updated weights for policy 0, policy_version 41672 (0.0002)
[2023-08-31 21:44:13,110][26276] Fps is (10 sec: 15971.4, 60 sec: 15836.6, 300 sec: 16050.7). Total num frames: 21344256. Throughput: 0: 16181.9. Samples: 9385469. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:44:13,110][26276] Avg episode reward: [(0, '-245164.524')]
[2023-08-31 21:44:15,251][26288] Updated weights for policy 0, policy_version 41752 (0.0002)
[2023-08-31 21:44:17,686][26288] Updated weights for policy 0, policy_version 41832 (0.0002)
[2023-08-31 21:44:18,111][26276] Fps is (10 sec: 15966.0, 60 sec: 15905.8, 300 sec: 16050.6). Total num frames: 21422080. Throughput: 0: 16304.2. Samples: 9479889. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:44:18,111][26276] Avg episode reward: [(0, '-186460.777')]
[2023-08-31 21:44:20,223][26288] Updated weights for policy 0, policy_version 41912 (0.0002)
[2023-08-31 21:44:22,699][26288] Updated weights for policy 0, policy_version 41992 (0.0002)
[2023-08-31 21:44:23,109][26276] Fps is (10 sec: 15976.2, 60 sec: 16042.5, 300 sec: 16078.4). Total num frames: 21504000. Throughput: 0: 16345.3. Samples: 9578828. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2023-08-31 21:44:23,109][26276] Avg episode reward: [(0, '-186460.777')]
[2023-08-31 21:44:25,345][26288] Updated weights for policy 0, policy_version 42072 (0.0002)
[2023-08-31 21:44:27,907][26288] Updated weights for policy 0, policy_version 42152 (0.0002)
[2023-08-31 21:44:28,109][26276] Fps is (10 sec: 15977.4, 60 sec: 16110.4, 300 sec: 16064.6). Total num frames: 21581824. Throughput: 0: 16242.1. Samples: 9625556. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2023-08-31 21:44:28,109][26276] Avg episode reward: [(0, '-162446.928')]
[2023-08-31 21:44:30,285][26288] Updated weights for policy 0, policy_version 42232 (0.0002)
[2023-08-31 21:44:32,648][26288] Updated weights for policy 0, policy_version 42312 (0.0002)
[2023-08-31 21:44:33,105][26276] Fps is (10 sec: 16390.0, 60 sec: 16316.0, 300 sec: 16106.3). Total num frames: 21667840. Throughput: 0: 16233.0. Samples: 9724622. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2023-08-31 21:44:33,106][26276] Avg episode reward: [(0, '-162446.928')]
[2023-08-31 21:44:35,341][26288] Updated weights for policy 0, policy_version 42392 (0.0002)
[2023-08-31 21:44:37,862][26288] Updated weights for policy 0, policy_version 42472 (0.0002)
[2023-08-31 21:44:38,110][26276] Fps is (10 sec: 16381.8, 60 sec: 16247.2, 300 sec: 16092.2). Total num frames: 21745664. Throughput: 0: 16164.2. Samples: 9821630. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2023-08-31 21:44:38,110][26276] Avg episode reward: [(0, '-37029.606')]
[2023-08-31 21:44:40,362][26288] Updated weights for policy 0, policy_version 42552 (0.0002)
[2023-08-31 21:44:42,923][26288] Updated weights for policy 0, policy_version 42632 (0.0002)
[2023-08-31 21:44:43,108][26276] Fps is (10 sec: 15970.6, 60 sec: 16179.8, 300 sec: 16106.4). Total num frames: 21827584. Throughput: 0: 16232.1. Samples: 9870377. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2023-08-31 21:44:43,108][26276] Avg episode reward: [(0, '-37029.606')]
[2023-08-31 21:44:45,539][26288] Updated weights for policy 0, policy_version 42712 (0.0002)
[2023-08-31 21:44:48,109][26276] Fps is (10 sec: 15975.7, 60 sec: 16178.1, 300 sec: 16106.3). Total num frames: 21905408. Throughput: 0: 16138.0. Samples: 9965592. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 21:44:48,109][26276] Avg episode reward: [(0, '-2836.324')]
[2023-08-31 21:44:48,142][26288] Updated weights for policy 0, policy_version 42792 (0.0002)
[2023-08-31 21:44:50,665][26288] Updated weights for policy 0, policy_version 42872 (0.0002)
[2023-08-31 21:44:53,109][26276] Fps is (10 sec: 15972.2, 60 sec: 16110.2, 300 sec: 16106.2). Total num frames: 21987328. Throughput: 0: 16128.7. Samples: 10060868. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 21:44:53,110][26276] Avg episode reward: [(0, '-2836.324')]
[2023-08-31 21:44:53,261][26288] Updated weights for policy 0, policy_version 42952 (0.0002)
[2023-08-31 21:44:56,050][26288] Updated weights for policy 0, policy_version 43032 (0.0002)
[2023-08-31 21:44:58,106][26276] Fps is (10 sec: 15979.9, 60 sec: 16111.0, 300 sec: 16092.5). Total num frames: 22065152. Throughput: 0: 15993.6. Samples: 10105111. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 21:44:58,106][26276] Avg episode reward: [(0, '-2348.082')]
[2023-08-31 21:44:58,106][26287] Saving new best policy, reward=-2348.082!
[2023-08-31 21:44:58,613][26288] Updated weights for policy 0, policy_version 43112 (0.0002)
[2023-08-31 21:45:01,125][26288] Updated weights for policy 0, policy_version 43192 (0.0002)
[2023-08-31 21:45:03,110][26276] Fps is (10 sec: 15563.4, 60 sec: 15973.9, 300 sec: 16092.3). Total num frames: 22142976. Throughput: 0: 16054.7. Samples: 10202342. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 21:45:03,110][26276] Avg episode reward: [(0, '-2348.082')]
[2023-08-31 21:45:03,766][26288] Updated weights for policy 0, policy_version 43272 (0.0002)
[2023-08-31 21:45:06,503][26288] Updated weights for policy 0, policy_version 43352 (0.0002)
[2023-08-31 21:45:08,107][26276] Fps is (10 sec: 15563.5, 60 sec: 15974.0, 300 sec: 16092.6). Total num frames: 22220800. Throughput: 0: 15877.3. Samples: 10293267. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 21:45:08,107][26276] Avg episode reward: [(0, '-2120.978')]
[2023-08-31 21:45:08,107][26287] Saving new best policy, reward=-2120.978!
[2023-08-31 21:45:08,978][26288] Updated weights for policy 0, policy_version 43432 (0.0002)
[2023-08-31 21:45:11,451][26288] Updated weights for policy 0, policy_version 43512 (0.0003)
[2023-08-31 21:45:13,106][26276] Fps is (10 sec: 15980.7, 60 sec: 15975.5, 300 sec: 16120.3). Total num frames: 22302720. Throughput: 0: 15962.9. Samples: 10343843. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 21:45:13,106][26276] Avg episode reward: [(0, '-2120.978')]
[2023-08-31 21:45:14,077][26288] Updated weights for policy 0, policy_version 43592 (0.0002)
[2023-08-31 21:45:16,576][26288] Updated weights for policy 0, policy_version 43672 (0.0002)
[2023-08-31 21:45:18,110][26276] Fps is (10 sec: 16378.4, 60 sec: 16042.8, 300 sec: 16106.1). Total num frames: 22384640. Throughput: 0: 15905.8. Samples: 10440456. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 21:45:18,110][26276] Avg episode reward: [(0, '-2315.416')]
[2023-08-31 21:45:19,010][26288] Updated weights for policy 0, policy_version 43752 (0.0002)
[2023-08-31 21:45:21,564][26288] Updated weights for policy 0, policy_version 43832 (0.0002)
[2023-08-31 21:45:23,110][26276] Fps is (10 sec: 16377.5, 60 sec: 16042.4, 300 sec: 16120.0). Total num frames: 22466560. Throughput: 0: 15942.1. Samples: 10539026. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 21:45:23,110][26276] Avg episode reward: [(0, '-2315.416')]
[2023-08-31 21:45:24,255][26288] Updated weights for policy 0, policy_version 43912 (0.0002)
[2023-08-31 21:45:26,801][26288] Updated weights for policy 0, policy_version 43992 (0.0002)
[2023-08-31 21:45:28,110][26276] Fps is (10 sec: 15565.0, 60 sec: 15974.1, 300 sec: 16092.2). Total num frames: 22540288. Throughput: 0: 15871.5. Samples: 10584627. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 21:45:28,111][26276] Avg episode reward: [(0, '-2608.870')]
[2023-08-31 21:45:29,681][26288] Updated weights for policy 0, policy_version 44072 (0.0003)
[2023-08-31 21:45:32,191][26288] Updated weights for policy 0, policy_version 44152 (0.0002)
[2023-08-31 21:45:33,110][26276] Fps is (10 sec: 15155.3, 60 sec: 15836.7, 300 sec: 16106.2). Total num frames: 22618112. Throughput: 0: 15780.8. Samples: 10675741. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 21:45:33,110][26276] Avg episode reward: [(0, '-2608.870')]
[2023-08-31 21:45:34,887][26288] Updated weights for policy 0, policy_version 44232 (0.0002)
[2023-08-31 21:45:37,486][26288] Updated weights for policy 0, policy_version 44312 (0.0002)
[2023-08-31 21:45:38,108][26276] Fps is (10 sec: 15567.8, 60 sec: 15838.4, 300 sec: 16092.3). Total num frames: 22695936. Throughput: 0: 15737.1. Samples: 10769019. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 21:45:38,108][26276] Avg episode reward: [(0, '-2760.236')]
[2023-08-31 21:45:40,012][26288] Updated weights for policy 0, policy_version 44392 (0.0002)
[2023-08-31 21:45:42,395][26288] Updated weights for policy 0, policy_version 44472 (0.0002)
[2023-08-31 21:45:43,106][26276] Fps is (10 sec: 15980.2, 60 sec: 15838.3, 300 sec: 16106.5). Total num frames: 22777856. Throughput: 0: 15840.8. Samples: 10817954. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 21:45:43,107][26276] Avg episode reward: [(0, '-2760.236')]
[2023-08-31 21:45:43,110][26287] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000044488_22777856.pth...
[2023-08-31 21:45:43,111][26287] Removing /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000038248_19582976.pth
[2023-08-31 21:45:45,127][26288] Updated weights for policy 0, policy_version 44552 (0.0002)
[2023-08-31 21:45:47,679][26288] Updated weights for policy 0, policy_version 44632 (0.0002)
[2023-08-31 21:45:48,110][26276] Fps is (10 sec: 15970.6, 60 sec: 15837.6, 300 sec: 16092.2). Total num frames: 22855680. Throughput: 0: 15829.8. Samples: 10914689. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[2023-08-31 21:45:48,111][26276] Avg episode reward: [(0, '-2807.790')]
[2023-08-31 21:45:50,364][26288] Updated weights for policy 0, policy_version 44712 (0.0002)
[2023-08-31 21:45:52,810][26288] Updated weights for policy 0, policy_version 44792 (0.0002)
[2023-08-31 21:45:53,106][26276] Fps is (10 sec: 15975.6, 60 sec: 15838.8, 300 sec: 16092.7). Total num frames: 22937600. Throughput: 0: 15920.1. Samples: 11009656. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[2023-08-31 21:45:53,106][26276] Avg episode reward: [(0, '-2807.790')]
[2023-08-31 21:45:55,692][26288] Updated weights for policy 0, policy_version 44872 (0.0002)
[2023-08-31 21:45:58,106][26276] Fps is (10 sec: 15570.9, 60 sec: 15769.4, 300 sec: 16064.7). Total num frames: 23011328. Throughput: 0: 15768.3. Samples: 11053421. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[2023-08-31 21:45:58,107][26276] Avg episode reward: [(0, '-2827.258')]
[2023-08-31 21:45:58,259][26288] Updated weights for policy 0, policy_version 44952 (0.0002)
[2023-08-31 21:46:00,744][26288] Updated weights for policy 0, policy_version 45032 (0.0002)
[2023-08-31 21:46:03,086][26288] Updated weights for policy 0, policy_version 45112 (0.0002)
[2023-08-31 21:46:03,106][26276] Fps is (10 sec: 15973.0, 60 sec: 15907.1, 300 sec: 16078.5). Total num frames: 23097344. Throughput: 0: 15790.9. Samples: 11150991. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[2023-08-31 21:46:03,107][26276] Avg episode reward: [(0, '-2827.258')]
[2023-08-31 21:46:05,908][26288] Updated weights for policy 0, policy_version 45192 (0.0002)
[2023-08-31 21:46:08,109][26276] Fps is (10 sec: 15971.0, 60 sec: 15837.4, 300 sec: 16050.6). Total num frames: 23171072. Throughput: 0: 15721.2. Samples: 11246457. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[2023-08-31 21:46:08,109][26276] Avg episode reward: [(0, '-2793.885')]
[2023-08-31 21:46:08,462][26288] Updated weights for policy 0, policy_version 45272 (0.0002)
[2023-08-31 21:46:11,071][26288] Updated weights for policy 0, policy_version 45352 (0.0002)
[2023-08-31 21:46:13,109][26276] Fps is (10 sec: 15150.8, 60 sec: 15768.7, 300 sec: 16036.7). Total num frames: 23248896. Throughput: 0: 15735.0. Samples: 11292694. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2023-08-31 21:46:13,110][26276] Avg episode reward: [(0, '-2793.885')]
[2023-08-31 21:46:13,607][26288] Updated weights for policy 0, policy_version 45432 (0.0002)
[2023-08-31 21:46:16,468][26288] Updated weights for policy 0, policy_version 45512 (0.0002)
[2023-08-31 21:46:18,106][26276] Fps is (10 sec: 15569.1, 60 sec: 15702.4, 300 sec: 16023.1). Total num frames: 23326720. Throughput: 0: 15754.0. Samples: 11384607. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2023-08-31 21:46:18,106][26276] Avg episode reward: [(0, '-2740.285')]
[2023-08-31 21:46:19,025][26288] Updated weights for policy 0, policy_version 45592 (0.0002)
[2023-08-31 21:46:21,562][26288] Updated weights for policy 0, policy_version 45672 (0.0002)
[2023-08-31 21:46:23,106][26276] Fps is (10 sec: 15980.5, 60 sec: 15702.5, 300 sec: 16037.0). Total num frames: 23408640. Throughput: 0: 15819.7. Samples: 11480870. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2023-08-31 21:46:23,106][26276] Avg episode reward: [(0, '-2740.285')]
[2023-08-31 21:46:24,064][26288] Updated weights for policy 0, policy_version 45752 (0.0002)
[2023-08-31 21:46:26,860][26288] Updated weights for policy 0, policy_version 45832 (0.0002)
[2023-08-31 21:46:28,106][26276] Fps is (10 sec: 15974.6, 60 sec: 15770.7, 300 sec: 16009.1). Total num frames: 23486464. Throughput: 0: 15741.6. Samples: 11526314. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2023-08-31 21:46:28,106][26276] Avg episode reward: [(0, '-2700.952')]
[2023-08-31 21:46:29,287][26288] Updated weights for policy 0, policy_version 45912 (0.0002)
[2023-08-31 21:46:31,770][26288] Updated weights for policy 0, policy_version 45992 (0.0002)
[2023-08-31 21:46:33,106][26276] Fps is (10 sec: 15973.5, 60 sec: 15838.9, 300 sec: 16009.2). Total num frames: 23568384. Throughput: 0: 15774.3. Samples: 11624469. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2023-08-31 21:46:33,106][26276] Avg episode reward: [(0, '-2700.952')]
[2023-08-31 21:46:34,304][26288] Updated weights for policy 0, policy_version 46072 (0.0002)
[2023-08-31 21:46:37,111][26288] Updated weights for policy 0, policy_version 46152 (0.0002)
[2023-08-31 21:46:38,109][26276] Fps is (10 sec: 15559.9, 60 sec: 15769.4, 300 sec: 15981.4). Total num frames: 23642112. Throughput: 0: 15733.6. Samples: 11717720. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2023-08-31 21:46:38,109][26276] Avg episode reward: [(0, '-2666.566')]
[2023-08-31 21:46:39,586][26288] Updated weights for policy 0, policy_version 46232 (0.0002)
[2023-08-31 21:46:42,148][26288] Updated weights for policy 0, policy_version 46312 (0.0002)
[2023-08-31 21:46:43,105][26276] Fps is (10 sec: 15566.3, 60 sec: 15769.9, 300 sec: 15981.4). Total num frames: 23724032. Throughput: 0: 15871.5. Samples: 11767619. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 21:46:43,105][26276] Avg episode reward: [(0, '-2666.566')]
[2023-08-31 21:46:44,658][26288] Updated weights for policy 0, policy_version 46392 (0.0002)
[2023-08-31 21:46:47,319][26288] Updated weights for policy 0, policy_version 46472 (0.0002)
[2023-08-31 21:46:48,108][26276] Fps is (10 sec: 15976.4, 60 sec: 15770.3, 300 sec: 15967.5). Total num frames: 23801856. Throughput: 0: 15799.9. Samples: 11862003. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 21:46:48,108][26276] Avg episode reward: [(0, '-2639.985')]
[2023-08-31 21:46:49,981][26288] Updated weights for policy 0, policy_version 46552 (0.0002)
[2023-08-31 21:46:52,418][26288] Updated weights for policy 0, policy_version 46632 (0.0002)
[2023-08-31 21:46:53,109][26276] Fps is (10 sec: 15967.8, 60 sec: 15768.6, 300 sec: 15953.4). Total num frames: 23883776. Throughput: 0: 15830.5. Samples: 11958844. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 21:46:53,110][26276] Avg episode reward: [(0, '-2639.985')]
[2023-08-31 21:46:55,170][26288] Updated weights for policy 0, policy_version 46712 (0.0002)
[2023-08-31 21:46:57,641][26288] Updated weights for policy 0, policy_version 46792 (0.0002)
[2023-08-31 21:46:58,105][26276] Fps is (10 sec: 15977.8, 60 sec: 15838.1, 300 sec: 15939.9). Total num frames: 23961600. Throughput: 0: 15799.9. Samples: 12003628. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 21:46:58,106][26276] Avg episode reward: [(0, '-2602.567')]
[2023-08-31 21:47:00,240][26288] Updated weights for policy 0, policy_version 46872 (0.0002)
[2023-08-31 21:47:02,771][26288] Updated weights for policy 0, policy_version 46952 (0.0002)
[2023-08-31 21:47:03,106][26276] Fps is (10 sec: 15980.3, 60 sec: 15769.8, 300 sec: 15953.8). Total num frames: 24043520. Throughput: 0: 15896.7. Samples: 12099955. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 21:47:03,106][26276] Avg episode reward: [(0, '-2602.567')]
[2023-08-31 21:47:05,718][26288] Updated weights for policy 0, policy_version 47032 (0.0002)
[2023-08-31 21:47:08,105][26276] Fps is (10 sec: 15565.2, 60 sec: 15770.5, 300 sec: 15925.9). Total num frames: 24117248. Throughput: 0: 15752.3. Samples: 12189717. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 21:47:08,105][26276] Avg episode reward: [(0, '-2601.215')]
[2023-08-31 21:47:08,291][26288] Updated weights for policy 0, policy_version 47112 (0.0002)
[2023-08-31 21:47:10,854][26288] Updated weights for policy 0, policy_version 47192 (0.0002)
[2023-08-31 21:47:13,106][26276] Fps is (10 sec: 15155.4, 60 sec: 15770.6, 300 sec: 15926.1). Total num frames: 24195072. Throughput: 0: 15819.8. Samples: 12238204. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:47:13,106][26276] Avg episode reward: [(0, '-2601.215')]
[2023-08-31 21:47:13,375][26288] Updated weights for policy 0, policy_version 47272 (0.0002)
[2023-08-31 21:47:16,268][26288] Updated weights for policy 0, policy_version 47352 (0.0002)
[2023-08-31 21:47:18,106][26276] Fps is (10 sec: 15564.0, 60 sec: 15769.6, 300 sec: 15898.0). Total num frames: 24272896. Throughput: 0: 15660.9. Samples: 12329200. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:47:18,106][26276] Avg episode reward: [(0, '-2620.911')]
[2023-08-31 21:47:18,741][26288] Updated weights for policy 0, policy_version 47432 (0.0002)
[2023-08-31 21:47:21,214][26288] Updated weights for policy 0, policy_version 47512 (0.0002)
[2023-08-31 21:47:23,105][26276] Fps is (10 sec: 15975.0, 60 sec: 15769.7, 300 sec: 15911.9). Total num frames: 24354816. Throughput: 0: 15796.5. Samples: 12428506. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:47:23,105][26276] Avg episode reward: [(0, '-2620.911')]
[2023-08-31 21:47:23,108][26287] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000047568_24354816.pth...
[2023-08-31 21:47:23,111][26287] Removing /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000041376_21184512.pth
[2023-08-31 21:47:23,756][26288] Updated weights for policy 0, policy_version 47592 (0.0002)
[2023-08-31 21:47:26,665][26288] Updated weights for policy 0, policy_version 47672 (0.0002)
[2023-08-31 21:47:28,106][26276] Fps is (10 sec: 15564.2, 60 sec: 15701.2, 300 sec: 15870.2). Total num frames: 24428544. Throughput: 0: 15751.1. Samples: 12476432. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:47:28,106][26276] Avg episode reward: [(0, '-2655.273')]
[2023-08-31 21:47:29,210][26288] Updated weights for policy 0, policy_version 47752 (0.0002)
[2023-08-31 21:47:31,720][26288] Updated weights for policy 0, policy_version 47832 (0.0002)
[2023-08-31 21:47:33,110][26276] Fps is (10 sec: 15556.9, 60 sec: 15700.3, 300 sec: 15883.9). Total num frames: 24510464. Throughput: 0: 15666.3. Samples: 12567031. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:47:33,110][26276] Avg episode reward: [(0, '-2655.273')]
[2023-08-31 21:47:34,392][26288] Updated weights for policy 0, policy_version 47912 (0.0002)
[2023-08-31 21:47:37,181][26288] Updated weights for policy 0, policy_version 47992 (0.0002)
[2023-08-31 21:47:38,108][26276] Fps is (10 sec: 15562.4, 60 sec: 15701.6, 300 sec: 15856.3). Total num frames: 24584192. Throughput: 0: 15542.1. Samples: 12658211. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:47:38,108][26276] Avg episode reward: [(0, '-2713.406')]
[2023-08-31 21:47:39,822][26288] Updated weights for policy 0, policy_version 48072 (0.0002)
[2023-08-31 21:47:42,451][26288] Updated weights for policy 0, policy_version 48152 (0.0002)
[2023-08-31 21:47:43,107][26276] Fps is (10 sec: 15160.7, 60 sec: 15632.7, 300 sec: 15842.5). Total num frames: 24662016. Throughput: 0: 15567.4. Samples: 12704181. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:47:43,107][26276] Avg episode reward: [(0, '-2713.406')]
[2023-08-31 21:47:45,151][26288] Updated weights for policy 0, policy_version 48232 (0.0002)
[2023-08-31 21:47:47,935][26288] Updated weights for policy 0, policy_version 48312 (0.0002)
[2023-08-31 21:47:48,110][26276] Fps is (10 sec: 15151.8, 60 sec: 15564.2, 300 sec: 15800.8). Total num frames: 24735744. Throughput: 0: 15523.9. Samples: 12798596. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:47:48,110][26276] Avg episode reward: [(0, '-2783.716')]
[2023-08-31 21:47:50,513][26288] Updated weights for policy 0, policy_version 48392 (0.0002)
[2023-08-31 21:47:52,981][26288] Updated weights for policy 0, policy_version 48472 (0.0002)
[2023-08-31 21:47:53,110][26276] Fps is (10 sec: 15559.3, 60 sec: 15564.6, 300 sec: 15786.7). Total num frames: 24817664. Throughput: 0: 15598.9. Samples: 12891745. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:47:53,110][26276] Avg episode reward: [(0, '-2783.716')]
[2023-08-31 21:47:55,436][26288] Updated weights for policy 0, policy_version 48552 (0.0002)
[2023-08-31 21:47:58,107][26276] Fps is (10 sec: 16389.0, 60 sec: 15632.7, 300 sec: 15787.1). Total num frames: 24899584. Throughput: 0: 15631.3. Samples: 12941634. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:47:58,107][26276] Avg episode reward: [(0, '-2826.737')]
[2023-08-31 21:47:58,107][26288] Updated weights for policy 0, policy_version 48632 (0.0002)
[2023-08-31 21:48:00,694][26288] Updated weights for policy 0, policy_version 48712 (0.0002)
[2023-08-31 21:48:03,105][26276] Fps is (10 sec: 15982.4, 60 sec: 15564.9, 300 sec: 15787.1). Total num frames: 24977408. Throughput: 0: 15708.6. Samples: 13036080. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:48:03,105][26276] Avg episode reward: [(0, '-2826.737')]
[2023-08-31 21:48:03,161][26288] Updated weights for policy 0, policy_version 48792 (0.0002)
[2023-08-31 21:48:05,644][26288] Updated weights for policy 0, policy_version 48872 (0.0002)
[2023-08-31 21:48:08,105][26276] Fps is (10 sec: 15567.4, 60 sec: 15633.1, 300 sec: 15800.9). Total num frames: 25055232. Throughput: 0: 15612.1. Samples: 13131050. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:48:08,105][26276] Avg episode reward: [(0, '-2796.121')]
[2023-08-31 21:48:08,404][26288] Updated weights for policy 0, policy_version 48952 (0.0002)
[2023-08-31 21:48:11,044][26288] Updated weights for policy 0, policy_version 49032 (0.0002)
[2023-08-31 21:48:13,106][26276] Fps is (10 sec: 15973.1, 60 sec: 15701.2, 300 sec: 15828.8). Total num frames: 25137152. Throughput: 0: 15608.0. Samples: 13178790. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[2023-08-31 21:48:13,106][26276] Avg episode reward: [(0, '-2796.121')]
[2023-08-31 21:48:13,559][26288] Updated weights for policy 0, policy_version 49112 (0.0002)
[2023-08-31 21:48:16,095][26288] Updated weights for policy 0, policy_version 49192 (0.0002)
[2023-08-31 21:48:18,108][26276] Fps is (10 sec: 15559.9, 60 sec: 15632.4, 300 sec: 15828.6). Total num frames: 25210880. Throughput: 0: 15728.8. Samples: 13274794. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[2023-08-31 21:48:18,108][26276] Avg episode reward: [(0, '-2653.647')]
[2023-08-31 21:48:18,884][26288] Updated weights for policy 0, policy_version 49272 (0.0002)
[2023-08-31 21:48:21,442][26288] Updated weights for policy 0, policy_version 49352 (0.0002)
[2023-08-31 21:48:23,110][26276] Fps is (10 sec: 15558.6, 60 sec: 15631.8, 300 sec: 15856.2). Total num frames: 25292800. Throughput: 0: 15759.4. Samples: 13367421. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[2023-08-31 21:48:23,111][26276] Avg episode reward: [(0, '-2653.647')]
[2023-08-31 21:48:23,853][26288] Updated weights for policy 0, policy_version 49432 (0.0002)
[2023-08-31 21:48:26,478][26288] Updated weights for policy 0, policy_version 49512 (0.0002)
[2023-08-31 21:48:28,105][26276] Fps is (10 sec: 15979.3, 60 sec: 15701.6, 300 sec: 15870.3). Total num frames: 25370624. Throughput: 0: 15805.1. Samples: 13415389. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[2023-08-31 21:48:28,106][26276] Avg episode reward: [(0, '-2506.603')]
[2023-08-31 21:48:29,323][26288] Updated weights for policy 0, policy_version 49592 (0.0002)
[2023-08-31 21:48:31,872][26288] Updated weights for policy 0, policy_version 49672 (0.0002)
[2023-08-31 21:48:33,106][26276] Fps is (10 sec: 15571.8, 60 sec: 15634.3, 300 sec: 15856.6). Total num frames: 25448448. Throughput: 0: 15746.2. Samples: 13507105. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[2023-08-31 21:48:33,106][26276] Avg episode reward: [(0, '-2506.603')]
[2023-08-31 21:48:34,359][26288] Updated weights for policy 0, policy_version 49752 (0.0002)
[2023-08-31 21:48:36,900][26288] Updated weights for policy 0, policy_version 49832 (0.0002)
[2023-08-31 21:48:38,106][26276] Fps is (10 sec: 15563.8, 60 sec: 15701.8, 300 sec: 15828.8). Total num frames: 25526272. Throughput: 0: 15779.1. Samples: 13601737. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[2023-08-31 21:48:38,106][26276] Avg episode reward: [(0, '-2329.647')]
[2023-08-31 21:48:39,735][26288] Updated weights for policy 0, policy_version 49912 (0.0002)
[2023-08-31 21:48:42,226][26288] Updated weights for policy 0, policy_version 49992 (0.0002)
[2023-08-31 21:48:43,106][26276] Fps is (10 sec: 15974.3, 60 sec: 15769.9, 300 sec: 15842.5). Total num frames: 25608192. Throughput: 0: 15715.3. Samples: 13648803. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:48:43,106][26276] Avg episode reward: [(0, '-2329.647')]
[2023-08-31 21:48:44,810][26288] Updated weights for policy 0, policy_version 50072 (0.0002)
[2023-08-31 21:48:47,560][26288] Updated weights for policy 0, policy_version 50152 (0.0002)
[2023-08-31 21:48:48,106][26276] Fps is (10 sec: 15973.9, 60 sec: 15838.8, 300 sec: 15814.7). Total num frames: 25686016. Throughput: 0: 15780.0. Samples: 13746195. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:48:48,106][26276] Avg episode reward: [(0, '-2180.955')]
[2023-08-31 21:48:50,115][26288] Updated weights for policy 0, policy_version 50232 (0.0002)
[2023-08-31 21:48:52,601][26288] Updated weights for policy 0, policy_version 50312 (0.0002)
[2023-08-31 21:48:53,107][26276] Fps is (10 sec: 15973.0, 60 sec: 15838.8, 300 sec: 15828.6). Total num frames: 25767936. Throughput: 0: 15735.5. Samples: 13839170. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:48:53,107][26276] Avg episode reward: [(0, '-2180.955')]
[2023-08-31 21:48:55,091][26288] Updated weights for policy 0, policy_version 50392 (0.0002)
[2023-08-31 21:48:57,887][26288] Updated weights for policy 0, policy_version 50472 (0.0002)
[2023-08-31 21:48:58,110][26276] Fps is (10 sec: 15558.9, 60 sec: 15700.5, 300 sec: 15786.9). Total num frames: 25841664. Throughput: 0: 15778.9. Samples: 13888901. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:48:58,110][26276] Avg episode reward: [(0, '-2050.740')]
[2023-08-31 21:48:58,111][26287] Saving new best policy, reward=-2050.740!
[2023-08-31 21:49:00,456][26288] Updated weights for policy 0, policy_version 50552 (0.0002)
[2023-08-31 21:49:02,932][26288] Updated weights for policy 0, policy_version 50632 (0.0002)
[2023-08-31 21:49:03,109][26276] Fps is (10 sec: 15560.4, 60 sec: 15768.5, 300 sec: 15800.6). Total num frames: 25923584. Throughput: 0: 15712.3. Samples: 13981865. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:49:03,110][26276] Avg episode reward: [(0, '-2050.740')]
[2023-08-31 21:49:03,112][26287] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000050632_25923584.pth...
[2023-08-31 21:49:03,113][26287] Removing /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000044488_22777856.pth
[2023-08-31 21:49:05,453][26288] Updated weights for policy 0, policy_version 50712 (0.0002)
[2023-08-31 21:49:08,105][26276] Fps is (10 sec: 15982.0, 60 sec: 15769.6, 300 sec: 15787.2). Total num frames: 26001408. Throughput: 0: 15827.7. Samples: 14079592. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:49:08,105][26276] Avg episode reward: [(0, '-1914.183')]
[2023-08-31 21:49:08,106][26287] Saving new best policy, reward=-1914.183!
[2023-08-31 21:49:08,229][26288] Updated weights for policy 0, policy_version 50792 (0.0002)
[2023-08-31 21:49:10,745][26288] Updated weights for policy 0, policy_version 50872 (0.0002)
[2023-08-31 21:49:13,109][26276] Fps is (10 sec: 15975.3, 60 sec: 15768.9, 300 sec: 15800.9). Total num frames: 26083328. Throughput: 0: 15735.0. Samples: 14123521. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:49:13,109][26276] Avg episode reward: [(0, '-1914.183')]
[2023-08-31 21:49:13,274][26288] Updated weights for policy 0, policy_version 50952 (0.0002)
[2023-08-31 21:49:15,785][26288] Updated weights for policy 0, policy_version 51032 (0.0002)
[2023-08-31 21:49:18,110][26276] Fps is (10 sec: 15148.5, 60 sec: 15701.0, 300 sec: 15759.2). Total num frames: 26152960. Throughput: 0: 15870.2. Samples: 14221328. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 21:49:18,110][26276] Avg episode reward: [(0, '-1872.646')]
[2023-08-31 21:49:18,111][26287] Saving new best policy, reward=-1872.646!
[2023-08-31 21:49:19,045][26288] Updated weights for policy 0, policy_version 51112 (0.0003)
[2023-08-31 21:49:21,579][26288] Updated weights for policy 0, policy_version 51192 (0.0002)
[2023-08-31 21:49:23,109][26276] Fps is (10 sec: 15154.7, 60 sec: 15701.6, 300 sec: 15773.0). Total num frames: 26234880. Throughput: 0: 15662.8. Samples: 14306616. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 21:49:23,109][26276] Avg episode reward: [(0, '-1871.446')]
[2023-08-31 21:49:23,110][26287] Saving new best policy, reward=-1871.446!
[2023-08-31 21:49:24,252][26288] Updated weights for policy 0, policy_version 51272 (0.0002)
[2023-08-31 21:49:26,805][26288] Updated weights for policy 0, policy_version 51352 (0.0002)
[2023-08-31 21:49:28,108][26276] Fps is (10 sec: 15977.8, 60 sec: 15700.7, 300 sec: 15745.2). Total num frames: 26312704. Throughput: 0: 15639.1. Samples: 14352590. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 21:49:28,108][26276] Avg episode reward: [(0, '-1871.446')]
[2023-08-31 21:49:29,523][26288] Updated weights for policy 0, policy_version 51432 (0.0003)
[2023-08-31 21:49:31,962][26288] Updated weights for policy 0, policy_version 51512 (0.0002)
[2023-08-31 21:49:33,105][26276] Fps is (10 sec: 15571.1, 60 sec: 15701.4, 300 sec: 15745.6). Total num frames: 26390528. Throughput: 0: 15574.2. Samples: 14447015. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 21:49:33,105][26276] Avg episode reward: [(0, '-1848.783')]
[2023-08-31 21:49:33,106][26287] Saving new best policy, reward=-1848.783!
[2023-08-31 21:49:34,486][26288] Updated weights for policy 0, policy_version 51592 (0.0002)
[2023-08-31 21:49:36,986][26288] Updated weights for policy 0, policy_version 51672 (0.0002)
[2023-08-31 21:49:38,106][26276] Fps is (10 sec: 15976.9, 60 sec: 15769.6, 300 sec: 15745.4). Total num frames: 26472448. Throughput: 0: 15713.3. Samples: 14546259. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 21:49:38,107][26276] Avg episode reward: [(0, '-1848.783')]
[2023-08-31 21:49:39,722][26288] Updated weights for policy 0, policy_version 51752 (0.0002)
[2023-08-31 21:49:42,327][26288] Updated weights for policy 0, policy_version 51832 (0.0002)
[2023-08-31 21:49:43,110][26276] Fps is (10 sec: 15966.9, 60 sec: 15700.2, 300 sec: 15745.3). Total num frames: 26550272. Throughput: 0: 15582.0. Samples: 14590086. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 21:49:43,110][26276] Avg episode reward: [(0, '-1841.214')]
[2023-08-31 21:49:43,110][26287] Saving new best policy, reward=-1841.214!
[2023-08-31 21:49:44,869][26288] Updated weights for policy 0, policy_version 51912 (0.0002)
[2023-08-31 21:49:47,526][26288] Updated weights for policy 0, policy_version 51992 (0.0002)
[2023-08-31 21:49:48,107][26276] Fps is (10 sec: 15563.2, 60 sec: 15701.1, 300 sec: 15731.5). Total num frames: 26628096. Throughput: 0: 15645.6. Samples: 14685878. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:49:48,107][26276] Avg episode reward: [(0, '-1841.214')]
[2023-08-31 21:49:50,233][26288] Updated weights for policy 0, policy_version 52072 (0.0002)
[2023-08-31 21:49:52,753][26288] Updated weights for policy 0, policy_version 52152 (0.0002)
[2023-08-31 21:49:53,108][26276] Fps is (10 sec: 15568.1, 60 sec: 15632.8, 300 sec: 15731.3). Total num frames: 26705920. Throughput: 0: 15539.2. Samples: 14778894. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:49:53,108][26276] Avg episode reward: [(0, '-1795.772')]
[2023-08-31 21:49:53,108][26287] Saving new best policy, reward=-1795.772!
[2023-08-31 21:49:55,236][26288] Updated weights for policy 0, policy_version 52232 (0.0002)
[2023-08-31 21:49:57,745][26288] Updated weights for policy 0, policy_version 52312 (0.0002)
[2023-08-31 21:49:58,105][26276] Fps is (10 sec: 15977.0, 60 sec: 15770.8, 300 sec: 15745.6). Total num frames: 26787840. Throughput: 0: 15667.1. Samples: 14828486. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:49:58,106][26276] Avg episode reward: [(0, '-1795.772')]
[2023-08-31 21:50:00,524][26288] Updated weights for policy 0, policy_version 52392 (0.0003)
[2023-08-31 21:50:02,937][26288] Updated weights for policy 0, policy_version 52472 (0.0002)
[2023-08-31 21:50:03,107][26276] Fps is (10 sec: 15975.9, 60 sec: 15702.0, 300 sec: 15745.3). Total num frames: 26865664. Throughput: 0: 15577.2. Samples: 14922254. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:50:03,107][26276] Avg episode reward: [(0, '-1733.556')]
[2023-08-31 21:50:03,107][26287] Saving new best policy, reward=-1733.556!
[2023-08-31 21:50:05,476][26288] Updated weights for policy 0, policy_version 52552 (0.0002)
[2023-08-31 21:50:07,961][26288] Updated weights for policy 0, policy_version 52632 (0.0002)
[2023-08-31 21:50:08,107][26276] Fps is (10 sec: 15971.2, 60 sec: 15769.0, 300 sec: 15745.2). Total num frames: 26947584. Throughput: 0: 15890.9. Samples: 15021677. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:50:08,108][26276] Avg episode reward: [(0, '-1733.556')]
[2023-08-31 21:50:10,726][26288] Updated weights for policy 0, policy_version 52712 (0.0002)
[2023-08-31 21:50:13,107][26276] Fps is (10 sec: 15973.2, 60 sec: 15701.7, 300 sec: 15731.6). Total num frames: 27025408. Throughput: 0: 15867.4. Samples: 15066622. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:50:13,108][26276] Avg episode reward: [(0, '-1760.995')]
[2023-08-31 21:50:13,205][26288] Updated weights for policy 0, policy_version 52792 (0.0002)
[2023-08-31 21:50:15,674][26288] Updated weights for policy 0, policy_version 52872 (0.0002)
[2023-08-31 21:50:18,105][26276] Fps is (10 sec: 15977.5, 60 sec: 15907.3, 300 sec: 15731.7). Total num frames: 27107328. Throughput: 0: 15950.2. Samples: 15164779. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:50:18,107][26276] Avg episode reward: [(0, '-1760.995')]
[2023-08-31 21:50:18,183][26288] Updated weights for policy 0, policy_version 52952 (0.0002)
[2023-08-31 21:50:20,890][26288] Updated weights for policy 0, policy_version 53032 (0.0002)
[2023-08-31 21:50:23,106][26276] Fps is (10 sec: 16386.6, 60 sec: 15907.0, 300 sec: 15759.4). Total num frames: 27189248. Throughput: 0: 15889.8. Samples: 15261298. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[2023-08-31 21:50:23,106][26276] Avg episode reward: [(0, '-1799.708')]
[2023-08-31 21:50:23,318][26288] Updated weights for policy 0, policy_version 53112 (0.0002)
[2023-08-31 21:50:25,857][26288] Updated weights for policy 0, policy_version 53192 (0.0002)
[2023-08-31 21:50:28,110][26276] Fps is (10 sec: 16376.3, 60 sec: 15973.7, 300 sec: 15773.1). Total num frames: 27271168. Throughput: 0: 16009.5. Samples: 15310517. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[2023-08-31 21:50:28,111][26276] Avg episode reward: [(0, '-1799.708')]
[2023-08-31 21:50:28,310][26288] Updated weights for policy 0, policy_version 53272 (0.0002)
[2023-08-31 21:50:31,065][26288] Updated weights for policy 0, policy_version 53352 (0.0002)
[2023-08-31 21:50:33,106][26276] Fps is (10 sec: 15974.2, 60 sec: 15974.2, 300 sec: 15773.2). Total num frames: 27348992. Throughput: 0: 15982.5. Samples: 15405077. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[2023-08-31 21:50:33,106][26276] Avg episode reward: [(0, '-1863.619')]
[2023-08-31 21:50:33,531][26288] Updated weights for policy 0, policy_version 53432 (0.0002)
[2023-08-31 21:50:36,026][26288] Updated weights for policy 0, policy_version 53512 (0.0002)
[2023-08-31 21:50:38,109][26276] Fps is (10 sec: 15975.5, 60 sec: 15973.5, 300 sec: 15772.9). Total num frames: 27430912. Throughput: 0: 16099.2. Samples: 15503386. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[2023-08-31 21:50:38,110][26276] Avg episode reward: [(0, '-1863.619')]
[2023-08-31 21:50:38,788][26288] Updated weights for policy 0, policy_version 53592 (0.0002)
[2023-08-31 21:50:41,316][26288] Updated weights for policy 0, policy_version 53672 (0.0002)
[2023-08-31 21:50:43,106][26276] Fps is (10 sec: 15973.9, 60 sec: 15975.3, 300 sec: 15773.3). Total num frames: 27508736. Throughput: 0: 15998.5. Samples: 15548436. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[2023-08-31 21:50:43,107][26276] Avg episode reward: [(0, '-1921.965')]
[2023-08-31 21:50:43,109][26287] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000053728_27508736.pth...
[2023-08-31 21:50:43,111][26287] Removing /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000047568_24354816.pth
[2023-08-31 21:50:43,826][26288] Updated weights for policy 0, policy_version 53752 (0.0002)
[2023-08-31 21:50:46,315][26288] Updated weights for policy 0, policy_version 53832 (0.0002)
[2023-08-31 21:50:48,105][26276] Fps is (10 sec: 15981.1, 60 sec: 16043.1, 300 sec: 15773.1). Total num frames: 27590656. Throughput: 0: 16099.0. Samples: 15646686. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[2023-08-31 21:50:48,105][26276] Avg episode reward: [(0, '-1921.965')]
[2023-08-31 21:50:49,138][26288] Updated weights for policy 0, policy_version 53912 (0.0002)
[2023-08-31 21:50:51,701][26288] Updated weights for policy 0, policy_version 53992 (0.0002)
[2023-08-31 21:50:53,106][26276] Fps is (10 sec: 15564.8, 60 sec: 15974.8, 300 sec: 15773.1). Total num frames: 27664384. Throughput: 0: 15938.8. Samples: 15738907. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:50:53,107][26276] Avg episode reward: [(0, '-1983.705')]
[2023-08-31 21:50:54,151][26288] Updated weights for policy 0, policy_version 54072 (0.0002)
[2023-08-31 21:50:56,655][26288] Updated weights for policy 0, policy_version 54152 (0.0002)
[2023-08-31 21:50:58,110][26276] Fps is (10 sec: 15557.4, 60 sec: 15973.2, 300 sec: 15759.0). Total num frames: 27746304. Throughput: 0: 16027.6. Samples: 15787904. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:50:58,110][26276] Avg episode reward: [(0, '-1983.705')]
[2023-08-31 21:50:59,412][26288] Updated weights for policy 0, policy_version 54232 (0.0002)
[2023-08-31 21:51:01,920][26288] Updated weights for policy 0, policy_version 54312 (0.0002)
[2023-08-31 21:51:03,108][26276] Fps is (10 sec: 15972.1, 60 sec: 15974.1, 300 sec: 15773.1). Total num frames: 27824128. Throughput: 0: 15949.2. Samples: 15882531. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:51:03,108][26276] Avg episode reward: [(0, '-2065.506')]
[2023-08-31 21:51:04,399][26288] Updated weights for policy 0, policy_version 54392 (0.0002)
[2023-08-31 21:51:06,963][26288] Updated weights for policy 0, policy_version 54472 (0.0003)
[2023-08-31 21:51:08,110][26276] Fps is (10 sec: 15974.9, 60 sec: 15973.8, 300 sec: 15786.9). Total num frames: 27906048. Throughput: 0: 15976.0. Samples: 15980279. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:51:08,110][26276] Avg episode reward: [(0, '-2065.506')]
[2023-08-31 21:51:09,651][26288] Updated weights for policy 0, policy_version 54552 (0.0002)
[2023-08-31 21:51:12,186][26288] Updated weights for policy 0, policy_version 54632 (0.0002)
[2023-08-31 21:51:13,107][26276] Fps is (10 sec: 15975.7, 60 sec: 15974.5, 300 sec: 15786.9). Total num frames: 27983872. Throughput: 0: 15899.2. Samples: 16025931. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:51:13,107][26276] Avg episode reward: [(0, '-2105.472')]
[2023-08-31 21:51:14,581][26288] Updated weights for policy 0, policy_version 54712 (0.0002)
[2023-08-31 21:51:17,111][26288] Updated weights for policy 0, policy_version 54792 (0.0002)
[2023-08-31 21:51:18,110][26276] Fps is (10 sec: 16383.5, 60 sec: 16041.4, 300 sec: 15800.6). Total num frames: 28069888. Throughput: 0: 15998.1. Samples: 16125057. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:51:18,110][26276] Avg episode reward: [(0, '-2105.472')]
[2023-08-31 21:51:19,815][26288] Updated weights for policy 0, policy_version 54872 (0.0002)
[2023-08-31 21:51:22,367][26288] Updated weights for policy 0, policy_version 54952 (0.0002)
[2023-08-31 21:51:23,109][26276] Fps is (10 sec: 15970.8, 60 sec: 15905.3, 300 sec: 15786.8). Total num frames: 28143616. Throughput: 0: 15920.3. Samples: 16219793. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:51:23,109][26276] Avg episode reward: [(0, '-2096.135')]
[2023-08-31 21:51:24,826][26288] Updated weights for policy 0, policy_version 55032 (0.0002)
[2023-08-31 21:51:27,365][26288] Updated weights for policy 0, policy_version 55112 (0.0002)
[2023-08-31 21:51:28,110][26276] Fps is (10 sec: 15565.1, 60 sec: 15906.2, 300 sec: 15786.8). Total num frames: 28225536. Throughput: 0: 16018.6. Samples: 16269328. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[2023-08-31 21:51:28,111][26276] Avg episode reward: [(0, '-2096.135')]
[2023-08-31 21:51:30,138][26288] Updated weights for policy 0, policy_version 55192 (0.0002)
[2023-08-31 21:51:32,582][26288] Updated weights for policy 0, policy_version 55272 (0.0002)
[2023-08-31 21:51:33,106][26276] Fps is (10 sec: 16389.9, 60 sec: 15974.5, 300 sec: 15814.9). Total num frames: 28307456. Throughput: 0: 15888.3. Samples: 16361664. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[2023-08-31 21:51:33,106][26276] Avg episode reward: [(0, '-2068.850')]
[2023-08-31 21:51:35,082][26288] Updated weights for policy 0, policy_version 55352 (0.0002)
[2023-08-31 21:51:37,601][26288] Updated weights for policy 0, policy_version 55432 (0.0002)
[2023-08-31 21:51:38,110][26276] Fps is (10 sec: 15974.4, 60 sec: 15906.0, 300 sec: 15800.6). Total num frames: 28385280. Throughput: 0: 16049.9. Samples: 16461208. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[2023-08-31 21:51:38,111][26276] Avg episode reward: [(0, '-2068.850')]
[2023-08-31 21:51:40,332][26288] Updated weights for policy 0, policy_version 55512 (0.0002)
[2023-08-31 21:51:42,870][26288] Updated weights for policy 0, policy_version 55592 (0.0002)
[2023-08-31 21:51:43,107][26276] Fps is (10 sec: 15562.5, 60 sec: 15905.9, 300 sec: 15800.9). Total num frames: 28463104. Throughput: 0: 15972.1. Samples: 16506603. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[2023-08-31 21:51:43,107][26276] Avg episode reward: [(0, '-2050.930')]
[2023-08-31 21:51:45,378][26288] Updated weights for policy 0, policy_version 55672 (0.0002)
[2023-08-31 21:51:47,862][26288] Updated weights for policy 0, policy_version 55752 (0.0002)
[2023-08-31 21:51:48,106][26276] Fps is (10 sec: 15980.7, 60 sec: 15906.0, 300 sec: 15801.0). Total num frames: 28545024. Throughput: 0: 16037.7. Samples: 16604199. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[2023-08-31 21:51:48,106][26276] Avg episode reward: [(0, '-2050.930')]
[2023-08-31 21:51:50,616][26288] Updated weights for policy 0, policy_version 55832 (0.0002)
[2023-08-31 21:51:53,108][26276] Fps is (10 sec: 15973.6, 60 sec: 15974.1, 300 sec: 15800.7). Total num frames: 28622848. Throughput: 0: 15962.4. Samples: 16698556. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[2023-08-31 21:51:53,108][26276] Avg episode reward: [(0, '-2035.945')]
[2023-08-31 21:51:53,146][26288] Updated weights for policy 0, policy_version 55912 (0.0002)
[2023-08-31 21:51:55,679][26288] Updated weights for policy 0, policy_version 55992 (0.0002)
[2023-08-31 21:51:58,106][26276] Fps is (10 sec: 15973.9, 60 sec: 15975.4, 300 sec: 15800.8). Total num frames: 28704768. Throughput: 0: 16031.2. Samples: 16747323. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[2023-08-31 21:51:58,107][26276] Avg episode reward: [(0, '-2035.945')]
[2023-08-31 21:51:58,138][26288] Updated weights for policy 0, policy_version 56072 (0.0002)
[2023-08-31 21:52:00,948][26288] Updated weights for policy 0, policy_version 56152 (0.0002)
[2023-08-31 21:52:03,106][26276] Fps is (10 sec: 16387.1, 60 sec: 16043.2, 300 sec: 15828.6). Total num frames: 28786688. Throughput: 0: 15895.0. Samples: 16840264. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 21:52:03,106][26276] Avg episode reward: [(0, '-2029.040')]
[2023-08-31 21:52:03,330][26288] Updated weights for policy 0, policy_version 56232 (0.0002)
[2023-08-31 21:52:05,950][26288] Updated weights for policy 0, policy_version 56312 (0.0002)
[2023-08-31 21:52:08,107][26276] Fps is (10 sec: 15972.5, 60 sec: 15975.0, 300 sec: 15828.5). Total num frames: 28864512. Throughput: 0: 15976.4. Samples: 16938706. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 21:52:08,108][26276] Avg episode reward: [(0, '-2029.040')]
[2023-08-31 21:52:08,426][26288] Updated weights for policy 0, policy_version 56392 (0.0002)
[2023-08-31 21:52:11,282][26288] Updated weights for policy 0, policy_version 56472 (0.0002)
[2023-08-31 21:52:13,107][26276] Fps is (10 sec: 15562.6, 60 sec: 15974.4, 300 sec: 15828.5). Total num frames: 28942336. Throughput: 0: 15862.0. Samples: 16983077. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 21:52:13,107][26276] Avg episode reward: [(0, '-2049.389')]
[2023-08-31 21:52:13,677][26288] Updated weights for policy 0, policy_version 56552 (0.0002)
[2023-08-31 21:52:16,132][26288] Updated weights for policy 0, policy_version 56632 (0.0002)
[2023-08-31 21:52:18,106][26276] Fps is (10 sec: 16386.2, 60 sec: 15975.4, 300 sec: 15842.4). Total num frames: 29028352. Throughput: 0: 16034.3. Samples: 17083216. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 21:52:18,106][26276] Avg episode reward: [(0, '-2049.389')]
[2023-08-31 21:52:18,656][26288] Updated weights for policy 0, policy_version 56712 (0.0002)
[2023-08-31 21:52:21,224][26288] Updated weights for policy 0, policy_version 56792 (0.0002)
[2023-08-31 21:52:23,106][26276] Fps is (10 sec: 16386.1, 60 sec: 16043.6, 300 sec: 15856.4). Total num frames: 29106176. Throughput: 0: 15955.7. Samples: 17179152. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 21:52:23,106][26276] Avg episode reward: [(0, '-2079.968')]
[2023-08-31 21:52:23,110][26287] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000056848_29106176.pth...
[2023-08-31 21:52:23,112][26287] Removing /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000050632_25923584.pth
[2023-08-31 21:52:23,752][26288] Updated weights for policy 0, policy_version 56872 (0.0002)
[2023-08-31 21:52:26,282][26288] Updated weights for policy 0, policy_version 56952 (0.0002)
[2023-08-31 21:52:28,106][26276] Fps is (10 sec: 15974.7, 60 sec: 16043.7, 300 sec: 15856.6). Total num frames: 29188096. Throughput: 0: 16027.0. Samples: 17227799. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 21:52:28,106][26276] Avg episode reward: [(0, '-2079.968')]
[2023-08-31 21:52:28,968][26288] Updated weights for policy 0, policy_version 57032 (0.0002)
[2023-08-31 21:52:31,454][26288] Updated weights for policy 0, policy_version 57112 (0.0002)
[2023-08-31 21:52:33,106][26276] Fps is (10 sec: 15973.9, 60 sec: 15974.2, 300 sec: 15870.3). Total num frames: 29265920. Throughput: 0: 15976.4. Samples: 17323143. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 21:52:33,107][26276] Avg episode reward: [(0, '-2108.942')]
[2023-08-31 21:52:33,931][26288] Updated weights for policy 0, policy_version 57192 (0.0002)
[2023-08-31 21:52:36,490][26288] Updated weights for policy 0, policy_version 57272 (0.0002)
[2023-08-31 21:52:38,108][26276] Fps is (10 sec: 15971.6, 60 sec: 16043.2, 300 sec: 15884.1). Total num frames: 29347840. Throughput: 0: 16054.4. Samples: 17421007. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2023-08-31 21:52:38,108][26276] Avg episode reward: [(0, '-2108.942')]
[2023-08-31 21:52:39,252][26288] Updated weights for policy 0, policy_version 57352 (0.0002)
[2023-08-31 21:52:41,721][26288] Updated weights for policy 0, policy_version 57432 (0.0002)
[2023-08-31 21:52:43,106][26276] Fps is (10 sec: 15974.5, 60 sec: 16042.9, 300 sec: 15898.2). Total num frames: 29425664. Throughput: 0: 15986.7. Samples: 17466720. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2023-08-31 21:52:43,106][26276] Avg episode reward: [(0, '-2129.928')]
[2023-08-31 21:52:44,178][26288] Updated weights for policy 0, policy_version 57512 (0.0002)
[2023-08-31 21:52:46,638][26288] Updated weights for policy 0, policy_version 57592 (0.0002)
[2023-08-31 21:52:48,110][26276] Fps is (10 sec: 15970.8, 60 sec: 16041.6, 300 sec: 15898.0). Total num frames: 29507584. Throughput: 0: 16123.6. Samples: 17565893. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2023-08-31 21:52:48,110][26276] Avg episode reward: [(0, '-2129.928')]
[2023-08-31 21:52:49,412][26288] Updated weights for policy 0, policy_version 57672 (0.0002)
[2023-08-31 21:52:51,886][26288] Updated weights for policy 0, policy_version 57752 (0.0002)
[2023-08-31 21:52:53,107][26276] Fps is (10 sec: 15972.8, 60 sec: 16042.8, 300 sec: 15884.1). Total num frames: 29585408. Throughput: 0: 16041.8. Samples: 17660579. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2023-08-31 21:52:53,107][26276] Avg episode reward: [(0, '-2127.844')]
[2023-08-31 21:52:54,426][26288] Updated weights for policy 0, policy_version 57832 (0.0002)
[2023-08-31 21:52:56,954][26288] Updated weights for policy 0, policy_version 57912 (0.0002)
[2023-08-31 21:52:58,106][26276] Fps is (10 sec: 15980.7, 60 sec: 16042.7, 300 sec: 15898.0). Total num frames: 29667328. Throughput: 0: 16131.9. Samples: 17708995. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2023-08-31 21:52:58,106][26276] Avg episode reward: [(0, '-2127.844')]
[2023-08-31 21:52:59,780][26288] Updated weights for policy 0, policy_version 57992 (0.0002)
[2023-08-31 21:53:02,288][26288] Updated weights for policy 0, policy_version 58072 (0.0002)
[2023-08-31 21:53:03,106][26276] Fps is (10 sec: 15976.3, 60 sec: 15974.4, 300 sec: 15898.0). Total num frames: 29745152. Throughput: 0: 15956.0. Samples: 17801232. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2023-08-31 21:53:03,106][26276] Avg episode reward: [(0, '-2131.371')]
[2023-08-31 21:53:04,619][26288] Updated weights for policy 0, policy_version 58152 (0.0002)
[2023-08-31 21:53:07,188][26288] Updated weights for policy 0, policy_version 58232 (0.0002)
[2023-08-31 21:53:08,106][26276] Fps is (10 sec: 15974.1, 60 sec: 16043.0, 300 sec: 15898.0). Total num frames: 29827072. Throughput: 0: 16049.3. Samples: 17901375. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2023-08-31 21:53:08,106][26276] Avg episode reward: [(0, '-2131.371')]
[2023-08-31 21:53:09,913][26288] Updated weights for policy 0, policy_version 58312 (0.0002)
[2023-08-31 21:53:12,403][26288] Updated weights for policy 0, policy_version 58392 (0.0002)
[2023-08-31 21:53:13,107][26276] Fps is (10 sec: 15972.9, 60 sec: 16042.7, 300 sec: 15912.0). Total num frames: 29904896. Throughput: 0: 15977.4. Samples: 17946797. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[2023-08-31 21:53:13,107][26276] Avg episode reward: [(0, '-2102.820')]
[2023-08-31 21:53:14,880][26288] Updated weights for policy 0, policy_version 58472 (0.0002)
[2023-08-31 21:53:17,355][26288] Updated weights for policy 0, policy_version 58552 (0.0002)
[2023-08-31 21:53:18,107][26276] Fps is (10 sec: 16382.1, 60 sec: 16042.3, 300 sec: 15925.9). Total num frames: 29990912. Throughput: 0: 16066.5. Samples: 18046155. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[2023-08-31 21:53:18,108][26276] Avg episode reward: [(0, '-2102.820')]
[2023-08-31 21:53:20,144][26288] Updated weights for policy 0, policy_version 58632 (0.0002)
[2023-08-31 21:53:22,769][26288] Updated weights for policy 0, policy_version 58712 (0.0002)
[2023-08-31 21:53:23,107][26276] Fps is (10 sec: 15974.7, 60 sec: 15974.2, 300 sec: 15911.8). Total num frames: 30064640. Throughput: 0: 15927.6. Samples: 18137730. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[2023-08-31 21:53:23,107][26276] Avg episode reward: [(0, '-2064.485')]
[2023-08-31 21:53:25,277][26288] Updated weights for policy 0, policy_version 58792 (0.0002)
[2023-08-31 21:53:27,820][26288] Updated weights for policy 0, policy_version 58872 (0.0002)
[2023-08-31 21:53:28,106][26276] Fps is (10 sec: 15567.3, 60 sec: 15974.4, 300 sec: 15925.8). Total num frames: 30146560. Throughput: 0: 15992.8. Samples: 18186394. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[2023-08-31 21:53:28,106][26276] Avg episode reward: [(0, '-2064.485')]
[2023-08-31 21:53:30,505][26288] Updated weights for policy 0, policy_version 58952 (0.0002)
[2023-08-31 21:53:33,068][26288] Updated weights for policy 0, policy_version 59032 (0.0002)
[2023-08-31 21:53:33,106][26276] Fps is (10 sec: 15975.6, 60 sec: 15974.5, 300 sec: 15925.8). Total num frames: 30224384. Throughput: 0: 15897.0. Samples: 18281192. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[2023-08-31 21:53:33,106][26276] Avg episode reward: [(0, '-2049.801')]
[2023-08-31 21:53:35,534][26288] Updated weights for policy 0, policy_version 59112 (0.0002)
[2023-08-31 21:53:38,106][26276] Fps is (10 sec: 15564.2, 60 sec: 15906.5, 300 sec: 15911.9). Total num frames: 30302208. Throughput: 0: 15960.1. Samples: 18378768. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[2023-08-31 21:53:38,107][26276] Avg episode reward: [(0, '-2049.801')]
[2023-08-31 21:53:38,108][26288] Updated weights for policy 0, policy_version 59192 (0.0002)
[2023-08-31 21:53:40,835][26288] Updated weights for policy 0, policy_version 59272 (0.0002)
[2023-08-31 21:53:43,109][26276] Fps is (10 sec: 15968.8, 60 sec: 15973.5, 300 sec: 15925.6). Total num frames: 30384128. Throughput: 0: 15884.0. Samples: 18423829. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[2023-08-31 21:53:43,110][26276] Avg episode reward: [(0, '-2045.342')]
[2023-08-31 21:53:43,313][26288] Updated weights for policy 0, policy_version 59352 (0.0002)
[2023-08-31 21:53:45,818][26288] Updated weights for policy 0, policy_version 59432 (0.0002)
[2023-08-31 21:53:48,106][26276] Fps is (10 sec: 16384.2, 60 sec: 15975.4, 300 sec: 15925.8). Total num frames: 30466048. Throughput: 0: 16025.1. Samples: 18522364. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[2023-08-31 21:53:48,106][26276] Avg episode reward: [(0, '-2045.342')]
[2023-08-31 21:53:48,292][26288] Updated weights for policy 0, policy_version 59512 (0.0002)
[2023-08-31 21:53:51,085][26288] Updated weights for policy 0, policy_version 59592 (0.0002)
[2023-08-31 21:53:53,106][26276] Fps is (10 sec: 15979.8, 60 sec: 15974.7, 300 sec: 15939.9). Total num frames: 30543872. Throughput: 0: 15888.2. Samples: 18616340. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:53:53,106][26276] Avg episode reward: [(0, '-2056.958')]
[2023-08-31 21:53:53,548][26288] Updated weights for policy 0, policy_version 59672 (0.0002)
[2023-08-31 21:53:56,011][26288] Updated weights for policy 0, policy_version 59752 (0.0002)
[2023-08-31 21:53:58,108][26276] Fps is (10 sec: 15971.9, 60 sec: 15974.0, 300 sec: 15939.8). Total num frames: 30625792. Throughput: 0: 15993.9. Samples: 18666537. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:53:58,108][26276] Avg episode reward: [(0, '-2056.958')]
[2023-08-31 21:53:58,470][26288] Updated weights for policy 0, policy_version 59832 (0.0002)
[2023-08-31 21:54:01,239][26288] Updated weights for policy 0, policy_version 59912 (0.0002)
[2023-08-31 21:54:03,107][26276] Fps is (10 sec: 15973.5, 60 sec: 15974.2, 300 sec: 15939.6). Total num frames: 30703616. Throughput: 0: 15873.1. Samples: 18760430. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:54:03,107][26276] Avg episode reward: [(0, '-2059.614')]
[2023-08-31 21:54:03,109][26287] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000059968_30703616.pth...
[2023-08-31 21:54:03,111][26287] Removing /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000053728_27508736.pth
[2023-08-31 21:54:03,730][26288] Updated weights for policy 0, policy_version 59992 (0.0002)
[2023-08-31 21:54:06,199][26288] Updated weights for policy 0, policy_version 60072 (0.0002)
[2023-08-31 21:54:08,108][26276] Fps is (10 sec: 15973.9, 60 sec: 15973.9, 300 sec: 15939.7). Total num frames: 30785536. Throughput: 0: 16048.2. Samples: 18859921. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:54:08,108][26276] Avg episode reward: [(0, '-2059.614')]
[2023-08-31 21:54:08,926][26288] Updated weights for policy 0, policy_version 60152 (0.0002)
[2023-08-31 21:54:11,636][26288] Updated weights for policy 0, policy_version 60232 (0.0002)
[2023-08-31 21:54:13,106][26276] Fps is (10 sec: 15565.4, 60 sec: 15906.3, 300 sec: 15953.8). Total num frames: 30859264. Throughput: 0: 15925.7. Samples: 18903056. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:54:13,106][26276] Avg episode reward: [(0, '-2075.522')]
[2023-08-31 21:54:14,178][26288] Updated weights for policy 0, policy_version 60312 (0.0002)
[2023-08-31 21:54:16,705][26288] Updated weights for policy 0, policy_version 60392 (0.0002)
[2023-08-31 21:54:18,107][26276] Fps is (10 sec: 15565.8, 60 sec: 15837.9, 300 sec: 15953.7). Total num frames: 30941184. Throughput: 0: 15942.2. Samples: 18998616. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:54:18,108][26276] Avg episode reward: [(0, '-2075.522')]
[2023-08-31 21:54:19,467][26288] Updated weights for policy 0, policy_version 60472 (0.0002)
[2023-08-31 21:54:22,055][26288] Updated weights for policy 0, policy_version 60552 (0.0002)
[2023-08-31 21:54:23,106][26276] Fps is (10 sec: 15975.0, 60 sec: 15906.4, 300 sec: 15953.7). Total num frames: 31019008. Throughput: 0: 15838.0. Samples: 19091472. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:54:23,106][26276] Avg episode reward: [(0, '-2090.742')]
[2023-08-31 21:54:24,518][26288] Updated weights for policy 0, policy_version 60632 (0.0002)
[2023-08-31 21:54:26,964][26288] Updated weights for policy 0, policy_version 60712 (0.0002)
[2023-08-31 21:54:28,109][26276] Fps is (10 sec: 15971.0, 60 sec: 15905.2, 300 sec: 15967.2). Total num frames: 31100928. Throughput: 0: 15934.5. Samples: 19140884. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:54:28,110][26276] Avg episode reward: [(0, '-2090.742')]
[2023-08-31 21:54:29,731][26288] Updated weights for policy 0, policy_version 60792 (0.0002)
[2023-08-31 21:54:32,392][26288] Updated weights for policy 0, policy_version 60872 (0.0002)
[2023-08-31 21:54:33,109][26276] Fps is (10 sec: 15559.9, 60 sec: 15837.1, 300 sec: 15939.5). Total num frames: 31174656. Throughput: 0: 15831.3. Samples: 19234816. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:54:33,109][26276] Avg episode reward: [(0, '-2091.984')]
[2023-08-31 21:54:34,962][26288] Updated weights for policy 0, policy_version 60952 (0.0002)
[2023-08-31 21:54:37,452][26288] Updated weights for policy 0, policy_version 61032 (0.0002)
[2023-08-31 21:54:38,107][26276] Fps is (10 sec: 15568.6, 60 sec: 15905.9, 300 sec: 15953.7). Total num frames: 31256576. Throughput: 0: 15867.9. Samples: 19330410. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:54:38,108][26276] Avg episode reward: [(0, '-2091.984')]
[2023-08-31 21:54:40,217][26288] Updated weights for policy 0, policy_version 61112 (0.0002)
[2023-08-31 21:54:42,739][26288] Updated weights for policy 0, policy_version 61192 (0.0002)
[2023-08-31 21:54:43,107][26276] Fps is (10 sec: 15977.2, 60 sec: 15838.5, 300 sec: 15953.6). Total num frames: 31334400. Throughput: 0: 15753.4. Samples: 19375434. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:54:43,108][26276] Avg episode reward: [(0, '-2093.260')]
[2023-08-31 21:54:45,268][26288] Updated weights for policy 0, policy_version 61272 (0.0002)
[2023-08-31 21:54:47,910][26288] Updated weights for policy 0, policy_version 61352 (0.0002)
[2023-08-31 21:54:48,106][26276] Fps is (10 sec: 15566.3, 60 sec: 15769.6, 300 sec: 15953.7). Total num frames: 31412224. Throughput: 0: 15821.9. Samples: 19472405. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:54:48,106][26276] Avg episode reward: [(0, '-2093.260')]
[2023-08-31 21:54:50,678][26288] Updated weights for policy 0, policy_version 61432 (0.0002)
[2023-08-31 21:54:53,105][26276] Fps is (10 sec: 15567.8, 60 sec: 15769.8, 300 sec: 15939.7). Total num frames: 31490048. Throughput: 0: 15659.1. Samples: 19564538. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:54:53,105][26276] Avg episode reward: [(0, '-2080.928')]
[2023-08-31 21:54:53,189][26288] Updated weights for policy 0, policy_version 61512 (0.0002)
[2023-08-31 21:54:55,760][26288] Updated weights for policy 0, policy_version 61592 (0.0002)
[2023-08-31 21:54:58,110][26276] Fps is (10 sec: 15967.8, 60 sec: 15768.9, 300 sec: 15953.4). Total num frames: 31571968. Throughput: 0: 15765.4. Samples: 19612561. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:54:58,110][26276] Avg episode reward: [(0, '-2080.928')]
[2023-08-31 21:54:58,263][26288] Updated weights for policy 0, policy_version 61672 (0.0002)
[2023-08-31 21:55:01,064][26288] Updated weights for policy 0, policy_version 61752 (0.0002)
[2023-08-31 21:55:03,106][26276] Fps is (10 sec: 15973.7, 60 sec: 15769.8, 300 sec: 15939.8). Total num frames: 31649792. Throughput: 0: 15717.4. Samples: 19705872. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:55:03,106][26276] Avg episode reward: [(0, '-2036.927')]
[2023-08-31 21:55:03,631][26288] Updated weights for policy 0, policy_version 61832 (0.0002)
[2023-08-31 21:55:06,264][26288] Updated weights for policy 0, policy_version 61912 (0.0002)
[2023-08-31 21:55:08,109][26276] Fps is (10 sec: 15566.3, 60 sec: 15701.0, 300 sec: 15939.6). Total num frames: 31727616. Throughput: 0: 15752.3. Samples: 19800378. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:55:08,109][26276] Avg episode reward: [(0, '-2036.927')]
[2023-08-31 21:55:08,753][26288] Updated weights for policy 0, policy_version 61992 (0.0002)
[2023-08-31 21:55:11,703][26288] Updated weights for policy 0, policy_version 62072 (0.0002)
[2023-08-31 21:55:13,107][26276] Fps is (10 sec: 15153.3, 60 sec: 15701.1, 300 sec: 15911.8). Total num frames: 31801344. Throughput: 0: 15643.9. Samples: 19844822. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:55:13,107][26276] Avg episode reward: [(0, '-1993.731')]
[2023-08-31 21:55:14,142][26288] Updated weights for policy 0, policy_version 62152 (0.0002)
[2023-08-31 21:55:16,652][26288] Updated weights for policy 0, policy_version 62232 (0.0002)
[2023-08-31 21:55:18,110][26276] Fps is (10 sec: 15973.5, 60 sec: 15769.0, 300 sec: 15925.6). Total num frames: 31887360. Throughput: 0: 15720.3. Samples: 19942242. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:55:18,110][26276] Avg episode reward: [(0, '-1993.731')]
[2023-08-31 21:55:19,592][26288] Updated weights for policy 0, policy_version 62312 (0.0002)
[2023-08-31 21:55:22,755][26288] Updated weights for policy 0, policy_version 62392 (0.0002)
[2023-08-31 21:55:23,110][26276] Fps is (10 sec: 14740.9, 60 sec: 15495.4, 300 sec: 15856.4). Total num frames: 31948800. Throughput: 0: 15371.0. Samples: 20022153. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:55:23,110][26276] Avg episode reward: [(0, '-1966.163')]
[2023-08-31 21:55:25,635][26288] Updated weights for policy 0, policy_version 62472 (0.0002)
[2023-08-31 21:55:28,106][26276] Fps is (10 sec: 13112.2, 60 sec: 15292.6, 300 sec: 15828.6). Total num frames: 32018432. Throughput: 0: 15353.5. Samples: 20066325. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:55:28,106][26276] Avg episode reward: [(0, '-1966.163')]
[2023-08-31 21:55:28,491][26288] Updated weights for policy 0, policy_version 62552 (0.0003)
[2023-08-31 21:55:31,167][26288] Updated weights for policy 0, policy_version 62632 (0.0002)
[2023-08-31 21:55:33,109][26276] Fps is (10 sec: 14337.1, 60 sec: 15291.6, 300 sec: 15800.8). Total num frames: 32092160. Throughput: 0: 15159.6. Samples: 20154638. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:55:33,111][26276] Avg episode reward: [(0, '-1894.957')]
[2023-08-31 21:55:34,161][26288] Updated weights for policy 0, policy_version 62712 (0.0002)
[2023-08-31 21:55:37,201][26288] Updated weights for policy 0, policy_version 62792 (0.0003)
[2023-08-31 21:55:38,106][26276] Fps is (10 sec: 13926.7, 60 sec: 15019.0, 300 sec: 15759.2). Total num frames: 32157696. Throughput: 0: 14906.7. Samples: 20235346. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:55:38,108][26276] Avg episode reward: [(0, '-1894.957')]
[2023-08-31 21:55:40,033][26288] Updated weights for policy 0, policy_version 62872 (0.0003)
[2023-08-31 21:55:42,788][26288] Updated weights for policy 0, policy_version 62952 (0.0002)
[2023-08-31 21:55:43,111][26276] Fps is (10 sec: 14333.2, 60 sec: 15017.6, 300 sec: 15745.0). Total num frames: 32235520. Throughput: 0: 14816.4. Samples: 20279317. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:55:43,112][26276] Avg episode reward: [(0, '-1894.957')]
[2023-08-31 21:55:43,119][26287] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000062960_32235520.pth...
[2023-08-31 21:55:43,121][26287] Removing /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000056848_29106176.pth
[2023-08-31 21:55:45,674][26288] Updated weights for policy 0, policy_version 63032 (0.0002)
[2023-08-31 21:55:48,110][26276] Fps is (10 sec: 15149.2, 60 sec: 14949.5, 300 sec: 15745.1). Total num frames: 32309248. Throughput: 0: 14713.5. Samples: 20368040. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:55:48,110][26276] Avg episode reward: [(0, '-1838.451')]
[2023-08-31 21:55:48,196][26288] Updated weights for policy 0, policy_version 63112 (0.0002)
[2023-08-31 21:55:50,813][26288] Updated weights for policy 0, policy_version 63192 (0.0002)
[2023-08-31 21:55:53,105][26276] Fps is (10 sec: 15574.4, 60 sec: 15018.7, 300 sec: 15745.6). Total num frames: 32391168. Throughput: 0: 14740.4. Samples: 20463637. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:55:53,106][26276] Avg episode reward: [(0, '-1838.451')]
[2023-08-31 21:55:53,379][26288] Updated weights for policy 0, policy_version 63272 (0.0002)
[2023-08-31 21:55:56,196][26288] Updated weights for policy 0, policy_version 63352 (0.0002)
[2023-08-31 21:55:58,105][26276] Fps is (10 sec: 15572.0, 60 sec: 14883.4, 300 sec: 15731.6). Total num frames: 32464896. Throughput: 0: 14724.5. Samples: 20507396. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:55:58,105][26276] Avg episode reward: [(0, '-1756.035')]
[2023-08-31 21:55:58,620][26288] Updated weights for policy 0, policy_version 63432 (0.0002)
[2023-08-31 21:56:01,566][26288] Updated weights for policy 0, policy_version 63512 (0.0002)
[2023-08-31 21:56:03,107][26276] Fps is (10 sec: 14742.6, 60 sec: 14813.5, 300 sec: 15703.8). Total num frames: 32538624. Throughput: 0: 14590.3. Samples: 20598769. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:56:03,107][26276] Avg episode reward: [(0, '-1756.035')]
[2023-08-31 21:56:04,565][26288] Updated weights for policy 0, policy_version 63592 (0.0002)
[2023-08-31 21:56:07,391][26288] Updated weights for policy 0, policy_version 63672 (0.0003)
[2023-08-31 21:56:08,108][26276] Fps is (10 sec: 14331.7, 60 sec: 14677.6, 300 sec: 15675.8). Total num frames: 32608256. Throughput: 0: 14694.7. Samples: 20683387. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:56:08,108][26276] Avg episode reward: [(0, '-1717.021')]
[2023-08-31 21:56:08,109][26287] Saving new best policy, reward=-1717.021!
[2023-08-31 21:56:10,164][26288] Updated weights for policy 0, policy_version 63752 (0.0002)
[2023-08-31 21:56:12,793][26288] Updated weights for policy 0, policy_version 63832 (0.0002)
[2023-08-31 21:56:13,110][26276] Fps is (10 sec: 14741.3, 60 sec: 14744.8, 300 sec: 15648.1). Total num frames: 32686080. Throughput: 0: 14696.4. Samples: 20727723. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:56:13,110][26276] Avg episode reward: [(0, '-1717.021')]
[2023-08-31 21:56:15,614][26288] Updated weights for policy 0, policy_version 63912 (0.0002)
[2023-08-31 21:56:18,107][26276] Fps is (10 sec: 15156.7, 60 sec: 14541.4, 300 sec: 15648.2). Total num frames: 32759808. Throughput: 0: 14755.6. Samples: 20818606. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:56:18,108][26276] Avg episode reward: [(0, '-1657.182')]
[2023-08-31 21:56:18,108][26287] Saving new best policy, reward=-1657.182!
[2023-08-31 21:56:18,179][26288] Updated weights for policy 0, policy_version 63992 (0.0002)
[2023-08-31 21:56:20,691][26288] Updated weights for policy 0, policy_version 64072 (0.0002)
[2023-08-31 21:56:23,108][26276] Fps is (10 sec: 15568.7, 60 sec: 14882.8, 300 sec: 15648.2). Total num frames: 32841728. Throughput: 0: 15105.6. Samples: 20915124. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:56:23,108][26276] Avg episode reward: [(0, '-1657.182')]
[2023-08-31 21:56:23,277][26288] Updated weights for policy 0, policy_version 64152 (0.0002)
[2023-08-31 21:56:26,005][26288] Updated weights for policy 0, policy_version 64232 (0.0002)
[2023-08-31 21:56:28,106][26276] Fps is (10 sec: 15976.9, 60 sec: 15018.8, 300 sec: 15634.2). Total num frames: 32919552. Throughput: 0: 15174.1. Samples: 20962067. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:56:28,106][26276] Avg episode reward: [(0, '-1592.499')]
[2023-08-31 21:56:28,106][26287] Saving new best policy, reward=-1592.499!
[2023-08-31 21:56:28,612][26288] Updated weights for policy 0, policy_version 64312 (0.0002)
[2023-08-31 21:56:31,093][26288] Updated weights for policy 0, policy_version 64392 (0.0002)
[2023-08-31 21:56:33,110][26276] Fps is (10 sec: 15560.7, 60 sec: 15086.7, 300 sec: 15634.2). Total num frames: 32997376. Throughput: 0: 15317.4. Samples: 21057330. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:56:33,110][26276] Avg episode reward: [(0, '-1592.499')]
[2023-08-31 21:56:33,691][26288] Updated weights for policy 0, policy_version 64472 (0.0002)
[2023-08-31 21:56:36,454][26288] Updated weights for policy 0, policy_version 64552 (0.0002)
[2023-08-31 21:56:38,108][26276] Fps is (10 sec: 15560.7, 60 sec: 15291.1, 300 sec: 15634.2). Total num frames: 33075200. Throughput: 0: 15216.7. Samples: 21148437. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:56:38,108][26276] Avg episode reward: [(0, '-1561.753')]
[2023-08-31 21:56:38,109][26287] Saving new best policy, reward=-1561.753!
[2023-08-31 21:56:39,078][26288] Updated weights for policy 0, policy_version 64632 (0.0002)
[2023-08-31 21:56:41,640][26288] Updated weights for policy 0, policy_version 64712 (0.0002)
[2023-08-31 21:56:43,107][26276] Fps is (10 sec: 15569.6, 60 sec: 15292.8, 300 sec: 15620.3). Total num frames: 33153024. Throughput: 0: 15311.0. Samples: 21196422. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:56:43,108][26276] Avg episode reward: [(0, '-1561.753')]
[2023-08-31 21:56:44,199][26288] Updated weights for policy 0, policy_version 64792 (0.0002)
[2023-08-31 21:56:46,938][26288] Updated weights for policy 0, policy_version 64872 (0.0002)
[2023-08-31 21:56:48,110][26276] Fps is (10 sec: 15562.0, 60 sec: 15359.9, 300 sec: 15620.2). Total num frames: 33230848. Throughput: 0: 15318.3. Samples: 21288135. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:56:48,110][26276] Avg episode reward: [(0, '-1514.846')]
[2023-08-31 21:56:48,111][26287] Saving new best policy, reward=-1514.846!
[2023-08-31 21:56:49,537][26288] Updated weights for policy 0, policy_version 64952 (0.0002)
[2023-08-31 21:56:51,977][26288] Updated weights for policy 0, policy_version 65032 (0.0002)
[2023-08-31 21:56:53,109][26276] Fps is (10 sec: 15970.7, 60 sec: 15358.9, 300 sec: 15620.2). Total num frames: 33312768. Throughput: 0: 15609.5. Samples: 21385835. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:56:53,110][26276] Avg episode reward: [(0, '-1514.846')]
[2023-08-31 21:56:54,429][26288] Updated weights for policy 0, policy_version 65112 (0.0002)
[2023-08-31 21:56:57,216][26288] Updated weights for policy 0, policy_version 65192 (0.0002)
[2023-08-31 21:56:58,110][26276] Fps is (10 sec: 15975.1, 60 sec: 15427.1, 300 sec: 15606.3). Total num frames: 33390592. Throughput: 0: 15738.7. Samples: 21435957. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:56:58,110][26276] Avg episode reward: [(0, '-1487.248')]
[2023-08-31 21:56:58,110][26287] Saving new best policy, reward=-1487.248!
[2023-08-31 21:56:59,797][26288] Updated weights for policy 0, policy_version 65272 (0.0002)
[2023-08-31 21:57:02,271][26288] Updated weights for policy 0, policy_version 65352 (0.0002)
[2023-08-31 21:57:03,105][26276] Fps is (10 sec: 15981.1, 60 sec: 15565.3, 300 sec: 15620.5). Total num frames: 33472512. Throughput: 0: 15791.3. Samples: 21529185. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2023-08-31 21:57:03,105][26276] Avg episode reward: [(0, '-1487.248')]
[2023-08-31 21:57:04,868][26288] Updated weights for policy 0, policy_version 65432 (0.0002)
[2023-08-31 21:57:07,619][26288] Updated weights for policy 0, policy_version 65512 (0.0002)
[2023-08-31 21:57:08,108][26276] Fps is (10 sec: 15566.9, 60 sec: 15633.0, 300 sec: 15606.4). Total num frames: 33546240. Throughput: 0: 15706.9. Samples: 21621947. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2023-08-31 21:57:08,108][26276] Avg episode reward: [(0, '-1450.822')]
[2023-08-31 21:57:08,129][26287] Saving new best policy, reward=-1450.822!
[2023-08-31 21:57:10,127][26288] Updated weights for policy 0, policy_version 65592 (0.0002)
[2023-08-31 21:57:12,827][26288] Updated weights for policy 0, policy_version 65672 (0.0002)
[2023-08-31 21:57:13,106][26276] Fps is (10 sec: 15154.0, 60 sec: 15634.1, 300 sec: 15578.7). Total num frames: 33624064. Throughput: 0: 15742.2. Samples: 21670474. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2023-08-31 21:57:13,106][26276] Avg episode reward: [(0, '-1450.822')]
[2023-08-31 21:57:15,385][26288] Updated weights for policy 0, policy_version 65752 (0.0002)
[2023-08-31 21:57:18,105][26276] Fps is (10 sec: 15569.5, 60 sec: 15701.9, 300 sec: 15578.7). Total num frames: 33701888. Throughput: 0: 15661.9. Samples: 21762038. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2023-08-31 21:57:18,107][26276] Avg episode reward: [(0, '-1420.976')]
[2023-08-31 21:57:18,108][26287] Saving new best policy, reward=-1420.976!
[2023-08-31 21:57:18,138][26288] Updated weights for policy 0, policy_version 65832 (0.0002)
[2023-08-31 21:57:20,715][26288] Updated weights for policy 0, policy_version 65912 (0.0002)
[2023-08-31 21:57:23,106][26276] Fps is (10 sec: 15974.4, 60 sec: 15701.7, 300 sec: 15578.7). Total num frames: 33783808. Throughput: 0: 15730.4. Samples: 21856272. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2023-08-31 21:57:23,106][26276] Avg episode reward: [(0, '-1420.976')]
[2023-08-31 21:57:23,109][26287] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000065984_33783808.pth...
[2023-08-31 21:57:23,111][26287] Removing /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000059968_30703616.pth
[2023-08-31 21:57:23,331][26288] Updated weights for policy 0, policy_version 65992 (0.0002)
[2023-08-31 21:57:25,769][26288] Updated weights for policy 0, policy_version 66072 (0.0002)
[2023-08-31 21:57:28,107][26276] Fps is (10 sec: 15971.1, 60 sec: 15700.9, 300 sec: 15578.6). Total num frames: 33861632. Throughput: 0: 15772.6. Samples: 21906192. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2023-08-31 21:57:28,108][26276] Avg episode reward: [(0, '-1427.952')]
[2023-08-31 21:57:28,575][26288] Updated weights for policy 0, policy_version 66152 (0.0002)
[2023-08-31 21:57:31,040][26288] Updated weights for policy 0, policy_version 66232 (0.0002)
[2023-08-31 21:57:33,107][26276] Fps is (10 sec: 15563.2, 60 sec: 15702.1, 300 sec: 15564.8). Total num frames: 33939456. Throughput: 0: 15812.1. Samples: 21999634. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2023-08-31 21:57:33,109][26276] Avg episode reward: [(0, '-1427.952')]
[2023-08-31 21:57:33,759][26288] Updated weights for policy 0, policy_version 66312 (0.0002)
[2023-08-31 21:57:36,258][26288] Updated weights for policy 0, policy_version 66392 (0.0002)
[2023-08-31 21:57:38,109][26276] Fps is (10 sec: 15153.0, 60 sec: 15632.9, 300 sec: 15550.8). Total num frames: 34013184. Throughput: 0: 15642.7. Samples: 22089744. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2023-08-31 21:57:38,110][26276] Avg episode reward: [(0, '-1456.468')]
[2023-08-31 21:57:39,136][26288] Updated weights for policy 0, policy_version 66472 (0.0002)
[2023-08-31 21:57:41,753][26288] Updated weights for policy 0, policy_version 66552 (0.0002)
[2023-08-31 21:57:43,107][26276] Fps is (10 sec: 15564.6, 60 sec: 15701.3, 300 sec: 15551.1). Total num frames: 34095104. Throughput: 0: 15580.4. Samples: 22137039. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2023-08-31 21:57:43,107][26276] Avg episode reward: [(0, '-1456.468')]
[2023-08-31 21:57:44,401][26288] Updated weights for policy 0, policy_version 66632 (0.0002)
[2023-08-31 21:57:46,957][26288] Updated weights for policy 0, policy_version 66712 (0.0002)
[2023-08-31 21:57:48,109][26276] Fps is (10 sec: 15563.9, 60 sec: 15633.2, 300 sec: 15536.9). Total num frames: 34168832. Throughput: 0: 15623.3. Samples: 22232297. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[2023-08-31 21:57:48,111][26276] Avg episode reward: [(0, '-1477.120')]
[2023-08-31 21:57:49,700][26288] Updated weights for policy 0, policy_version 66792 (0.0002)
[2023-08-31 21:57:52,300][26288] Updated weights for policy 0, policy_version 66872 (0.0002)
[2023-08-31 21:57:53,110][26276] Fps is (10 sec: 15560.2, 60 sec: 15632.9, 300 sec: 15536.8). Total num frames: 34250752. Throughput: 0: 15583.1. Samples: 22323219. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[2023-08-31 21:57:53,110][26276] Avg episode reward: [(0, '-1477.120')]
[2023-08-31 21:57:54,835][26288] Updated weights for policy 0, policy_version 66952 (0.0002)
[2023-08-31 21:57:57,548][26288] Updated weights for policy 0, policy_version 67032 (0.0002)
[2023-08-31 21:57:58,108][26276] Fps is (10 sec: 15976.8, 60 sec: 15633.5, 300 sec: 15536.9). Total num frames: 34328576. Throughput: 0: 15597.1. Samples: 22372372. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[2023-08-31 21:57:58,108][26276] Avg episode reward: [(0, '-1477.698')]
[2023-08-31 21:58:00,196][26288] Updated weights for policy 0, policy_version 67112 (0.0002)
[2023-08-31 21:58:02,748][26288] Updated weights for policy 0, policy_version 67192 (0.0002)
[2023-08-31 21:58:03,106][26276] Fps is (10 sec: 15571.8, 60 sec: 15564.7, 300 sec: 15523.2). Total num frames: 34406400. Throughput: 0: 15587.1. Samples: 22463469. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[2023-08-31 21:58:03,106][26276] Avg episode reward: [(0, '-1477.698')]
[2023-08-31 21:58:05,278][26288] Updated weights for policy 0, policy_version 67272 (0.0002)
[2023-08-31 21:58:08,027][26288] Updated weights for policy 0, policy_version 67352 (0.0002)
[2023-08-31 21:58:08,107][26276] Fps is (10 sec: 15566.2, 60 sec: 15633.4, 300 sec: 15523.1). Total num frames: 34484224. Throughput: 0: 15665.7. Samples: 22561242. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[2023-08-31 21:58:08,107][26276] Avg episode reward: [(0, '-1505.912')]
[2023-08-31 21:58:10,588][26288] Updated weights for policy 0, policy_version 67432 (0.0002)
[2023-08-31 21:58:13,109][26276] Fps is (10 sec: 15559.6, 60 sec: 15632.3, 300 sec: 15495.3). Total num frames: 34562048. Throughput: 0: 15547.2. Samples: 22605844. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[2023-08-31 21:58:13,109][26276] Avg episode reward: [(0, '-1505.912')]
[2023-08-31 21:58:13,190][26288] Updated weights for policy 0, policy_version 67512 (0.0002)
[2023-08-31 21:58:15,797][26288] Updated weights for policy 0, policy_version 67592 (0.0003)
[2023-08-31 21:58:18,110][26276] Fps is (10 sec: 15560.0, 60 sec: 15631.8, 300 sec: 15509.1). Total num frames: 34639872. Throughput: 0: 15563.8. Samples: 22700050. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[2023-08-31 21:58:18,110][26276] Avg episode reward: [(0, '-1555.127')]
[2023-08-31 21:58:18,576][26288] Updated weights for policy 0, policy_version 67672 (0.0002)
[2023-08-31 21:58:21,085][26288] Updated weights for policy 0, policy_version 67752 (0.0002)
[2023-08-31 21:58:23,107][26276] Fps is (10 sec: 15568.7, 60 sec: 15564.7, 300 sec: 15495.3). Total num frames: 34717696. Throughput: 0: 15609.2. Samples: 22792127. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[2023-08-31 21:58:23,108][26276] Avg episode reward: [(0, '-1555.127')]
[2023-08-31 21:58:23,688][26288] Updated weights for policy 0, policy_version 67832 (0.0002)
[2023-08-31 21:58:26,207][26288] Updated weights for policy 0, policy_version 67912 (0.0002)
[2023-08-31 21:58:28,108][26276] Fps is (10 sec: 15567.6, 60 sec: 15564.5, 300 sec: 15495.3). Total num frames: 34795520. Throughput: 0: 15631.9. Samples: 22840489. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:58:28,108][26276] Avg episode reward: [(0, '-1574.846')]
[2023-08-31 21:58:29,020][26288] Updated weights for policy 0, policy_version 67992 (0.0002)
[2023-08-31 21:58:31,656][26288] Updated weights for policy 0, policy_version 68072 (0.0002)
[2023-08-31 21:58:33,110][26276] Fps is (10 sec: 15559.1, 60 sec: 15564.0, 300 sec: 15495.2). Total num frames: 34873344. Throughput: 0: 15548.3. Samples: 22931987. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:58:33,111][26276] Avg episode reward: [(0, '-1574.846')]
[2023-08-31 21:58:34,208][26288] Updated weights for policy 0, policy_version 68152 (0.0002)
[2023-08-31 21:58:36,672][26288] Updated weights for policy 0, policy_version 68232 (0.0002)
[2023-08-31 21:58:38,107][26276] Fps is (10 sec: 15976.3, 60 sec: 15701.8, 300 sec: 15495.5). Total num frames: 34955264. Throughput: 0: 15712.1. Samples: 23030211. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:58:38,107][26276] Avg episode reward: [(0, '-1577.224')]
[2023-08-31 21:58:39,419][26288] Updated weights for policy 0, policy_version 68312 (0.0002)
[2023-08-31 21:58:41,870][26288] Updated weights for policy 0, policy_version 68392 (0.0002)
[2023-08-31 21:58:43,105][26276] Fps is (10 sec: 15982.2, 60 sec: 15633.6, 300 sec: 15481.5). Total num frames: 35033088. Throughput: 0: 15612.7. Samples: 23074905. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:58:43,106][26276] Avg episode reward: [(0, '-1574.004')]
[2023-08-31 21:58:44,437][26288] Updated weights for policy 0, policy_version 68472 (0.0002)
[2023-08-31 21:58:46,920][26288] Updated weights for policy 0, policy_version 68552 (0.0002)
[2023-08-31 21:58:48,116][26276] Fps is (10 sec: 15959.6, 60 sec: 15767.8, 300 sec: 15494.8). Total num frames: 35115008. Throughput: 0: 15772.4. Samples: 23173392. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:58:48,117][26276] Avg episode reward: [(0, '-1574.004')]
[2023-08-31 21:58:49,757][26288] Updated weights for policy 0, policy_version 68632 (0.0002)
[2023-08-31 21:58:52,537][26288] Updated weights for policy 0, policy_version 68712 (0.0002)
[2023-08-31 21:58:53,106][26276] Fps is (10 sec: 15154.8, 60 sec: 15566.0, 300 sec: 15453.8). Total num frames: 35184640. Throughput: 0: 15573.2. Samples: 23262017. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:58:53,106][26276] Avg episode reward: [(0, '-1575.853')]
[2023-08-31 21:58:55,394][26288] Updated weights for policy 0, policy_version 68792 (0.0002)
[2023-08-31 21:58:58,049][26288] Updated weights for policy 0, policy_version 68872 (0.0002)
[2023-08-31 21:58:58,108][26276] Fps is (10 sec: 14758.4, 60 sec: 15564.9, 300 sec: 15453.7). Total num frames: 35262464. Throughput: 0: 15540.0. Samples: 23305120. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:58:58,108][26276] Avg episode reward: [(0, '-1575.853')]
[2023-08-31 21:59:00,939][26288] Updated weights for policy 0, policy_version 68952 (0.0002)
[2023-08-31 21:59:03,107][26276] Fps is (10 sec: 15153.2, 60 sec: 15496.2, 300 sec: 15426.0). Total num frames: 35336192. Throughput: 0: 15416.8. Samples: 23393758. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:59:03,107][26276] Avg episode reward: [(0, '-1627.942')]
[2023-08-31 21:59:03,110][26287] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000069016_35336192.pth...
[2023-08-31 21:59:03,112][26287] Removing /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000062960_32235520.pth
[2023-08-31 21:59:03,558][26288] Updated weights for policy 0, policy_version 69032 (0.0002)
[2023-08-31 21:59:06,368][26288] Updated weights for policy 0, policy_version 69112 (0.0003)
[2023-08-31 21:59:08,105][26276] Fps is (10 sec: 15159.1, 60 sec: 15497.0, 300 sec: 15439.9). Total num frames: 35414016. Throughput: 0: 15404.7. Samples: 23485315. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:59:08,105][26276] Avg episode reward: [(0, '-1627.942')]
[2023-08-31 21:59:08,918][26288] Updated weights for policy 0, policy_version 69192 (0.0002)
[2023-08-31 21:59:11,626][26288] Updated weights for policy 0, policy_version 69272 (0.0002)
[2023-08-31 21:59:13,107][26276] Fps is (10 sec: 15565.2, 60 sec: 15497.1, 300 sec: 15426.0). Total num frames: 35491840. Throughput: 0: 15357.0. Samples: 23531531. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:59:13,107][26276] Avg episode reward: [(0, '-1634.864')]
[2023-08-31 21:59:14,127][26288] Updated weights for policy 0, policy_version 69352 (0.0002)
[2023-08-31 21:59:16,598][26288] Updated weights for policy 0, policy_version 69432 (0.0002)
[2023-08-31 21:59:18,107][26276] Fps is (10 sec: 15971.5, 60 sec: 15565.6, 300 sec: 15439.8). Total num frames: 35573760. Throughput: 0: 15495.2. Samples: 23629217. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:59:18,107][26276] Avg episode reward: [(0, '-1634.864')]
[2023-08-31 21:59:18,985][26288] Updated weights for policy 0, policy_version 69512 (0.0002)
[2023-08-31 21:59:21,778][26288] Updated weights for policy 0, policy_version 69592 (0.0002)
[2023-08-31 21:59:23,110][26276] Fps is (10 sec: 15969.1, 60 sec: 15563.9, 300 sec: 15425.9). Total num frames: 35651584. Throughput: 0: 15419.3. Samples: 23724129. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:59:23,110][26276] Avg episode reward: [(0, '-1638.474')]
[2023-08-31 21:59:24,271][26288] Updated weights for policy 0, policy_version 69672 (0.0002)
[2023-08-31 21:59:26,820][26288] Updated weights for policy 0, policy_version 69752 (0.0002)
[2023-08-31 21:59:28,106][26276] Fps is (10 sec: 15566.2, 60 sec: 15565.4, 300 sec: 15440.0). Total num frames: 35729408. Throughput: 0: 15517.5. Samples: 23773200. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:59:28,107][26276] Avg episode reward: [(0, '-1638.474')]
[2023-08-31 21:59:29,335][26288] Updated weights for policy 0, policy_version 69832 (0.0002)
[2023-08-31 21:59:32,154][26288] Updated weights for policy 0, policy_version 69912 (0.0002)
[2023-08-31 21:59:33,110][26276] Fps is (10 sec: 15564.5, 60 sec: 15564.8, 300 sec: 15425.8). Total num frames: 35807232. Throughput: 0: 15411.3. Samples: 23866806. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:59:33,110][26276] Avg episode reward: [(0, '-1651.346')]
[2023-08-31 21:59:34,681][26288] Updated weights for policy 0, policy_version 69992 (0.0002)
[2023-08-31 21:59:37,186][26288] Updated weights for policy 0, policy_version 70072 (0.0002)
[2023-08-31 21:59:38,108][26276] Fps is (10 sec: 15971.1, 60 sec: 15564.5, 300 sec: 15439.8). Total num frames: 35889152. Throughput: 0: 15587.9. Samples: 23963508. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:59:38,109][26276] Avg episode reward: [(0, '-1651.346')]
[2023-08-31 21:59:39,989][26288] Updated weights for policy 0, policy_version 70152 (0.0002)
[2023-08-31 21:59:42,499][26288] Updated weights for policy 0, policy_version 70232 (0.0002)
[2023-08-31 21:59:43,110][26276] Fps is (10 sec: 15974.8, 60 sec: 15563.6, 300 sec: 15439.6). Total num frames: 35966976. Throughput: 0: 15616.8. Samples: 24007913. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:59:43,110][26276] Avg episode reward: [(0, '-1699.134')]
[2023-08-31 21:59:45,074][26288] Updated weights for policy 0, policy_version 70312 (0.0002)
[2023-08-31 21:59:47,608][26288] Updated weights for policy 0, policy_version 70392 (0.0002)
[2023-08-31 21:59:48,108][26276] Fps is (10 sec: 15564.4, 60 sec: 15498.6, 300 sec: 15439.7). Total num frames: 36044800. Throughput: 0: 15801.5. Samples: 24104847. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:59:48,108][26276] Avg episode reward: [(0, '-1699.134')]
[2023-08-31 21:59:50,469][26288] Updated weights for policy 0, policy_version 70472 (0.0002)
[2023-08-31 21:59:52,917][26288] Updated weights for policy 0, policy_version 70552 (0.0002)
[2023-08-31 21:59:53,109][26276] Fps is (10 sec: 15566.5, 60 sec: 15632.2, 300 sec: 15426.0). Total num frames: 36122624. Throughput: 0: 15840.7. Samples: 24198206. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:59:53,109][26276] Avg episode reward: [(0, '-1757.772')]
[2023-08-31 21:59:55,496][26288] Updated weights for policy 0, policy_version 70632 (0.0002)
[2023-08-31 21:59:57,969][26288] Updated weights for policy 0, policy_version 70712 (0.0002)
[2023-08-31 21:59:58,109][26276] Fps is (10 sec: 15973.9, 60 sec: 15701.1, 300 sec: 15439.7). Total num frames: 36204544. Throughput: 0: 15858.2. Samples: 24245180. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 21:59:58,109][26276] Avg episode reward: [(0, '-1757.772')]
[2023-08-31 22:00:00,860][26288] Updated weights for policy 0, policy_version 70792 (0.0002)
[2023-08-31 22:00:03,105][26276] Fps is (10 sec: 15979.9, 60 sec: 15770.0, 300 sec: 15440.0). Total num frames: 36282368. Throughput: 0: 15733.4. Samples: 24337198. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:00:03,106][26276] Avg episode reward: [(0, '-1794.866')]
[2023-08-31 22:00:03,338][26288] Updated weights for policy 0, policy_version 70872 (0.0002)
[2023-08-31 22:00:05,873][26288] Updated weights for policy 0, policy_version 70952 (0.0002)
[2023-08-31 22:00:08,108][26276] Fps is (10 sec: 15976.2, 60 sec: 15837.2, 300 sec: 15467.6). Total num frames: 36364288. Throughput: 0: 15835.5. Samples: 24436686. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:00:08,108][26276] Avg episode reward: [(0, '-1794.866')]
[2023-08-31 22:00:08,318][26288] Updated weights for policy 0, policy_version 71032 (0.0002)
[2023-08-31 22:00:11,138][26288] Updated weights for policy 0, policy_version 71112 (0.0002)
[2023-08-31 22:00:13,106][26276] Fps is (10 sec: 15564.3, 60 sec: 15769.8, 300 sec: 15426.2). Total num frames: 36438016. Throughput: 0: 15761.1. Samples: 24482448. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:00:13,106][26276] Avg episode reward: [(0, '-1845.364')]
[2023-08-31 22:00:13,708][26288] Updated weights for policy 0, policy_version 71192 (0.0002)
[2023-08-31 22:00:16,631][26288] Updated weights for policy 0, policy_version 71272 (0.0003)
[2023-08-31 22:00:18,110][26276] Fps is (10 sec: 14741.5, 60 sec: 15632.2, 300 sec: 15467.6). Total num frames: 36511744. Throughput: 0: 15664.7. Samples: 24571715. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:00:18,110][26276] Avg episode reward: [(0, '-1845.364')]
[2023-08-31 22:00:19,316][26288] Updated weights for policy 0, policy_version 71352 (0.0002)
[2023-08-31 22:00:22,233][26288] Updated weights for policy 0, policy_version 71432 (0.0002)
[2023-08-31 22:00:23,109][26276] Fps is (10 sec: 14740.7, 60 sec: 15565.0, 300 sec: 15481.3). Total num frames: 36585472. Throughput: 0: 15451.5. Samples: 24658844. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:00:23,109][26276] Avg episode reward: [(0, '-1898.956')]
[2023-08-31 22:00:24,932][26288] Updated weights for policy 0, policy_version 71512 (0.0002)
[2023-08-31 22:00:27,666][26288] Updated weights for policy 0, policy_version 71592 (0.0002)
[2023-08-31 22:00:28,106][26276] Fps is (10 sec: 14751.6, 60 sec: 15496.5, 300 sec: 15481.7). Total num frames: 36659200. Throughput: 0: 15497.2. Samples: 24705225. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:00:28,106][26276] Avg episode reward: [(0, '-1898.956')]
[2023-08-31 22:00:30,379][26288] Updated weights for policy 0, policy_version 71672 (0.0002)
[2023-08-31 22:00:33,109][26276] Fps is (10 sec: 14745.8, 60 sec: 15428.6, 300 sec: 15509.1). Total num frames: 36732928. Throughput: 0: 15338.0. Samples: 24795070. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:00:33,110][26276] Avg episode reward: [(0, '-1931.284')]
[2023-08-31 22:00:33,355][26288] Updated weights for policy 0, policy_version 71752 (0.0002)
[2023-08-31 22:00:35,961][26288] Updated weights for policy 0, policy_version 71832 (0.0002)
[2023-08-31 22:00:38,108][26276] Fps is (10 sec: 14742.8, 60 sec: 15291.7, 300 sec: 15495.5). Total num frames: 36806656. Throughput: 0: 15222.7. Samples: 24883216. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:00:38,108][26276] Avg episode reward: [(0, '-1931.284')]
[2023-08-31 22:00:38,638][26288] Updated weights for policy 0, policy_version 71912 (0.0002)
[2023-08-31 22:00:41,263][26288] Updated weights for policy 0, policy_version 71992 (0.0002)
[2023-08-31 22:00:43,110][26276] Fps is (10 sec: 14744.2, 60 sec: 15223.5, 300 sec: 15495.4). Total num frames: 36880384. Throughput: 0: 15217.4. Samples: 24929983. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:00:43,110][26276] Avg episode reward: [(0, '-1926.016')]
[2023-08-31 22:00:43,125][26287] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000072040_36884480.pth...
[2023-08-31 22:00:43,127][26287] Removing /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000065984_33783808.pth
[2023-08-31 22:00:44,176][26288] Updated weights for policy 0, policy_version 72072 (0.0002)
[2023-08-31 22:00:46,778][26288] Updated weights for policy 0, policy_version 72152 (0.0002)
[2023-08-31 22:00:48,106][26276] Fps is (10 sec: 15158.5, 60 sec: 15224.1, 300 sec: 15481.5). Total num frames: 36958208. Throughput: 0: 15162.1. Samples: 25019498. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:00:48,106][26276] Avg episode reward: [(0, '-1926.016')]
[2023-08-31 22:00:49,556][26288] Updated weights for policy 0, policy_version 72232 (0.0002)
[2023-08-31 22:00:52,351][26288] Updated weights for policy 0, policy_version 72312 (0.0002)
[2023-08-31 22:00:53,105][26276] Fps is (10 sec: 15162.3, 60 sec: 15156.1, 300 sec: 15481.5). Total num frames: 37031936. Throughput: 0: 14913.2. Samples: 25107749. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:00:53,106][26276] Avg episode reward: [(0, '-1926.016')]
[2023-08-31 22:00:55,442][26288] Updated weights for policy 0, policy_version 72392 (0.0002)
[2023-08-31 22:00:58,106][26276] Fps is (10 sec: 14336.2, 60 sec: 14951.1, 300 sec: 15467.7). Total num frames: 37101568. Throughput: 0: 14783.8. Samples: 25147717. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:00:58,106][26276] Avg episode reward: [(0, '-1921.788')]
[2023-08-31 22:00:58,136][26288] Updated weights for policy 0, policy_version 72472 (0.0002)
[2023-08-31 22:01:00,643][26288] Updated weights for policy 0, policy_version 72552 (0.0002)
[2023-08-31 22:01:03,107][26276] Fps is (10 sec: 15152.2, 60 sec: 15018.2, 300 sec: 15509.3). Total num frames: 37183488. Throughput: 0: 14890.0. Samples: 25241723. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:01:03,107][26276] Avg episode reward: [(0, '-1921.788')]
[2023-08-31 22:01:03,262][26288] Updated weights for policy 0, policy_version 72632 (0.0002)
[2023-08-31 22:01:06,227][26288] Updated weights for policy 0, policy_version 72712 (0.0002)
[2023-08-31 22:01:08,106][26276] Fps is (10 sec: 15564.2, 60 sec: 14882.5, 300 sec: 15495.6). Total num frames: 37257216. Throughput: 0: 14925.7. Samples: 25330455. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:01:08,106][26276] Avg episode reward: [(0, '-1912.429')]
[2023-08-31 22:01:08,817][26288] Updated weights for policy 0, policy_version 72792 (0.0002)
[2023-08-31 22:01:11,305][26288] Updated weights for policy 0, policy_version 72872 (0.0002)
[2023-08-31 22:01:13,109][26276] Fps is (10 sec: 15561.6, 60 sec: 15017.8, 300 sec: 15523.0). Total num frames: 37339136. Throughput: 0: 14968.8. Samples: 25378870. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:01:13,110][26276] Avg episode reward: [(0, '-1912.429')]
[2023-08-31 22:01:13,936][26288] Updated weights for policy 0, policy_version 72952 (0.0002)
[2023-08-31 22:01:16,931][26288] Updated weights for policy 0, policy_version 73032 (0.0003)
[2023-08-31 22:01:18,110][26276] Fps is (10 sec: 14739.8, 60 sec: 14882.2, 300 sec: 15467.5). Total num frames: 37404672. Throughput: 0: 14948.1. Samples: 25467750. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:01:18,110][26276] Avg episode reward: [(0, '-1897.734')]
[2023-08-31 22:01:19,848][26288] Updated weights for policy 0, policy_version 73112 (0.0002)
[2023-08-31 22:01:22,651][26288] Updated weights for policy 0, policy_version 73192 (0.0002)
[2023-08-31 22:01:23,106][26276] Fps is (10 sec: 13930.7, 60 sec: 14882.9, 300 sec: 15453.7). Total num frames: 37478400. Throughput: 0: 14894.4. Samples: 25553438. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:01:23,107][26276] Avg episode reward: [(0, '-1897.734')]
[2023-08-31 22:01:25,315][26288] Updated weights for policy 0, policy_version 73272 (0.0002)
[2023-08-31 22:01:28,035][26288] Updated weights for policy 0, policy_version 73352 (0.0002)
[2023-08-31 22:01:28,105][26276] Fps is (10 sec: 15162.5, 60 sec: 14950.6, 300 sec: 15454.0). Total num frames: 37556224. Throughput: 0: 14891.0. Samples: 25600007. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:01:28,105][26276] Avg episode reward: [(0, '-1885.766')]
[2023-08-31 22:01:30,552][26288] Updated weights for policy 0, policy_version 73432 (0.0002)
[2023-08-31 22:01:32,990][26288] Updated weights for policy 0, policy_version 73512 (0.0002)
[2023-08-31 22:01:33,107][26276] Fps is (10 sec: 15973.1, 60 sec: 15087.4, 300 sec: 15467.7). Total num frames: 37638144. Throughput: 0: 15009.1. Samples: 25694926. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:01:33,107][26276] Avg episode reward: [(0, '-1885.766')]
[2023-08-31 22:01:35,772][26288] Updated weights for policy 0, policy_version 73592 (0.0002)
[2023-08-31 22:01:38,107][26276] Fps is (10 sec: 15972.1, 60 sec: 15155.6, 300 sec: 15467.6). Total num frames: 37715968. Throughput: 0: 15125.9. Samples: 25788432. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:01:38,108][26276] Avg episode reward: [(0, '-1857.409')]
[2023-08-31 22:01:38,337][26288] Updated weights for policy 0, policy_version 73672 (0.0002)
[2023-08-31 22:01:40,751][26288] Updated weights for policy 0, policy_version 73752 (0.0002)
[2023-08-31 22:01:43,110][26276] Fps is (10 sec: 15970.4, 60 sec: 15291.9, 300 sec: 15481.5). Total num frames: 37797888. Throughput: 0: 15345.5. Samples: 25838323. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:01:43,110][26276] Avg episode reward: [(0, '-1857.409')]
[2023-08-31 22:01:43,182][26288] Updated weights for policy 0, policy_version 73832 (0.0002)
[2023-08-31 22:01:45,927][26288] Updated weights for policy 0, policy_version 73912 (0.0002)
[2023-08-31 22:01:48,105][26276] Fps is (10 sec: 15976.3, 60 sec: 15291.8, 300 sec: 15467.8). Total num frames: 37875712. Throughput: 0: 15366.1. Samples: 25933167. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:01:48,106][26276] Avg episode reward: [(0, '-1850.478')]
[2023-08-31 22:01:48,456][26288] Updated weights for policy 0, policy_version 73992 (0.0002)
[2023-08-31 22:01:50,868][26288] Updated weights for policy 0, policy_version 74072 (0.0002)
[2023-08-31 22:01:53,106][26276] Fps is (10 sec: 16390.5, 60 sec: 15496.5, 300 sec: 15495.6). Total num frames: 37961728. Throughput: 0: 15606.9. Samples: 26032756. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:01:53,106][26276] Avg episode reward: [(0, '-1850.478')]
[2023-08-31 22:01:53,324][26288] Updated weights for policy 0, policy_version 74152 (0.0002)
[2023-08-31 22:01:56,054][26288] Updated weights for policy 0, policy_version 74232 (0.0002)
[2023-08-31 22:01:58,109][26276] Fps is (10 sec: 16377.3, 60 sec: 15632.1, 300 sec: 15481.3). Total num frames: 38039552. Throughput: 0: 15616.1. Samples: 26081596. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:01:58,110][26276] Avg episode reward: [(0, '-1838.632')]
[2023-08-31 22:01:58,535][26288] Updated weights for policy 0, policy_version 74312 (0.0002)
[2023-08-31 22:02:00,990][26288] Updated weights for policy 0, policy_version 74392 (0.0002)
[2023-08-31 22:02:03,106][26276] Fps is (10 sec: 15974.2, 60 sec: 15633.5, 300 sec: 15509.4). Total num frames: 38121472. Throughput: 0: 15804.9. Samples: 26178902. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:02:03,106][26276] Avg episode reward: [(0, '-1838.632')]
[2023-08-31 22:02:03,461][26288] Updated weights for policy 0, policy_version 74472 (0.0002)
[2023-08-31 22:02:06,118][26288] Updated weights for policy 0, policy_version 74552 (0.0002)
[2023-08-31 22:02:08,106][26276] Fps is (10 sec: 16389.6, 60 sec: 15769.6, 300 sec: 15523.1). Total num frames: 38203392. Throughput: 0: 16053.8. Samples: 26275856. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:02:08,106][26276] Avg episode reward: [(0, '-1837.662')]
[2023-08-31 22:02:08,560][26288] Updated weights for policy 0, policy_version 74632 (0.0002)
[2023-08-31 22:02:11,045][26288] Updated weights for policy 0, policy_version 74712 (0.0002)
[2023-08-31 22:02:13,110][26276] Fps is (10 sec: 16377.0, 60 sec: 15769.5, 300 sec: 15536.8). Total num frames: 38285312. Throughput: 0: 16122.9. Samples: 26325612. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:02:13,110][26276] Avg episode reward: [(0, '-1837.662')]
[2023-08-31 22:02:13,448][26288] Updated weights for policy 0, policy_version 74792 (0.0002)
[2023-08-31 22:02:16,186][26288] Updated weights for policy 0, policy_version 74872 (0.0002)
[2023-08-31 22:02:18,110][26276] Fps is (10 sec: 15968.1, 60 sec: 15974.4, 300 sec: 15522.9). Total num frames: 38363136. Throughput: 0: 16138.5. Samples: 26421208. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:02:18,110][26276] Avg episode reward: [(0, '-1845.749')]
[2023-08-31 22:02:18,615][26288] Updated weights for policy 0, policy_version 74952 (0.0002)
[2023-08-31 22:02:21,115][26288] Updated weights for policy 0, policy_version 75032 (0.0002)
[2023-08-31 22:02:23,105][26276] Fps is (10 sec: 16391.6, 60 sec: 16179.5, 300 sec: 15551.0). Total num frames: 38449152. Throughput: 0: 16295.7. Samples: 26521718. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:02:23,105][26276] Avg episode reward: [(0, '-1845.749')]
[2023-08-31 22:02:23,108][26287] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000075096_38449152.pth...
[2023-08-31 22:02:23,110][26287] Removing /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000069016_35336192.pth
[2023-08-31 22:02:23,503][26288] Updated weights for policy 0, policy_version 75112 (0.0002)
[2023-08-31 22:02:26,218][26288] Updated weights for policy 0, policy_version 75192 (0.0002)
[2023-08-31 22:02:28,110][26276] Fps is (10 sec: 16384.8, 60 sec: 16178.0, 300 sec: 15550.8). Total num frames: 38526976. Throughput: 0: 16192.3. Samples: 26566975. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:02:28,110][26276] Avg episode reward: [(0, '-1864.356')]
[2023-08-31 22:02:28,642][26288] Updated weights for policy 0, policy_version 75272 (0.0002)
[2023-08-31 22:02:31,145][26288] Updated weights for policy 0, policy_version 75352 (0.0002)
[2023-08-31 22:02:33,107][26276] Fps is (10 sec: 16380.5, 60 sec: 16247.4, 300 sec: 15592.6). Total num frames: 38612992. Throughput: 0: 16325.4. Samples: 26667840. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:02:33,108][26276] Avg episode reward: [(0, '-1864.356')]
[2023-08-31 22:02:33,496][26288] Updated weights for policy 0, policy_version 75432 (0.0002)
[2023-08-31 22:02:36,292][26288] Updated weights for policy 0, policy_version 75512 (0.0002)
[2023-08-31 22:02:38,110][26276] Fps is (10 sec: 16383.2, 60 sec: 16246.5, 300 sec: 15578.5). Total num frames: 38690816. Throughput: 0: 16232.4. Samples: 26763285. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:02:38,110][26276] Avg episode reward: [(0, '-1880.605')]
[2023-08-31 22:02:38,733][26288] Updated weights for policy 0, policy_version 75592 (0.0002)
[2023-08-31 22:02:41,174][26288] Updated weights for policy 0, policy_version 75672 (0.0002)
[2023-08-31 22:02:43,105][26276] Fps is (10 sec: 15977.8, 60 sec: 16248.6, 300 sec: 15606.7). Total num frames: 38772736. Throughput: 0: 16290.4. Samples: 26814593. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:02:43,105][26276] Avg episode reward: [(0, '-1880.605')]
[2023-08-31 22:02:43,605][26288] Updated weights for policy 0, policy_version 75752 (0.0002)
[2023-08-31 22:02:46,130][26288] Updated weights for policy 0, policy_version 75832 (0.0002)
[2023-08-31 22:02:48,107][26276] Fps is (10 sec: 16389.5, 60 sec: 16315.4, 300 sec: 15606.6). Total num frames: 38854656. Throughput: 0: 16333.4. Samples: 26913924. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:02:48,107][26276] Avg episode reward: [(0, '-1894.144')]
[2023-08-31 22:02:48,598][26288] Updated weights for policy 0, policy_version 75912 (0.0002)
[2023-08-31 22:02:51,205][26288] Updated weights for policy 0, policy_version 75992 (0.0002)
[2023-08-31 22:02:53,105][26276] Fps is (10 sec: 16383.8, 60 sec: 16247.5, 300 sec: 15620.5). Total num frames: 38936576. Throughput: 0: 16305.3. Samples: 27009584. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:02:53,106][26276] Avg episode reward: [(0, '-1894.144')]
[2023-08-31 22:02:53,684][26288] Updated weights for policy 0, policy_version 76072 (0.0002)
[2023-08-31 22:02:56,446][26288] Updated weights for policy 0, policy_version 76152 (0.0002)
[2023-08-31 22:02:58,106][26276] Fps is (10 sec: 15975.4, 60 sec: 16248.4, 300 sec: 15620.3). Total num frames: 39014400. Throughput: 0: 16229.4. Samples: 27055871. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:02:58,107][26276] Avg episode reward: [(0, '-1893.882')]
[2023-08-31 22:02:58,968][26288] Updated weights for policy 0, policy_version 76232 (0.0002)
[2023-08-31 22:03:01,480][26288] Updated weights for policy 0, policy_version 76312 (0.0002)
[2023-08-31 22:03:03,107][26276] Fps is (10 sec: 15970.9, 60 sec: 16247.0, 300 sec: 15634.2). Total num frames: 39096320. Throughput: 0: 16267.5. Samples: 27153205. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:03:03,108][26276] Avg episode reward: [(0, '-1893.882')]
[2023-08-31 22:03:04,008][26288] Updated weights for policy 0, policy_version 76392 (0.0002)
[2023-08-31 22:03:06,675][26288] Updated weights for policy 0, policy_version 76472 (0.0002)
[2023-08-31 22:03:08,107][26276] Fps is (10 sec: 15973.4, 60 sec: 16179.0, 300 sec: 15634.4). Total num frames: 39174144. Throughput: 0: 16158.8. Samples: 27248887. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:03:08,107][26276] Avg episode reward: [(0, '-1907.393')]
[2023-08-31 22:03:09,214][26288] Updated weights for policy 0, policy_version 76552 (0.0002)
[2023-08-31 22:03:11,626][26288] Updated weights for policy 0, policy_version 76632 (0.0002)
[2023-08-31 22:03:13,106][26276] Fps is (10 sec: 16387.0, 60 sec: 16248.6, 300 sec: 15662.2). Total num frames: 39260160. Throughput: 0: 16231.5. Samples: 27297329. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:03:13,106][26276] Avg episode reward: [(0, '-1907.393')]
[2023-08-31 22:03:14,129][26288] Updated weights for policy 0, policy_version 76712 (0.0002)
[2023-08-31 22:03:16,775][26288] Updated weights for policy 0, policy_version 76792 (0.0002)
[2023-08-31 22:03:18,110][26276] Fps is (10 sec: 16378.3, 60 sec: 16247.4, 300 sec: 15661.8). Total num frames: 39337984. Throughput: 0: 16138.4. Samples: 27394112. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:03:18,110][26276] Avg episode reward: [(0, '-1927.586')]
[2023-08-31 22:03:19,270][26288] Updated weights for policy 0, policy_version 76872 (0.0002)
[2023-08-31 22:03:21,814][26288] Updated weights for policy 0, policy_version 76952 (0.0002)
[2023-08-31 22:03:23,107][26276] Fps is (10 sec: 15972.2, 60 sec: 16178.7, 300 sec: 15675.9). Total num frames: 39419904. Throughput: 0: 16203.1. Samples: 27492378. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:03:23,107][26276] Avg episode reward: [(0, '-1927.586')]
[2023-08-31 22:03:24,415][26288] Updated weights for policy 0, policy_version 77032 (0.0002)
[2023-08-31 22:03:26,796][26288] Updated weights for policy 0, policy_version 77112 (0.0002)
[2023-08-31 22:03:28,107][26276] Fps is (10 sec: 16389.6, 60 sec: 16248.2, 300 sec: 15689.9). Total num frames: 39501824. Throughput: 0: 16111.1. Samples: 27539615. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:03:28,107][26276] Avg episode reward: [(0, '-1932.227')]
[2023-08-31 22:03:29,284][26288] Updated weights for policy 0, policy_version 77192 (0.0002)
[2023-08-31 22:03:31,714][26288] Updated weights for policy 0, policy_version 77272 (0.0002)
[2023-08-31 22:03:33,105][26276] Fps is (10 sec: 16386.6, 60 sec: 16179.7, 300 sec: 15689.8). Total num frames: 39583744. Throughput: 0: 16143.9. Samples: 27640380. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:03:33,106][26276] Avg episode reward: [(0, '-1932.227')]
[2023-08-31 22:03:34,539][26288] Updated weights for policy 0, policy_version 77352 (0.0002)
[2023-08-31 22:03:37,082][26288] Updated weights for policy 0, policy_version 77432 (0.0002)
[2023-08-31 22:03:38,110][26276] Fps is (10 sec: 15559.7, 60 sec: 16110.9, 300 sec: 15675.6). Total num frames: 39657472. Throughput: 0: 16097.2. Samples: 27734032. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:03:38,110][26276] Avg episode reward: [(0, '-1941.057')]
[2023-08-31 22:03:39,631][26288] Updated weights for policy 0, policy_version 77512 (0.0002)
[2023-08-31 22:03:42,095][26288] Updated weights for policy 0, policy_version 77592 (0.0002)
[2023-08-31 22:03:43,109][26276] Fps is (10 sec: 15968.5, 60 sec: 16178.1, 300 sec: 15690.1). Total num frames: 39743488. Throughput: 0: 16129.0. Samples: 27781726. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:03:43,109][26276] Avg episode reward: [(0, '-1941.057')]
[2023-08-31 22:03:44,717][26288] Updated weights for policy 0, policy_version 77672 (0.0002)
[2023-08-31 22:03:47,056][26288] Updated weights for policy 0, policy_version 77752 (0.0002)
[2023-08-31 22:03:48,110][26276] Fps is (10 sec: 16794.0, 60 sec: 16178.4, 300 sec: 15731.2). Total num frames: 39825408. Throughput: 0: 16161.0. Samples: 27880484. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:03:48,110][26276] Avg episode reward: [(0, '-1959.008')]
[2023-08-31 22:03:49,648][26288] Updated weights for policy 0, policy_version 77832 (0.0002)
[2023-08-31 22:03:52,075][26288] Updated weights for policy 0, policy_version 77912 (0.0002)
[2023-08-31 22:03:53,110][26276] Fps is (10 sec: 16382.5, 60 sec: 16177.9, 300 sec: 15745.2). Total num frames: 39907328. Throughput: 0: 16237.8. Samples: 27979644. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:03:53,110][26276] Avg episode reward: [(0, '-1959.008')]
[2023-08-31 22:03:54,755][26288] Updated weights for policy 0, policy_version 77992 (0.0002)
[2023-08-31 22:03:57,215][26288] Updated weights for policy 0, policy_version 78072 (0.0002)
[2023-08-31 22:03:58,106][26276] Fps is (10 sec: 15981.0, 60 sec: 16179.3, 300 sec: 15759.3). Total num frames: 39985152. Throughput: 0: 16175.4. Samples: 28025222. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:03:58,106][26276] Avg episode reward: [(0, '-1976.912')]
[2023-08-31 22:03:59,687][26288] Updated weights for policy 0, policy_version 78152 (0.0002)
[2023-08-31 22:04:02,162][26288] Updated weights for policy 0, policy_version 78232 (0.0002)
[2023-08-31 22:04:03,107][26276] Fps is (10 sec: 15979.4, 60 sec: 16179.4, 300 sec: 15773.0). Total num frames: 40067072. Throughput: 0: 16263.0. Samples: 28125894. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:04:03,107][26276] Avg episode reward: [(0, '-1976.912')]
[2023-08-31 22:04:03,110][26287] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000078256_40067072.pth...
[2023-08-31 22:04:03,112][26287] Removing /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000072040_36884480.pth
[2023-08-31 22:04:04,814][26288] Updated weights for policy 0, policy_version 78312 (0.0002)
[2023-08-31 22:04:07,322][26288] Updated weights for policy 0, policy_version 78392 (0.0002)
[2023-08-31 22:04:08,110][26276] Fps is (10 sec: 16376.8, 60 sec: 16246.6, 300 sec: 15786.8). Total num frames: 40148992. Throughput: 0: 16195.7. Samples: 28221232. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:04:08,110][26276] Avg episode reward: [(0, '-1982.673')]
[2023-08-31 22:04:09,896][26288] Updated weights for policy 0, policy_version 78472 (0.0002)
[2023-08-31 22:04:12,466][26288] Updated weights for policy 0, policy_version 78552 (0.0002)
[2023-08-31 22:04:13,110][26276] Fps is (10 sec: 15969.5, 60 sec: 16109.8, 300 sec: 15772.9). Total num frames: 40226816. Throughput: 0: 16206.8. Samples: 28268975. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:04:13,110][26276] Avg episode reward: [(0, '-1982.673')]
[2023-08-31 22:04:15,190][26288] Updated weights for policy 0, policy_version 78632 (0.0002)
[2023-08-31 22:04:17,560][26288] Updated weights for policy 0, policy_version 78712 (0.0002)
[2023-08-31 22:04:18,110][26276] Fps is (10 sec: 15975.1, 60 sec: 16179.4, 300 sec: 15787.0). Total num frames: 40308736. Throughput: 0: 16078.8. Samples: 28363990. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:04:18,110][26276] Avg episode reward: [(0, '-1979.125')]
[2023-08-31 22:04:19,907][26288] Updated weights for policy 0, policy_version 78792 (0.0002)
[2023-08-31 22:04:22,397][26288] Updated weights for policy 0, policy_version 78872 (0.0002)
[2023-08-31 22:04:23,105][26276] Fps is (10 sec: 16801.5, 60 sec: 16248.0, 300 sec: 15814.8). Total num frames: 40394752. Throughput: 0: 16270.8. Samples: 28466140. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:04:23,105][26276] Avg episode reward: [(0, '-1979.125')]
[2023-08-31 22:04:25,126][26288] Updated weights for policy 0, policy_version 78952 (0.0002)
[2023-08-31 22:04:27,509][26288] Updated weights for policy 0, policy_version 79032 (0.0002)
[2023-08-31 22:04:28,106][26276] Fps is (10 sec: 16389.0, 60 sec: 16179.3, 300 sec: 15814.9). Total num frames: 40472576. Throughput: 0: 16215.9. Samples: 28511400. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:04:28,107][26276] Avg episode reward: [(0, '-1962.857')]
[2023-08-31 22:04:29,903][26288] Updated weights for policy 0, policy_version 79112 (0.0002)
[2023-08-31 22:04:32,340][26288] Updated weights for policy 0, policy_version 79192 (0.0002)
[2023-08-31 22:04:33,106][26276] Fps is (10 sec: 15973.8, 60 sec: 16179.2, 300 sec: 15814.9). Total num frames: 40554496. Throughput: 0: 16279.5. Samples: 28612993. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:04:33,106][26276] Avg episode reward: [(0, '-1962.091')]
[2023-08-31 22:04:34,970][26288] Updated weights for policy 0, policy_version 79272 (0.0002)
[2023-08-31 22:04:37,380][26288] Updated weights for policy 0, policy_version 79352 (0.0002)
[2023-08-31 22:04:38,108][26276] Fps is (10 sec: 16791.1, 60 sec: 16384.6, 300 sec: 15842.6). Total num frames: 40640512. Throughput: 0: 16270.2. Samples: 28711767. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:04:38,108][26276] Avg episode reward: [(0, '-1962.502')]
[2023-08-31 22:04:39,720][26288] Updated weights for policy 0, policy_version 79432 (0.0002)
[2023-08-31 22:04:42,246][26288] Updated weights for policy 0, policy_version 79512 (0.0002)
[2023-08-31 22:04:43,110][26276] Fps is (10 sec: 16376.7, 60 sec: 16247.2, 300 sec: 15842.4). Total num frames: 40718336. Throughput: 0: 16397.9. Samples: 28763200. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:04:43,110][26276] Avg episode reward: [(0, '-1964.166')]
[2023-08-31 22:04:44,988][26288] Updated weights for policy 0, policy_version 79592 (0.0002)
[2023-08-31 22:04:47,477][26288] Updated weights for policy 0, policy_version 79672 (0.0002)
[2023-08-31 22:04:48,109][26276] Fps is (10 sec: 15972.2, 60 sec: 16247.6, 300 sec: 15856.4). Total num frames: 40800256. Throughput: 0: 16263.8. Samples: 28857806. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:04:48,110][26276] Avg episode reward: [(0, '-1964.166')]
[2023-08-31 22:04:49,953][26288] Updated weights for policy 0, policy_version 79752 (0.0002)
[2023-08-31 22:04:52,639][26288] Updated weights for policy 0, policy_version 79832 (0.0002)
[2023-08-31 22:04:53,105][26276] Fps is (10 sec: 15982.1, 60 sec: 16180.5, 300 sec: 15842.7). Total num frames: 40878080. Throughput: 0: 16267.8. Samples: 28953207. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:04:53,105][26276] Avg episode reward: [(0, '-1951.985')]
[2023-08-31 22:04:55,408][26288] Updated weights for policy 0, policy_version 79912 (0.0002)
[2023-08-31 22:04:57,905][26288] Updated weights for policy 0, policy_version 79992 (0.0002)
[2023-08-31 22:04:58,105][26276] Fps is (10 sec: 15571.0, 60 sec: 16179.3, 300 sec: 15842.5). Total num frames: 40955904. Throughput: 0: 16207.3. Samples: 28998229. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:04:58,106][26276] Avg episode reward: [(0, '-1945.956')]
[2023-08-31 22:05:00,406][26288] Updated weights for policy 0, policy_version 80072 (0.0002)
[2023-08-31 22:05:02,922][26288] Updated weights for policy 0, policy_version 80152 (0.0002)
[2023-08-31 22:05:03,110][26276] Fps is (10 sec: 15967.1, 60 sec: 16178.4, 300 sec: 15842.4). Total num frames: 41037824. Throughput: 0: 16287.6. Samples: 29096938. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:05:03,110][26276] Avg episode reward: [(0, '-1935.313')]
[2023-08-31 22:05:05,584][26288] Updated weights for policy 0, policy_version 80232 (0.0002)
[2023-08-31 22:05:08,037][26288] Updated weights for policy 0, policy_version 80312 (0.0002)
[2023-08-31 22:05:08,105][26276] Fps is (10 sec: 16384.0, 60 sec: 16180.5, 300 sec: 15870.3). Total num frames: 41119744. Throughput: 0: 16134.5. Samples: 29192195. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:05:08,106][26276] Avg episode reward: [(0, '-1935.313')]
[2023-08-31 22:05:10,575][26288] Updated weights for policy 0, policy_version 80392 (0.0002)
[2023-08-31 22:05:13,109][26276] Fps is (10 sec: 15975.8, 60 sec: 16179.5, 300 sec: 15884.2). Total num frames: 41197568. Throughput: 0: 16219.8. Samples: 29241332. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:05:13,109][26276] Avg episode reward: [(0, '-1921.606')]
[2023-08-31 22:05:13,277][26288] Updated weights for policy 0, policy_version 80472 (0.0002)
[2023-08-31 22:05:15,709][26288] Updated weights for policy 0, policy_version 80552 (0.0002)
[2023-08-31 22:05:16,705][26287] Early stopping after 2 epochs (8 sgd steps), loss delta 0.0000003
[2023-08-31 22:05:18,110][26276] Fps is (10 sec: 15966.8, 60 sec: 16179.1, 300 sec: 15911.9). Total num frames: 41279488. Throughput: 0: 16087.9. Samples: 29337020. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 22:05:18,110][26276] Avg episode reward: [(0, '-1921.606')]
[2023-08-31 22:05:18,198][26288] Updated weights for policy 0, policy_version 80632 (0.0002)
[2023-08-31 22:05:20,717][26288] Updated weights for policy 0, policy_version 80712 (0.0002)
[2023-08-31 22:05:23,106][26276] Fps is (10 sec: 15979.8, 60 sec: 16042.6, 300 sec: 15925.8). Total num frames: 41357312. Throughput: 0: 16078.6. Samples: 29435267. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 22:05:23,106][26276] Avg episode reward: [(0, '-1915.576')]
[2023-08-31 22:05:23,454][26288] Updated weights for policy 0, policy_version 80792 (0.0002)
[2023-08-31 22:05:25,993][26288] Updated weights for policy 0, policy_version 80872 (0.0002)
[2023-08-31 22:05:28,106][26276] Fps is (10 sec: 15981.3, 60 sec: 16111.1, 300 sec: 15953.8). Total num frames: 41439232. Throughput: 0: 15928.6. Samples: 29479920. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 22:05:28,106][26276] Avg episode reward: [(0, '-1915.576')]
[2023-08-31 22:05:28,441][26288] Updated weights for policy 0, policy_version 80952 (0.0002)
[2023-08-31 22:05:30,866][26288] Updated weights for policy 0, policy_version 81032 (0.0002)
[2023-08-31 22:05:33,106][26276] Fps is (10 sec: 16382.5, 60 sec: 16110.7, 300 sec: 15981.4). Total num frames: 41521152. Throughput: 0: 16060.5. Samples: 29580484. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 22:05:33,107][26276] Avg episode reward: [(0, '-1897.965')]
[2023-08-31 22:05:33,612][26288] Updated weights for policy 0, policy_version 81112 (0.0002)
[2023-08-31 22:05:36,089][26288] Updated weights for policy 0, policy_version 81192 (0.0002)
[2023-08-31 22:05:38,109][26276] Fps is (10 sec: 16378.2, 60 sec: 16042.3, 300 sec: 16009.2). Total num frames: 41603072. Throughput: 0: 16050.5. Samples: 29675546. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 22:05:38,109][26276] Avg episode reward: [(0, '-1897.965')]
[2023-08-31 22:05:38,499][26288] Updated weights for policy 0, policy_version 81272 (0.0002)
[2023-08-31 22:05:40,984][26288] Updated weights for policy 0, policy_version 81352 (0.0002)
[2023-08-31 22:05:43,106][26276] Fps is (10 sec: 15975.4, 60 sec: 16043.8, 300 sec: 16009.1). Total num frames: 41680896. Throughput: 0: 16165.5. Samples: 29725686. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 22:05:43,106][26276] Avg episode reward: [(0, '-1875.268')]
[2023-08-31 22:05:43,109][26287] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000081408_41680896.pth...
[2023-08-31 22:05:43,111][26287] Removing /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000075096_38449152.pth
[2023-08-31 22:05:43,729][26288] Updated weights for policy 0, policy_version 81432 (0.0002)
[2023-08-31 22:05:46,155][26288] Updated weights for policy 0, policy_version 81512 (0.0002)
[2023-08-31 22:05:48,106][26276] Fps is (10 sec: 15978.8, 60 sec: 16043.4, 300 sec: 16036.8). Total num frames: 41762816. Throughput: 0: 16103.0. Samples: 29821520. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 22:05:48,108][26276] Avg episode reward: [(0, '-1875.268')]
[2023-08-31 22:05:48,682][26288] Updated weights for policy 0, policy_version 81592 (0.0002)
[2023-08-31 22:05:51,140][26288] Updated weights for policy 0, policy_version 81672 (0.0002)
[2023-08-31 22:05:53,109][26276] Fps is (10 sec: 15969.6, 60 sec: 16041.7, 300 sec: 16064.5). Total num frames: 41840640. Throughput: 0: 16174.6. Samples: 29920110. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 22:05:53,109][26276] Avg episode reward: [(0, '-1863.919')]
[2023-08-31 22:05:53,827][26288] Updated weights for policy 0, policy_version 81752 (0.0002)
[2023-08-31 22:05:56,237][26288] Updated weights for policy 0, policy_version 81832 (0.0002)
[2023-08-31 22:05:58,105][26276] Fps is (10 sec: 16386.2, 60 sec: 16179.2, 300 sec: 16078.7). Total num frames: 41926656. Throughput: 0: 16134.1. Samples: 29967306. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 22:05:58,105][26276] Avg episode reward: [(0, '-1863.919')]
[2023-08-31 22:05:58,763][26288] Updated weights for policy 0, policy_version 81912 (0.0002)
[2023-08-31 22:06:01,165][26288] Updated weights for policy 0, policy_version 81992 (0.0002)
[2023-08-31 22:06:03,110][26276] Fps is (10 sec: 16382.1, 60 sec: 16110.9, 300 sec: 16092.2). Total num frames: 42004480. Throughput: 0: 16222.8. Samples: 30067047. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 22:06:03,110][26276] Avg episode reward: [(0, '-1843.102')]
[2023-08-31 22:06:03,884][26288] Updated weights for policy 0, policy_version 82072 (0.0002)
[2023-08-31 22:06:06,403][26288] Updated weights for policy 0, policy_version 82152 (0.0002)
[2023-08-31 22:06:08,106][26276] Fps is (10 sec: 15972.3, 60 sec: 16110.6, 300 sec: 16092.6). Total num frames: 42086400. Throughput: 0: 16118.3. Samples: 30160606. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:06:08,107][26276] Avg episode reward: [(0, '-1843.102')]
[2023-08-31 22:06:08,981][26288] Updated weights for policy 0, policy_version 82232 (0.0002)
[2023-08-31 22:06:11,500][26288] Updated weights for policy 0, policy_version 82312 (0.0002)
[2023-08-31 22:06:13,110][26276] Fps is (10 sec: 15975.1, 60 sec: 16110.8, 300 sec: 16134.1). Total num frames: 42164224. Throughput: 0: 16206.9. Samples: 30209291. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:06:13,110][26276] Avg episode reward: [(0, '-1822.743')]
[2023-08-31 22:06:14,264][26288] Updated weights for policy 0, policy_version 82392 (0.0002)
[2023-08-31 22:06:16,693][26288] Updated weights for policy 0, policy_version 82472 (0.0002)
[2023-08-31 22:06:18,107][26276] Fps is (10 sec: 15974.0, 60 sec: 16111.8, 300 sec: 16161.8). Total num frames: 42246144. Throughput: 0: 16063.2. Samples: 30303333. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:06:18,107][26276] Avg episode reward: [(0, '-1822.743')]
[2023-08-31 22:06:19,182][26288] Updated weights for policy 0, policy_version 82552 (0.0002)
[2023-08-31 22:06:21,549][26288] Updated weights for policy 0, policy_version 82632 (0.0002)
[2023-08-31 22:06:23,108][26276] Fps is (10 sec: 16386.5, 60 sec: 16178.5, 300 sec: 16175.6). Total num frames: 42328064. Throughput: 0: 16166.8. Samples: 30403034. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:06:23,108][26276] Avg episode reward: [(0, '-1796.146')]
[2023-08-31 22:06:24,157][26288] Updated weights for policy 0, policy_version 82712 (0.0002)
[2023-08-31 22:06:26,726][26288] Updated weights for policy 0, policy_version 82792 (0.0002)
[2023-08-31 22:06:28,105][26276] Fps is (10 sec: 16386.8, 60 sec: 16179.4, 300 sec: 16175.8). Total num frames: 42409984. Throughput: 0: 16105.5. Samples: 30450422. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:06:28,105][26276] Avg episode reward: [(0, '-1796.146')]
[2023-08-31 22:06:29,183][26288] Updated weights for policy 0, policy_version 82872 (0.0002)
[2023-08-31 22:06:31,664][26288] Updated weights for policy 0, policy_version 82952 (0.0002)
[2023-08-31 22:06:33,105][26276] Fps is (10 sec: 16388.6, 60 sec: 16179.5, 300 sec: 16189.7). Total num frames: 42491904. Throughput: 0: 16193.0. Samples: 30550187. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:06:33,105][26276] Avg episode reward: [(0, '-1795.598')]
[2023-08-31 22:06:34,349][26288] Updated weights for policy 0, policy_version 83032 (0.0002)
[2023-08-31 22:06:37,574][26288] Updated weights for policy 0, policy_version 83112 (0.0003)
[2023-08-31 22:06:38,106][26276] Fps is (10 sec: 15153.8, 60 sec: 15975.3, 300 sec: 16148.2). Total num frames: 42561536. Throughput: 0: 15866.7. Samples: 30634064. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:06:38,107][26276] Avg episode reward: [(0, '-1795.598')]
[2023-08-31 22:06:40,380][26288] Updated weights for policy 0, policy_version 83192 (0.0002)
[2023-08-31 22:06:43,108][26276] Fps is (10 sec: 13923.0, 60 sec: 15837.4, 300 sec: 16120.1). Total num frames: 42631168. Throughput: 0: 15785.2. Samples: 30677680. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:06:43,108][26276] Avg episode reward: [(0, '-1795.598')]
[2023-08-31 22:06:43,438][26288] Updated weights for policy 0, policy_version 83272 (0.0003)
[2023-08-31 22:06:46,582][26288] Updated weights for policy 0, policy_version 83352 (0.0003)
[2023-08-31 22:06:48,107][26276] Fps is (10 sec: 13106.3, 60 sec: 15496.5, 300 sec: 16036.8). Total num frames: 42692608. Throughput: 0: 15340.3. Samples: 30757307. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:06:48,107][26276] Avg episode reward: [(0, '-1799.806')]
[2023-08-31 22:06:49,501][26288] Updated weights for policy 0, policy_version 83432 (0.0002)
[2023-08-31 22:06:52,008][26288] Updated weights for policy 0, policy_version 83512 (0.0002)
[2023-08-31 22:06:53,108][26276] Fps is (10 sec: 14335.7, 60 sec: 15565.0, 300 sec: 16050.9). Total num frames: 42774528. Throughput: 0: 15252.6. Samples: 30846996. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:06:53,108][26276] Avg episode reward: [(0, '-1799.806')]
[2023-08-31 22:06:54,708][26288] Updated weights for policy 0, policy_version 83592 (0.0002)
[2023-08-31 22:06:57,290][26288] Updated weights for policy 0, policy_version 83672 (0.0002)
[2023-08-31 22:06:58,105][26276] Fps is (10 sec: 15976.7, 60 sec: 15428.2, 300 sec: 16036.9). Total num frames: 42852352. Throughput: 0: 15187.5. Samples: 30892662. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[2023-08-31 22:06:58,105][26276] Avg episode reward: [(0, '-1800.499')]
[2023-08-31 22:06:59,750][26288] Updated weights for policy 0, policy_version 83752 (0.0002)
[2023-08-31 22:07:02,242][26288] Updated weights for policy 0, policy_version 83832 (0.0002)
[2023-08-31 22:07:03,106][26276] Fps is (10 sec: 15978.3, 60 sec: 15497.7, 300 sec: 16036.9). Total num frames: 42934272. Throughput: 0: 15293.3. Samples: 30991513. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[2023-08-31 22:07:03,106][26276] Avg episode reward: [(0, '-1800.499')]
[2023-08-31 22:07:05,080][26288] Updated weights for policy 0, policy_version 83912 (0.0003)
[2023-08-31 22:07:07,583][26288] Updated weights for policy 0, policy_version 83992 (0.0002)
[2023-08-31 22:07:08,110][26276] Fps is (10 sec: 15966.6, 60 sec: 15427.3, 300 sec: 16023.0). Total num frames: 43012096. Throughput: 0: 15140.7. Samples: 31084396. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[2023-08-31 22:07:08,110][26276] Avg episode reward: [(0, '-1801.451')]
[2023-08-31 22:07:10,079][26288] Updated weights for policy 0, policy_version 84072 (0.0002)
[2023-08-31 22:07:13,105][26276] Fps is (10 sec: 14746.2, 60 sec: 15292.9, 300 sec: 15995.5). Total num frames: 43081728. Throughput: 0: 15182.6. Samples: 31133638. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[2023-08-31 22:07:13,105][26276] Avg episode reward: [(0, '-1801.451')]
[2023-08-31 22:07:13,136][26288] Updated weights for policy 0, policy_version 84152 (0.0002)
[2023-08-31 22:07:16,054][26288] Updated weights for policy 0, policy_version 84232 (0.0002)
[2023-08-31 22:07:18,109][26276] Fps is (10 sec: 13927.8, 60 sec: 15086.3, 300 sec: 15939.5). Total num frames: 43151360. Throughput: 0: 14763.1. Samples: 31214581. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[2023-08-31 22:07:18,110][26276] Avg episode reward: [(0, '-1806.043')]
[2023-08-31 22:07:18,981][26288] Updated weights for policy 0, policy_version 84312 (0.0002)
[2023-08-31 22:07:21,583][26288] Updated weights for policy 0, policy_version 84392 (0.0002)
[2023-08-31 22:07:23,106][26276] Fps is (10 sec: 14744.3, 60 sec: 15019.2, 300 sec: 15939.9). Total num frames: 43229184. Throughput: 0: 14906.3. Samples: 31304846. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[2023-08-31 22:07:23,106][26276] Avg episode reward: [(0, '-1806.043')]
[2023-08-31 22:07:23,109][26287] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000084432_43229184.pth...
[2023-08-31 22:07:23,111][26287] Removing /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000078256_40067072.pth
[2023-08-31 22:07:24,155][26288] Updated weights for policy 0, policy_version 84472 (0.0002)
[2023-08-31 22:07:26,934][26288] Updated weights for policy 0, policy_version 84552 (0.0002)
[2023-08-31 22:07:28,108][26276] Fps is (10 sec: 15566.0, 60 sec: 14949.6, 300 sec: 15911.9). Total num frames: 43307008. Throughput: 0: 14966.1. Samples: 31351162. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[2023-08-31 22:07:28,109][26276] Avg episode reward: [(0, '-1811.548')]
[2023-08-31 22:07:29,379][26288] Updated weights for policy 0, policy_version 84632 (0.0002)
[2023-08-31 22:07:31,933][26288] Updated weights for policy 0, policy_version 84712 (0.0002)
[2023-08-31 22:07:33,105][26276] Fps is (10 sec: 15976.0, 60 sec: 14950.5, 300 sec: 15926.1). Total num frames: 43388928. Throughput: 0: 15327.2. Samples: 31447008. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[2023-08-31 22:07:33,105][26276] Avg episode reward: [(0, '-1811.548')]
[2023-08-31 22:07:34,400][26288] Updated weights for policy 0, policy_version 84792 (0.0002)
[2023-08-31 22:07:37,208][26288] Updated weights for policy 0, policy_version 84872 (0.0002)
[2023-08-31 22:07:38,105][26276] Fps is (10 sec: 15979.2, 60 sec: 15087.1, 300 sec: 15911.9). Total num frames: 43466752. Throughput: 0: 15411.0. Samples: 31540453. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[2023-08-31 22:07:38,106][26276] Avg episode reward: [(0, '-1807.409')]
[2023-08-31 22:07:39,728][26288] Updated weights for policy 0, policy_version 84952 (0.0002)
[2023-08-31 22:07:42,285][26288] Updated weights for policy 0, policy_version 85032 (0.0003)
[2023-08-31 22:07:43,106][26276] Fps is (10 sec: 15973.3, 60 sec: 15292.2, 300 sec: 15912.0). Total num frames: 43548672. Throughput: 0: 15466.5. Samples: 31588660. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[2023-08-31 22:07:43,106][26276] Avg episode reward: [(0, '-1807.409')]
[2023-08-31 22:07:44,753][26288] Updated weights for policy 0, policy_version 85112 (0.0002)
[2023-08-31 22:07:47,561][26288] Updated weights for policy 0, policy_version 85192 (0.0002)
[2023-08-31 22:07:48,106][26276] Fps is (10 sec: 15972.7, 60 sec: 15564.9, 300 sec: 15898.0). Total num frames: 43626496. Throughput: 0: 15370.2. Samples: 31683184. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:07:48,107][26276] Avg episode reward: [(0, '-1801.756')]
[2023-08-31 22:07:50,134][26288] Updated weights for policy 0, policy_version 85272 (0.0002)
[2023-08-31 22:07:52,741][26288] Updated weights for policy 0, policy_version 85352 (0.0002)
[2023-08-31 22:07:53,109][26276] Fps is (10 sec: 15560.2, 60 sec: 15496.3, 300 sec: 15897.9). Total num frames: 43704320. Throughput: 0: 15427.5. Samples: 31778611. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:07:53,109][26276] Avg episode reward: [(0, '-1801.756')]
[2023-08-31 22:07:55,302][26288] Updated weights for policy 0, policy_version 85432 (0.0002)
[2023-08-31 22:07:58,110][26276] Fps is (10 sec: 15149.8, 60 sec: 15427.0, 300 sec: 15870.1). Total num frames: 43778048. Throughput: 0: 15382.8. Samples: 31825941. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:07:58,110][26276] Avg episode reward: [(0, '-1802.519')]
[2023-08-31 22:07:58,114][26288] Updated weights for policy 0, policy_version 85512 (0.0002)
[2023-08-31 22:08:00,689][26288] Updated weights for policy 0, policy_version 85592 (0.0002)
[2023-08-31 22:08:03,109][26276] Fps is (10 sec: 15564.7, 60 sec: 15427.4, 300 sec: 15884.0). Total num frames: 43859968. Throughput: 0: 15628.4. Samples: 31917855. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:08:03,109][26276] Avg episode reward: [(0, '-1802.519')]
[2023-08-31 22:08:03,116][26288] Updated weights for policy 0, policy_version 85672 (0.0002)
[2023-08-31 22:08:05,714][26288] Updated weights for policy 0, policy_version 85752 (0.0002)
[2023-08-31 22:08:08,110][26276] Fps is (10 sec: 15975.0, 60 sec: 15428.4, 300 sec: 15856.2). Total num frames: 43937792. Throughput: 0: 15728.5. Samples: 32012686. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:08:08,110][26276] Avg episode reward: [(0, '-1803.173')]
[2023-08-31 22:08:08,380][26288] Updated weights for policy 0, policy_version 85832 (0.0002)
[2023-08-31 22:08:10,903][26288] Updated weights for policy 0, policy_version 85912 (0.0002)
[2023-08-31 22:08:13,105][26276] Fps is (10 sec: 15979.8, 60 sec: 15633.0, 300 sec: 15870.5). Total num frames: 44019712. Throughput: 0: 15791.3. Samples: 32061725. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:08:13,106][26276] Avg episode reward: [(0, '-1803.173')]
[2023-08-31 22:08:13,443][26288] Updated weights for policy 0, policy_version 85992 (0.0002)
[2023-08-31 22:08:15,957][26288] Updated weights for policy 0, policy_version 86072 (0.0002)
[2023-08-31 22:08:18,109][26276] Fps is (10 sec: 15975.9, 60 sec: 15769.7, 300 sec: 15856.3). Total num frames: 44097536. Throughput: 0: 15816.9. Samples: 32158825. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:08:18,109][26276] Avg episode reward: [(0, '-1801.597')]
[2023-08-31 22:08:18,777][26288] Updated weights for policy 0, policy_version 86152 (0.0002)
[2023-08-31 22:08:21,427][26288] Updated weights for policy 0, policy_version 86232 (0.0002)
[2023-08-31 22:08:23,106][26276] Fps is (10 sec: 15563.3, 60 sec: 15769.5, 300 sec: 15842.5). Total num frames: 44175360. Throughput: 0: 15775.3. Samples: 32250357. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:08:23,107][26276] Avg episode reward: [(0, '-1801.597')]
[2023-08-31 22:08:23,923][26288] Updated weights for policy 0, policy_version 86312 (0.0002)
[2023-08-31 22:08:26,664][26288] Updated weights for policy 0, policy_version 86392 (0.0002)
[2023-08-31 22:08:28,106][26276] Fps is (10 sec: 15159.7, 60 sec: 15702.0, 300 sec: 15814.7). Total num frames: 44249088. Throughput: 0: 15751.0. Samples: 32297452. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:08:28,106][26276] Avg episode reward: [(0, '-1795.020')]
[2023-08-31 22:08:29,478][26288] Updated weights for policy 0, policy_version 86472 (0.0002)
[2023-08-31 22:08:32,088][26288] Updated weights for policy 0, policy_version 86552 (0.0002)
[2023-08-31 22:08:33,108][26276] Fps is (10 sec: 15152.4, 60 sec: 15632.2, 300 sec: 15828.7). Total num frames: 44326912. Throughput: 0: 15641.7. Samples: 32387088. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:08:33,108][26276] Avg episode reward: [(0, '-1795.020')]
[2023-08-31 22:08:34,747][26288] Updated weights for policy 0, policy_version 86632 (0.0002)
[2023-08-31 22:08:37,457][26288] Updated weights for policy 0, policy_version 86712 (0.0002)
[2023-08-31 22:08:38,106][26276] Fps is (10 sec: 15154.2, 60 sec: 15564.6, 300 sec: 15787.1). Total num frames: 44400640. Throughput: 0: 15553.4. Samples: 32478479. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:08:38,107][26276] Avg episode reward: [(0, '-1777.116')]
[2023-08-31 22:08:40,273][26288] Updated weights for policy 0, policy_version 86792 (0.0002)
[2023-08-31 22:08:42,952][26288] Updated weights for policy 0, policy_version 86872 (0.0002)
[2023-08-31 22:08:43,110][26276] Fps is (10 sec: 15152.2, 60 sec: 15495.4, 300 sec: 15773.0). Total num frames: 44478464. Throughput: 0: 15478.4. Samples: 32522470. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:08:43,110][26276] Avg episode reward: [(0, '-1777.116')]
[2023-08-31 22:08:45,523][26288] Updated weights for policy 0, policy_version 86952 (0.0002)
[2023-08-31 22:08:48,106][26276] Fps is (10 sec: 15565.5, 60 sec: 15496.7, 300 sec: 15759.4). Total num frames: 44556288. Throughput: 0: 15525.6. Samples: 32616464. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:08:48,106][26276] Avg episode reward: [(0, '-1778.547')]
[2023-08-31 22:08:48,475][26288] Updated weights for policy 0, policy_version 87032 (0.0002)
[2023-08-31 22:08:51,139][26288] Updated weights for policy 0, policy_version 87112 (0.0002)
[2023-08-31 22:08:53,109][26276] Fps is (10 sec: 14338.3, 60 sec: 15291.8, 300 sec: 15717.4). Total num frames: 44621824. Throughput: 0: 15319.4. Samples: 32702042. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:08:53,109][26276] Avg episode reward: [(0, '-1776.570')]
[2023-08-31 22:08:54,277][26288] Updated weights for policy 0, policy_version 87192 (0.0003)
[2023-08-31 22:08:56,977][26288] Updated weights for policy 0, policy_version 87272 (0.0002)
[2023-08-31 22:08:58,110][26276] Fps is (10 sec: 14330.0, 60 sec: 15360.0, 300 sec: 15703.5). Total num frames: 44699648. Throughput: 0: 15128.9. Samples: 32742598. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:08:58,110][26276] Avg episode reward: [(0, '-1776.570')]
[2023-08-31 22:08:59,699][26288] Updated weights for policy 0, policy_version 87352 (0.0003)
[2023-08-31 22:09:02,468][26288] Updated weights for policy 0, policy_version 87432 (0.0002)
[2023-08-31 22:09:03,109][26276] Fps is (10 sec: 15154.5, 60 sec: 15223.4, 300 sec: 15675.9). Total num frames: 44773376. Throughput: 0: 14993.9. Samples: 32833554. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:09:03,109][26276] Avg episode reward: [(0, '-1753.894')]
[2023-08-31 22:09:03,114][26287] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000087448_44773376.pth...
[2023-08-31 22:09:03,116][26287] Removing /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000081408_41680896.pth
[2023-08-31 22:09:05,216][26288] Updated weights for policy 0, policy_version 87512 (0.0002)
[2023-08-31 22:09:07,949][26288] Updated weights for policy 0, policy_version 87592 (0.0002)
[2023-08-31 22:09:08,109][26276] Fps is (10 sec: 14746.7, 60 sec: 15155.3, 300 sec: 15662.0). Total num frames: 44847104. Throughput: 0: 14914.2. Samples: 32921542. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:09:08,110][26276] Avg episode reward: [(0, '-1753.894')]
[2023-08-31 22:09:10,658][26288] Updated weights for policy 0, policy_version 87672 (0.0002)
[2023-08-31 22:09:13,110][26276] Fps is (10 sec: 14744.6, 60 sec: 15017.6, 300 sec: 15634.2). Total num frames: 44920832. Throughput: 0: 14876.2. Samples: 32966940. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:09:13,110][26276] Avg episode reward: [(0, '-1740.963')]
[2023-08-31 22:09:13,492][26288] Updated weights for policy 0, policy_version 87752 (0.0003)
[2023-08-31 22:09:16,187][26288] Updated weights for policy 0, policy_version 87832 (0.0002)
[2023-08-31 22:09:18,107][26276] Fps is (10 sec: 15159.0, 60 sec: 15019.1, 300 sec: 15606.4). Total num frames: 44998656. Throughput: 0: 14872.1. Samples: 33056313. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:09:18,107][26276] Avg episode reward: [(0, '-1740.963')]
[2023-08-31 22:09:18,867][26288] Updated weights for policy 0, policy_version 87912 (0.0002)
[2023-08-31 22:09:21,812][26288] Updated weights for policy 0, policy_version 87992 (0.0003)
[2023-08-31 22:09:23,107][26276] Fps is (10 sec: 14750.4, 60 sec: 14882.1, 300 sec: 15578.7). Total num frames: 45068288. Throughput: 0: 14808.2. Samples: 33144848. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:09:23,107][26276] Avg episode reward: [(0, '-1733.679')]
[2023-08-31 22:09:24,458][26288] Updated weights for policy 0, policy_version 88072 (0.0002)
[2023-08-31 22:09:27,067][26288] Updated weights for policy 0, policy_version 88152 (0.0002)
[2023-08-31 22:09:28,106][26276] Fps is (10 sec: 15156.9, 60 sec: 15018.7, 300 sec: 15578.7). Total num frames: 45150208. Throughput: 0: 14867.8. Samples: 33191453. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:09:28,106][26276] Avg episode reward: [(0, '-1733.679')]
[2023-08-31 22:09:29,549][26288] Updated weights for policy 0, policy_version 88232 (0.0002)
[2023-08-31 22:09:32,404][26288] Updated weights for policy 0, policy_version 88312 (0.0002)
[2023-08-31 22:09:33,110][26276] Fps is (10 sec: 15559.2, 60 sec: 14949.9, 300 sec: 15536.9). Total num frames: 45223936. Throughput: 0: 14829.8. Samples: 33283867. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 22:09:33,110][26276] Avg episode reward: [(0, '-1740.100')]
[2023-08-31 22:09:34,799][26288] Updated weights for policy 0, policy_version 88392 (0.0002)
[2023-08-31 22:09:37,399][26288] Updated weights for policy 0, policy_version 88472 (0.0002)
[2023-08-31 22:09:38,110][26276] Fps is (10 sec: 15558.0, 60 sec: 15086.0, 300 sec: 15550.9). Total num frames: 45305856. Throughput: 0: 15099.2. Samples: 33381529. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 22:09:38,110][26276] Avg episode reward: [(0, '-1740.100')]
[2023-08-31 22:09:39,952][26288] Updated weights for policy 0, policy_version 88552 (0.0002)
[2023-08-31 22:09:42,826][26288] Updated weights for policy 0, policy_version 88632 (0.0002)
[2023-08-31 22:09:43,106][26276] Fps is (10 sec: 15571.7, 60 sec: 15019.8, 300 sec: 15523.3). Total num frames: 45379584. Throughput: 0: 15249.5. Samples: 33428759. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 22:09:43,106][26276] Avg episode reward: [(0, '-1747.526')]
[2023-08-31 22:09:45,512][26288] Updated weights for policy 0, policy_version 88712 (0.0002)
[2023-08-31 22:09:48,107][26276] Fps is (10 sec: 15159.2, 60 sec: 15018.3, 300 sec: 15523.0). Total num frames: 45457408. Throughput: 0: 15196.8. Samples: 33517386. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 22:09:48,108][26276] Avg episode reward: [(0, '-1747.526')]
[2023-08-31 22:09:48,144][26288] Updated weights for policy 0, policy_version 88792 (0.0002)
[2023-08-31 22:09:50,782][26288] Updated weights for policy 0, policy_version 88872 (0.0002)
[2023-08-31 22:09:53,106][26276] Fps is (10 sec: 14744.3, 60 sec: 15087.5, 300 sec: 15495.3). Total num frames: 45527040. Throughput: 0: 15215.0. Samples: 33606171. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 22:09:53,107][26276] Avg episode reward: [(0, '-1732.578')]
[2023-08-31 22:09:54,264][26288] Updated weights for policy 0, policy_version 88952 (0.0003)
[2023-08-31 22:09:56,943][26288] Updated weights for policy 0, policy_version 89032 (0.0002)
[2023-08-31 22:09:58,106][26276] Fps is (10 sec: 14338.8, 60 sec: 15019.8, 300 sec: 15467.8). Total num frames: 45600768. Throughput: 0: 15059.4. Samples: 33644553. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 22:09:58,106][26276] Avg episode reward: [(0, '-1732.578')]
[2023-08-31 22:09:59,437][26288] Updated weights for policy 0, policy_version 89112 (0.0002)
[2023-08-31 22:10:02,105][26288] Updated weights for policy 0, policy_version 89192 (0.0002)
[2023-08-31 22:10:03,106][26276] Fps is (10 sec: 15156.0, 60 sec: 15087.7, 300 sec: 15453.7). Total num frames: 45678592. Throughput: 0: 15180.3. Samples: 33739414. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 22:10:03,107][26276] Avg episode reward: [(0, '-1731.649')]
[2023-08-31 22:10:05,039][26288] Updated weights for policy 0, policy_version 89272 (0.0002)
[2023-08-31 22:10:07,512][26288] Updated weights for policy 0, policy_version 89352 (0.0002)
[2023-08-31 22:10:08,108][26276] Fps is (10 sec: 15561.0, 60 sec: 15155.5, 300 sec: 15453.8). Total num frames: 45756416. Throughput: 0: 15218.9. Samples: 33829722. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 22:10:08,108][26276] Avg episode reward: [(0, '-1735.478')]
[2023-08-31 22:10:09,956][26288] Updated weights for policy 0, policy_version 89432 (0.0002)
[2023-08-31 22:10:12,408][26288] Updated weights for policy 0, policy_version 89512 (0.0002)
[2023-08-31 22:10:13,114][26276] Fps is (10 sec: 15962.1, 60 sec: 15290.7, 300 sec: 15453.5). Total num frames: 45838336. Throughput: 0: 15290.6. Samples: 33879652. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 22:10:13,114][26276] Avg episode reward: [(0, '-1738.025')]
[2023-08-31 22:10:15,173][26288] Updated weights for policy 0, policy_version 89592 (0.0002)
[2023-08-31 22:10:17,695][26288] Updated weights for policy 0, policy_version 89672 (0.0002)
[2023-08-31 22:10:18,109][26276] Fps is (10 sec: 15973.3, 60 sec: 15291.3, 300 sec: 15453.6). Total num frames: 45916160. Throughput: 0: 15350.4. Samples: 33974615. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 22:10:18,109][26276] Avg episode reward: [(0, '-1740.550')]
[2023-08-31 22:10:20,224][26288] Updated weights for policy 0, policy_version 89752 (0.0002)
[2023-08-31 22:10:22,735][26288] Updated weights for policy 0, policy_version 89832 (0.0002)
[2023-08-31 22:10:23,105][26276] Fps is (10 sec: 15987.6, 60 sec: 15496.8, 300 sec: 15453.7). Total num frames: 45998080. Throughput: 0: 15354.5. Samples: 34072408. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 22:10:23,106][26276] Avg episode reward: [(0, '-1736.795')]
[2023-08-31 22:10:25,456][26288] Updated weights for policy 0, policy_version 89912 (0.0002)
[2023-08-31 22:10:27,951][26288] Updated weights for policy 0, policy_version 89992 (0.0002)
[2023-08-31 22:10:28,106][26276] Fps is (10 sec: 15978.9, 60 sec: 15428.2, 300 sec: 15439.9). Total num frames: 46075904. Throughput: 0: 15306.2. Samples: 34117541. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2023-08-31 22:10:28,106][26276] Avg episode reward: [(0, '-1733.135')]
[2023-08-31 22:10:30,396][26288] Updated weights for policy 0, policy_version 90072 (0.0002)
[2023-08-31 22:10:33,105][26276] Fps is (10 sec: 15974.9, 60 sec: 15566.1, 300 sec: 15440.1). Total num frames: 46157824. Throughput: 0: 15529.1. Samples: 34216159. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2023-08-31 22:10:33,105][26288] Updated weights for policy 0, policy_version 90152 (0.0002)
[2023-08-31 22:10:33,106][26276] Avg episode reward: [(0, '-1722.819')]
[2023-08-31 22:10:36,103][26288] Updated weights for policy 0, policy_version 90232 (0.0002)
[2023-08-31 22:10:38,110][26276] Fps is (10 sec: 15148.8, 60 sec: 15360.0, 300 sec: 15411.8). Total num frames: 46227456. Throughput: 0: 15464.4. Samples: 34302125. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2023-08-31 22:10:38,110][26276] Avg episode reward: [(0, '-1709.910')]
[2023-08-31 22:10:38,763][26288] Updated weights for policy 0, policy_version 90312 (0.0002)
[2023-08-31 22:10:41,306][26288] Updated weights for policy 0, policy_version 90392 (0.0002)
[2023-08-31 22:10:43,108][26276] Fps is (10 sec: 14741.3, 60 sec: 15427.6, 300 sec: 15398.1). Total num frames: 46305280. Throughput: 0: 15655.8. Samples: 34349100. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2023-08-31 22:10:43,108][26276] Avg episode reward: [(0, '-1709.910')]
[2023-08-31 22:10:43,110][26287] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000090440_46305280.pth...
[2023-08-31 22:10:43,113][26287] Removing /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000084432_43229184.pth
[2023-08-31 22:10:44,170][26288] Updated weights for policy 0, policy_version 90472 (0.0002)
[2023-08-31 22:10:46,762][26288] Updated weights for policy 0, policy_version 90552 (0.0002)
[2023-08-31 22:10:48,107][26276] Fps is (10 sec: 15569.5, 60 sec: 15428.4, 300 sec: 15398.3). Total num frames: 46383104. Throughput: 0: 15563.0. Samples: 34439765. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2023-08-31 22:10:48,107][26276] Avg episode reward: [(0, '-1678.042')]
[2023-08-31 22:10:49,296][26288] Updated weights for policy 0, policy_version 90632 (0.0002)
[2023-08-31 22:10:51,786][26288] Updated weights for policy 0, policy_version 90712 (0.0002)
[2023-08-31 22:10:53,106][26276] Fps is (10 sec: 15977.7, 60 sec: 15633.2, 300 sec: 15384.3). Total num frames: 46465024. Throughput: 0: 15728.9. Samples: 34537488. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2023-08-31 22:10:53,106][26276] Avg episode reward: [(0, '-1678.042')]
[2023-08-31 22:10:54,548][26288] Updated weights for policy 0, policy_version 90792 (0.0003)
[2023-08-31 22:10:57,064][26288] Updated weights for policy 0, policy_version 90872 (0.0002)
[2023-08-31 22:10:58,109][26276] Fps is (10 sec: 15971.9, 60 sec: 15700.5, 300 sec: 15384.4). Total num frames: 46542848. Throughput: 0: 15632.4. Samples: 34583032. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2023-08-31 22:10:58,109][26276] Avg episode reward: [(0, '-1653.752')]
[2023-08-31 22:10:59,511][26288] Updated weights for policy 0, policy_version 90952 (0.0002)
[2023-08-31 22:11:02,049][26288] Updated weights for policy 0, policy_version 91032 (0.0002)
[2023-08-31 22:11:03,109][26276] Fps is (10 sec: 15559.5, 60 sec: 15700.4, 300 sec: 15370.3). Total num frames: 46620672. Throughput: 0: 15693.6. Samples: 34680838. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2023-08-31 22:11:03,110][26276] Avg episode reward: [(0, '-1653.752')]
[2023-08-31 22:11:05,081][26288] Updated weights for policy 0, policy_version 91112 (0.0002)
[2023-08-31 22:11:07,714][26288] Updated weights for policy 0, policy_version 91192 (0.0002)
[2023-08-31 22:11:08,106][26276] Fps is (10 sec: 15159.2, 60 sec: 15633.6, 300 sec: 15356.7). Total num frames: 46694400. Throughput: 0: 15472.6. Samples: 34768687. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2023-08-31 22:11:08,106][26276] Avg episode reward: [(0, '-1626.757')]
[2023-08-31 22:11:10,210][26288] Updated weights for policy 0, policy_version 91272 (0.0002)
[2023-08-31 22:11:12,948][26288] Updated weights for policy 0, policy_version 91352 (0.0002)
[2023-08-31 22:11:13,108][26276] Fps is (10 sec: 15156.7, 60 sec: 15566.2, 300 sec: 15342.6). Total num frames: 46772224. Throughput: 0: 15554.7. Samples: 34817542. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2023-08-31 22:11:13,109][26276] Avg episode reward: [(0, '-1626.757')]
[2023-08-31 22:11:15,914][26288] Updated weights for policy 0, policy_version 91432 (0.0002)
[2023-08-31 22:11:18,109][26276] Fps is (10 sec: 14741.2, 60 sec: 15428.2, 300 sec: 15300.9). Total num frames: 46841856. Throughput: 0: 15261.4. Samples: 34902981. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2023-08-31 22:11:18,109][26276] Avg episode reward: [(0, '-1597.639')]
[2023-08-31 22:11:18,695][26288] Updated weights for policy 0, policy_version 91512 (0.0002)
[2023-08-31 22:11:21,276][26288] Updated weights for policy 0, policy_version 91592 (0.0002)
[2023-08-31 22:11:23,106][26276] Fps is (10 sec: 15158.8, 60 sec: 15428.1, 300 sec: 15300.9). Total num frames: 46923776. Throughput: 0: 15426.2. Samples: 34996240. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 22:11:23,106][26276] Avg episode reward: [(0, '-1597.639')]
[2023-08-31 22:11:23,769][26288] Updated weights for policy 0, policy_version 91672 (0.0002)
[2023-08-31 22:11:26,504][26288] Updated weights for policy 0, policy_version 91752 (0.0002)
[2023-08-31 22:11:28,106][26276] Fps is (10 sec: 15978.4, 60 sec: 15428.1, 300 sec: 15287.0). Total num frames: 47001600. Throughput: 0: 15431.6. Samples: 35043499. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 22:11:28,107][26276] Avg episode reward: [(0, '-1584.603')]
[2023-08-31 22:11:29,083][26288] Updated weights for policy 0, policy_version 91832 (0.0002)
[2023-08-31 22:11:31,501][26288] Updated weights for policy 0, policy_version 91912 (0.0002)
[2023-08-31 22:11:33,108][26276] Fps is (10 sec: 15971.2, 60 sec: 15427.5, 300 sec: 15328.7). Total num frames: 47083520. Throughput: 0: 15555.6. Samples: 35139781. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 22:11:33,108][26276] Avg episode reward: [(0, '-1584.603')]
[2023-08-31 22:11:34,002][26288] Updated weights for policy 0, policy_version 91992 (0.0002)
[2023-08-31 22:11:36,797][26288] Updated weights for policy 0, policy_version 92072 (0.0002)
[2023-08-31 22:11:38,110][26276] Fps is (10 sec: 15968.7, 60 sec: 15564.8, 300 sec: 15356.4). Total num frames: 47161344. Throughput: 0: 15477.5. Samples: 35234039. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 22:11:38,110][26276] Avg episode reward: [(0, '-1580.915')]
[2023-08-31 22:11:39,255][26288] Updated weights for policy 0, policy_version 92152 (0.0002)
[2023-08-31 22:11:41,674][26288] Updated weights for policy 0, policy_version 92232 (0.0002)
[2023-08-31 22:11:43,109][26276] Fps is (10 sec: 15972.2, 60 sec: 15632.7, 300 sec: 15425.8). Total num frames: 47243264. Throughput: 0: 15580.7. Samples: 35284176. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 22:11:43,110][26276] Avg episode reward: [(0, '-1580.915')]
[2023-08-31 22:11:44,180][26288] Updated weights for policy 0, policy_version 92312 (0.0002)
[2023-08-31 22:11:46,893][26288] Updated weights for policy 0, policy_version 92392 (0.0002)
[2023-08-31 22:11:48,106][26276] Fps is (10 sec: 15981.4, 60 sec: 15633.4, 300 sec: 15412.2). Total num frames: 47321088. Throughput: 0: 15531.9. Samples: 35379716. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 22:11:48,106][26276] Avg episode reward: [(0, '-1586.044')]
[2023-08-31 22:11:49,397][26288] Updated weights for policy 0, policy_version 92472 (0.0002)
[2023-08-31 22:11:51,790][26288] Updated weights for policy 0, policy_version 92552 (0.0002)
[2023-08-31 22:11:53,106][26276] Fps is (10 sec: 16390.0, 60 sec: 15701.4, 300 sec: 15439.8). Total num frames: 47407104. Throughput: 0: 15797.5. Samples: 35479570. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 22:11:53,106][26276] Avg episode reward: [(0, '-1586.044')]
[2023-08-31 22:11:54,353][26288] Updated weights for policy 0, policy_version 92632 (0.0002)
[2023-08-31 22:11:57,192][26288] Updated weights for policy 0, policy_version 92712 (0.0002)
[2023-08-31 22:11:58,110][26276] Fps is (10 sec: 15968.1, 60 sec: 15632.8, 300 sec: 15411.9). Total num frames: 47480832. Throughput: 0: 15690.2. Samples: 35523620. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 22:11:58,110][26276] Avg episode reward: [(0, '-1586.773')]
[2023-08-31 22:11:59,638][26288] Updated weights for policy 0, policy_version 92792 (0.0002)
[2023-08-31 22:12:02,151][26288] Updated weights for policy 0, policy_version 92872 (0.0002)
[2023-08-31 22:12:03,105][26276] Fps is (10 sec: 15565.1, 60 sec: 15702.3, 300 sec: 15426.2). Total num frames: 47562752. Throughput: 0: 15959.6. Samples: 35621105. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 22:12:03,106][26276] Avg episode reward: [(0, '-1586.773')]
[2023-08-31 22:12:04,670][26288] Updated weights for policy 0, policy_version 92952 (0.0002)
[2023-08-31 22:12:07,560][26288] Updated weights for policy 0, policy_version 93032 (0.0002)
[2023-08-31 22:12:08,106][26276] Fps is (10 sec: 15979.6, 60 sec: 15769.5, 300 sec: 15453.7). Total num frames: 47640576. Throughput: 0: 15935.0. Samples: 35713320. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 22:12:08,107][26276] Avg episode reward: [(0, '-1579.733')]
[2023-08-31 22:12:09,989][26288] Updated weights for policy 0, policy_version 93112 (0.0002)
[2023-08-31 22:12:12,688][26288] Updated weights for policy 0, policy_version 93192 (0.0002)
[2023-08-31 22:12:13,108][26276] Fps is (10 sec: 15561.0, 60 sec: 15769.7, 300 sec: 15481.6). Total num frames: 47718400. Throughput: 0: 15976.8. Samples: 35762476. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 22:12:13,108][26276] Avg episode reward: [(0, '-1579.733')]
[2023-08-31 22:12:15,075][26288] Updated weights for policy 0, policy_version 93272 (0.0002)
[2023-08-31 22:12:17,939][26288] Updated weights for policy 0, policy_version 93352 (0.0002)
[2023-08-31 22:12:18,109][26276] Fps is (10 sec: 15560.7, 60 sec: 15906.1, 300 sec: 15481.3). Total num frames: 47796224. Throughput: 0: 15916.6. Samples: 35856044. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 22:12:18,109][26276] Avg episode reward: [(0, '-1580.339')]
[2023-08-31 22:12:20,416][26288] Updated weights for policy 0, policy_version 93432 (0.0002)
[2023-08-31 22:12:22,800][26288] Updated weights for policy 0, policy_version 93512 (0.0002)
[2023-08-31 22:12:23,106][26276] Fps is (10 sec: 16386.5, 60 sec: 15974.3, 300 sec: 15509.4). Total num frames: 47882240. Throughput: 0: 16002.1. Samples: 35954073. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:12:23,107][26276] Avg episode reward: [(0, '-1580.339')]
[2023-08-31 22:12:23,112][26287] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000093520_47882240.pth...
[2023-08-31 22:12:23,114][26287] Removing /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000087448_44773376.pth
[2023-08-31 22:12:25,499][26288] Updated weights for policy 0, policy_version 93592 (0.0002)
[2023-08-31 22:12:28,108][26276] Fps is (10 sec: 15975.3, 60 sec: 15905.6, 300 sec: 15481.3). Total num frames: 47955968. Throughput: 0: 15976.4. Samples: 36003099. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:12:28,109][26276] Avg episode reward: [(0, '-1564.941')]
[2023-08-31 22:12:28,162][26288] Updated weights for policy 0, policy_version 93672 (0.0002)
[2023-08-31 22:12:30,925][26288] Updated weights for policy 0, policy_version 93752 (0.0002)
[2023-08-31 22:12:33,107][26276] Fps is (10 sec: 15154.9, 60 sec: 15838.2, 300 sec: 15481.4). Total num frames: 48033792. Throughput: 0: 15826.5. Samples: 36091923. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:12:33,107][26276] Avg episode reward: [(0, '-1564.941')]
[2023-08-31 22:12:33,644][26288] Updated weights for policy 0, policy_version 93832 (0.0003)
[2023-08-31 22:12:36,465][26288] Updated weights for policy 0, policy_version 93912 (0.0002)
[2023-08-31 22:12:38,106][26276] Fps is (10 sec: 15158.4, 60 sec: 15770.6, 300 sec: 15453.7). Total num frames: 48107520. Throughput: 0: 15604.1. Samples: 36181765. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:12:38,107][26276] Avg episode reward: [(0, '-1546.482')]
[2023-08-31 22:12:38,892][26288] Updated weights for policy 0, policy_version 93992 (0.0002)
[2023-08-31 22:12:41,490][26288] Updated weights for policy 0, policy_version 94072 (0.0002)
[2023-08-31 22:12:43,109][26276] Fps is (10 sec: 15560.6, 60 sec: 15769.6, 300 sec: 15467.5). Total num frames: 48189440. Throughput: 0: 15736.9. Samples: 36231772. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:12:43,109][26276] Avg episode reward: [(0, '-1546.482')]
[2023-08-31 22:12:43,987][26288] Updated weights for policy 0, policy_version 94152 (0.0002)
[2023-08-31 22:12:46,773][26288] Updated weights for policy 0, policy_version 94232 (0.0002)
[2023-08-31 22:12:48,107][26276] Fps is (10 sec: 15972.8, 60 sec: 15769.2, 300 sec: 15467.7). Total num frames: 48267264. Throughput: 0: 15613.0. Samples: 36323719. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:12:48,108][26276] Avg episode reward: [(0, '-1532.431')]
[2023-08-31 22:12:49,277][26288] Updated weights for policy 0, policy_version 94312 (0.0002)
[2023-08-31 22:12:51,815][26288] Updated weights for policy 0, policy_version 94392 (0.0002)
[2023-08-31 22:12:53,107][26276] Fps is (10 sec: 15568.2, 60 sec: 15632.7, 300 sec: 15481.6). Total num frames: 48345088. Throughput: 0: 15726.1. Samples: 36421005. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:12:53,107][26276] Avg episode reward: [(0, '-1532.431')]
[2023-08-31 22:12:54,384][26288] Updated weights for policy 0, policy_version 94472 (0.0002)
[2023-08-31 22:12:57,195][26288] Updated weights for policy 0, policy_version 94552 (0.0002)
[2023-08-31 22:12:58,106][26276] Fps is (10 sec: 15566.7, 60 sec: 15702.2, 300 sec: 15467.7). Total num frames: 48422912. Throughput: 0: 15686.4. Samples: 36468338. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:12:58,106][26276] Avg episode reward: [(0, '-1522.229')]
[2023-08-31 22:12:59,619][26288] Updated weights for policy 0, policy_version 94632 (0.0002)
[2023-08-31 22:13:02,157][26288] Updated weights for policy 0, policy_version 94712 (0.0002)
[2023-08-31 22:13:03,110][26276] Fps is (10 sec: 15969.7, 60 sec: 15700.2, 300 sec: 15481.5). Total num frames: 48504832. Throughput: 0: 15718.9. Samples: 36563412. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:13:03,110][26276] Avg episode reward: [(0, '-1522.229')]
[2023-08-31 22:13:04,644][26288] Updated weights for policy 0, policy_version 94792 (0.0002)
[2023-08-31 22:13:07,429][26288] Updated weights for policy 0, policy_version 94872 (0.0002)
[2023-08-31 22:13:08,110][26276] Fps is (10 sec: 15968.2, 60 sec: 15700.4, 300 sec: 15467.4). Total num frames: 48582656. Throughput: 0: 15615.2. Samples: 36656815. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:13:08,110][26276] Avg episode reward: [(0, '-1523.205')]
[2023-08-31 22:13:09,820][26288] Updated weights for policy 0, policy_version 94952 (0.0002)
[2023-08-31 22:13:12,393][26288] Updated weights for policy 0, policy_version 95032 (0.0002)
[2023-08-31 22:13:13,110][26276] Fps is (10 sec: 15974.0, 60 sec: 15769.0, 300 sec: 15481.4). Total num frames: 48664576. Throughput: 0: 15672.1. Samples: 36708373. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:13:13,110][26276] Avg episode reward: [(0, '-1523.205')]
[2023-08-31 22:13:14,863][26288] Updated weights for policy 0, policy_version 95112 (0.0002)
[2023-08-31 22:13:17,758][26288] Updated weights for policy 0, policy_version 95192 (0.0002)
[2023-08-31 22:13:18,108][26276] Fps is (10 sec: 15977.6, 60 sec: 15769.8, 300 sec: 15481.4). Total num frames: 48742400. Throughput: 0: 15802.0. Samples: 36803038. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:13:18,108][26276] Avg episode reward: [(0, '-1519.696')]
[2023-08-31 22:13:20,264][26288] Updated weights for policy 0, policy_version 95272 (0.0002)
[2023-08-31 22:13:22,834][26288] Updated weights for policy 0, policy_version 95352 (0.0002)
[2023-08-31 22:13:23,105][26276] Fps is (10 sec: 15982.9, 60 sec: 15701.7, 300 sec: 15509.3). Total num frames: 48824320. Throughput: 0: 15889.3. Samples: 36896761. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:13:23,105][26276] Avg episode reward: [(0, '-1519.696')]
[2023-08-31 22:13:25,404][26288] Updated weights for policy 0, policy_version 95432 (0.0002)
[2023-08-31 22:13:28,109][26276] Fps is (10 sec: 15563.0, 60 sec: 15701.1, 300 sec: 15495.3). Total num frames: 48898048. Throughput: 0: 15839.0. Samples: 36944528. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:13:28,110][26276] Avg episode reward: [(0, '-1521.681')]
[2023-08-31 22:13:28,271][26288] Updated weights for policy 0, policy_version 95512 (0.0002)
[2023-08-31 22:13:31,237][26288] Updated weights for policy 0, policy_version 95592 (0.0002)
[2023-08-31 22:13:33,106][26276] Fps is (10 sec: 14743.8, 60 sec: 15633.2, 300 sec: 15495.4). Total num frames: 48971776. Throughput: 0: 15668.5. Samples: 37028783. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:13:33,106][26276] Avg episode reward: [(0, '-1521.681')]
[2023-08-31 22:13:33,674][26288] Updated weights for policy 0, policy_version 95672 (0.0002)
[2023-08-31 22:13:36,033][26288] Updated weights for policy 0, policy_version 95752 (0.0002)
[2023-08-31 22:13:38,109][26276] Fps is (10 sec: 15565.7, 60 sec: 15769.0, 300 sec: 15509.3). Total num frames: 49053696. Throughput: 0: 15669.6. Samples: 37126160. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:13:38,110][26276] Avg episode reward: [(0, '-1514.238')]
[2023-08-31 22:13:38,874][26288] Updated weights for policy 0, policy_version 95832 (0.0002)
[2023-08-31 22:13:41,784][26288] Updated weights for policy 0, policy_version 95912 (0.0003)
[2023-08-31 22:13:43,109][26276] Fps is (10 sec: 15151.3, 60 sec: 15564.9, 300 sec: 15481.3). Total num frames: 49123328. Throughput: 0: 15618.6. Samples: 37171216. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:13:43,109][26276] Avg episode reward: [(0, '-1514.238')]
[2023-08-31 22:13:44,887][26288] Updated weights for policy 0, policy_version 95992 (0.0002)
[2023-08-31 22:13:47,620][26288] Updated weights for policy 0, policy_version 96072 (0.0002)
[2023-08-31 22:13:48,106][26276] Fps is (10 sec: 13929.9, 60 sec: 15428.6, 300 sec: 15495.5). Total num frames: 49192960. Throughput: 0: 15340.6. Samples: 37253680. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:13:48,106][26276] Avg episode reward: [(0, '-1514.238')]
[2023-08-31 22:13:51,000][26288] Updated weights for policy 0, policy_version 96152 (0.0003)
[2023-08-31 22:13:53,107][26276] Fps is (10 sec: 13518.8, 60 sec: 15223.4, 300 sec: 15453.9). Total num frames: 49258496. Throughput: 0: 15053.9. Samples: 37334198. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:13:53,107][26276] Avg episode reward: [(0, '-1504.340')]
[2023-08-31 22:13:53,664][26288] Updated weights for policy 0, policy_version 96232 (0.0002)
[2023-08-31 22:13:56,285][26288] Updated weights for policy 0, policy_version 96312 (0.0002)
[2023-08-31 22:13:58,110][26276] Fps is (10 sec: 14330.2, 60 sec: 15222.5, 300 sec: 15467.5). Total num frames: 49336320. Throughput: 0: 14950.7. Samples: 37381152. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:13:58,111][26276] Avg episode reward: [(0, '-1504.340')]
[2023-08-31 22:13:59,379][26288] Updated weights for policy 0, policy_version 96392 (0.0002)
[2023-08-31 22:14:02,476][26288] Updated weights for policy 0, policy_version 96472 (0.0002)
[2023-08-31 22:14:03,106][26276] Fps is (10 sec: 14337.7, 60 sec: 14951.4, 300 sec: 15440.0). Total num frames: 49401856. Throughput: 0: 14606.2. Samples: 37460286. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:14:03,106][26276] Avg episode reward: [(0, '-1489.911')]
[2023-08-31 22:14:03,110][26287] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000096488_49401856.pth...
[2023-08-31 22:14:03,111][26287] Removing /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000090440_46305280.pth
[2023-08-31 22:14:04,969][26288] Updated weights for policy 0, policy_version 96552 (0.0002)
[2023-08-31 22:14:07,531][26288] Updated weights for policy 0, policy_version 96632 (0.0002)
[2023-08-31 22:14:08,106][26276] Fps is (10 sec: 14751.2, 60 sec: 15019.6, 300 sec: 15467.8). Total num frames: 49483776. Throughput: 0: 14663.5. Samples: 37556639. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:14:08,107][26276] Avg episode reward: [(0, '-1489.911')]
[2023-08-31 22:14:09,968][26288] Updated weights for policy 0, policy_version 96712 (0.0002)
[2023-08-31 22:14:12,903][26288] Updated weights for policy 0, policy_version 96792 (0.0002)
[2023-08-31 22:14:13,107][26276] Fps is (10 sec: 15562.7, 60 sec: 14882.8, 300 sec: 15453.7). Total num frames: 49557504. Throughput: 0: 14650.5. Samples: 37603772. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:14:13,108][26276] Avg episode reward: [(0, '-1464.693')]
[2023-08-31 22:14:15,611][26288] Updated weights for policy 0, policy_version 96872 (0.0002)
[2023-08-31 22:14:18,106][26276] Fps is (10 sec: 15155.1, 60 sec: 14882.5, 300 sec: 15481.5). Total num frames: 49635328. Throughput: 0: 14797.1. Samples: 37694654. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:14:18,107][26276] Avg episode reward: [(0, '-1464.693')]
[2023-08-31 22:14:18,225][26288] Updated weights for policy 0, policy_version 96952 (0.0002)
[2023-08-31 22:14:21,031][26288] Updated weights for policy 0, policy_version 97032 (0.0003)
[2023-08-31 22:14:23,110][26276] Fps is (10 sec: 15560.6, 60 sec: 14812.6, 300 sec: 15467.4). Total num frames: 49713152. Throughput: 0: 14673.7. Samples: 37786499. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:14:23,110][26276] Avg episode reward: [(0, '-1436.707')]
[2023-08-31 22:14:23,465][26288] Updated weights for policy 0, policy_version 97112 (0.0002)
[2023-08-31 22:14:25,808][26288] Updated weights for policy 0, policy_version 97192 (0.0002)
[2023-08-31 22:14:28,106][26276] Fps is (10 sec: 16385.3, 60 sec: 15019.6, 300 sec: 15509.5). Total num frames: 49799168. Throughput: 0: 14815.4. Samples: 37837864. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:14:28,106][26276] Avg episode reward: [(0, '-1436.707')]
[2023-08-31 22:14:28,225][26288] Updated weights for policy 0, policy_version 97272 (0.0002)
[2023-08-31 22:14:30,866][26288] Updated weights for policy 0, policy_version 97352 (0.0002)
[2023-08-31 22:14:33,110][26276] Fps is (10 sec: 16793.6, 60 sec: 15154.2, 300 sec: 15509.3). Total num frames: 49881088. Throughput: 0: 15161.8. Samples: 37936018. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:14:33,110][26276] Avg episode reward: [(0, '-1406.060')]
[2023-08-31 22:14:33,111][26287] Saving new best policy, reward=-1406.060!
[2023-08-31 22:14:33,333][26288] Updated weights for policy 0, policy_version 97432 (0.0002)
[2023-08-31 22:14:35,868][26288] Updated weights for policy 0, policy_version 97512 (0.0002)
[2023-08-31 22:14:38,105][26276] Fps is (10 sec: 15975.0, 60 sec: 15087.8, 300 sec: 15523.2). Total num frames: 49958912. Throughput: 0: 15563.3. Samples: 38034516. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:14:38,105][26276] Avg episode reward: [(0, '-1406.060')]
[2023-08-31 22:14:38,341][26288] Updated weights for policy 0, policy_version 97592 (0.0002)
[2023-08-31 22:14:41,056][26288] Updated weights for policy 0, policy_version 97672 (0.0002)
[2023-08-31 22:14:43,108][26276] Fps is (10 sec: 15977.4, 60 sec: 15291.9, 300 sec: 15537.0). Total num frames: 50040832. Throughput: 0: 15592.8. Samples: 38082798. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:14:43,108][26276] Avg episode reward: [(0, '-1377.083')]
[2023-08-31 22:14:43,109][26287] Saving new best policy, reward=-1377.083!
[2023-08-31 22:14:43,547][26288] Updated weights for policy 0, policy_version 97752 (0.0002)
[2023-08-31 22:14:46,014][26288] Updated weights for policy 0, policy_version 97832 (0.0002)
[2023-08-31 22:14:48,108][26276] Fps is (10 sec: 16379.4, 60 sec: 15496.0, 300 sec: 15578.6). Total num frames: 50122752. Throughput: 0: 15967.1. Samples: 38178837. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:14:48,108][26276] Avg episode reward: [(0, '-1377.083')]
[2023-08-31 22:14:48,548][26288] Updated weights for policy 0, policy_version 97912 (0.0002)
[2023-08-31 22:14:51,254][26288] Updated weights for policy 0, policy_version 97992 (0.0002)
[2023-08-31 22:14:53,108][26276] Fps is (10 sec: 15974.5, 60 sec: 15701.1, 300 sec: 15592.4). Total num frames: 50200576. Throughput: 0: 15934.1. Samples: 38273702. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:14:53,108][26276] Avg episode reward: [(0, '-1350.759')]
[2023-08-31 22:14:53,109][26287] Saving new best policy, reward=-1350.759!
[2023-08-31 22:14:53,743][26288] Updated weights for policy 0, policy_version 98072 (0.0002)
[2023-08-31 22:14:56,407][26288] Updated weights for policy 0, policy_version 98152 (0.0002)
[2023-08-31 22:14:58,109][26276] Fps is (10 sec: 15563.8, 60 sec: 15701.7, 300 sec: 15592.4). Total num frames: 50278400. Throughput: 0: 15960.6. Samples: 38322022. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:14:58,109][26276] Avg episode reward: [(0, '-1350.759')]
[2023-08-31 22:14:58,964][26288] Updated weights for policy 0, policy_version 98232 (0.0002)
[2023-08-31 22:15:01,772][26288] Updated weights for policy 0, policy_version 98312 (0.0002)
[2023-08-31 22:15:03,108][26276] Fps is (10 sec: 15564.7, 60 sec: 15905.6, 300 sec: 15592.6). Total num frames: 50356224. Throughput: 0: 15959.5. Samples: 38412860. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:15:03,108][26276] Avg episode reward: [(0, '-1324.236')]
[2023-08-31 22:15:03,109][26287] Saving new best policy, reward=-1324.236!
[2023-08-31 22:15:04,153][26288] Updated weights for policy 0, policy_version 98392 (0.0002)
[2023-08-31 22:15:06,714][26288] Updated weights for policy 0, policy_version 98472 (0.0002)
[2023-08-31 22:15:08,110][26276] Fps is (10 sec: 15972.2, 60 sec: 15905.1, 300 sec: 15592.8). Total num frames: 50438144. Throughput: 0: 16117.1. Samples: 38511767. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:15:08,110][26276] Avg episode reward: [(0, '-1324.236')]
[2023-08-31 22:15:09,195][26288] Updated weights for policy 0, policy_version 98552 (0.0002)
[2023-08-31 22:15:11,917][26288] Updated weights for policy 0, policy_version 98632 (0.0002)
[2023-08-31 22:15:13,109][26276] Fps is (10 sec: 15973.5, 60 sec: 15974.1, 300 sec: 15592.6). Total num frames: 50515968. Throughput: 0: 16087.7. Samples: 38561861. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:15:13,109][26276] Avg episode reward: [(0, '-1301.573')]
[2023-08-31 22:15:13,109][26287] Saving new best policy, reward=-1301.573!
[2023-08-31 22:15:14,368][26288] Updated weights for policy 0, policy_version 98712 (0.0002)
[2023-08-31 22:15:16,814][26288] Updated weights for policy 0, policy_version 98792 (0.0002)
[2023-08-31 22:15:18,105][26276] Fps is (10 sec: 16392.0, 60 sec: 16111.3, 300 sec: 15606.5). Total num frames: 50601984. Throughput: 0: 16047.2. Samples: 38658064. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 22:15:18,106][26276] Avg episode reward: [(0, '-1301.573')]
[2023-08-31 22:15:19,168][26288] Updated weights for policy 0, policy_version 98872 (0.0002)
[2023-08-31 22:15:21,870][26288] Updated weights for policy 0, policy_version 98952 (0.0002)
[2023-08-31 22:15:23,105][26276] Fps is (10 sec: 16390.0, 60 sec: 16112.3, 300 sec: 15606.5). Total num frames: 50679808. Throughput: 0: 16023.4. Samples: 38755563. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 22:15:23,105][26276] Avg episode reward: [(0, '-1288.134')]
[2023-08-31 22:15:23,105][26287] Saving new best policy, reward=-1288.134!
[2023-08-31 22:15:24,401][26288] Updated weights for policy 0, policy_version 99032 (0.0002)
[2023-08-31 22:15:26,834][26288] Updated weights for policy 0, policy_version 99112 (0.0002)
[2023-08-31 22:15:28,105][26276] Fps is (10 sec: 16383.5, 60 sec: 16111.0, 300 sec: 15620.3). Total num frames: 50765824. Throughput: 0: 16056.2. Samples: 38805286. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 22:15:28,106][26276] Avg episode reward: [(0, '-1288.134')]
[2023-08-31 22:15:29,361][26288] Updated weights for policy 0, policy_version 99192 (0.0002)
[2023-08-31 22:15:31,945][26288] Updated weights for policy 0, policy_version 99272 (0.0002)
[2023-08-31 22:15:33,110][26276] Fps is (10 sec: 16375.5, 60 sec: 16042.6, 300 sec: 15648.1). Total num frames: 50843648. Throughput: 0: 16027.5. Samples: 38900107. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 22:15:33,110][26276] Avg episode reward: [(0, '-1280.484')]
[2023-08-31 22:15:33,111][26287] Saving new best policy, reward=-1280.484!
[2023-08-31 22:15:34,435][26288] Updated weights for policy 0, policy_version 99352 (0.0002)
[2023-08-31 22:15:36,942][26288] Updated weights for policy 0, policy_version 99432 (0.0002)
[2023-08-31 22:15:38,106][26276] Fps is (10 sec: 15973.6, 60 sec: 16110.7, 300 sec: 15662.1). Total num frames: 50925568. Throughput: 0: 16132.6. Samples: 38999638. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 22:15:38,106][26276] Avg episode reward: [(0, '-1280.484')]
[2023-08-31 22:15:39,385][26288] Updated weights for policy 0, policy_version 99512 (0.0002)
[2023-08-31 22:15:42,141][26288] Updated weights for policy 0, policy_version 99592 (0.0002)
[2023-08-31 22:15:43,109][26276] Fps is (10 sec: 15975.5, 60 sec: 16042.3, 300 sec: 15661.9). Total num frames: 51003392. Throughput: 0: 16106.2. Samples: 39046815. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 22:15:43,110][26276] Avg episode reward: [(0, '-1279.061')]
[2023-08-31 22:15:43,130][26287] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000099624_51007488.pth...
[2023-08-31 22:15:43,132][26287] Removing /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000093520_47882240.pth
[2023-08-31 22:15:43,132][26287] Saving new best policy, reward=-1279.061!
[2023-08-31 22:15:44,549][26288] Updated weights for policy 0, policy_version 99672 (0.0002)
[2023-08-31 22:15:46,971][26288] Updated weights for policy 0, policy_version 99752 (0.0002)
[2023-08-31 22:15:48,109][26276] Fps is (10 sec: 16379.3, 60 sec: 16110.7, 300 sec: 15675.7). Total num frames: 51089408. Throughput: 0: 16296.9. Samples: 39146235. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 22:15:48,109][26276] Avg episode reward: [(0, '-1279.061')]
[2023-08-31 22:15:49,506][26288] Updated weights for policy 0, policy_version 99832 (0.0002)
[2023-08-31 22:15:52,203][26288] Updated weights for policy 0, policy_version 99912 (0.0002)
[2023-08-31 22:15:53,108][26276] Fps is (10 sec: 16386.2, 60 sec: 16110.9, 300 sec: 15675.9). Total num frames: 51167232. Throughput: 0: 16214.2. Samples: 39241374. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 22:15:53,108][26276] Avg episode reward: [(0, '-1269.736')]
[2023-08-31 22:15:53,109][26287] Saving new best policy, reward=-1269.736!
[2023-08-31 22:15:54,742][26288] Updated weights for policy 0, policy_version 99992 (0.0002)
[2023-08-31 22:15:57,270][26288] Updated weights for policy 0, policy_version 100072 (0.0002)
[2023-08-31 22:15:58,106][26276] Fps is (10 sec: 15978.8, 60 sec: 16179.9, 300 sec: 15689.9). Total num frames: 51249152. Throughput: 0: 16183.1. Samples: 39290058. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 22:15:58,107][26276] Avg episode reward: [(0, '-1269.736')]
[2023-08-31 22:15:59,757][26288] Updated weights for policy 0, policy_version 100152 (0.0002)
[2023-08-31 22:16:02,504][26288] Updated weights for policy 0, policy_version 100232 (0.0002)
[2023-08-31 22:16:03,110][26276] Fps is (10 sec: 15971.9, 60 sec: 16178.8, 300 sec: 15703.4). Total num frames: 51326976. Throughput: 0: 16109.7. Samples: 39383074. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 22:16:03,110][26276] Avg episode reward: [(0, '-1271.085')]
[2023-08-31 22:16:05,018][26288] Updated weights for policy 0, policy_version 100312 (0.0002)
[2023-08-31 22:16:07,502][26288] Updated weights for policy 0, policy_version 100392 (0.0002)
[2023-08-31 22:16:08,109][26276] Fps is (10 sec: 15969.3, 60 sec: 16179.4, 300 sec: 15717.5). Total num frames: 51408896. Throughput: 0: 16137.3. Samples: 39481812. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 22:16:08,110][26276] Avg episode reward: [(0, '-1271.085')]
[2023-08-31 22:16:10,189][26288] Updated weights for policy 0, policy_version 100472 (0.0002)
[2023-08-31 22:16:12,719][26288] Updated weights for policy 0, policy_version 100552 (0.0002)
[2023-08-31 22:16:13,109][26276] Fps is (10 sec: 15976.2, 60 sec: 16179.2, 300 sec: 15745.3). Total num frames: 51486720. Throughput: 0: 16067.1. Samples: 39528358. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 22:16:13,109][26276] Avg episode reward: [(0, '-1275.396')]
[2023-08-31 22:16:15,165][26288] Updated weights for policy 0, policy_version 100632 (0.0002)
[2023-08-31 22:16:17,620][26288] Updated weights for policy 0, policy_version 100712 (0.0002)
[2023-08-31 22:16:18,106][26276] Fps is (10 sec: 15979.7, 60 sec: 16110.7, 300 sec: 15745.3). Total num frames: 51568640. Throughput: 0: 16175.2. Samples: 39627923. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:16:18,106][26276] Avg episode reward: [(0, '-1275.396')]
[2023-08-31 22:16:20,336][26288] Updated weights for policy 0, policy_version 100792 (0.0002)
[2023-08-31 22:16:22,822][26288] Updated weights for policy 0, policy_version 100872 (0.0002)
[2023-08-31 22:16:23,108][26276] Fps is (10 sec: 16384.8, 60 sec: 16178.3, 300 sec: 15759.1). Total num frames: 51650560. Throughput: 0: 16074.6. Samples: 39723028. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:16:23,108][26276] Avg episode reward: [(0, '-1279.604')]
[2023-08-31 22:16:25,316][26288] Updated weights for policy 0, policy_version 100952 (0.0002)
[2023-08-31 22:16:27,767][26288] Updated weights for policy 0, policy_version 101032 (0.0002)
[2023-08-31 22:16:28,107][26276] Fps is (10 sec: 16383.2, 60 sec: 16110.7, 300 sec: 15759.3). Total num frames: 51732480. Throughput: 0: 16118.1. Samples: 39772083. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:16:28,107][26276] Avg episode reward: [(0, '-1279.604')]
[2023-08-31 22:16:30,597][26288] Updated weights for policy 0, policy_version 101112 (0.0002)
[2023-08-31 22:16:33,101][26288] Updated weights for policy 0, policy_version 101192 (0.0002)
[2023-08-31 22:16:33,106][26276] Fps is (10 sec: 15978.2, 60 sec: 16112.1, 300 sec: 15759.4). Total num frames: 51810304. Throughput: 0: 16004.4. Samples: 39866384. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:16:33,106][26276] Avg episode reward: [(0, '-1274.320')]
[2023-08-31 22:16:35,511][26288] Updated weights for policy 0, policy_version 101272 (0.0002)
[2023-08-31 22:16:37,970][26288] Updated weights for policy 0, policy_version 101352 (0.0002)
[2023-08-31 22:16:38,106][26276] Fps is (10 sec: 15975.0, 60 sec: 16110.9, 300 sec: 15759.4). Total num frames: 51892224. Throughput: 0: 16100.7. Samples: 39965870. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:16:38,106][26276] Avg episode reward: [(0, '-1274.320')]
[2023-08-31 22:16:40,735][26288] Updated weights for policy 0, policy_version 101432 (0.0002)
[2023-08-31 22:16:43,109][26276] Fps is (10 sec: 15969.1, 60 sec: 16111.1, 300 sec: 15759.0). Total num frames: 51970048. Throughput: 0: 16025.5. Samples: 40011251. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:16:43,109][26276] Avg episode reward: [(0, '-1284.540')]
[2023-08-31 22:16:43,300][26288] Updated weights for policy 0, policy_version 101512 (0.0002)
[2023-08-31 22:16:45,837][26288] Updated weights for policy 0, policy_version 101592 (0.0002)
[2023-08-31 22:16:48,108][26276] Fps is (10 sec: 15971.4, 60 sec: 16042.9, 300 sec: 15745.2). Total num frames: 52051968. Throughput: 0: 16111.2. Samples: 40108048. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:16:48,108][26276] Avg episode reward: [(0, '-1284.540')]
[2023-08-31 22:16:48,320][26288] Updated weights for policy 0, policy_version 101672 (0.0002)
[2023-08-31 22:16:51,038][26288] Updated weights for policy 0, policy_version 101752 (0.0002)
[2023-08-31 22:16:53,106][26276] Fps is (10 sec: 15979.4, 60 sec: 16043.3, 300 sec: 15759.4). Total num frames: 52129792. Throughput: 0: 16010.9. Samples: 40202247. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:16:53,106][26276] Avg episode reward: [(0, '-1309.307')]
[2023-08-31 22:16:53,561][26288] Updated weights for policy 0, policy_version 101832 (0.0002)
[2023-08-31 22:16:55,973][26288] Updated weights for policy 0, policy_version 101912 (0.0002)
[2023-08-31 22:16:58,109][26276] Fps is (10 sec: 15973.5, 60 sec: 16042.0, 300 sec: 15759.0). Total num frames: 52211712. Throughput: 0: 16085.3. Samples: 40252195. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:16:58,109][26276] Avg episode reward: [(0, '-1309.307')]
[2023-08-31 22:16:58,385][26288] Updated weights for policy 0, policy_version 101992 (0.0002)
[2023-08-31 22:17:01,195][26288] Updated weights for policy 0, policy_version 102072 (0.0002)
[2023-08-31 22:17:03,108][26276] Fps is (10 sec: 15971.2, 60 sec: 16043.2, 300 sec: 15759.1). Total num frames: 52289536. Throughput: 0: 15986.2. Samples: 40347331. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:17:03,108][26276] Avg episode reward: [(0, '-1309.222')]
[2023-08-31 22:17:03,673][26288] Updated weights for policy 0, policy_version 102152 (0.0002)
[2023-08-31 22:17:06,347][26288] Updated weights for policy 0, policy_version 102232 (0.0002)
[2023-08-31 22:17:08,108][26276] Fps is (10 sec: 15565.6, 60 sec: 15974.8, 300 sec: 15759.2). Total num frames: 52367360. Throughput: 0: 15997.9. Samples: 40442931. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:17:08,108][26276] Avg episode reward: [(0, '-1309.222')]
[2023-08-31 22:17:08,944][26288] Updated weights for policy 0, policy_version 102312 (0.0002)
[2023-08-31 22:17:11,548][26288] Updated weights for policy 0, policy_version 102392 (0.0002)
[2023-08-31 22:17:13,110][26276] Fps is (10 sec: 15561.5, 60 sec: 15974.0, 300 sec: 15759.1). Total num frames: 52445184. Throughput: 0: 15911.5. Samples: 40488158. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:17:13,110][26276] Avg episode reward: [(0, '-1314.527')]
[2023-08-31 22:17:14,102][26288] Updated weights for policy 0, policy_version 102472 (0.0002)
[2023-08-31 22:17:16,596][26288] Updated weights for policy 0, policy_version 102552 (0.0002)
[2023-08-31 22:17:18,105][26276] Fps is (10 sec: 15978.7, 60 sec: 15974.6, 300 sec: 15745.4). Total num frames: 52527104. Throughput: 0: 16007.5. Samples: 40586717. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:17:18,106][26276] Avg episode reward: [(0, '-1314.527')]
[2023-08-31 22:17:19,133][26288] Updated weights for policy 0, policy_version 102632 (0.0002)
[2023-08-31 22:17:21,850][26288] Updated weights for policy 0, policy_version 102712 (0.0002)
[2023-08-31 22:17:23,107][26276] Fps is (10 sec: 15979.0, 60 sec: 15906.4, 300 sec: 15759.3). Total num frames: 52604928. Throughput: 0: 15893.4. Samples: 40681092. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:17:23,107][26276] Avg episode reward: [(0, '-1319.092')]
[2023-08-31 22:17:23,110][26287] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000102744_52604928.pth...
[2023-08-31 22:17:23,113][26287] Removing /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000096488_49401856.pth
[2023-08-31 22:17:24,437][26288] Updated weights for policy 0, policy_version 102792 (0.0002)
[2023-08-31 22:17:26,991][26288] Updated weights for policy 0, policy_version 102872 (0.0002)
[2023-08-31 22:17:28,110][26276] Fps is (10 sec: 15967.6, 60 sec: 15905.3, 300 sec: 15772.9). Total num frames: 52686848. Throughput: 0: 15927.6. Samples: 40728003. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:17:28,110][26276] Avg episode reward: [(0, '-1319.092')]
[2023-08-31 22:17:29,479][26288] Updated weights for policy 0, policy_version 102952 (0.0002)
[2023-08-31 22:17:32,259][26288] Updated weights for policy 0, policy_version 103032 (0.0002)
[2023-08-31 22:17:33,106][26276] Fps is (10 sec: 15976.0, 60 sec: 15906.0, 300 sec: 15787.0). Total num frames: 52764672. Throughput: 0: 15866.5. Samples: 40822011. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:17:33,106][26276] Avg episode reward: [(0, '-1315.088')]
[2023-08-31 22:17:34,798][26288] Updated weights for policy 0, policy_version 103112 (0.0002)
[2023-08-31 22:17:37,391][26288] Updated weights for policy 0, policy_version 103192 (0.0002)
[2023-08-31 22:17:38,109][26276] Fps is (10 sec: 15566.0, 60 sec: 15837.2, 300 sec: 15773.1). Total num frames: 52842496. Throughput: 0: 15900.9. Samples: 40917833. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:17:38,109][26276] Avg episode reward: [(0, '-1315.088')]
[2023-08-31 22:17:39,936][26288] Updated weights for policy 0, policy_version 103272 (0.0002)
[2023-08-31 22:17:42,741][26288] Updated weights for policy 0, policy_version 103352 (0.0003)
[2023-08-31 22:17:43,107][26276] Fps is (10 sec: 15563.1, 60 sec: 15838.3, 300 sec: 15773.1). Total num frames: 52920320. Throughput: 0: 15819.1. Samples: 40964036. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:17:43,107][26276] Avg episode reward: [(0, '-1331.568')]
[2023-08-31 22:17:45,230][26288] Updated weights for policy 0, policy_version 103432 (0.0002)
[2023-08-31 22:17:47,731][26288] Updated weights for policy 0, policy_version 103512 (0.0002)
[2023-08-31 22:17:48,110][26276] Fps is (10 sec: 15973.2, 60 sec: 15837.4, 300 sec: 15786.8). Total num frames: 53002240. Throughput: 0: 15841.7. Samples: 41060236. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:17:48,110][26276] Avg episode reward: [(0, '-1331.568')]
[2023-08-31 22:17:50,366][26288] Updated weights for policy 0, policy_version 103592 (0.0002)
[2023-08-31 22:17:52,970][26288] Updated weights for policy 0, policy_version 103672 (0.0002)
[2023-08-31 22:17:53,110][26276] Fps is (10 sec: 15970.0, 60 sec: 15836.8, 300 sec: 15786.8). Total num frames: 53080064. Throughput: 0: 15806.1. Samples: 41154237. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:17:53,110][26276] Avg episode reward: [(0, '-1336.274')]
[2023-08-31 22:17:55,406][26288] Updated weights for policy 0, policy_version 103752 (0.0002)
[2023-08-31 22:17:57,858][26288] Updated weights for policy 0, policy_version 103832 (0.0002)
[2023-08-31 22:17:58,106][26276] Fps is (10 sec: 16390.1, 60 sec: 15906.8, 300 sec: 15801.1). Total num frames: 53166080. Throughput: 0: 15906.1. Samples: 41203868. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:17:58,106][26276] Avg episode reward: [(0, '-1336.274')]
[2023-08-31 22:18:00,584][26288] Updated weights for policy 0, policy_version 103912 (0.0002)
[2023-08-31 22:18:03,110][26276] Fps is (10 sec: 15974.3, 60 sec: 15837.3, 300 sec: 15787.0). Total num frames: 53239808. Throughput: 0: 15834.2. Samples: 41299330. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:18:03,110][26276] Avg episode reward: [(0, '-1337.474')]
[2023-08-31 22:18:03,224][26288] Updated weights for policy 0, policy_version 103992 (0.0002)
[2023-08-31 22:18:05,728][26288] Updated weights for policy 0, policy_version 104072 (0.0002)
[2023-08-31 22:18:08,110][26276] Fps is (10 sec: 15557.9, 60 sec: 15905.5, 300 sec: 15786.9). Total num frames: 53321728. Throughput: 0: 15862.7. Samples: 41394964. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:18:08,111][26276] Avg episode reward: [(0, '-1337.474')]
[2023-08-31 22:18:08,255][26288] Updated weights for policy 0, policy_version 104152 (0.0002)
[2023-08-31 22:18:10,994][26288] Updated weights for policy 0, policy_version 104232 (0.0002)
[2023-08-31 22:18:13,106][26276] Fps is (10 sec: 15980.8, 60 sec: 15907.2, 300 sec: 15787.1). Total num frames: 53399552. Throughput: 0: 15893.1. Samples: 41443138. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:18:13,106][26276] Avg episode reward: [(0, '-1341.756')]
[2023-08-31 22:18:13,614][26288] Updated weights for policy 0, policy_version 104312 (0.0002)
[2023-08-31 22:18:16,097][26288] Updated weights for policy 0, policy_version 104392 (0.0002)
[2023-08-31 22:18:18,106][26276] Fps is (10 sec: 15570.8, 60 sec: 15837.6, 300 sec: 15773.0). Total num frames: 53477376. Throughput: 0: 15887.1. Samples: 41536936. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[2023-08-31 22:18:18,107][26276] Avg episode reward: [(0, '-1341.756')]
[2023-08-31 22:18:18,729][26288] Updated weights for policy 0, policy_version 104472 (0.0002)
[2023-08-31 22:18:21,494][26288] Updated weights for policy 0, policy_version 104552 (0.0002)
[2023-08-31 22:18:23,110][26276] Fps is (10 sec: 15559.2, 60 sec: 15837.2, 300 sec: 15786.9). Total num frames: 53555200. Throughput: 0: 15810.4. Samples: 41629313. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[2023-08-31 22:18:23,110][26276] Avg episode reward: [(0, '-1332.288')]
[2023-08-31 22:18:24,041][26288] Updated weights for policy 0, policy_version 104632 (0.0002)
[2023-08-31 22:18:26,636][26288] Updated weights for policy 0, policy_version 104712 (0.0002)
[2023-08-31 22:18:28,106][26276] Fps is (10 sec: 15975.9, 60 sec: 15838.9, 300 sec: 15814.8). Total num frames: 53637120. Throughput: 0: 15832.5. Samples: 41676471. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[2023-08-31 22:18:28,106][26276] Avg episode reward: [(0, '-1332.288')]
[2023-08-31 22:18:29,129][26288] Updated weights for policy 0, policy_version 104792 (0.0002)
[2023-08-31 22:18:31,934][26288] Updated weights for policy 0, policy_version 104872 (0.0002)
[2023-08-31 22:18:33,108][26276] Fps is (10 sec: 15567.0, 60 sec: 15769.1, 300 sec: 15787.0). Total num frames: 53710848. Throughput: 0: 15770.8. Samples: 41769903. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[2023-08-31 22:18:33,108][26276] Avg episode reward: [(0, '-1298.349')]
[2023-08-31 22:18:34,492][26288] Updated weights for policy 0, policy_version 104952 (0.0002)
[2023-08-31 22:18:37,028][26288] Updated weights for policy 0, policy_version 105032 (0.0002)
[2023-08-31 22:18:38,109][26276] Fps is (10 sec: 15560.0, 60 sec: 15837.9, 300 sec: 15828.6). Total num frames: 53792768. Throughput: 0: 15800.4. Samples: 41865232. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[2023-08-31 22:18:38,109][26276] Avg episode reward: [(0, '-1298.349')]
[2023-08-31 22:18:39,663][26288] Updated weights for policy 0, policy_version 105112 (0.0002)
[2023-08-31 22:18:42,531][26288] Updated weights for policy 0, policy_version 105192 (0.0002)
[2023-08-31 22:18:43,109][26276] Fps is (10 sec: 15563.6, 60 sec: 15769.1, 300 sec: 15842.3). Total num frames: 53866496. Throughput: 0: 15730.1. Samples: 41911771. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[2023-08-31 22:18:43,109][26276] Avg episode reward: [(0, '-1246.362')]
[2023-08-31 22:18:43,110][26287] Saving new best policy, reward=-1246.362!
[2023-08-31 22:18:45,452][26288] Updated weights for policy 0, policy_version 105272 (0.0002)
[2023-08-31 22:18:48,108][26276] Fps is (10 sec: 14336.8, 60 sec: 15565.2, 300 sec: 15856.3). Total num frames: 53936128. Throughput: 0: 15481.3. Samples: 41995958. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[2023-08-31 22:18:48,108][26276] Avg episode reward: [(0, '-1246.362')]
[2023-08-31 22:18:48,307][26288] Updated weights for policy 0, policy_version 105352 (0.0002)
[2023-08-31 22:18:51,120][26288] Updated weights for policy 0, policy_version 105432 (0.0002)
[2023-08-31 22:18:53,110][26276] Fps is (10 sec: 13924.7, 60 sec: 15428.2, 300 sec: 15828.6). Total num frames: 54005760. Throughput: 0: 15294.0. Samples: 42083192. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[2023-08-31 22:18:53,111][26276] Avg episode reward: [(0, '-1183.877')]
[2023-08-31 22:18:53,111][26287] Saving new best policy, reward=-1183.877!
[2023-08-31 22:18:53,986][26288] Updated weights for policy 0, policy_version 105512 (0.0002)
[2023-08-31 22:18:56,612][26288] Updated weights for policy 0, policy_version 105592 (0.0003)
[2023-08-31 22:18:58,108][26276] Fps is (10 sec: 14746.1, 60 sec: 15291.3, 300 sec: 15870.2). Total num frames: 54083584. Throughput: 0: 15208.8. Samples: 42127560. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[2023-08-31 22:18:58,108][26276] Avg episode reward: [(0, '-1183.877')]
[2023-08-31 22:18:59,101][26288] Updated weights for policy 0, policy_version 105672 (0.0002)
[2023-08-31 22:19:01,581][26288] Updated weights for policy 0, policy_version 105752 (0.0002)
[2023-08-31 22:19:03,108][26276] Fps is (10 sec: 15977.8, 60 sec: 15428.8, 300 sec: 15870.2). Total num frames: 54165504. Throughput: 0: 15296.4. Samples: 42225300. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[2023-08-31 22:19:03,109][26276] Avg episode reward: [(0, '-1113.693')]
[2023-08-31 22:19:03,112][26287] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000105792_54165504.pth...
[2023-08-31 22:19:03,114][26287] Removing /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000099624_51007488.pth
[2023-08-31 22:19:03,114][26287] Saving new best policy, reward=-1113.693!
[2023-08-31 22:19:04,287][26288] Updated weights for policy 0, policy_version 105832 (0.0002)
[2023-08-31 22:19:06,879][26288] Updated weights for policy 0, policy_version 105912 (0.0002)
[2023-08-31 22:19:08,106][26276] Fps is (10 sec: 15977.8, 60 sec: 15361.2, 300 sec: 15884.2). Total num frames: 54243328. Throughput: 0: 15321.2. Samples: 42318704. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[2023-08-31 22:19:08,106][26276] Avg episode reward: [(0, '-1113.693')]
[2023-08-31 22:19:09,359][26288] Updated weights for policy 0, policy_version 105992 (0.0002)
[2023-08-31 22:19:11,877][26288] Updated weights for policy 0, policy_version 106072 (0.0002)
[2023-08-31 22:19:13,106][26276] Fps is (10 sec: 15978.0, 60 sec: 15428.3, 300 sec: 15898.1). Total num frames: 54325248. Throughput: 0: 15373.0. Samples: 42368260. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[2023-08-31 22:19:13,106][26276] Avg episode reward: [(0, '-1038.944')]
[2023-08-31 22:19:13,107][26287] Saving new best policy, reward=-1038.944!
[2023-08-31 22:19:14,609][26288] Updated weights for policy 0, policy_version 106152 (0.0002)
[2023-08-31 22:19:17,144][26288] Updated weights for policy 0, policy_version 106232 (0.0002)
[2023-08-31 22:19:18,106][26276] Fps is (10 sec: 15973.3, 60 sec: 15428.3, 300 sec: 15898.2). Total num frames: 54403072. Throughput: 0: 15389.4. Samples: 42462397. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 22:19:18,107][26276] Avg episode reward: [(0, '-1038.944')]
[2023-08-31 22:19:19,662][26288] Updated weights for policy 0, policy_version 106312 (0.0002)
[2023-08-31 22:19:22,171][26288] Updated weights for policy 0, policy_version 106392 (0.0002)
[2023-08-31 22:19:23,107][26276] Fps is (10 sec: 15972.5, 60 sec: 15497.2, 300 sec: 15884.1). Total num frames: 54484992. Throughput: 0: 15433.9. Samples: 42559733. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 22:19:23,107][26276] Avg episode reward: [(0, '-977.510')]
[2023-08-31 22:19:23,108][26287] Saving new best policy, reward=-977.510!
[2023-08-31 22:19:24,835][26288] Updated weights for policy 0, policy_version 106472 (0.0002)
[2023-08-31 22:19:27,216][26288] Updated weights for policy 0, policy_version 106552 (0.0002)
[2023-08-31 22:19:28,106][26276] Fps is (10 sec: 16384.6, 60 sec: 15496.4, 300 sec: 15884.4). Total num frames: 54566912. Throughput: 0: 15442.0. Samples: 42606613. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 22:19:28,106][26276] Avg episode reward: [(0, '-977.510')]
[2023-08-31 22:19:29,728][26288] Updated weights for policy 0, policy_version 106632 (0.0002)
[2023-08-31 22:19:32,160][26288] Updated weights for policy 0, policy_version 106712 (0.0002)
[2023-08-31 22:19:33,108][26276] Fps is (10 sec: 15973.2, 60 sec: 15564.9, 300 sec: 15884.0). Total num frames: 54644736. Throughput: 0: 15784.2. Samples: 42706241. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 22:19:33,108][26276] Avg episode reward: [(0, '-942.980')]
[2023-08-31 22:19:33,109][26287] Saving new best policy, reward=-942.980!
[2023-08-31 22:19:34,949][26288] Updated weights for policy 0, policy_version 106792 (0.0002)
[2023-08-31 22:19:37,476][26288] Updated weights for policy 0, policy_version 106872 (0.0002)
[2023-08-31 22:19:38,108][26276] Fps is (10 sec: 15970.5, 60 sec: 15564.9, 300 sec: 15884.1). Total num frames: 54726656. Throughput: 0: 15941.2. Samples: 42800515. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 22:19:38,109][26276] Avg episode reward: [(0, '-942.980')]
[2023-08-31 22:19:40,059][26288] Updated weights for policy 0, policy_version 106952 (0.0002)
[2023-08-31 22:19:42,759][26288] Updated weights for policy 0, policy_version 107032 (0.0002)
[2023-08-31 22:19:43,109][26276] Fps is (10 sec: 15973.2, 60 sec: 15633.2, 300 sec: 15870.2). Total num frames: 54804480. Throughput: 0: 16015.6. Samples: 42848277. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 22:19:43,109][26276] Avg episode reward: [(0, '-915.970')]
[2023-08-31 22:19:43,109][26287] Saving new best policy, reward=-915.970!
[2023-08-31 22:19:45,301][26288] Updated weights for policy 0, policy_version 107112 (0.0002)
[2023-08-31 22:19:47,871][26288] Updated weights for policy 0, policy_version 107192 (0.0002)
[2023-08-31 22:19:48,105][26276] Fps is (10 sec: 15979.6, 60 sec: 15838.6, 300 sec: 15884.3). Total num frames: 54886400. Throughput: 0: 15918.8. Samples: 42941597. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 22:19:48,105][26276] Avg episode reward: [(0, '-915.970')]
[2023-08-31 22:19:50,429][26288] Updated weights for policy 0, policy_version 107272 (0.0002)
[2023-08-31 22:19:53,108][26276] Fps is (10 sec: 15565.4, 60 sec: 15906.7, 300 sec: 15870.3). Total num frames: 54960128. Throughput: 0: 15978.2. Samples: 43037763. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 22:19:53,109][26276] Avg episode reward: [(0, '-888.723')]
[2023-08-31 22:19:53,109][26287] Saving new best policy, reward=-888.723!
[2023-08-31 22:19:53,286][26288] Updated weights for policy 0, policy_version 107352 (0.0002)
[2023-08-31 22:19:55,903][26288] Updated weights for policy 0, policy_version 107432 (0.0002)
[2023-08-31 22:19:58,110][26276] Fps is (10 sec: 15147.5, 60 sec: 15905.5, 300 sec: 15870.2). Total num frames: 55037952. Throughput: 0: 15847.6. Samples: 43081471. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 22:19:58,110][26276] Avg episode reward: [(0, '-888.723')]
[2023-08-31 22:19:58,555][26288] Updated weights for policy 0, policy_version 107512 (0.0002)
[2023-08-31 22:20:01,027][26288] Updated weights for policy 0, policy_version 107592 (0.0002)
[2023-08-31 22:20:03,106][26276] Fps is (10 sec: 15568.8, 60 sec: 15838.5, 300 sec: 15856.6). Total num frames: 55115776. Throughput: 0: 15857.2. Samples: 43175958. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 22:20:03,106][26276] Avg episode reward: [(0, '-883.725')]
[2023-08-31 22:20:03,106][26287] Saving new best policy, reward=-883.725!
[2023-08-31 22:20:03,875][26288] Updated weights for policy 0, policy_version 107672 (0.0002)
[2023-08-31 22:20:06,411][26288] Updated weights for policy 0, policy_version 107752 (0.0002)
[2023-08-31 22:20:08,108][26276] Fps is (10 sec: 15567.9, 60 sec: 15837.2, 300 sec: 15856.4). Total num frames: 55193600. Throughput: 0: 15717.4. Samples: 43267036. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 22:20:08,109][26276] Avg episode reward: [(0, '-885.351')]
[2023-08-31 22:20:08,924][26288] Updated weights for policy 0, policy_version 107832 (0.0002)
[2023-08-31 22:20:11,471][26288] Updated weights for policy 0, policy_version 107912 (0.0002)
[2023-08-31 22:20:13,108][26276] Fps is (10 sec: 15970.7, 60 sec: 15837.3, 300 sec: 15842.3). Total num frames: 55275520. Throughput: 0: 15787.7. Samples: 43317090. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 22:20:13,109][26276] Avg episode reward: [(0, '-885.351')]
[2023-08-31 22:20:14,378][26288] Updated weights for policy 0, policy_version 107992 (0.0002)
[2023-08-31 22:20:16,986][26288] Updated weights for policy 0, policy_version 108072 (0.0002)
[2023-08-31 22:20:18,107][26276] Fps is (10 sec: 15567.4, 60 sec: 15769.5, 300 sec: 15828.5). Total num frames: 55349248. Throughput: 0: 15565.7. Samples: 43406677. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 22:20:18,107][26276] Avg episode reward: [(0, '-887.223')]
[2023-08-31 22:20:19,536][26288] Updated weights for policy 0, policy_version 108152 (0.0002)
[2023-08-31 22:20:22,048][26288] Updated weights for policy 0, policy_version 108232 (0.0002)
[2023-08-31 22:20:23,108][26276] Fps is (10 sec: 15565.0, 60 sec: 15769.4, 300 sec: 15814.6). Total num frames: 55431168. Throughput: 0: 15625.4. Samples: 43503651. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 22:20:23,108][26276] Avg episode reward: [(0, '-887.223')]
[2023-08-31 22:20:24,808][26288] Updated weights for policy 0, policy_version 108312 (0.0003)
[2023-08-31 22:20:27,422][26288] Updated weights for policy 0, policy_version 108392 (0.0002)
[2023-08-31 22:20:28,106][26276] Fps is (10 sec: 15566.2, 60 sec: 15633.1, 300 sec: 15801.1). Total num frames: 55504896. Throughput: 0: 15563.7. Samples: 43548599. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 22:20:28,106][26276] Avg episode reward: [(0, '-887.578')]
[2023-08-31 22:20:30,212][26288] Updated weights for policy 0, policy_version 108472 (0.0002)
[2023-08-31 22:20:32,779][26288] Updated weights for policy 0, policy_version 108552 (0.0002)
[2023-08-31 22:20:33,106][26276] Fps is (10 sec: 15157.2, 60 sec: 15633.4, 300 sec: 15786.9). Total num frames: 55582720. Throughput: 0: 15515.6. Samples: 43639823. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 22:20:33,107][26276] Avg episode reward: [(0, '-887.578')]
[2023-08-31 22:20:35,632][26288] Updated weights for policy 0, policy_version 108632 (0.0002)
[2023-08-31 22:20:38,110][26276] Fps is (10 sec: 15148.4, 60 sec: 15496.1, 300 sec: 15773.0). Total num frames: 55656448. Throughput: 0: 15411.3. Samples: 43731303. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 22:20:38,110][26276] Avg episode reward: [(0, '-882.740')]
[2023-08-31 22:20:38,111][26287] Saving new best policy, reward=-882.740!
[2023-08-31 22:20:38,240][26288] Updated weights for policy 0, policy_version 108712 (0.0002)
[2023-08-31 22:20:40,881][26288] Updated weights for policy 0, policy_version 108792 (0.0002)
[2023-08-31 22:20:43,110][26276] Fps is (10 sec: 15149.9, 60 sec: 15496.2, 300 sec: 15745.2). Total num frames: 55734272. Throughput: 0: 15470.5. Samples: 43777642. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 22:20:43,110][26276] Avg episode reward: [(0, '-882.740')]
[2023-08-31 22:20:43,112][26287] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000108856_55734272.pth...
[2023-08-31 22:20:43,113][26287] Removing /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000102744_52604928.pth
[2023-08-31 22:20:43,420][26288] Updated weights for policy 0, policy_version 108872 (0.0002)
[2023-08-31 22:20:46,197][26288] Updated weights for policy 0, policy_version 108952 (0.0002)
[2023-08-31 22:20:48,108][26276] Fps is (10 sec: 15567.7, 60 sec: 15427.5, 300 sec: 15745.3). Total num frames: 55812096. Throughput: 0: 15417.2. Samples: 43869771. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 22:20:48,108][26276] Avg episode reward: [(0, '-878.334')]
[2023-08-31 22:20:48,109][26287] Saving new best policy, reward=-878.334!
[2023-08-31 22:20:48,814][26288] Updated weights for policy 0, policy_version 109032 (0.0002)
[2023-08-31 22:20:51,388][26288] Updated weights for policy 0, policy_version 109112 (0.0002)
[2023-08-31 22:20:53,106][26276] Fps is (10 sec: 15571.5, 60 sec: 15497.2, 300 sec: 15731.4). Total num frames: 55889920. Throughput: 0: 15511.3. Samples: 43965004. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 22:20:53,106][26276] Avg episode reward: [(0, '-878.334')]
[2023-08-31 22:20:53,847][26288] Updated weights for policy 0, policy_version 109192 (0.0002)
[2023-08-31 22:20:56,626][26288] Updated weights for policy 0, policy_version 109272 (0.0002)
[2023-08-31 22:20:58,107][26276] Fps is (10 sec: 15566.2, 60 sec: 15497.3, 300 sec: 15731.5). Total num frames: 55967744. Throughput: 0: 15431.1. Samples: 44011479. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 22:20:58,108][26276] Avg episode reward: [(0, '-877.607')]
[2023-08-31 22:20:58,108][26287] Saving new best policy, reward=-877.607!
[2023-08-31 22:20:59,105][26288] Updated weights for policy 0, policy_version 109352 (0.0002)
[2023-08-31 22:21:01,606][26288] Updated weights for policy 0, policy_version 109432 (0.0002)
[2023-08-31 22:21:03,107][26276] Fps is (10 sec: 15971.5, 60 sec: 15564.3, 300 sec: 15731.5). Total num frames: 56049664. Throughput: 0: 15606.2. Samples: 44108971. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 22:21:03,109][26276] Avg episode reward: [(0, '-877.607')]
[2023-08-31 22:21:04,090][26288] Updated weights for policy 0, policy_version 109512 (0.0002)
[2023-08-31 22:21:06,984][26288] Updated weights for policy 0, policy_version 109592 (0.0002)
[2023-08-31 22:21:08,110][26276] Fps is (10 sec: 15970.0, 60 sec: 15564.3, 300 sec: 15731.3). Total num frames: 56127488. Throughput: 0: 15494.2. Samples: 44200923. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 22:21:08,110][26276] Avg episode reward: [(0, '-872.172')]
[2023-08-31 22:21:08,111][26287] Saving new best policy, reward=-872.172!
[2023-08-31 22:21:09,514][26288] Updated weights for policy 0, policy_version 109672 (0.0002)
[2023-08-31 22:21:12,064][26288] Updated weights for policy 0, policy_version 109752 (0.0002)
[2023-08-31 22:21:13,105][26276] Fps is (10 sec: 15977.6, 60 sec: 15565.4, 300 sec: 15731.4). Total num frames: 56209408. Throughput: 0: 15589.8. Samples: 44250135. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 22:21:13,106][26276] Avg episode reward: [(0, '-872.172')]
[2023-08-31 22:21:14,574][26288] Updated weights for policy 0, policy_version 109832 (0.0002)
[2023-08-31 22:21:17,275][26288] Updated weights for policy 0, policy_version 109912 (0.0002)
[2023-08-31 22:21:18,110][26276] Fps is (10 sec: 15974.1, 60 sec: 15632.1, 300 sec: 15717.4). Total num frames: 56287232. Throughput: 0: 15622.5. Samples: 44342895. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:21:18,110][26276] Avg episode reward: [(0, '-867.768')]
[2023-08-31 22:21:18,111][26287] Saving new best policy, reward=-867.768!
[2023-08-31 22:21:19,849][26288] Updated weights for policy 0, policy_version 109992 (0.0002)
[2023-08-31 22:21:22,348][26288] Updated weights for policy 0, policy_version 110072 (0.0002)
[2023-08-31 22:21:23,108][26276] Fps is (10 sec: 15970.3, 60 sec: 15633.0, 300 sec: 15717.5). Total num frames: 56369152. Throughput: 0: 15783.8. Samples: 44441539. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:21:23,108][26276] Avg episode reward: [(0, '-867.768')]
[2023-08-31 22:21:24,825][26288] Updated weights for policy 0, policy_version 110152 (0.0002)
[2023-08-31 22:21:27,572][26288] Updated weights for policy 0, policy_version 110232 (0.0002)
[2023-08-31 22:21:28,107][26276] Fps is (10 sec: 15979.9, 60 sec: 15701.0, 300 sec: 15717.5). Total num frames: 56446976. Throughput: 0: 15757.3. Samples: 44486672. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:21:28,107][26276] Avg episode reward: [(0, '-861.523')]
[2023-08-31 22:21:28,107][26287] Saving new best policy, reward=-861.523!
[2023-08-31 22:21:30,167][26288] Updated weights for policy 0, policy_version 110312 (0.0002)
[2023-08-31 22:21:32,602][26288] Updated weights for policy 0, policy_version 110392 (0.0002)
[2023-08-31 22:21:33,106][26276] Fps is (10 sec: 15978.0, 60 sec: 15769.8, 300 sec: 15717.6). Total num frames: 56528896. Throughput: 0: 15855.9. Samples: 44583249. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:21:33,106][26276] Avg episode reward: [(0, '-861.523')]
[2023-08-31 22:21:35,383][26288] Updated weights for policy 0, policy_version 110472 (0.0002)
[2023-08-31 22:21:37,904][26288] Updated weights for policy 0, policy_version 110552 (0.0002)
[2023-08-31 22:21:38,108][26276] Fps is (10 sec: 15562.4, 60 sec: 15770.1, 300 sec: 15703.7). Total num frames: 56602624. Throughput: 0: 15828.4. Samples: 44677326. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:21:38,109][26276] Avg episode reward: [(0, '-858.432')]
[2023-08-31 22:21:38,109][26287] Saving new best policy, reward=-858.432!
[2023-08-31 22:21:40,484][26288] Updated weights for policy 0, policy_version 110632 (0.0002)
[2023-08-31 22:21:42,980][26288] Updated weights for policy 0, policy_version 110712 (0.0002)
[2023-08-31 22:21:43,108][26276] Fps is (10 sec: 15561.1, 60 sec: 15838.4, 300 sec: 15703.6). Total num frames: 56684544. Throughput: 0: 15860.7. Samples: 44725224. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:21:43,108][26276] Avg episode reward: [(0, '-858.432')]
[2023-08-31 22:21:45,802][26288] Updated weights for policy 0, policy_version 110792 (0.0002)
[2023-08-31 22:21:48,110][26276] Fps is (10 sec: 15562.2, 60 sec: 15769.1, 300 sec: 15689.5). Total num frames: 56758272. Throughput: 0: 15765.3. Samples: 44818448. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:21:48,110][26276] Avg episode reward: [(0, '-852.863')]
[2023-08-31 22:21:48,110][26287] Saving new best policy, reward=-852.863!
[2023-08-31 22:21:48,409][26288] Updated weights for policy 0, policy_version 110872 (0.0002)
[2023-08-31 22:21:50,994][26288] Updated weights for policy 0, policy_version 110952 (0.0002)
[2023-08-31 22:21:53,106][26276] Fps is (10 sec: 15568.7, 60 sec: 15837.9, 300 sec: 15689.9). Total num frames: 56840192. Throughput: 0: 15820.3. Samples: 44912763. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:21:53,106][26276] Avg episode reward: [(0, '-852.863')]
[2023-08-31 22:21:53,552][26288] Updated weights for policy 0, policy_version 111032 (0.0002)
[2023-08-31 22:21:56,256][26288] Updated weights for policy 0, policy_version 111112 (0.0002)
[2023-08-31 22:21:58,106][26276] Fps is (10 sec: 15981.4, 60 sec: 15838.3, 300 sec: 15689.9). Total num frames: 56918016. Throughput: 0: 15828.1. Samples: 44962402. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:21:58,106][26276] Avg episode reward: [(0, '-842.316')]
[2023-08-31 22:21:58,106][26287] Saving new best policy, reward=-842.316!
[2023-08-31 22:21:58,790][26288] Updated weights for policy 0, policy_version 111192 (0.0002)
[2023-08-31 22:22:01,255][26288] Updated weights for policy 0, policy_version 111272 (0.0002)
[2023-08-31 22:22:03,108][26276] Fps is (10 sec: 15970.0, 60 sec: 15837.6, 300 sec: 15703.6). Total num frames: 56999936. Throughput: 0: 15860.7. Samples: 45056596. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:22:03,109][26276] Avg episode reward: [(0, '-842.316')]
[2023-08-31 22:22:03,730][26288] Updated weights for policy 0, policy_version 111352 (0.0002)
[2023-08-31 22:22:06,434][26288] Updated weights for policy 0, policy_version 111432 (0.0002)
[2023-08-31 22:22:08,108][26276] Fps is (10 sec: 15971.4, 60 sec: 15838.5, 300 sec: 15703.8). Total num frames: 57077760. Throughput: 0: 15788.4. Samples: 45152010. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:22:08,108][26276] Avg episode reward: [(0, '-826.403')]
[2023-08-31 22:22:08,108][26287] Saving new best policy, reward=-826.403!
[2023-08-31 22:22:08,997][26288] Updated weights for policy 0, policy_version 111512 (0.0002)
[2023-08-31 22:22:11,627][26288] Updated weights for policy 0, policy_version 111592 (0.0002)
[2023-08-31 22:22:13,108][26276] Fps is (10 sec: 15565.9, 60 sec: 15769.0, 300 sec: 15689.6). Total num frames: 57155584. Throughput: 0: 15837.6. Samples: 45199376. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:22:13,109][26276] Avg episode reward: [(0, '-826.403')]
[2023-08-31 22:22:14,231][26288] Updated weights for policy 0, policy_version 111672 (0.0002)
[2023-08-31 22:22:17,031][26288] Updated weights for policy 0, policy_version 111752 (0.0002)
[2023-08-31 22:22:18,107][26276] Fps is (10 sec: 15566.0, 60 sec: 15770.5, 300 sec: 15689.8). Total num frames: 57233408. Throughput: 0: 15711.3. Samples: 45290274. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:22:18,107][26276] Avg episode reward: [(0, '-810.627')]
[2023-08-31 22:22:18,107][26287] Saving new best policy, reward=-810.627!
[2023-08-31 22:22:19,601][26288] Updated weights for policy 0, policy_version 111832 (0.0002)
[2023-08-31 22:22:22,400][26288] Updated weights for policy 0, policy_version 111912 (0.0002)
[2023-08-31 22:22:23,106][26276] Fps is (10 sec: 15157.6, 60 sec: 15633.6, 300 sec: 15662.2). Total num frames: 57307136. Throughput: 0: 15658.5. Samples: 45381923. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:22:23,106][26276] Avg episode reward: [(0, '-810.627')]
[2023-08-31 22:22:23,134][26287] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000111936_57311232.pth...
[2023-08-31 22:22:23,136][26287] Removing /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000105792_54165504.pth
[2023-08-31 22:22:24,884][26288] Updated weights for policy 0, policy_version 111992 (0.0002)
[2023-08-31 22:22:27,544][26288] Updated weights for policy 0, policy_version 112072 (0.0003)
[2023-08-31 22:22:28,108][26276] Fps is (10 sec: 15562.4, 60 sec: 15700.9, 300 sec: 15675.8). Total num frames: 57389056. Throughput: 0: 15704.5. Samples: 45431929. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:22:28,108][26276] Avg episode reward: [(0, '-798.300')]
[2023-08-31 22:22:28,109][26287] Saving new best policy, reward=-798.300!
[2023-08-31 22:22:30,108][26288] Updated weights for policy 0, policy_version 112152 (0.0002)
[2023-08-31 22:22:32,545][26288] Updated weights for policy 0, policy_version 112232 (0.0002)
[2023-08-31 22:22:33,110][26276] Fps is (10 sec: 16377.5, 60 sec: 15700.2, 300 sec: 15689.7). Total num frames: 57470976. Throughput: 0: 15737.7. Samples: 45526643. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:22:33,110][26276] Avg episode reward: [(0, '-798.300')]
[2023-08-31 22:22:35,161][26288] Updated weights for policy 0, policy_version 112312 (0.0002)
[2023-08-31 22:22:37,841][26288] Updated weights for policy 0, policy_version 112392 (0.0002)
[2023-08-31 22:22:38,105][26276] Fps is (10 sec: 15569.2, 60 sec: 15702.1, 300 sec: 15676.0). Total num frames: 57544704. Throughput: 0: 15726.2. Samples: 45620439. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:22:38,106][26276] Avg episode reward: [(0, '-786.294')]
[2023-08-31 22:22:38,114][26287] Saving new best policy, reward=-786.294!
[2023-08-31 22:22:40,358][26288] Updated weights for policy 0, policy_version 112472 (0.0002)
[2023-08-31 22:22:42,910][26288] Updated weights for policy 0, policy_version 112552 (0.0002)
[2023-08-31 22:22:43,110][26276] Fps is (10 sec: 15564.6, 60 sec: 15700.8, 300 sec: 15675.8). Total num frames: 57626624. Throughput: 0: 15716.2. Samples: 45669700. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:22:43,110][26276] Avg episode reward: [(0, '-786.294')]
[2023-08-31 22:22:45,330][26288] Updated weights for policy 0, policy_version 112632 (0.0002)
[2023-08-31 22:22:48,110][26276] Fps is (10 sec: 15967.2, 60 sec: 15769.6, 300 sec: 15675.9). Total num frames: 57704448. Throughput: 0: 15733.0. Samples: 45764608. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:22:48,111][26276] Avg episode reward: [(0, '-775.757')]
[2023-08-31 22:22:48,121][26287] Saving new best policy, reward=-775.757!
[2023-08-31 22:22:48,122][26288] Updated weights for policy 0, policy_version 112712 (0.0002)
[2023-08-31 22:22:50,580][26288] Updated weights for policy 0, policy_version 112792 (0.0002)
[2023-08-31 22:22:53,109][26276] Fps is (10 sec: 16386.1, 60 sec: 15837.0, 300 sec: 15675.7). Total num frames: 57790464. Throughput: 0: 15769.0. Samples: 45861638. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:22:53,109][26288] Updated weights for policy 0, policy_version 112872 (0.0002)
[2023-08-31 22:22:53,110][26276] Avg episode reward: [(0, '-775.757')]
[2023-08-31 22:22:55,627][26288] Updated weights for policy 0, policy_version 112952 (0.0002)
[2023-08-31 22:22:58,108][26276] Fps is (10 sec: 16387.4, 60 sec: 15837.3, 300 sec: 15689.9). Total num frames: 57868288. Throughput: 0: 15813.3. Samples: 45910981. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:22:58,108][26276] Avg episode reward: [(0, '-765.302')]
[2023-08-31 22:22:58,109][26287] Saving new best policy, reward=-765.302!
[2023-08-31 22:22:58,317][26288] Updated weights for policy 0, policy_version 113032 (0.0002)
[2023-08-31 22:23:00,769][26288] Updated weights for policy 0, policy_version 113112 (0.0002)
[2023-08-31 22:23:03,105][26276] Fps is (10 sec: 15979.9, 60 sec: 15838.6, 300 sec: 15690.0). Total num frames: 57950208. Throughput: 0: 15937.7. Samples: 46007448. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:23:03,106][26276] Avg episode reward: [(0, '-765.302')]
[2023-08-31 22:23:03,301][26288] Updated weights for policy 0, policy_version 113192 (0.0002)
[2023-08-31 22:23:05,902][26288] Updated weights for policy 0, policy_version 113272 (0.0002)
[2023-08-31 22:23:08,106][26276] Fps is (10 sec: 15568.4, 60 sec: 15770.1, 300 sec: 15675.9). Total num frames: 58023936. Throughput: 0: 15922.7. Samples: 46098436. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:23:08,107][26276] Avg episode reward: [(0, '-757.029')]
[2023-08-31 22:23:08,107][26287] Saving new best policy, reward=-757.029!
[2023-08-31 22:23:08,713][26288] Updated weights for policy 0, policy_version 113352 (0.0002)
[2023-08-31 22:23:11,185][26288] Updated weights for policy 0, policy_version 113432 (0.0002)
[2023-08-31 22:23:13,106][26276] Fps is (10 sec: 15564.4, 60 sec: 15838.4, 300 sec: 15689.8). Total num frames: 58105856. Throughput: 0: 15906.3. Samples: 46147672. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:23:13,106][26276] Avg episode reward: [(0, '-757.029')]
[2023-08-31 22:23:13,694][26288] Updated weights for policy 0, policy_version 113512 (0.0002)
[2023-08-31 22:23:16,272][26288] Updated weights for policy 0, policy_version 113592 (0.0002)
[2023-08-31 22:23:18,110][26276] Fps is (10 sec: 15967.4, 60 sec: 15837.0, 300 sec: 15689.7). Total num frames: 58183680. Throughput: 0: 15943.5. Samples: 46244098. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:23:18,110][26276] Avg episode reward: [(0, '-749.916')]
[2023-08-31 22:23:18,110][26287] Saving new best policy, reward=-749.916!
[2023-08-31 22:23:18,947][26288] Updated weights for policy 0, policy_version 113672 (0.0002)
[2023-08-31 22:23:21,489][26288] Updated weights for policy 0, policy_version 113752 (0.0002)
[2023-08-31 22:23:23,106][26276] Fps is (10 sec: 15563.5, 60 sec: 15906.0, 300 sec: 15675.8). Total num frames: 58261504. Throughput: 0: 15945.5. Samples: 46338004. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:23:23,107][26276] Avg episode reward: [(0, '-749.916')]
[2023-08-31 22:23:24,169][26288] Updated weights for policy 0, policy_version 113832 (0.0002)
[2023-08-31 22:23:26,833][26288] Updated weights for policy 0, policy_version 113912 (0.0002)
[2023-08-31 22:23:28,108][26276] Fps is (10 sec: 15567.2, 60 sec: 15837.8, 300 sec: 15689.8). Total num frames: 58339328. Throughput: 0: 15914.5. Samples: 46385827. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:23:28,109][26276] Avg episode reward: [(0, '-736.571')]
[2023-08-31 22:23:28,119][26287] Saving new best policy, reward=-736.571!
[2023-08-31 22:23:29,382][26288] Updated weights for policy 0, policy_version 113992 (0.0002)
[2023-08-31 22:23:31,786][26288] Updated weights for policy 0, policy_version 114072 (0.0002)
[2023-08-31 22:23:33,110][26276] Fps is (10 sec: 16378.0, 60 sec: 15906.1, 300 sec: 15703.6). Total num frames: 58425344. Throughput: 0: 15929.2. Samples: 46481427. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:23:33,110][26276] Avg episode reward: [(0, '-736.571')]
[2023-08-31 22:23:34,322][26288] Updated weights for policy 0, policy_version 114152 (0.0002)
[2023-08-31 22:23:37,106][26288] Updated weights for policy 0, policy_version 114232 (0.0002)
[2023-08-31 22:23:38,106][26276] Fps is (10 sec: 16388.6, 60 sec: 15974.4, 300 sec: 15717.7). Total num frames: 58503168. Throughput: 0: 15854.8. Samples: 46575051. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:23:38,106][26276] Avg episode reward: [(0, '-712.368')]
[2023-08-31 22:23:38,106][26287] Saving new best policy, reward=-712.368!
[2023-08-31 22:23:39,707][26288] Updated weights for policy 0, policy_version 114312 (0.0002)
[2023-08-31 22:23:42,220][26288] Updated weights for policy 0, policy_version 114392 (0.0002)
[2023-08-31 22:23:43,108][26276] Fps is (10 sec: 15567.8, 60 sec: 15906.6, 300 sec: 15745.3). Total num frames: 58580992. Throughput: 0: 15788.9. Samples: 46621486. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:23:43,108][26276] Avg episode reward: [(0, '-712.368')]
[2023-08-31 22:23:44,755][26288] Updated weights for policy 0, policy_version 114472 (0.0002)
[2023-08-31 22:23:47,483][26288] Updated weights for policy 0, policy_version 114552 (0.0002)
[2023-08-31 22:23:48,106][26276] Fps is (10 sec: 15564.7, 60 sec: 15907.3, 300 sec: 15773.3). Total num frames: 58658816. Throughput: 0: 15842.5. Samples: 46720367. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:23:48,106][26276] Avg episode reward: [(0, '-689.159')]
[2023-08-31 22:23:48,106][26287] Saving new best policy, reward=-689.159!
[2023-08-31 22:23:49,981][26288] Updated weights for policy 0, policy_version 114632 (0.0002)
[2023-08-31 22:23:52,488][26288] Updated weights for policy 0, policy_version 114712 (0.0002)
[2023-08-31 22:23:53,106][26276] Fps is (10 sec: 15977.8, 60 sec: 15838.6, 300 sec: 15787.0). Total num frames: 58740736. Throughput: 0: 15896.3. Samples: 46813778. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:23:53,106][26276] Avg episode reward: [(0, '-689.159')]
[2023-08-31 22:23:55,235][26288] Updated weights for policy 0, policy_version 114792 (0.0002)
[2023-08-31 22:23:58,112][26276] Fps is (10 sec: 15145.1, 60 sec: 15700.2, 300 sec: 15745.1). Total num frames: 58810368. Throughput: 0: 15809.6. Samples: 46859210. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:23:58,113][26276] Avg episode reward: [(0, '-666.633')]
[2023-08-31 22:23:58,113][26287] Saving new best policy, reward=-666.633!
[2023-08-31 22:23:58,218][26288] Updated weights for policy 0, policy_version 114872 (0.0002)
[2023-08-31 22:24:00,655][26288] Updated weights for policy 0, policy_version 114952 (0.0002)
[2023-08-31 22:24:03,110][26276] Fps is (10 sec: 15149.5, 60 sec: 15700.2, 300 sec: 15759.0). Total num frames: 58892288. Throughput: 0: 15705.6. Samples: 46950849. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:24:03,111][26276] Avg episode reward: [(0, '-666.633')]
[2023-08-31 22:24:03,113][26287] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000115024_58892288.pth...
[2023-08-31 22:24:03,115][26287] Removing /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000108856_55734272.pth
[2023-08-31 22:24:03,163][26288] Updated weights for policy 0, policy_version 115032 (0.0002)
[2023-08-31 22:24:05,671][26288] Updated weights for policy 0, policy_version 115112 (0.0002)
[2023-08-31 22:24:08,106][26276] Fps is (10 sec: 15984.1, 60 sec: 15769.4, 300 sec: 15745.3). Total num frames: 58970112. Throughput: 0: 15717.8. Samples: 47045303. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:24:08,107][26276] Avg episode reward: [(0, '-644.984')]
[2023-08-31 22:24:08,107][26287] Saving new best policy, reward=-644.984!
[2023-08-31 22:24:08,396][26288] Updated weights for policy 0, policy_version 115192 (0.0002)
[2023-08-31 22:24:10,983][26288] Updated weights for policy 0, policy_version 115272 (0.0002)
[2023-08-31 22:24:13,107][26276] Fps is (10 sec: 15979.7, 60 sec: 15769.4, 300 sec: 15759.2). Total num frames: 59052032. Throughput: 0: 15705.5. Samples: 47092547. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:24:13,107][26276] Avg episode reward: [(0, '-644.984')]
[2023-08-31 22:24:13,544][26288] Updated weights for policy 0, policy_version 115352 (0.0002)
[2023-08-31 22:24:16,111][26288] Updated weights for policy 0, policy_version 115432 (0.0002)
[2023-08-31 22:24:18,107][26276] Fps is (10 sec: 15973.9, 60 sec: 15770.5, 300 sec: 15745.3). Total num frames: 59129856. Throughput: 0: 15727.9. Samples: 47189129. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:24:18,107][26276] Avg episode reward: [(0, '-619.162')]
[2023-08-31 22:24:18,107][26287] Saving new best policy, reward=-619.162!
[2023-08-31 22:24:18,860][26288] Updated weights for policy 0, policy_version 115512 (0.0002)
[2023-08-31 22:24:21,372][26288] Updated weights for policy 0, policy_version 115592 (0.0002)
[2023-08-31 22:24:23,112][26276] Fps is (10 sec: 15555.8, 60 sec: 15768.0, 300 sec: 15731.1). Total num frames: 59207680. Throughput: 0: 15754.4. Samples: 47284104. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:24:23,113][26276] Avg episode reward: [(0, '-619.162')]
[2023-08-31 22:24:23,880][26288] Updated weights for policy 0, policy_version 115672 (0.0002)
[2023-08-31 22:24:26,310][26288] Updated weights for policy 0, policy_version 115752 (0.0002)
[2023-08-31 22:24:28,115][26276] Fps is (10 sec: 15551.6, 60 sec: 15767.8, 300 sec: 15731.0). Total num frames: 59285504. Throughput: 0: 15817.0. Samples: 47333358. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:24:28,115][26276] Avg episode reward: [(0, '-594.338')]
[2023-08-31 22:24:28,116][26287] Saving new best policy, reward=-594.338!
[2023-08-31 22:24:29,258][26288] Updated weights for policy 0, policy_version 115832 (0.0002)
[2023-08-31 22:24:31,946][26288] Updated weights for policy 0, policy_version 115912 (0.0002)
[2023-08-31 22:24:33,108][26276] Fps is (10 sec: 15571.0, 60 sec: 15633.5, 300 sec: 15717.5). Total num frames: 59363328. Throughput: 0: 15578.2. Samples: 47421430. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:24:33,109][26276] Avg episode reward: [(0, '-594.338')]
[2023-08-31 22:24:34,409][26288] Updated weights for policy 0, policy_version 115992 (0.0002)
[2023-08-31 22:24:36,936][26288] Updated weights for policy 0, policy_version 116072 (0.0002)
[2023-08-31 22:24:38,112][26276] Fps is (10 sec: 15569.5, 60 sec: 15631.4, 300 sec: 15717.3). Total num frames: 59441152. Throughput: 0: 15694.6. Samples: 47520130. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:24:38,112][26276] Avg episode reward: [(0, '-580.756')]
[2023-08-31 22:24:38,136][26287] Saving new best policy, reward=-580.756!
[2023-08-31 22:24:39,622][26288] Updated weights for policy 0, policy_version 116152 (0.0002)
[2023-08-31 22:24:42,172][26288] Updated weights for policy 0, policy_version 116232 (0.0002)
[2023-08-31 22:24:43,114][26276] Fps is (10 sec: 15965.8, 60 sec: 15699.9, 300 sec: 15717.1). Total num frames: 59523072. Throughput: 0: 15706.2. Samples: 47566011. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:24:43,114][26276] Avg episode reward: [(0, '-580.756')]
[2023-08-31 22:24:44,620][26288] Updated weights for policy 0, policy_version 116312 (0.0002)
[2023-08-31 22:24:47,356][26288] Updated weights for policy 0, policy_version 116392 (0.0002)
[2023-08-31 22:24:48,109][26276] Fps is (10 sec: 15570.0, 60 sec: 15632.3, 300 sec: 15717.5). Total num frames: 59596800. Throughput: 0: 15783.5. Samples: 47661086. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:24:48,109][26276] Avg episode reward: [(0, '-565.229')]
[2023-08-31 22:24:48,126][26287] Saving new best policy, reward=-565.229!
[2023-08-31 22:24:50,349][26288] Updated weights for policy 0, policy_version 116472 (0.0002)
[2023-08-31 22:24:52,982][26288] Updated weights for policy 0, policy_version 116552 (0.0002)
[2023-08-31 22:24:53,106][26276] Fps is (10 sec: 15166.3, 60 sec: 15564.7, 300 sec: 15717.7). Total num frames: 59674624. Throughput: 0: 15622.9. Samples: 47748333. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:24:53,107][26276] Avg episode reward: [(0, '-565.229')]
[2023-08-31 22:24:55,563][26288] Updated weights for policy 0, policy_version 116632 (0.0002)
[2023-08-31 22:24:58,108][26276] Fps is (10 sec: 15566.2, 60 sec: 15702.5, 300 sec: 15717.4). Total num frames: 59752448. Throughput: 0: 15637.2. Samples: 47796240. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:24:58,109][26276] Avg episode reward: [(0, '-565.229')]
[2023-08-31 22:24:58,147][26288] Updated weights for policy 0, policy_version 116712 (0.0002)
[2023-08-31 22:25:00,965][26288] Updated weights for policy 0, policy_version 116792 (0.0003)
[2023-08-31 22:25:03,106][26276] Fps is (10 sec: 15565.0, 60 sec: 15634.0, 300 sec: 15717.6). Total num frames: 59830272. Throughput: 0: 15526.2. Samples: 47887802. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:25:03,107][26276] Avg episode reward: [(0, '-548.697')]
[2023-08-31 22:25:03,107][26287] Saving new best policy, reward=-548.697!
[2023-08-31 22:25:03,546][26288] Updated weights for policy 0, policy_version 116872 (0.0002)
[2023-08-31 22:25:06,150][26288] Updated weights for policy 0, policy_version 116952 (0.0002)
[2023-08-31 22:25:08,107][26276] Fps is (10 sec: 15565.4, 60 sec: 15632.8, 300 sec: 15703.7). Total num frames: 59908096. Throughput: 0: 15514.9. Samples: 47982200. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:25:08,108][26276] Avg episode reward: [(0, '-548.697')]
[2023-08-31 22:25:09,054][26288] Updated weights for policy 0, policy_version 117032 (0.0002)
[2023-08-31 22:25:11,578][26288] Updated weights for policy 0, policy_version 117112 (0.0002)
[2023-08-31 22:25:13,110][26276] Fps is (10 sec: 15149.2, 60 sec: 15495.6, 300 sec: 15703.4). Total num frames: 59981824. Throughput: 0: 15385.3. Samples: 48025620. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:25:13,110][26276] Avg episode reward: [(0, '-533.262')]
[2023-08-31 22:25:13,111][26287] Saving new best policy, reward=-533.262!
[2023-08-31 22:25:14,197][26288] Updated weights for policy 0, policy_version 117192 (0.0002)
[2023-08-31 22:25:16,690][26288] Updated weights for policy 0, policy_version 117272 (0.0002)
[2023-08-31 22:25:18,107][26276] Fps is (10 sec: 15974.8, 60 sec: 15632.9, 300 sec: 15717.6). Total num frames: 60067840. Throughput: 0: 15574.6. Samples: 48122268. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:25:18,107][26276] Avg episode reward: [(0, '-533.262')]
[2023-08-31 22:25:19,418][26288] Updated weights for policy 0, policy_version 117352 (0.0002)
[2023-08-31 22:25:21,855][26288] Updated weights for policy 0, policy_version 117432 (0.0002)
[2023-08-31 22:25:23,115][26276] Fps is (10 sec: 16376.2, 60 sec: 15632.4, 300 sec: 15730.9). Total num frames: 60145664. Throughput: 0: 15509.3. Samples: 48218094. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:25:23,115][26276] Avg episode reward: [(0, '-522.551')]
[2023-08-31 22:25:23,116][26287] Saving new best policy, reward=-522.551!
[2023-08-31 22:25:24,340][26288] Updated weights for policy 0, policy_version 117512 (0.0002)
[2023-08-31 22:25:26,876][26288] Updated weights for policy 0, policy_version 117592 (0.0002)
[2023-08-31 22:25:28,107][26276] Fps is (10 sec: 15565.8, 60 sec: 15635.3, 300 sec: 15731.4). Total num frames: 60223488. Throughput: 0: 15576.6. Samples: 48266847. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:25:28,107][26276] Avg episode reward: [(0, '-522.551')]
[2023-08-31 22:25:29,588][26288] Updated weights for policy 0, policy_version 117672 (0.0002)
[2023-08-31 22:25:32,170][26288] Updated weights for policy 0, policy_version 117752 (0.0002)
[2023-08-31 22:25:33,108][26276] Fps is (10 sec: 15576.2, 60 sec: 15633.2, 300 sec: 15745.4). Total num frames: 60301312. Throughput: 0: 15532.9. Samples: 48360050. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:25:33,108][26276] Avg episode reward: [(0, '-511.699')]
[2023-08-31 22:25:33,108][26287] Saving new best policy, reward=-511.699!
[2023-08-31 22:25:34,706][26288] Updated weights for policy 0, policy_version 117832 (0.0002)
[2023-08-31 22:25:37,184][26288] Updated weights for policy 0, policy_version 117912 (0.0002)
[2023-08-31 22:25:38,106][26276] Fps is (10 sec: 15976.1, 60 sec: 15703.1, 300 sec: 15759.4). Total num frames: 60383232. Throughput: 0: 15763.8. Samples: 48457688. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:25:38,106][26276] Avg episode reward: [(0, '-511.699')]
[2023-08-31 22:25:39,901][26288] Updated weights for policy 0, policy_version 117992 (0.0002)
[2023-08-31 22:25:42,505][26288] Updated weights for policy 0, policy_version 118072 (0.0002)
[2023-08-31 22:25:43,112][26276] Fps is (10 sec: 15967.1, 60 sec: 15633.4, 300 sec: 15759.0). Total num frames: 60461056. Throughput: 0: 15690.5. Samples: 48502385. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:25:43,113][26276] Avg episode reward: [(0, '-498.421')]
[2023-08-31 22:25:43,115][26287] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000118088_60461056.pth...
[2023-08-31 22:25:43,117][26287] Removing /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000111936_57311232.pth
[2023-08-31 22:25:43,119][26287] Saving new best policy, reward=-498.421!
[2023-08-31 22:25:45,044][26288] Updated weights for policy 0, policy_version 118152 (0.0002)
[2023-08-31 22:25:47,638][26288] Updated weights for policy 0, policy_version 118232 (0.0002)
[2023-08-31 22:25:48,108][26276] Fps is (10 sec: 15969.6, 60 sec: 15769.7, 300 sec: 15772.9). Total num frames: 60542976. Throughput: 0: 15796.5. Samples: 48598680. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:25:48,109][26276] Avg episode reward: [(0, '-498.421')]
[2023-08-31 22:25:50,401][26288] Updated weights for policy 0, policy_version 118312 (0.0002)
[2023-08-31 22:25:52,865][26288] Updated weights for policy 0, policy_version 118392 (0.0002)
[2023-08-31 22:25:53,105][26276] Fps is (10 sec: 15985.6, 60 sec: 15769.9, 300 sec: 15773.2). Total num frames: 60620800. Throughput: 0: 15779.1. Samples: 48692225. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:25:53,106][26276] Avg episode reward: [(0, '-487.104')]
[2023-08-31 22:25:53,106][26287] Saving new best policy, reward=-487.104!
[2023-08-31 22:25:55,247][26288] Updated weights for policy 0, policy_version 118472 (0.0002)
[2023-08-31 22:25:57,620][26288] Updated weights for policy 0, policy_version 118552 (0.0002)
[2023-08-31 22:25:58,108][26276] Fps is (10 sec: 15975.9, 60 sec: 15837.9, 300 sec: 15773.1). Total num frames: 60702720. Throughput: 0: 15946.9. Samples: 48743187. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:25:58,108][26276] Avg episode reward: [(0, '-487.104')]
[2023-08-31 22:26:00,308][26288] Updated weights for policy 0, policy_version 118632 (0.0002)
[2023-08-31 22:26:02,720][26288] Updated weights for policy 0, policy_version 118712 (0.0002)
[2023-08-31 22:26:03,109][26276] Fps is (10 sec: 16377.4, 60 sec: 15905.3, 300 sec: 15787.0). Total num frames: 60784640. Throughput: 0: 15972.3. Samples: 48841057. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:26:03,110][26276] Avg episode reward: [(0, '-474.360')]
[2023-08-31 22:26:03,110][26287] Saving new best policy, reward=-474.360!
[2023-08-31 22:26:05,301][26288] Updated weights for policy 0, policy_version 118792 (0.0002)
[2023-08-31 22:26:07,807][26288] Updated weights for policy 0, policy_version 118872 (0.0002)
[2023-08-31 22:26:08,114][26276] Fps is (10 sec: 16372.9, 60 sec: 15972.6, 300 sec: 15786.5). Total num frames: 60866560. Throughput: 0: 16020.9. Samples: 48939024. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:26:08,115][26276] Avg episode reward: [(0, '-474.360')]
[2023-08-31 22:26:11,373][26288] Updated weights for policy 0, policy_version 118952 (0.0003)
[2023-08-31 22:26:13,108][26276] Fps is (10 sec: 14337.8, 60 sec: 15770.2, 300 sec: 15731.5). Total num frames: 60928000. Throughput: 0: 15639.4. Samples: 48970646. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:26:13,110][26276] Avg episode reward: [(0, '-457.950')]
[2023-08-31 22:26:13,111][26287] Saving new best policy, reward=-457.950!
[2023-08-31 22:26:14,206][26288] Updated weights for policy 0, policy_version 119032 (0.0002)
[2023-08-31 22:26:16,747][26288] Updated weights for policy 0, policy_version 119112 (0.0002)
[2023-08-31 22:26:18,110][26276] Fps is (10 sec: 13932.2, 60 sec: 15632.3, 300 sec: 15717.4). Total num frames: 61005824. Throughput: 0: 15597.6. Samples: 49061982. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:26:18,110][26276] Avg episode reward: [(0, '-457.950')]
[2023-08-31 22:26:19,323][26288] Updated weights for policy 0, policy_version 119192 (0.0002)
[2023-08-31 22:26:22,130][26288] Updated weights for policy 0, policy_version 119272 (0.0002)
[2023-08-31 22:26:23,109][26276] Fps is (10 sec: 15153.4, 60 sec: 15566.3, 300 sec: 15703.5). Total num frames: 61079552. Throughput: 0: 15495.6. Samples: 49155048. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2023-08-31 22:26:23,110][26276] Avg episode reward: [(0, '-439.544')]
[2023-08-31 22:26:23,127][26287] Saving new best policy, reward=-439.544!
[2023-08-31 22:26:24,643][26288] Updated weights for policy 0, policy_version 119352 (0.0002)
[2023-08-31 22:26:27,154][26288] Updated weights for policy 0, policy_version 119432 (0.0002)
[2023-08-31 22:26:28,108][26276] Fps is (10 sec: 15568.2, 60 sec: 15632.7, 300 sec: 15703.5). Total num frames: 61161472. Throughput: 0: 15595.3. Samples: 49204106. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2023-08-31 22:26:28,108][26276] Avg episode reward: [(0, '-439.544')]
[2023-08-31 22:26:29,689][26288] Updated weights for policy 0, policy_version 119512 (0.0002)
[2023-08-31 22:26:32,483][26288] Updated weights for policy 0, policy_version 119592 (0.0002)
[2023-08-31 22:26:33,105][26276] Fps is (10 sec: 15980.6, 60 sec: 15633.7, 300 sec: 15717.7). Total num frames: 61239296. Throughput: 0: 15511.5. Samples: 49296650. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2023-08-31 22:26:33,106][26276] Avg episode reward: [(0, '-422.154')]
[2023-08-31 22:26:33,106][26287] Saving new best policy, reward=-422.154!
[2023-08-31 22:26:35,030][26288] Updated weights for policy 0, policy_version 119672 (0.0002)
[2023-08-31 22:26:37,592][26288] Updated weights for policy 0, policy_version 119752 (0.0002)
[2023-08-31 22:26:38,110][26276] Fps is (10 sec: 15561.7, 60 sec: 15563.6, 300 sec: 15703.5). Total num frames: 61317120. Throughput: 0: 15586.3. Samples: 49393680. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2023-08-31 22:26:38,110][26276] Avg episode reward: [(0, '-422.154')]
[2023-08-31 22:26:40,166][26288] Updated weights for policy 0, policy_version 119832 (0.0002)
[2023-08-31 22:26:42,964][26288] Updated weights for policy 0, policy_version 119912 (0.0002)
[2023-08-31 22:26:43,106][26276] Fps is (10 sec: 15564.7, 60 sec: 15566.6, 300 sec: 15717.8). Total num frames: 61394944. Throughput: 0: 15510.6. Samples: 49441130. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2023-08-31 22:26:43,106][26276] Avg episode reward: [(0, '-407.025')]
[2023-08-31 22:26:43,106][26287] Saving new best policy, reward=-407.025!
[2023-08-31 22:26:45,391][26288] Updated weights for policy 0, policy_version 119992 (0.0002)
[2023-08-31 22:26:47,821][26288] Updated weights for policy 0, policy_version 120072 (0.0002)
[2023-08-31 22:26:48,108][26276] Fps is (10 sec: 16387.2, 60 sec: 15633.2, 300 sec: 15731.3). Total num frames: 61480960. Throughput: 0: 15448.0. Samples: 49536196. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2023-08-31 22:26:48,108][26276] Avg episode reward: [(0, '-407.025')]
[2023-08-31 22:26:50,311][26288] Updated weights for policy 0, policy_version 120152 (0.0002)
[2023-08-31 22:26:52,993][26288] Updated weights for policy 0, policy_version 120232 (0.0002)
[2023-08-31 22:26:53,105][26276] Fps is (10 sec: 16384.2, 60 sec: 15633.0, 300 sec: 15731.4). Total num frames: 61558784. Throughput: 0: 15395.7. Samples: 49631691. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2023-08-31 22:26:53,106][26276] Avg episode reward: [(0, '-390.840')]
[2023-08-31 22:26:53,106][26287] Saving new best policy, reward=-390.840!
[2023-08-31 22:26:55,546][26288] Updated weights for policy 0, policy_version 120312 (0.0002)
[2023-08-31 22:26:58,034][26288] Updated weights for policy 0, policy_version 120392 (0.0002)
[2023-08-31 22:26:58,109][26276] Fps is (10 sec: 15972.8, 60 sec: 15632.7, 300 sec: 15731.4). Total num frames: 61640704. Throughput: 0: 15772.1. Samples: 49680405. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2023-08-31 22:26:58,109][26276] Avg episode reward: [(0, '-390.840')]
[2023-08-31 22:27:00,767][26288] Updated weights for policy 0, policy_version 120472 (0.0002)
[2023-08-31 22:27:03,105][26276] Fps is (10 sec: 15975.0, 60 sec: 15565.9, 300 sec: 15731.5). Total num frames: 61718528. Throughput: 0: 15838.0. Samples: 49774610. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2023-08-31 22:27:03,105][26276] Avg episode reward: [(0, '-376.164')]
[2023-08-31 22:27:03,106][26287] Saving new best policy, reward=-376.164!
[2023-08-31 22:27:03,343][26288] Updated weights for policy 0, policy_version 120552 (0.0002)
[2023-08-31 22:27:05,916][26288] Updated weights for policy 0, policy_version 120632 (0.0002)
[2023-08-31 22:27:08,108][26276] Fps is (10 sec: 15566.7, 60 sec: 15498.2, 300 sec: 15731.4). Total num frames: 61796352. Throughput: 0: 15890.8. Samples: 49870112. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2023-08-31 22:27:08,108][26276] Avg episode reward: [(0, '-376.164')]
[2023-08-31 22:27:08,510][26288] Updated weights for policy 0, policy_version 120712 (0.0002)
[2023-08-31 22:27:11,277][26288] Updated weights for policy 0, policy_version 120792 (0.0002)
[2023-08-31 22:27:13,109][26276] Fps is (10 sec: 15558.3, 60 sec: 15769.3, 300 sec: 15731.3). Total num frames: 61874176. Throughput: 0: 15865.7. Samples: 49918080. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2023-08-31 22:27:13,109][26276] Avg episode reward: [(0, '-361.795')]
[2023-08-31 22:27:13,110][26287] Saving new best policy, reward=-361.795!
[2023-08-31 22:27:13,804][26288] Updated weights for policy 0, policy_version 120872 (0.0002)
[2023-08-31 22:27:16,324][26288] Updated weights for policy 0, policy_version 120952 (0.0002)
[2023-08-31 22:27:18,110][26276] Fps is (10 sec: 15971.0, 60 sec: 15837.9, 300 sec: 15759.0). Total num frames: 61956096. Throughput: 0: 15899.0. Samples: 50012176. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2023-08-31 22:27:18,110][26276] Avg episode reward: [(0, '-361.795')]
[2023-08-31 22:27:18,816][26288] Updated weights for policy 0, policy_version 121032 (0.0002)
[2023-08-31 22:27:21,484][26288] Updated weights for policy 0, policy_version 121112 (0.0002)
[2023-08-31 22:27:23,105][26276] Fps is (10 sec: 15980.5, 60 sec: 15907.2, 300 sec: 15745.5). Total num frames: 62033920. Throughput: 0: 15869.8. Samples: 50107750. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2023-08-31 22:27:23,106][26276] Avg episode reward: [(0, '-322.417')]
[2023-08-31 22:27:23,109][26287] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000121160_62033920.pth...
[2023-08-31 22:27:23,110][26287] Removing /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000115024_58892288.pth
[2023-08-31 22:27:23,110][26287] Saving new best policy, reward=-322.417!
[2023-08-31 22:27:23,918][26288] Updated weights for policy 0, policy_version 121192 (0.0002)
[2023-08-31 22:27:26,405][26288] Updated weights for policy 0, policy_version 121272 (0.0002)
[2023-08-31 22:27:28,105][26276] Fps is (10 sec: 15982.0, 60 sec: 15906.9, 300 sec: 15745.6). Total num frames: 62115840. Throughput: 0: 15927.8. Samples: 50157875. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:27:28,105][26276] Avg episode reward: [(0, '-322.417')]
[2023-08-31 22:27:28,885][26288] Updated weights for policy 0, policy_version 121352 (0.0002)
[2023-08-31 22:27:31,567][26288] Updated weights for policy 0, policy_version 121432 (0.0002)
[2023-08-31 22:27:33,105][26276] Fps is (10 sec: 16384.1, 60 sec: 15974.4, 300 sec: 15773.1). Total num frames: 62197760. Throughput: 0: 15948.6. Samples: 50253840. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:27:33,106][26276] Avg episode reward: [(0, '-414.710')]
[2023-08-31 22:27:34,068][26288] Updated weights for policy 0, policy_version 121512 (0.0002)
[2023-08-31 22:27:36,496][26288] Updated weights for policy 0, policy_version 121592 (0.0002)
[2023-08-31 22:27:38,107][26276] Fps is (10 sec: 16381.8, 60 sec: 16043.6, 300 sec: 15773.3). Total num frames: 62279680. Throughput: 0: 16021.3. Samples: 50352668. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:27:38,107][26276] Avg episode reward: [(0, '-414.710')]
[2023-08-31 22:27:38,990][26288] Updated weights for policy 0, policy_version 121672 (0.0002)
[2023-08-31 22:27:41,832][26288] Updated weights for policy 0, policy_version 121752 (0.0002)
[2023-08-31 22:27:43,105][26276] Fps is (10 sec: 15974.2, 60 sec: 16042.7, 300 sec: 15773.3). Total num frames: 62357504. Throughput: 0: 16080.1. Samples: 50403952. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:27:43,106][26276] Avg episode reward: [(0, '-680.451')]
[2023-08-31 22:27:44,374][26288] Updated weights for policy 0, policy_version 121832 (0.0002)
[2023-08-31 22:27:46,771][26288] Updated weights for policy 0, policy_version 121912 (0.0002)
[2023-08-31 22:27:48,105][26276] Fps is (10 sec: 15976.6, 60 sec: 15975.2, 300 sec: 15759.4). Total num frames: 62439424. Throughput: 0: 16025.2. Samples: 50495746. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:27:48,105][26276] Avg episode reward: [(0, '-680.451')]
[2023-08-31 22:27:49,254][26288] Updated weights for policy 0, policy_version 121992 (0.0002)
[2023-08-31 22:27:51,957][26288] Updated weights for policy 0, policy_version 122072 (0.0002)
[2023-08-31 22:27:53,109][26276] Fps is (10 sec: 15969.2, 60 sec: 15973.5, 300 sec: 15759.1). Total num frames: 62517248. Throughput: 0: 16022.0. Samples: 50591117. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:27:53,109][26276] Avg episode reward: [(0, '-960.838')]
[2023-08-31 22:27:54,420][26288] Updated weights for policy 0, policy_version 122152 (0.0002)
[2023-08-31 22:27:56,786][26288] Updated weights for policy 0, policy_version 122232 (0.0002)
[2023-08-31 22:27:58,105][26276] Fps is (10 sec: 16383.8, 60 sec: 16043.7, 300 sec: 15773.1). Total num frames: 62603264. Throughput: 0: 16087.3. Samples: 50641947. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:27:58,106][26276] Avg episode reward: [(0, '-960.838')]
[2023-08-31 22:27:59,184][26288] Updated weights for policy 0, policy_version 122312 (0.0002)
[2023-08-31 22:28:01,866][26288] Updated weights for policy 0, policy_version 122392 (0.0002)
[2023-08-31 22:28:03,108][26276] Fps is (10 sec: 16795.0, 60 sec: 16110.2, 300 sec: 15800.7). Total num frames: 62685184. Throughput: 0: 16164.7. Samples: 50739555. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:28:03,108][26276] Avg episode reward: [(0, '-1279.102')]
[2023-08-31 22:28:04,302][26288] Updated weights for policy 0, policy_version 122472 (0.0002)
[2023-08-31 22:28:06,734][26288] Updated weights for policy 0, policy_version 122552 (0.0002)
[2023-08-31 22:28:08,105][26276] Fps is (10 sec: 16384.1, 60 sec: 16179.9, 300 sec: 15800.9). Total num frames: 62767104. Throughput: 0: 16294.8. Samples: 50841015. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:28:08,105][26276] Avg episode reward: [(0, '-1279.102')]
[2023-08-31 22:28:09,195][26288] Updated weights for policy 0, policy_version 122632 (0.0002)
[2023-08-31 22:28:11,856][26288] Updated weights for policy 0, policy_version 122712 (0.0002)
[2023-08-31 22:28:13,109][26276] Fps is (10 sec: 16382.7, 60 sec: 16247.6, 300 sec: 15814.8). Total num frames: 62849024. Throughput: 0: 16196.2. Samples: 50886761. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:28:13,109][26276] Avg episode reward: [(0, '-1399.979')]
[2023-08-31 22:28:14,272][26288] Updated weights for policy 0, policy_version 122792 (0.0002)
[2023-08-31 22:28:16,755][26288] Updated weights for policy 0, policy_version 122872 (0.0002)
[2023-08-31 22:28:18,109][26276] Fps is (10 sec: 15969.1, 60 sec: 16179.6, 300 sec: 15814.6). Total num frames: 62926848. Throughput: 0: 16294.1. Samples: 50987127. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:28:18,109][26276] Avg episode reward: [(0, '-1399.979')]
[2023-08-31 22:28:19,299][26288] Updated weights for policy 0, policy_version 122952 (0.0002)
[2023-08-31 22:28:21,971][26288] Updated weights for policy 0, policy_version 123032 (0.0002)
[2023-08-31 22:28:23,105][26276] Fps is (10 sec: 15979.5, 60 sec: 16247.4, 300 sec: 15828.8). Total num frames: 63008768. Throughput: 0: 16210.7. Samples: 51082132. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:28:23,106][26276] Avg episode reward: [(0, '-1691.102')]
[2023-08-31 22:28:24,414][26288] Updated weights for policy 0, policy_version 123112 (0.0002)
[2023-08-31 22:28:26,927][26288] Updated weights for policy 0, policy_version 123192 (0.0002)
[2023-08-31 22:28:28,107][26276] Fps is (10 sec: 16386.0, 60 sec: 16246.9, 300 sec: 15814.9). Total num frames: 63090688. Throughput: 0: 16197.4. Samples: 51132863. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[2023-08-31 22:28:28,108][26276] Avg episode reward: [(0, '-1691.102')]
[2023-08-31 22:28:29,417][26288] Updated weights for policy 0, policy_version 123272 (0.0002)
[2023-08-31 22:28:32,147][26288] Updated weights for policy 0, policy_version 123352 (0.0002)
[2023-08-31 22:28:33,105][26276] Fps is (10 sec: 16384.1, 60 sec: 16247.4, 300 sec: 15828.6). Total num frames: 63172608. Throughput: 0: 16248.3. Samples: 51226923. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[2023-08-31 22:28:33,106][26276] Avg episode reward: [(0, '-1770.847')]
[2023-08-31 22:28:34,554][26288] Updated weights for policy 0, policy_version 123432 (0.0002)
[2023-08-31 22:28:37,058][26288] Updated weights for policy 0, policy_version 123512 (0.0002)
[2023-08-31 22:28:38,107][26276] Fps is (10 sec: 16384.5, 60 sec: 16247.3, 300 sec: 15842.6). Total num frames: 63254528. Throughput: 0: 16353.4. Samples: 51326992. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[2023-08-31 22:28:38,107][26276] Avg episode reward: [(0, '-1770.847')]
[2023-08-31 22:28:39,486][26288] Updated weights for policy 0, policy_version 123592 (0.0002)
[2023-08-31 22:28:42,231][26288] Updated weights for policy 0, policy_version 123672 (0.0002)
[2023-08-31 22:28:43,109][26276] Fps is (10 sec: 15968.9, 60 sec: 16246.5, 300 sec: 15842.3). Total num frames: 63332352. Throughput: 0: 16258.4. Samples: 51373634. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[2023-08-31 22:28:43,109][26276] Avg episode reward: [(0, '-1643.219')]
[2023-08-31 22:28:44,711][26288] Updated weights for policy 0, policy_version 123752 (0.0002)
[2023-08-31 22:28:47,144][26288] Updated weights for policy 0, policy_version 123832 (0.0002)
[2023-08-31 22:28:48,108][26276] Fps is (10 sec: 15973.0, 60 sec: 16246.7, 300 sec: 15842.4). Total num frames: 63414272. Throughput: 0: 16291.1. Samples: 51472655. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[2023-08-31 22:28:48,108][26276] Avg episode reward: [(0, '-1643.219')]
[2023-08-31 22:28:49,856][26288] Updated weights for policy 0, policy_version 123912 (0.0002)
[2023-08-31 22:28:52,321][26288] Updated weights for policy 0, policy_version 123992 (0.0002)
[2023-08-31 22:28:53,110][26276] Fps is (10 sec: 16382.1, 60 sec: 16315.4, 300 sec: 15884.3). Total num frames: 63496192. Throughput: 0: 16168.1. Samples: 51568656. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[2023-08-31 22:28:53,110][26276] Avg episode reward: [(0, '-1569.837')]
[2023-08-31 22:28:54,753][26288] Updated weights for policy 0, policy_version 124072 (0.0002)
[2023-08-31 22:28:57,248][26288] Updated weights for policy 0, policy_version 124152 (0.0002)
[2023-08-31 22:28:58,110][26276] Fps is (10 sec: 16380.5, 60 sec: 16246.2, 300 sec: 15884.1). Total num frames: 63578112. Throughput: 0: 16245.9. Samples: 51617848. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[2023-08-31 22:28:58,111][26276] Avg episode reward: [(0, '-1569.837')]
[2023-08-31 22:29:00,181][26288] Updated weights for policy 0, policy_version 124232 (0.0002)
[2023-08-31 22:29:02,642][26288] Updated weights for policy 0, policy_version 124312 (0.0002)
[2023-08-31 22:29:03,108][26276] Fps is (10 sec: 15567.7, 60 sec: 16110.9, 300 sec: 15870.2). Total num frames: 63651840. Throughput: 0: 16067.8. Samples: 51710173. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[2023-08-31 22:29:03,108][26276] Avg episode reward: [(0, '-1601.305')]
[2023-08-31 22:29:03,112][26287] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000124320_63651840.pth...
[2023-08-31 22:29:03,115][26287] Removing /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000118088_60461056.pth
[2023-08-31 22:29:05,217][26288] Updated weights for policy 0, policy_version 124392 (0.0002)
[2023-08-31 22:29:07,753][26288] Updated weights for policy 0, policy_version 124472 (0.0002)
[2023-08-31 22:29:08,109][26276] Fps is (10 sec: 15566.3, 60 sec: 16109.9, 300 sec: 15870.1). Total num frames: 63733760. Throughput: 0: 16112.3. Samples: 51807243. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[2023-08-31 22:29:08,109][26276] Avg episode reward: [(0, '-1601.305')]
[2023-08-31 22:29:10,426][26288] Updated weights for policy 0, policy_version 124552 (0.0002)
[2023-08-31 22:29:12,921][26288] Updated weights for policy 0, policy_version 124632 (0.0002)
[2023-08-31 22:29:13,107][26276] Fps is (10 sec: 15976.8, 60 sec: 16043.2, 300 sec: 15870.3). Total num frames: 63811584. Throughput: 0: 16016.3. Samples: 51853584. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[2023-08-31 22:29:13,107][26276] Avg episode reward: [(0, '-1736.530')]
[2023-08-31 22:29:15,431][26288] Updated weights for policy 0, policy_version 124712 (0.0002)
[2023-08-31 22:29:17,933][26288] Updated weights for policy 0, policy_version 124792 (0.0002)
[2023-08-31 22:29:18,105][26276] Fps is (10 sec: 15980.3, 60 sec: 16111.8, 300 sec: 15884.5). Total num frames: 63893504. Throughput: 0: 16114.1. Samples: 51952059. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[2023-08-31 22:29:18,106][26276] Avg episode reward: [(0, '-1736.530')]
[2023-08-31 22:29:20,715][26288] Updated weights for policy 0, policy_version 124872 (0.0002)
[2023-08-31 22:29:23,106][26276] Fps is (10 sec: 15975.3, 60 sec: 16042.5, 300 sec: 15884.6). Total num frames: 63971328. Throughput: 0: 15988.2. Samples: 52046446. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[2023-08-31 22:29:23,106][26276] Avg episode reward: [(0, '-1807.352')]
[2023-08-31 22:29:23,144][26288] Updated weights for policy 0, policy_version 124952 (0.0002)
[2023-08-31 22:29:25,661][26288] Updated weights for policy 0, policy_version 125032 (0.0002)
[2023-08-31 22:29:28,066][26288] Updated weights for policy 0, policy_version 125112 (0.0002)
[2023-08-31 22:29:28,108][26276] Fps is (10 sec: 16379.9, 60 sec: 16110.8, 300 sec: 15911.9). Total num frames: 64057344. Throughput: 0: 16046.3. Samples: 52095702. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 22:29:28,108][26276] Avg episode reward: [(0, '-1807.352')]
[2023-08-31 22:29:30,887][26288] Updated weights for policy 0, policy_version 125192 (0.0002)
[2023-08-31 22:29:33,107][26276] Fps is (10 sec: 15972.3, 60 sec: 15973.9, 300 sec: 15898.3). Total num frames: 64131072. Throughput: 0: 15933.1. Samples: 52189635. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 22:29:33,108][26276] Avg episode reward: [(0, '-1930.344')]
[2023-08-31 22:29:33,493][26288] Updated weights for policy 0, policy_version 125272 (0.0002)
[2023-08-31 22:29:36,069][26288] Updated weights for policy 0, policy_version 125352 (0.0002)
[2023-08-31 22:29:38,107][26276] Fps is (10 sec: 15565.7, 60 sec: 15974.3, 300 sec: 15898.4). Total num frames: 64212992. Throughput: 0: 15929.9. Samples: 52285458. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 22:29:38,108][26276] Avg episode reward: [(0, '-1930.344')]
[2023-08-31 22:29:38,546][26288] Updated weights for policy 0, policy_version 125432 (0.0002)
[2023-08-31 22:29:41,433][26288] Updated weights for policy 0, policy_version 125512 (0.0003)
[2023-08-31 22:29:43,108][26276] Fps is (10 sec: 15564.0, 60 sec: 15906.4, 300 sec: 15898.1). Total num frames: 64286720. Throughput: 0: 15837.7. Samples: 52330512. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 22:29:43,108][26276] Avg episode reward: [(0, '-1894.996')]
[2023-08-31 22:29:43,894][26288] Updated weights for policy 0, policy_version 125592 (0.0002)
[2023-08-31 22:29:46,435][26288] Updated weights for policy 0, policy_version 125672 (0.0002)
[2023-08-31 22:29:48,111][26276] Fps is (10 sec: 15559.7, 60 sec: 15905.4, 300 sec: 15911.7). Total num frames: 64368640. Throughput: 0: 15920.7. Samples: 52426643. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 22:29:48,112][26276] Avg episode reward: [(0, '-1894.996')]
[2023-08-31 22:29:48,976][26288] Updated weights for policy 0, policy_version 125752 (0.0002)
[2023-08-31 22:29:51,763][26288] Updated weights for policy 0, policy_version 125832 (0.0002)
[2023-08-31 22:29:53,109][26276] Fps is (10 sec: 15972.6, 60 sec: 15838.1, 300 sec: 15911.9). Total num frames: 64446464. Throughput: 0: 15819.4. Samples: 52519117. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 22:29:53,109][26276] Avg episode reward: [(0, '-1913.034')]
[2023-08-31 22:29:54,309][26288] Updated weights for policy 0, policy_version 125912 (0.0002)
[2023-08-31 22:29:56,806][26288] Updated weights for policy 0, policy_version 125992 (0.0002)
[2023-08-31 22:29:58,108][26276] Fps is (10 sec: 15979.0, 60 sec: 15838.5, 300 sec: 15925.7). Total num frames: 64528384. Throughput: 0: 15884.5. Samples: 52568401. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 22:29:58,108][26276] Avg episode reward: [(0, '-1913.034')]
[2023-08-31 22:29:59,415][26288] Updated weights for policy 0, policy_version 126072 (0.0002)
[2023-08-31 22:30:02,076][26288] Updated weights for policy 0, policy_version 126152 (0.0002)
[2023-08-31 22:30:03,107][26276] Fps is (10 sec: 15568.5, 60 sec: 15838.3, 300 sec: 15912.0). Total num frames: 64602112. Throughput: 0: 15782.6. Samples: 52662297. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 22:30:03,107][26276] Avg episode reward: [(0, '-1630.226')]
[2023-08-31 22:30:04,575][26288] Updated weights for policy 0, policy_version 126232 (0.0002)
[2023-08-31 22:30:06,995][26288] Updated weights for policy 0, policy_version 126312 (0.0002)
[2023-08-31 22:30:08,109][26276] Fps is (10 sec: 15972.1, 60 sec: 15906.1, 300 sec: 15953.6). Total num frames: 64688128. Throughput: 0: 15882.4. Samples: 52761202. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 22:30:08,109][26276] Avg episode reward: [(0, '-1630.226')]
[2023-08-31 22:30:09,641][26288] Updated weights for policy 0, policy_version 126392 (0.0002)
[2023-08-31 22:30:12,415][26288] Updated weights for policy 0, policy_version 126472 (0.0002)
[2023-08-31 22:30:13,110][26276] Fps is (10 sec: 15969.2, 60 sec: 15837.0, 300 sec: 15911.8). Total num frames: 64761856. Throughput: 0: 15768.7. Samples: 52805326. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 22:30:13,110][26276] Avg episode reward: [(0, '-1459.444')]
[2023-08-31 22:30:14,917][26288] Updated weights for policy 0, policy_version 126552 (0.0002)
[2023-08-31 22:30:17,385][26288] Updated weights for policy 0, policy_version 126632 (0.0002)
[2023-08-31 22:30:18,106][26276] Fps is (10 sec: 15979.2, 60 sec: 15905.9, 300 sec: 15940.2). Total num frames: 64847872. Throughput: 0: 15851.8. Samples: 52902948. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 22:30:18,106][26276] Avg episode reward: [(0, '-1459.444')]
[2023-08-31 22:30:19,892][26288] Updated weights for policy 0, policy_version 126712 (0.0002)
[2023-08-31 22:30:22,599][26288] Updated weights for policy 0, policy_version 126792 (0.0002)
[2023-08-31 22:30:23,110][26276] Fps is (10 sec: 16383.9, 60 sec: 15905.1, 300 sec: 15939.5). Total num frames: 64925696. Throughput: 0: 15814.6. Samples: 52997158. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 22:30:23,110][26276] Avg episode reward: [(0, '-1250.499')]
[2023-08-31 22:30:25,125][26288] Updated weights for policy 0, policy_version 126872 (0.0002)
[2023-08-31 22:30:27,523][26288] Updated weights for policy 0, policy_version 126952 (0.0002)
[2023-08-31 22:30:28,108][26276] Fps is (10 sec: 15971.8, 60 sec: 15837.9, 300 sec: 15953.6). Total num frames: 65007616. Throughput: 0: 15904.9. Samples: 53046231. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 22:30:28,108][26276] Avg episode reward: [(0, '-1250.499')]
[2023-08-31 22:30:30,052][26288] Updated weights for policy 0, policy_version 127032 (0.0002)
[2023-08-31 22:30:32,918][26288] Updated weights for policy 0, policy_version 127112 (0.0002)
[2023-08-31 22:30:33,109][26276] Fps is (10 sec: 15566.8, 60 sec: 15837.5, 300 sec: 15925.6). Total num frames: 65081344. Throughput: 0: 15939.7. Samples: 53143902. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:30:33,109][26276] Avg episode reward: [(0, '-979.529')]
[2023-08-31 22:30:35,466][26288] Updated weights for policy 0, policy_version 127192 (0.0002)
[2023-08-31 22:30:38,009][26288] Updated weights for policy 0, policy_version 127272 (0.0002)
[2023-08-31 22:30:38,108][26276] Fps is (10 sec: 15563.9, 60 sec: 15837.6, 300 sec: 15939.9). Total num frames: 65163264. Throughput: 0: 15937.0. Samples: 53236273. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:30:38,109][26276] Avg episode reward: [(0, '-979.529')]
[2023-08-31 22:30:40,645][26288] Updated weights for policy 0, policy_version 127352 (0.0002)
[2023-08-31 22:30:43,107][26276] Fps is (10 sec: 15976.4, 60 sec: 15906.3, 300 sec: 15925.9). Total num frames: 65241088. Throughput: 0: 15921.9. Samples: 53284884. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:30:43,109][26276] Avg episode reward: [(0, '-876.646')]
[2023-08-31 22:30:43,112][26287] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000127424_65241088.pth...
[2023-08-31 22:30:43,115][26287] Removing /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000121160_62033920.pth
[2023-08-31 22:30:43,177][26288] Updated weights for policy 0, policy_version 127432 (0.0002)
[2023-08-31 22:30:45,602][26288] Updated weights for policy 0, policy_version 127512 (0.0002)
[2023-08-31 22:30:48,110][26276] Fps is (10 sec: 15971.2, 60 sec: 15906.2, 300 sec: 15939.4). Total num frames: 65323008. Throughput: 0: 16013.1. Samples: 53382947. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:30:48,111][26276] Avg episode reward: [(0, '-876.646')]
[2023-08-31 22:30:48,218][26288] Updated weights for policy 0, policy_version 127592 (0.0002)
[2023-08-31 22:30:50,920][26288] Updated weights for policy 0, policy_version 127672 (0.0002)
[2023-08-31 22:30:53,110][26276] Fps is (10 sec: 15970.5, 60 sec: 15905.9, 300 sec: 15925.7). Total num frames: 65400832. Throughput: 0: 15888.5. Samples: 53476196. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:30:53,110][26276] Avg episode reward: [(0, '-815.387')]
[2023-08-31 22:30:53,363][26288] Updated weights for policy 0, policy_version 127752 (0.0002)
[2023-08-31 22:30:55,904][26288] Updated weights for policy 0, policy_version 127832 (0.0002)
[2023-08-31 22:30:58,106][26276] Fps is (10 sec: 16392.0, 60 sec: 15975.0, 300 sec: 15939.9). Total num frames: 65486848. Throughput: 0: 15991.7. Samples: 53524883. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:30:58,106][26276] Avg episode reward: [(0, '-815.387')]
[2023-08-31 22:30:58,376][26288] Updated weights for policy 0, policy_version 127912 (0.0002)
[2023-08-31 22:31:01,084][26288] Updated weights for policy 0, policy_version 127992 (0.0002)
[2023-08-31 22:31:03,110][26276] Fps is (10 sec: 16383.7, 60 sec: 16041.8, 300 sec: 15926.0). Total num frames: 65564672. Throughput: 0: 15944.2. Samples: 53620501. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:31:03,110][26276] Avg episode reward: [(0, '-795.881')]
[2023-08-31 22:31:03,508][26288] Updated weights for policy 0, policy_version 128072 (0.0002)
[2023-08-31 22:31:06,135][26288] Updated weights for policy 0, policy_version 128152 (0.0002)
[2023-08-31 22:31:08,110][26276] Fps is (10 sec: 15558.5, 60 sec: 15906.0, 300 sec: 15981.3). Total num frames: 65642496. Throughput: 0: 16020.0. Samples: 53718053. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:31:08,110][26276] Avg episode reward: [(0, '-795.881')]
[2023-08-31 22:31:08,617][26288] Updated weights for policy 0, policy_version 128232 (0.0002)
[2023-08-31 22:31:11,356][26288] Updated weights for policy 0, policy_version 128312 (0.0002)
[2023-08-31 22:31:13,107][26276] Fps is (10 sec: 15570.3, 60 sec: 15975.3, 300 sec: 15981.5). Total num frames: 65720320. Throughput: 0: 15966.3. Samples: 53764695. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:31:13,107][26276] Avg episode reward: [(0, '-655.327')]
[2023-08-31 22:31:13,909][26288] Updated weights for policy 0, policy_version 128392 (0.0002)
[2023-08-31 22:31:16,442][26288] Updated weights for policy 0, policy_version 128472 (0.0002)
[2023-08-31 22:31:18,110][26276] Fps is (10 sec: 15973.3, 60 sec: 15905.0, 300 sec: 16009.1). Total num frames: 65802240. Throughput: 0: 15907.1. Samples: 53859748. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:31:18,111][26276] Avg episode reward: [(0, '-655.327')]
[2023-08-31 22:31:18,948][26288] Updated weights for policy 0, policy_version 128552 (0.0002)
[2023-08-31 22:31:21,717][26288] Updated weights for policy 0, policy_version 128632 (0.0002)
[2023-08-31 22:31:23,110][26276] Fps is (10 sec: 15968.6, 60 sec: 15906.1, 300 sec: 15995.1). Total num frames: 65880064. Throughput: 0: 15936.3. Samples: 53953432. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:31:23,110][26276] Avg episode reward: [(0, '-559.676')]
[2023-08-31 22:31:24,199][26288] Updated weights for policy 0, policy_version 128712 (0.0002)
[2023-08-31 22:31:26,730][26288] Updated weights for policy 0, policy_version 128792 (0.0002)
[2023-08-31 22:31:28,110][26276] Fps is (10 sec: 15975.5, 60 sec: 15905.7, 300 sec: 16008.9). Total num frames: 65961984. Throughput: 0: 15989.9. Samples: 54004465. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:31:28,110][26276] Avg episode reward: [(0, '-559.676')]
[2023-08-31 22:31:29,296][26288] Updated weights for policy 0, policy_version 128872 (0.0002)
[2023-08-31 22:31:32,156][26288] Updated weights for policy 0, policy_version 128952 (0.0002)
[2023-08-31 22:31:33,106][26276] Fps is (10 sec: 15981.4, 60 sec: 15975.2, 300 sec: 16009.3). Total num frames: 66039808. Throughput: 0: 15839.7. Samples: 54095662. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:31:33,106][26276] Avg episode reward: [(0, '-499.579')]
[2023-08-31 22:31:34,608][26288] Updated weights for policy 0, policy_version 129032 (0.0002)
[2023-08-31 22:31:37,093][26288] Updated weights for policy 0, policy_version 129112 (0.0002)
[2023-08-31 22:31:38,105][26276] Fps is (10 sec: 15571.9, 60 sec: 15907.0, 300 sec: 16009.1). Total num frames: 66117632. Throughput: 0: 15949.7. Samples: 54193856. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:31:38,105][26276] Avg episode reward: [(0, '-499.579')]
[2023-08-31 22:31:39,645][26288] Updated weights for policy 0, policy_version 129192 (0.0002)
[2023-08-31 22:31:42,527][26288] Updated weights for policy 0, policy_version 129272 (0.0002)
[2023-08-31 22:31:43,108][26276] Fps is (10 sec: 15151.2, 60 sec: 15837.6, 300 sec: 15967.4). Total num frames: 66191360. Throughput: 0: 15934.2. Samples: 54241967. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:31:43,109][26276] Avg episode reward: [(0, '-450.553')]
[2023-08-31 22:31:45,165][26288] Updated weights for policy 0, policy_version 129352 (0.0002)
[2023-08-31 22:31:47,738][26288] Updated weights for policy 0, policy_version 129432 (0.0002)
[2023-08-31 22:31:48,105][26276] Fps is (10 sec: 15564.7, 60 sec: 15839.3, 300 sec: 15981.4). Total num frames: 66273280. Throughput: 0: 15781.4. Samples: 54330587. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:31:48,105][26276] Avg episode reward: [(0, '-450.553')]
[2023-08-31 22:31:50,329][26288] Updated weights for policy 0, policy_version 129512 (0.0002)
[2023-08-31 22:31:53,085][26288] Updated weights for policy 0, policy_version 129592 (0.0002)
[2023-08-31 22:31:53,107][26276] Fps is (10 sec: 15976.3, 60 sec: 15838.6, 300 sec: 15967.6). Total num frames: 66351104. Throughput: 0: 15671.7. Samples: 54423241. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:31:53,108][26276] Avg episode reward: [(0, '-383.732')]
[2023-08-31 22:31:55,686][26288] Updated weights for policy 0, policy_version 129672 (0.0002)
[2023-08-31 22:31:58,110][26276] Fps is (10 sec: 15557.0, 60 sec: 15700.1, 300 sec: 15967.2). Total num frames: 66428928. Throughput: 0: 15702.1. Samples: 54471344. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:31:58,110][26276] Avg episode reward: [(0, '-383.732')]
[2023-08-31 22:31:58,227][26288] Updated weights for policy 0, policy_version 129752 (0.0002)
[2023-08-31 22:32:00,801][26288] Updated weights for policy 0, policy_version 129832 (0.0002)
[2023-08-31 22:32:03,109][26276] Fps is (10 sec: 15561.5, 60 sec: 15701.5, 300 sec: 15967.4). Total num frames: 66506752. Throughput: 0: 15681.3. Samples: 54565391. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:32:03,110][26276] Avg episode reward: [(0, '-368.083')]
[2023-08-31 22:32:03,479][26288] Updated weights for policy 0, policy_version 129912 (0.0002)
[2023-08-31 22:32:06,033][26288] Updated weights for policy 0, policy_version 129992 (0.0002)
[2023-08-31 22:32:08,105][26276] Fps is (10 sec: 15981.9, 60 sec: 15770.7, 300 sec: 15981.5). Total num frames: 66588672. Throughput: 0: 15731.3. Samples: 54661267. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:32:08,106][26276] Avg episode reward: [(0, '-368.083')]
[2023-08-31 22:32:08,515][26288] Updated weights for policy 0, policy_version 130072 (0.0002)
[2023-08-31 22:32:11,023][26288] Updated weights for policy 0, policy_version 130152 (0.0002)
[2023-08-31 22:32:13,109][26276] Fps is (10 sec: 15975.1, 60 sec: 15769.0, 300 sec: 15967.5). Total num frames: 66666496. Throughput: 0: 15693.3. Samples: 54710655. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:32:13,109][26276] Avg episode reward: [(0, '-469.554')]
[2023-08-31 22:32:13,813][26288] Updated weights for policy 0, policy_version 130232 (0.0002)
[2023-08-31 22:32:16,354][26288] Updated weights for policy 0, policy_version 130312 (0.0002)
[2023-08-31 22:32:18,105][26276] Fps is (10 sec: 15974.8, 60 sec: 15771.0, 300 sec: 15981.4). Total num frames: 66748416. Throughput: 0: 15733.8. Samples: 54803672. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:32:18,105][26276] Avg episode reward: [(0, '-469.554')]
[2023-08-31 22:32:18,865][26288] Updated weights for policy 0, policy_version 130392 (0.0002)
[2023-08-31 22:32:21,638][26288] Updated weights for policy 0, policy_version 130472 (0.0002)
[2023-08-31 22:32:23,107][26276] Fps is (10 sec: 15567.3, 60 sec: 15702.1, 300 sec: 15953.5). Total num frames: 66822144. Throughput: 0: 15594.6. Samples: 54895650. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:32:23,108][26276] Avg episode reward: [(0, '-552.079')]
[2023-08-31 22:32:23,111][26287] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000130512_66822144.pth...
[2023-08-31 22:32:23,114][26287] Removing /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000124320_63651840.pth
[2023-08-31 22:32:24,267][26288] Updated weights for policy 0, policy_version 130552 (0.0002)
[2023-08-31 22:32:26,850][26288] Updated weights for policy 0, policy_version 130632 (0.0002)
[2023-08-31 22:32:28,107][26276] Fps is (10 sec: 15151.9, 60 sec: 15633.7, 300 sec: 15939.6). Total num frames: 66899968. Throughput: 0: 15595.4. Samples: 54943743. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:32:28,108][26276] Avg episode reward: [(0, '-552.079')]
[2023-08-31 22:32:29,378][26288] Updated weights for policy 0, policy_version 130712 (0.0002)
[2023-08-31 22:32:32,142][26288] Updated weights for policy 0, policy_version 130792 (0.0002)
[2023-08-31 22:32:33,106][26276] Fps is (10 sec: 15567.2, 60 sec: 15633.1, 300 sec: 15925.8). Total num frames: 66977792. Throughput: 0: 15765.0. Samples: 55040020. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:32:33,108][26276] Avg episode reward: [(0, '-643.412')]
[2023-08-31 22:32:34,586][26288] Updated weights for policy 0, policy_version 130872 (0.0002)
[2023-08-31 22:32:37,105][26288] Updated weights for policy 0, policy_version 130952 (0.0002)
[2023-08-31 22:32:38,107][26276] Fps is (10 sec: 15975.2, 60 sec: 15700.9, 300 sec: 15939.6). Total num frames: 67059712. Throughput: 0: 15828.4. Samples: 55135510. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[2023-08-31 22:32:38,107][26276] Avg episode reward: [(0, '-643.412')]
[2023-08-31 22:32:39,697][26288] Updated weights for policy 0, policy_version 131032 (0.0002)
[2023-08-31 22:32:42,377][26288] Updated weights for policy 0, policy_version 131112 (0.0002)
[2023-08-31 22:32:43,109][26276] Fps is (10 sec: 15969.8, 60 sec: 15769.5, 300 sec: 15925.6). Total num frames: 67137536. Throughput: 0: 15830.2. Samples: 55183679. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[2023-08-31 22:32:43,109][26276] Avg episode reward: [(0, '-703.767')]
[2023-08-31 22:32:45,001][26288] Updated weights for policy 0, policy_version 131192 (0.0002)
[2023-08-31 22:32:47,435][26288] Updated weights for policy 0, policy_version 131272 (0.0002)
[2023-08-31 22:32:48,108][26276] Fps is (10 sec: 15972.5, 60 sec: 15768.8, 300 sec: 15939.7). Total num frames: 67219456. Throughput: 0: 15816.6. Samples: 55277116. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[2023-08-31 22:32:48,108][26276] Avg episode reward: [(0, '-703.767')]
[2023-08-31 22:32:50,077][26288] Updated weights for policy 0, policy_version 131352 (0.0002)
[2023-08-31 22:32:52,849][26288] Updated weights for policy 0, policy_version 131432 (0.0002)
[2023-08-31 22:32:53,105][26276] Fps is (10 sec: 15979.8, 60 sec: 15770.1, 300 sec: 15911.9). Total num frames: 67297280. Throughput: 0: 15725.2. Samples: 55368901. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[2023-08-31 22:32:53,105][26276] Avg episode reward: [(0, '-756.989')]
[2023-08-31 22:32:55,340][26288] Updated weights for policy 0, policy_version 131512 (0.0002)
[2023-08-31 22:32:57,884][26288] Updated weights for policy 0, policy_version 131592 (0.0002)
[2023-08-31 22:32:58,108][26276] Fps is (10 sec: 15565.5, 60 sec: 15770.3, 300 sec: 15898.1). Total num frames: 67375104. Throughput: 0: 15738.3. Samples: 55418855. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[2023-08-31 22:32:58,108][26276] Avg episode reward: [(0, '-756.989')]
[2023-08-31 22:33:00,390][26288] Updated weights for policy 0, policy_version 131672 (0.0002)
[2023-08-31 22:33:03,107][26276] Fps is (10 sec: 15561.4, 60 sec: 15770.1, 300 sec: 15884.0). Total num frames: 67452928. Throughput: 0: 15824.0. Samples: 55515789. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[2023-08-31 22:33:03,108][26276] Avg episode reward: [(0, '-763.261')]
[2023-08-31 22:33:03,180][26288] Updated weights for policy 0, policy_version 131752 (0.0002)
[2023-08-31 22:33:05,703][26288] Updated weights for policy 0, policy_version 131832 (0.0002)
[2023-08-31 22:33:08,107][26276] Fps is (10 sec: 15975.0, 60 sec: 15769.1, 300 sec: 15884.2). Total num frames: 67534848. Throughput: 0: 15814.8. Samples: 55607314. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[2023-08-31 22:33:08,107][26276] Avg episode reward: [(0, '-763.261')]
[2023-08-31 22:33:08,322][26288] Updated weights for policy 0, policy_version 131912 (0.0002)
[2023-08-31 22:33:11,004][26288] Updated weights for policy 0, policy_version 131992 (0.0002)
[2023-08-31 22:33:13,108][26276] Fps is (10 sec: 15563.8, 60 sec: 15701.6, 300 sec: 15870.3). Total num frames: 67608576. Throughput: 0: 15794.1. Samples: 55654492. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[2023-08-31 22:33:13,108][26276] Avg episode reward: [(0, '-717.795')]
[2023-08-31 22:33:13,796][26288] Updated weights for policy 0, policy_version 132072 (0.0002)
[2023-08-31 22:33:16,457][26288] Updated weights for policy 0, policy_version 132152 (0.0002)
[2023-08-31 22:33:18,107][26276] Fps is (10 sec: 15155.9, 60 sec: 15632.6, 300 sec: 15856.3). Total num frames: 67686400. Throughput: 0: 15648.6. Samples: 55744222. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[2023-08-31 22:33:18,107][26276] Avg episode reward: [(0, '-717.795')]
[2023-08-31 22:33:19,072][26288] Updated weights for policy 0, policy_version 132232 (0.0002)
[2023-08-31 22:33:21,629][26288] Updated weights for policy 0, policy_version 132312 (0.0002)
[2023-08-31 22:33:23,108][26276] Fps is (10 sec: 15156.1, 60 sec: 15633.0, 300 sec: 15828.6). Total num frames: 67760128. Throughput: 0: 15637.8. Samples: 55839220. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[2023-08-31 22:33:23,108][26276] Avg episode reward: [(0, '-607.351')]
[2023-08-31 22:33:24,415][26288] Updated weights for policy 0, policy_version 132392 (0.0002)
[2023-08-31 22:33:26,809][26288] Updated weights for policy 0, policy_version 132472 (0.0002)
[2023-08-31 22:33:28,107][26276] Fps is (10 sec: 15974.7, 60 sec: 15769.8, 300 sec: 15842.4). Total num frames: 67846144. Throughput: 0: 15578.8. Samples: 55884691. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[2023-08-31 22:33:28,107][26276] Avg episode reward: [(0, '-607.351')]
[2023-08-31 22:33:29,304][26288] Updated weights for policy 0, policy_version 132552 (0.0002)
[2023-08-31 22:33:31,682][26288] Updated weights for policy 0, policy_version 132632 (0.0002)
[2023-08-31 22:33:33,105][26276] Fps is (10 sec: 16797.5, 60 sec: 15838.0, 300 sec: 15842.6). Total num frames: 67928064. Throughput: 0: 15742.0. Samples: 55985460. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[2023-08-31 22:33:33,106][26276] Avg episode reward: [(0, '-504.526')]
[2023-08-31 22:33:34,293][26288] Updated weights for policy 0, policy_version 132712 (0.0002)
[2023-08-31 22:33:36,752][26288] Updated weights for policy 0, policy_version 132792 (0.0002)
[2023-08-31 22:33:38,109][26276] Fps is (10 sec: 16380.7, 60 sec: 15837.4, 300 sec: 15856.4). Total num frames: 68009984. Throughput: 0: 15881.8. Samples: 56083632. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:33:38,109][26276] Avg episode reward: [(0, '-504.526')]
[2023-08-31 22:33:39,296][26288] Updated weights for policy 0, policy_version 132872 (0.0002)
[2023-08-31 22:33:41,731][26288] Updated weights for policy 0, policy_version 132952 (0.0002)
[2023-08-31 22:33:43,106][26276] Fps is (10 sec: 15973.5, 60 sec: 15838.6, 300 sec: 15842.6). Total num frames: 68087808. Throughput: 0: 15852.4. Samples: 56132186. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:33:43,106][26276] Avg episode reward: [(0, '-410.873')]
[2023-08-31 22:33:44,458][26288] Updated weights for policy 0, policy_version 133032 (0.0002)
[2023-08-31 22:33:47,038][26288] Updated weights for policy 0, policy_version 133112 (0.0002)
[2023-08-31 22:33:48,110][26276] Fps is (10 sec: 15972.1, 60 sec: 15837.3, 300 sec: 15842.5). Total num frames: 68169728. Throughput: 0: 15802.4. Samples: 56226937. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:33:48,110][26276] Avg episode reward: [(0, '-410.873')]
[2023-08-31 22:33:49,626][26288] Updated weights for policy 0, policy_version 133192 (0.0002)
[2023-08-31 22:33:52,134][26288] Updated weights for policy 0, policy_version 133272 (0.0002)
[2023-08-31 22:33:53,107][26276] Fps is (10 sec: 15971.9, 60 sec: 15837.3, 300 sec: 15828.8). Total num frames: 68247552. Throughput: 0: 15904.9. Samples: 56323034. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:33:53,108][26276] Avg episode reward: [(0, '-366.681')]
[2023-08-31 22:33:54,779][26288] Updated weights for policy 0, policy_version 133352 (0.0002)
[2023-08-31 22:33:57,253][26288] Updated weights for policy 0, policy_version 133432 (0.0002)
[2023-08-31 22:33:58,107][26276] Fps is (10 sec: 15979.8, 60 sec: 15906.4, 300 sec: 15856.5). Total num frames: 68329472. Throughput: 0: 15882.2. Samples: 56369168. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:33:58,107][26276] Avg episode reward: [(0, '-366.681')]
[2023-08-31 22:33:59,623][26288] Updated weights for policy 0, policy_version 133512 (0.0002)
[2023-08-31 22:34:02,189][26288] Updated weights for policy 0, policy_version 133592 (0.0002)
[2023-08-31 22:34:03,110][26276] Fps is (10 sec: 15970.7, 60 sec: 15905.6, 300 sec: 15842.5). Total num frames: 68407296. Throughput: 0: 16134.6. Samples: 56470325. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:34:03,111][26276] Avg episode reward: [(0, '-412.736')]
[2023-08-31 22:34:03,114][26287] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000133608_68407296.pth...
[2023-08-31 22:34:03,116][26287] Removing /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000127424_65241088.pth
[2023-08-31 22:34:04,946][26288] Updated weights for policy 0, policy_version 133672 (0.0002)
[2023-08-31 22:34:07,566][26288] Updated weights for policy 0, policy_version 133752 (0.0002)
[2023-08-31 22:34:08,115][26276] Fps is (10 sec: 15961.1, 60 sec: 15904.1, 300 sec: 15855.9). Total num frames: 68489216. Throughput: 0: 16051.8. Samples: 56561670. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:34:08,115][26276] Avg episode reward: [(0, '-412.736')]
[2023-08-31 22:34:10,213][26288] Updated weights for policy 0, policy_version 133832 (0.0002)
[2023-08-31 22:34:13,107][26276] Fps is (10 sec: 15159.1, 60 sec: 15838.1, 300 sec: 15814.6). Total num frames: 68558848. Throughput: 0: 16076.0. Samples: 56608117. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:34:13,107][26276] Avg episode reward: [(0, '-628.312')]
[2023-08-31 22:34:13,242][26288] Updated weights for policy 0, policy_version 133912 (0.0002)
[2023-08-31 22:34:15,663][26288] Updated weights for policy 0, policy_version 133992 (0.0002)
[2023-08-31 22:34:18,107][26276] Fps is (10 sec: 15167.1, 60 sec: 15906.0, 300 sec: 15828.6). Total num frames: 68640768. Throughput: 0: 15868.9. Samples: 56699592. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:34:18,109][26276] Avg episode reward: [(0, '-657.944')]
[2023-08-31 22:34:18,136][26288] Updated weights for policy 0, policy_version 134072 (0.0002)
[2023-08-31 22:34:20,562][26288] Updated weights for policy 0, policy_version 134152 (0.0002)
[2023-08-31 22:34:23,107][26276] Fps is (10 sec: 15973.8, 60 sec: 15974.4, 300 sec: 15800.9). Total num frames: 68718592. Throughput: 0: 15812.1. Samples: 56795158. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:34:23,110][26276] Avg episode reward: [(0, '-834.390')]
[2023-08-31 22:34:23,531][26288] Updated weights for policy 0, policy_version 134232 (0.0002)
[2023-08-31 22:34:25,999][26288] Updated weights for policy 0, policy_version 134312 (0.0002)
[2023-08-31 22:34:28,110][26276] Fps is (10 sec: 15559.9, 60 sec: 15836.9, 300 sec: 15814.6). Total num frames: 68796416. Throughput: 0: 15732.3. Samples: 56840213. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:34:28,111][26276] Avg episode reward: [(0, '-961.092')]
[2023-08-31 22:34:28,683][26288] Updated weights for policy 0, policy_version 134392 (0.0002)
[2023-08-31 22:34:31,506][26288] Updated weights for policy 0, policy_version 134472 (0.0002)
[2023-08-31 22:34:33,115][26276] Fps is (10 sec: 15552.8, 60 sec: 15767.0, 300 sec: 15800.4). Total num frames: 68874240. Throughput: 0: 15646.8. Samples: 56931122. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:34:33,115][26276] Avg episode reward: [(0, '-961.092')]
[2023-08-31 22:34:34,228][26288] Updated weights for policy 0, policy_version 134552 (0.0002)
[2023-08-31 22:34:36,613][26288] Updated weights for policy 0, policy_version 134632 (0.0002)
[2023-08-31 22:34:38,110][26276] Fps is (10 sec: 15565.4, 60 sec: 15701.0, 300 sec: 15814.6). Total num frames: 68952064. Throughput: 0: 15656.2. Samples: 57027605. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:34:38,110][26276] Avg episode reward: [(0, '-974.772')]
[2023-08-31 22:34:39,193][26288] Updated weights for policy 0, policy_version 134712 (0.0002)
[2023-08-31 22:34:41,735][26288] Updated weights for policy 0, policy_version 134792 (0.0002)
[2023-08-31 22:34:43,114][26276] Fps is (10 sec: 15975.7, 60 sec: 15767.4, 300 sec: 15814.5). Total num frames: 69033984. Throughput: 0: 15665.8. Samples: 57074250. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 22:34:43,114][26276] Avg episode reward: [(0, '-974.772')]
[2023-08-31 22:34:44,636][26288] Updated weights for policy 0, policy_version 134872 (0.0002)
[2023-08-31 22:34:47,081][26288] Updated weights for policy 0, policy_version 134952 (0.0002)
[2023-08-31 22:34:48,106][26276] Fps is (10 sec: 15981.2, 60 sec: 15702.5, 300 sec: 15814.9). Total num frames: 69111808. Throughput: 0: 15499.8. Samples: 57167756. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 22:34:48,106][26276] Avg episode reward: [(0, '-1034.198')]
[2023-08-31 22:34:49,617][26288] Updated weights for policy 0, policy_version 135032 (0.0002)
[2023-08-31 22:34:52,248][26288] Updated weights for policy 0, policy_version 135112 (0.0002)
[2023-08-31 22:34:53,107][26276] Fps is (10 sec: 15575.7, 60 sec: 15701.3, 300 sec: 15800.9). Total num frames: 69189632. Throughput: 0: 15582.8. Samples: 57262776. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 22:34:53,108][26276] Avg episode reward: [(0, '-1034.198')]
[2023-08-31 22:34:55,087][26288] Updated weights for policy 0, policy_version 135192 (0.0002)
[2023-08-31 22:34:57,649][26288] Updated weights for policy 0, policy_version 135272 (0.0002)
[2023-08-31 22:34:58,107][26276] Fps is (10 sec: 15152.9, 60 sec: 15564.7, 300 sec: 15800.8). Total num frames: 69263360. Throughput: 0: 15524.7. Samples: 57306731. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 22:34:58,107][26276] Avg episode reward: [(0, '-1005.844')]
[2023-08-31 22:35:00,206][26288] Updated weights for policy 0, policy_version 135352 (0.0002)
[2023-08-31 22:35:02,834][26288] Updated weights for policy 0, policy_version 135432 (0.0002)
[2023-08-31 22:35:03,109][26276] Fps is (10 sec: 15561.7, 60 sec: 15633.1, 300 sec: 15786.9). Total num frames: 69345280. Throughput: 0: 15595.7. Samples: 57401430. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 22:35:03,110][26276] Avg episode reward: [(0, '-1005.844')]
[2023-08-31 22:35:05,636][26288] Updated weights for policy 0, policy_version 135512 (0.0002)
[2023-08-31 22:35:08,115][26276] Fps is (10 sec: 15552.8, 60 sec: 15496.6, 300 sec: 15786.7). Total num frames: 69419008. Throughput: 0: 15515.1. Samples: 57493453. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 22:35:08,115][26276] Avg episode reward: [(0, '-890.174')]
[2023-08-31 22:35:08,169][26288] Updated weights for policy 0, policy_version 135592 (0.0002)
[2023-08-31 22:35:10,672][26288] Updated weights for policy 0, policy_version 135672 (0.0002)
[2023-08-31 22:35:13,107][26276] Fps is (10 sec: 15568.9, 60 sec: 15701.4, 300 sec: 15773.0). Total num frames: 69500928. Throughput: 0: 15615.3. Samples: 57542844. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 22:35:13,107][26276] Avg episode reward: [(0, '-890.174')]
[2023-08-31 22:35:13,216][26288] Updated weights for policy 0, policy_version 135752 (0.0002)
[2023-08-31 22:35:16,002][26288] Updated weights for policy 0, policy_version 135832 (0.0002)
[2023-08-31 22:35:18,106][26276] Fps is (10 sec: 15578.9, 60 sec: 15565.1, 300 sec: 15759.4). Total num frames: 69574656. Throughput: 0: 15595.0. Samples: 57632753. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 22:35:18,106][26276] Avg episode reward: [(0, '-605.403')]
[2023-08-31 22:35:18,941][26288] Updated weights for policy 0, policy_version 135912 (0.0002)
[2023-08-31 22:35:21,723][26288] Updated weights for policy 0, policy_version 135992 (0.0002)
[2023-08-31 22:35:23,106][26276] Fps is (10 sec: 14746.0, 60 sec: 15496.8, 300 sec: 15731.5). Total num frames: 69648384. Throughput: 0: 15415.2. Samples: 57721233. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 22:35:23,107][26276] Avg episode reward: [(0, '-605.403')]
[2023-08-31 22:35:24,322][26288] Updated weights for policy 0, policy_version 136072 (0.0002)
[2023-08-31 22:35:27,060][26288] Updated weights for policy 0, policy_version 136152 (0.0002)
[2023-08-31 22:35:28,107][26276] Fps is (10 sec: 15152.8, 60 sec: 15497.3, 300 sec: 15745.4). Total num frames: 69726208. Throughput: 0: 15372.4. Samples: 57765904. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 22:35:28,108][26276] Avg episode reward: [(0, '-329.774')]
[2023-08-31 22:35:29,579][26288] Updated weights for policy 0, policy_version 136232 (0.0002)
[2023-08-31 22:35:32,084][26288] Updated weights for policy 0, policy_version 136312 (0.0002)
[2023-08-31 22:35:33,115][26276] Fps is (10 sec: 15551.5, 60 sec: 15496.6, 300 sec: 15731.1). Total num frames: 69804032. Throughput: 0: 15460.8. Samples: 57863635. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 22:35:33,115][26276] Avg episode reward: [(0, '-329.774')]
[2023-08-31 22:35:34,691][26288] Updated weights for policy 0, policy_version 136392 (0.0002)
[2023-08-31 22:35:37,411][26288] Updated weights for policy 0, policy_version 136472 (0.0002)
[2023-08-31 22:35:38,112][26276] Fps is (10 sec: 15558.1, 60 sec: 15496.1, 300 sec: 15731.2). Total num frames: 69881856. Throughput: 0: 15412.5. Samples: 57956406. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 22:35:38,112][26276] Avg episode reward: [(0, '-296.080')]
[2023-08-31 22:35:38,113][26287] Saving new best policy, reward=-296.080!
[2023-08-31 22:35:39,953][26288] Updated weights for policy 0, policy_version 136552 (0.0002)
[2023-08-31 22:35:42,576][26288] Updated weights for policy 0, policy_version 136632 (0.0002)
[2023-08-31 22:35:43,105][26276] Fps is (10 sec: 15580.0, 60 sec: 15430.6, 300 sec: 15717.8). Total num frames: 69959680. Throughput: 0: 15514.4. Samples: 58004846. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:35:43,105][26276] Avg episode reward: [(0, '-296.080')]
[2023-08-31 22:35:43,108][26287] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000136640_69959680.pth...
[2023-08-31 22:35:43,109][26287] Removing /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000130512_66822144.pth
[2023-08-31 22:35:45,254][26288] Updated weights for policy 0, policy_version 136712 (0.0002)
[2023-08-31 22:35:48,115][26276] Fps is (10 sec: 15150.5, 60 sec: 15357.7, 300 sec: 15703.4). Total num frames: 70033408. Throughput: 0: 15379.3. Samples: 58093584. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:35:48,115][26276] Avg episode reward: [(0, '-240.032')]
[2023-08-31 22:35:48,115][26287] Saving new best policy, reward=-240.032!
[2023-08-31 22:35:48,256][26288] Updated weights for policy 0, policy_version 136792 (0.0002)
[2023-08-31 22:35:50,837][26288] Updated weights for policy 0, policy_version 136872 (0.0002)
[2023-08-31 22:35:53,109][26276] Fps is (10 sec: 15558.7, 60 sec: 15427.8, 300 sec: 15689.6). Total num frames: 70115328. Throughput: 0: 15426.6. Samples: 58187559. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:35:53,109][26276] Avg episode reward: [(0, '-240.032')]
[2023-08-31 22:35:53,342][26288] Updated weights for policy 0, policy_version 136952 (0.0002)
[2023-08-31 22:35:55,955][26288] Updated weights for policy 0, policy_version 137032 (0.0002)
[2023-08-31 22:35:58,106][26276] Fps is (10 sec: 15988.4, 60 sec: 15496.8, 300 sec: 15690.0). Total num frames: 70193152. Throughput: 0: 15429.3. Samples: 58237153. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:35:58,106][26276] Avg episode reward: [(0, '-225.113')]
[2023-08-31 22:35:58,107][26287] Saving new best policy, reward=-225.113!
[2023-08-31 22:35:58,599][26288] Updated weights for policy 0, policy_version 137112 (0.0002)
[2023-08-31 22:36:01,060][26288] Updated weights for policy 0, policy_version 137192 (0.0002)
[2023-08-31 22:36:03,107][26276] Fps is (10 sec: 15977.9, 60 sec: 15497.1, 300 sec: 15703.8). Total num frames: 70275072. Throughput: 0: 15519.6. Samples: 58331152. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:36:03,108][26276] Avg episode reward: [(0, '-225.113')]
[2023-08-31 22:36:03,504][26288] Updated weights for policy 0, policy_version 137272 (0.0002)
[2023-08-31 22:36:06,282][26288] Updated weights for policy 0, policy_version 137352 (0.0002)
[2023-08-31 22:36:08,109][26276] Fps is (10 sec: 15560.3, 60 sec: 15498.1, 300 sec: 15689.6). Total num frames: 70348800. Throughput: 0: 15638.7. Samples: 58425015. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:36:08,109][26276] Avg episode reward: [(0, '-210.637')]
[2023-08-31 22:36:08,122][26287] Saving new best policy, reward=-210.637!
[2023-08-31 22:36:08,866][26288] Updated weights for policy 0, policy_version 137432 (0.0002)
[2023-08-31 22:36:11,441][26288] Updated weights for policy 0, policy_version 137512 (0.0002)
[2023-08-31 22:36:13,106][26276] Fps is (10 sec: 15566.6, 60 sec: 15496.8, 300 sec: 15690.0). Total num frames: 70430720. Throughput: 0: 15693.9. Samples: 58472101. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:36:13,106][26276] Avg episode reward: [(0, '-210.637')]
[2023-08-31 22:36:14,037][26288] Updated weights for policy 0, policy_version 137592 (0.0002)
[2023-08-31 22:36:16,889][26288] Updated weights for policy 0, policy_version 137672 (0.0002)
[2023-08-31 22:36:18,108][26276] Fps is (10 sec: 15975.5, 60 sec: 15564.2, 300 sec: 15689.9). Total num frames: 70508544. Throughput: 0: 15606.6. Samples: 58565829. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:36:18,109][26276] Avg episode reward: [(0, '-270.832')]
[2023-08-31 22:36:19,345][26288] Updated weights for policy 0, policy_version 137752 (0.0002)
[2023-08-31 22:36:21,920][26288] Updated weights for policy 0, policy_version 137832 (0.0002)
[2023-08-31 22:36:23,109][26276] Fps is (10 sec: 15559.5, 60 sec: 15632.3, 300 sec: 15675.9). Total num frames: 70586368. Throughput: 0: 15665.9. Samples: 58661331. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:36:23,109][26276] Avg episode reward: [(0, '-270.832')]
[2023-08-31 22:36:24,449][26288] Updated weights for policy 0, policy_version 137912 (0.0002)
[2023-08-31 22:36:27,244][26288] Updated weights for policy 0, policy_version 137992 (0.0002)
[2023-08-31 22:36:28,114][26276] Fps is (10 sec: 15555.3, 60 sec: 15631.2, 300 sec: 15675.4). Total num frames: 70664192. Throughput: 0: 15653.8. Samples: 58709412. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:36:28,115][26276] Avg episode reward: [(0, '-244.129')]
[2023-08-31 22:36:29,742][26288] Updated weights for policy 0, policy_version 138072 (0.0002)
[2023-08-31 22:36:32,268][26288] Updated weights for policy 0, policy_version 138152 (0.0002)
[2023-08-31 22:36:33,109][26276] Fps is (10 sec: 15975.0, 60 sec: 15703.0, 300 sec: 15689.6). Total num frames: 70746112. Throughput: 0: 15752.1. Samples: 58802333. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:36:33,109][26276] Avg episode reward: [(0, '-244.129')]
[2023-08-31 22:36:34,791][26288] Updated weights for policy 0, policy_version 138232 (0.0002)
[2023-08-31 22:36:37,591][26288] Updated weights for policy 0, policy_version 138312 (0.0002)
[2023-08-31 22:36:38,105][26276] Fps is (10 sec: 15989.0, 60 sec: 15703.0, 300 sec: 15703.8). Total num frames: 70823936. Throughput: 0: 15753.4. Samples: 58896400. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:36:38,106][26276] Avg episode reward: [(0, '-188.755')]
[2023-08-31 22:36:38,106][26287] Saving new best policy, reward=-188.755!
[2023-08-31 22:36:40,025][26288] Updated weights for policy 0, policy_version 138392 (0.0002)
[2023-08-31 22:36:42,475][26288] Updated weights for policy 0, policy_version 138472 (0.0002)
[2023-08-31 22:36:43,107][26276] Fps is (10 sec: 15977.6, 60 sec: 15769.2, 300 sec: 15703.6). Total num frames: 70905856. Throughput: 0: 15742.6. Samples: 58945580. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:36:43,107][26276] Avg episode reward: [(0, '-188.755')]
[2023-08-31 22:36:44,951][26288] Updated weights for policy 0, policy_version 138552 (0.0002)
[2023-08-31 22:36:47,708][26288] Updated weights for policy 0, policy_version 138632 (0.0002)
[2023-08-31 22:36:48,105][26276] Fps is (10 sec: 15974.5, 60 sec: 15840.4, 300 sec: 15703.8). Total num frames: 70983680. Throughput: 0: 15861.5. Samples: 59044894. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 22:36:48,105][26276] Avg episode reward: [(0, '-376.599')]
[2023-08-31 22:36:50,563][26288] Updated weights for policy 0, policy_version 138712 (0.0002)
[2023-08-31 22:36:53,114][26276] Fps is (10 sec: 15143.5, 60 sec: 15699.9, 300 sec: 15689.5). Total num frames: 71057408. Throughput: 0: 15714.7. Samples: 59132263. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 22:36:53,115][26276] Avg episode reward: [(0, '-376.599')]
[2023-08-31 22:36:53,189][26288] Updated weights for policy 0, policy_version 138792 (0.0002)
[2023-08-31 22:36:55,862][26288] Updated weights for policy 0, policy_version 138872 (0.0002)
[2023-08-31 22:36:58,115][26276] Fps is (10 sec: 14731.1, 60 sec: 15630.7, 300 sec: 15675.6). Total num frames: 71131136. Throughput: 0: 15703.0. Samples: 59178881. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 22:36:58,116][26276] Avg episode reward: [(0, '-488.768')]
[2023-08-31 22:36:58,671][26288] Updated weights for policy 0, policy_version 138952 (0.0002)
[2023-08-31 22:37:01,227][26288] Updated weights for policy 0, policy_version 139032 (0.0002)
[2023-08-31 22:37:03,112][26276] Fps is (10 sec: 15568.1, 60 sec: 15631.7, 300 sec: 15675.5). Total num frames: 71213056. Throughput: 0: 15653.4. Samples: 59270297. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 22:37:03,113][26276] Avg episode reward: [(0, '-488.768')]
[2023-08-31 22:37:03,793][26288] Updated weights for policy 0, policy_version 139112 (0.0002)
[2023-08-31 22:37:06,433][26288] Updated weights for policy 0, policy_version 139192 (0.0002)
[2023-08-31 22:37:08,107][26276] Fps is (10 sec: 15576.7, 60 sec: 15633.5, 300 sec: 15662.1). Total num frames: 71286784. Throughput: 0: 15625.9. Samples: 59364471. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 22:37:08,109][26276] Avg episode reward: [(0, '-599.259')]
[2023-08-31 22:37:09,210][26288] Updated weights for policy 0, policy_version 139272 (0.0002)
[2023-08-31 22:37:11,685][26288] Updated weights for policy 0, policy_version 139352 (0.0002)
[2023-08-31 22:37:13,115][26276] Fps is (10 sec: 15560.7, 60 sec: 15630.7, 300 sec: 15661.5). Total num frames: 71368704. Throughput: 0: 15572.4. Samples: 59410178. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 22:37:13,115][26276] Avg episode reward: [(0, '-599.259')]
[2023-08-31 22:37:14,190][26288] Updated weights for policy 0, policy_version 139432 (0.0002)
[2023-08-31 22:37:16,624][26288] Updated weights for policy 0, policy_version 139512 (0.0002)
[2023-08-31 22:37:18,105][26276] Fps is (10 sec: 16387.5, 60 sec: 15702.1, 300 sec: 15689.9). Total num frames: 71450624. Throughput: 0: 15708.9. Samples: 59509181. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 22:37:18,106][26276] Avg episode reward: [(0, '-646.561')]
[2023-08-31 22:37:19,316][26288] Updated weights for policy 0, policy_version 139592 (0.0002)
[2023-08-31 22:37:21,837][26288] Updated weights for policy 0, policy_version 139672 (0.0002)
[2023-08-31 22:37:23,107][26276] Fps is (10 sec: 16396.7, 60 sec: 15770.1, 300 sec: 15703.7). Total num frames: 71532544. Throughput: 0: 15746.2. Samples: 59605008. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 22:37:23,107][26276] Avg episode reward: [(0, '-646.561')]
[2023-08-31 22:37:23,111][26287] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000139712_71532544.pth...
[2023-08-31 22:37:23,113][26287] Removing /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000133608_68407296.pth
[2023-08-31 22:37:24,347][26288] Updated weights for policy 0, policy_version 139752 (0.0002)
[2023-08-31 22:37:26,817][26288] Updated weights for policy 0, policy_version 139832 (0.0002)
[2023-08-31 22:37:28,107][26276] Fps is (10 sec: 15972.1, 60 sec: 15771.6, 300 sec: 15703.6). Total num frames: 71610368. Throughput: 0: 15733.5. Samples: 59653588. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 22:37:28,107][26276] Avg episode reward: [(0, '-866.204')]
[2023-08-31 22:37:29,554][26288] Updated weights for policy 0, policy_version 139912 (0.0002)
[2023-08-31 22:37:32,008][26288] Updated weights for policy 0, policy_version 139992 (0.0002)
[2023-08-31 22:37:33,106][26276] Fps is (10 sec: 15976.3, 60 sec: 15770.3, 300 sec: 15703.7). Total num frames: 71692288. Throughput: 0: 15645.4. Samples: 59748952. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 22:37:33,106][26276] Avg episode reward: [(0, '-866.204')]
[2023-08-31 22:37:34,540][26288] Updated weights for policy 0, policy_version 140072 (0.0002)
[2023-08-31 22:37:36,991][26288] Updated weights for policy 0, policy_version 140152 (0.0002)
[2023-08-31 22:37:38,115][26276] Fps is (10 sec: 15961.3, 60 sec: 15767.1, 300 sec: 15703.3). Total num frames: 71770112. Throughput: 0: 15859.1. Samples: 59845928. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 22:37:38,116][26276] Avg episode reward: [(0, '-1066.357')]
[2023-08-31 22:37:39,646][26288] Updated weights for policy 0, policy_version 140232 (0.0002)
[2023-08-31 22:37:42,053][26288] Updated weights for policy 0, policy_version 140312 (0.0002)
[2023-08-31 22:37:43,113][26276] Fps is (10 sec: 16373.3, 60 sec: 15836.3, 300 sec: 15717.3). Total num frames: 71856128. Throughput: 0: 15910.6. Samples: 59894817. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 22:37:43,113][26276] Avg episode reward: [(0, '-1066.357')]
[2023-08-31 22:37:44,560][26288] Updated weights for policy 0, policy_version 140392 (0.0002)
[2023-08-31 22:37:47,388][26288] Updated weights for policy 0, policy_version 140472 (0.0002)
[2023-08-31 22:37:48,108][26276] Fps is (10 sec: 15984.8, 60 sec: 15768.7, 300 sec: 15703.5). Total num frames: 71929856. Throughput: 0: 16077.4. Samples: 59993718. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[2023-08-31 22:37:48,109][26276] Avg episode reward: [(0, '-1024.614')]
[2023-08-31 22:37:49,879][26288] Updated weights for policy 0, policy_version 140552 (0.0003)
[2023-08-31 22:37:52,409][26288] Updated weights for policy 0, policy_version 140632 (0.0002)
[2023-08-31 22:37:53,112][26276] Fps is (10 sec: 15566.4, 60 sec: 15906.9, 300 sec: 15717.3). Total num frames: 72011776. Throughput: 0: 16055.8. Samples: 60087048. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[2023-08-31 22:37:53,112][26276] Avg episode reward: [(0, '-1024.614')]
[2023-08-31 22:37:54,846][26288] Updated weights for policy 0, policy_version 140712 (0.0002)
[2023-08-31 22:37:57,513][26288] Updated weights for policy 0, policy_version 140792 (0.0002)
[2023-08-31 22:37:58,107][26276] Fps is (10 sec: 16385.6, 60 sec: 16044.7, 300 sec: 15731.4). Total num frames: 72093696. Throughput: 0: 16165.1. Samples: 60137488. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[2023-08-31 22:37:58,108][26276] Avg episode reward: [(0, '-942.118')]
[2023-08-31 22:37:59,993][26288] Updated weights for policy 0, policy_version 140872 (0.0002)
[2023-08-31 22:38:02,525][26288] Updated weights for policy 0, policy_version 140952 (0.0002)
[2023-08-31 22:38:03,115][26276] Fps is (10 sec: 16379.1, 60 sec: 16042.1, 300 sec: 15731.0). Total num frames: 72175616. Throughput: 0: 16071.2. Samples: 60232532. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[2023-08-31 22:38:03,115][26276] Avg episode reward: [(0, '-942.118')]
[2023-08-31 22:38:05,096][26288] Updated weights for policy 0, policy_version 141032 (0.0002)
[2023-08-31 22:38:07,957][26288] Updated weights for policy 0, policy_version 141112 (0.0002)
[2023-08-31 22:38:08,115][26276] Fps is (10 sec: 15553.0, 60 sec: 16040.6, 300 sec: 15731.0). Total num frames: 72249344. Throughput: 0: 16017.2. Samples: 60325909. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[2023-08-31 22:38:08,115][26276] Avg episode reward: [(0, '-968.833')]
[2023-08-31 22:38:10,437][26288] Updated weights for policy 0, policy_version 141192 (0.0002)
[2023-08-31 22:38:12,993][26288] Updated weights for policy 0, policy_version 141272 (0.0002)
[2023-08-31 22:38:13,115][26276] Fps is (10 sec: 15564.6, 60 sec: 16042.7, 300 sec: 15744.9). Total num frames: 72331264. Throughput: 0: 15988.7. Samples: 60373207. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[2023-08-31 22:38:13,115][26276] Avg episode reward: [(0, '-968.833')]
[2023-08-31 22:38:15,459][26288] Updated weights for policy 0, policy_version 141352 (0.0002)
[2023-08-31 22:38:18,115][26276] Fps is (10 sec: 15974.4, 60 sec: 15971.8, 300 sec: 15758.8). Total num frames: 72409088. Throughput: 0: 16029.1. Samples: 60470406. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[2023-08-31 22:38:18,115][26276] Avg episode reward: [(0, '-977.215')]
[2023-08-31 22:38:18,182][26288] Updated weights for policy 0, policy_version 141432 (0.0002)
[2023-08-31 22:38:20,695][26288] Updated weights for policy 0, policy_version 141512 (0.0002)
[2023-08-31 22:38:23,107][26276] Fps is (10 sec: 15986.1, 60 sec: 15974.4, 300 sec: 15745.3). Total num frames: 72491008. Throughput: 0: 15993.7. Samples: 60565524. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[2023-08-31 22:38:23,108][26276] Avg episode reward: [(0, '-977.215')]
[2023-08-31 22:38:23,134][26288] Updated weights for policy 0, policy_version 141592 (0.0002)
[2023-08-31 22:38:25,639][26288] Updated weights for policy 0, policy_version 141672 (0.0002)
[2023-08-31 22:38:28,110][26276] Fps is (10 sec: 15982.8, 60 sec: 15973.6, 300 sec: 15731.2). Total num frames: 72568832. Throughput: 0: 16015.2. Samples: 60615456. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[2023-08-31 22:38:28,110][26276] Avg episode reward: [(0, '-951.134')]
[2023-08-31 22:38:28,377][26288] Updated weights for policy 0, policy_version 141752 (0.0002)
[2023-08-31 22:38:30,801][26288] Updated weights for policy 0, policy_version 141832 (0.0002)
[2023-08-31 22:38:33,115][26276] Fps is (10 sec: 16371.5, 60 sec: 16040.3, 300 sec: 15745.0). Total num frames: 72654848. Throughput: 0: 15947.4. Samples: 60711455. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[2023-08-31 22:38:33,115][26276] Avg episode reward: [(0, '-951.134')]
[2023-08-31 22:38:33,306][26288] Updated weights for policy 0, policy_version 141912 (0.0002)
[2023-08-31 22:38:35,733][26288] Updated weights for policy 0, policy_version 141992 (0.0002)
[2023-08-31 22:38:38,106][26276] Fps is (10 sec: 16390.6, 60 sec: 16045.1, 300 sec: 15745.3). Total num frames: 72732672. Throughput: 0: 15984.4. Samples: 60806253. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[2023-08-31 22:38:38,106][26276] Avg episode reward: [(0, '-1070.320')]
[2023-08-31 22:38:38,408][26288] Updated weights for policy 0, policy_version 142072 (0.0002)
[2023-08-31 22:38:40,920][26288] Updated weights for policy 0, policy_version 142152 (0.0002)
[2023-08-31 22:38:43,115][26276] Fps is (10 sec: 15974.5, 60 sec: 15973.8, 300 sec: 15745.0). Total num frames: 72814592. Throughput: 0: 15996.4. Samples: 60857446. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[2023-08-31 22:38:43,115][26276] Avg episode reward: [(0, '-1070.320')]
[2023-08-31 22:38:43,404][26288] Updated weights for policy 0, policy_version 142232 (0.0002)
[2023-08-31 22:38:45,858][26288] Updated weights for policy 0, policy_version 142312 (0.0002)
[2023-08-31 22:38:48,115][26276] Fps is (10 sec: 16368.6, 60 sec: 16109.1, 300 sec: 15758.8). Total num frames: 72896512. Throughput: 0: 16064.7. Samples: 60955452. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[2023-08-31 22:38:48,116][26276] Avg episode reward: [(0, '-1193.861')]
[2023-08-31 22:38:48,601][26288] Updated weights for policy 0, policy_version 142392 (0.0002)
[2023-08-31 22:38:51,141][26288] Updated weights for policy 0, policy_version 142472 (0.0002)
[2023-08-31 22:38:53,107][26276] Fps is (10 sec: 16397.6, 60 sec: 16112.3, 300 sec: 15759.2). Total num frames: 72978432. Throughput: 0: 16095.0. Samples: 61050047. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:38:53,107][26276] Avg episode reward: [(0, '-1193.861')]
[2023-08-31 22:38:53,592][26288] Updated weights for policy 0, policy_version 142552 (0.0002)
[2023-08-31 22:38:56,013][26288] Updated weights for policy 0, policy_version 142632 (0.0002)
[2023-08-31 22:38:58,106][26276] Fps is (10 sec: 15989.6, 60 sec: 16043.1, 300 sec: 15759.4). Total num frames: 73056256. Throughput: 0: 16155.2. Samples: 61100048. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:38:58,106][26276] Avg episode reward: [(0, '-1379.536')]
[2023-08-31 22:38:58,669][26288] Updated weights for policy 0, policy_version 142712 (0.0002)
[2023-08-31 22:39:01,128][26288] Updated weights for policy 0, policy_version 142792 (0.0002)
[2023-08-31 22:39:03,109][26276] Fps is (10 sec: 15971.3, 60 sec: 16044.3, 300 sec: 15759.5). Total num frames: 73138176. Throughput: 0: 16158.1. Samples: 61197418. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:39:03,109][26276] Avg episode reward: [(0, '-1379.536')]
[2023-08-31 22:39:03,112][26287] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000142848_73138176.pth...
[2023-08-31 22:39:03,113][26287] Removing /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000136640_69959680.pth
[2023-08-31 22:39:03,657][26288] Updated weights for policy 0, policy_version 142872 (0.0002)
[2023-08-31 22:39:06,127][26288] Updated weights for policy 0, policy_version 142952 (0.0002)
[2023-08-31 22:39:08,113][26276] Fps is (10 sec: 15962.0, 60 sec: 16111.4, 300 sec: 15786.6). Total num frames: 73216000. Throughput: 0: 16147.6. Samples: 61292265. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:39:08,115][26276] Avg episode reward: [(0, '-1497.794')]
[2023-08-31 22:39:08,832][26288] Updated weights for policy 0, policy_version 143032 (0.0002)
[2023-08-31 22:39:11,370][26288] Updated weights for policy 0, policy_version 143112 (0.0002)
[2023-08-31 22:39:13,114][26276] Fps is (10 sec: 15965.4, 60 sec: 16111.0, 300 sec: 15786.6). Total num frames: 73297920. Throughput: 0: 16108.1. Samples: 61340394. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:39:13,114][26276] Avg episode reward: [(0, '-1497.794')]
[2023-08-31 22:39:13,997][26288] Updated weights for policy 0, policy_version 143192 (0.0002)
[2023-08-31 22:39:16,435][26288] Updated weights for policy 0, policy_version 143272 (0.0002)
[2023-08-31 22:39:18,108][26276] Fps is (10 sec: 15982.8, 60 sec: 16112.8, 300 sec: 15786.9). Total num frames: 73375744. Throughput: 0: 16136.0. Samples: 61437466. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:39:18,109][26276] Avg episode reward: [(0, '-1561.415')]
[2023-08-31 22:39:19,159][26288] Updated weights for policy 0, policy_version 143352 (0.0002)
[2023-08-31 22:39:21,586][26288] Updated weights for policy 0, policy_version 143432 (0.0002)
[2023-08-31 22:39:23,107][26276] Fps is (10 sec: 16395.9, 60 sec: 16179.3, 300 sec: 15814.9). Total num frames: 73461760. Throughput: 0: 16176.7. Samples: 61534226. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:39:23,107][26276] Avg episode reward: [(0, '-1561.415')]
[2023-08-31 22:39:23,969][26288] Updated weights for policy 0, policy_version 143512 (0.0002)
[2023-08-31 22:39:26,551][26288] Updated weights for policy 0, policy_version 143592 (0.0002)
[2023-08-31 22:39:28,113][26276] Fps is (10 sec: 16376.3, 60 sec: 16178.3, 300 sec: 15814.8). Total num frames: 73539584. Throughput: 0: 16142.9. Samples: 61583845. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:39:28,113][26276] Avg episode reward: [(0, '-1544.841')]
[2023-08-31 22:39:29,372][26288] Updated weights for policy 0, policy_version 143672 (0.0002)
[2023-08-31 22:39:31,924][26288] Updated weights for policy 0, policy_version 143752 (0.0002)
[2023-08-31 22:39:33,113][26276] Fps is (10 sec: 15555.1, 60 sec: 16043.1, 300 sec: 15814.6). Total num frames: 73617408. Throughput: 0: 16018.1. Samples: 61676234. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:39:33,113][26276] Avg episode reward: [(0, '-1544.841')]
[2023-08-31 22:39:34,360][26288] Updated weights for policy 0, policy_version 143832 (0.0002)
[2023-08-31 22:39:37,104][26288] Updated weights for policy 0, policy_version 143912 (0.0002)
[2023-08-31 22:39:38,108][26276] Fps is (10 sec: 15981.5, 60 sec: 16110.2, 300 sec: 15815.0). Total num frames: 73699328. Throughput: 0: 16027.3. Samples: 61771305. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:39:38,109][26276] Avg episode reward: [(0, '-1469.099')]
[2023-08-31 22:39:39,503][26288] Updated weights for policy 0, policy_version 143992 (0.0002)
[2023-08-31 22:39:42,043][26288] Updated weights for policy 0, policy_version 144072 (0.0002)
[2023-08-31 22:39:43,114][26276] Fps is (10 sec: 16382.6, 60 sec: 16111.2, 300 sec: 15828.2). Total num frames: 73781248. Throughput: 0: 16046.0. Samples: 61822253. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:39:43,114][26276] Avg episode reward: [(0, '-1469.099')]
[2023-08-31 22:39:44,625][26288] Updated weights for policy 0, policy_version 144152 (0.0002)
[2023-08-31 22:39:47,516][26288] Updated weights for policy 0, policy_version 144232 (0.0002)
[2023-08-31 22:39:48,107][26276] Fps is (10 sec: 15567.6, 60 sec: 15976.7, 300 sec: 15814.8). Total num frames: 73854976. Throughput: 0: 15953.6. Samples: 61915301. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:39:48,107][26276] Avg episode reward: [(0, '-1408.986')]
[2023-08-31 22:39:49,886][26288] Updated weights for policy 0, policy_version 144312 (0.0002)
[2023-08-31 22:39:52,430][26288] Updated weights for policy 0, policy_version 144392 (0.0002)
[2023-08-31 22:39:53,115][26276] Fps is (10 sec: 15563.2, 60 sec: 15972.1, 300 sec: 15842.1). Total num frames: 73936896. Throughput: 0: 15974.6. Samples: 62011148. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 22:39:53,115][26276] Avg episode reward: [(0, '-1408.986')]
[2023-08-31 22:39:54,878][26288] Updated weights for policy 0, policy_version 144472 (0.0002)
[2023-08-31 22:39:57,501][26288] Updated weights for policy 0, policy_version 144552 (0.0002)
[2023-08-31 22:39:58,115][26276] Fps is (10 sec: 16370.3, 60 sec: 16040.2, 300 sec: 15842.2). Total num frames: 74018816. Throughput: 0: 16023.4. Samples: 62061459. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 22:39:58,115][26276] Avg episode reward: [(0, '-1277.174')]
[2023-08-31 22:39:59,960][26288] Updated weights for policy 0, policy_version 144632 (0.0002)
[2023-08-31 22:40:02,477][26288] Updated weights for policy 0, policy_version 144712 (0.0002)
[2023-08-31 22:40:03,112][26276] Fps is (10 sec: 16388.9, 60 sec: 16041.7, 300 sec: 15870.4). Total num frames: 74100736. Throughput: 0: 16011.1. Samples: 62158027. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 22:40:03,112][26276] Avg episode reward: [(0, '-1277.174')]
[2023-08-31 22:40:04,991][26288] Updated weights for policy 0, policy_version 144792 (0.0002)
[2023-08-31 22:40:07,679][26288] Updated weights for policy 0, policy_version 144872 (0.0002)
[2023-08-31 22:40:08,114][26276] Fps is (10 sec: 15976.4, 60 sec: 16042.6, 300 sec: 15856.0). Total num frames: 74178560. Throughput: 0: 15968.8. Samples: 62252932. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 22:40:08,114][26276] Avg episode reward: [(0, '-1233.520')]
[2023-08-31 22:40:10,236][26288] Updated weights for policy 0, policy_version 144952 (0.0002)
[2023-08-31 22:40:12,729][26288] Updated weights for policy 0, policy_version 145032 (0.0002)
[2023-08-31 22:40:13,113][26276] Fps is (10 sec: 15973.5, 60 sec: 16043.1, 300 sec: 15883.8). Total num frames: 74260480. Throughput: 0: 15939.8. Samples: 62301131. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 22:40:13,113][26276] Avg episode reward: [(0, '-1233.520')]
[2023-08-31 22:40:15,257][26288] Updated weights for policy 0, policy_version 145112 (0.0002)
[2023-08-31 22:40:17,924][26288] Updated weights for policy 0, policy_version 145192 (0.0002)
[2023-08-31 22:40:18,111][26276] Fps is (10 sec: 15979.1, 60 sec: 16042.0, 300 sec: 15897.8). Total num frames: 74338304. Throughput: 0: 16071.0. Samples: 62399391. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 22:40:18,111][26276] Avg episode reward: [(0, '-1236.722')]
[2023-08-31 22:40:20,355][26288] Updated weights for policy 0, policy_version 145272 (0.0002)
[2023-08-31 22:40:22,755][26288] Updated weights for policy 0, policy_version 145352 (0.0002)
[2023-08-31 22:40:23,106][26276] Fps is (10 sec: 16395.5, 60 sec: 16043.0, 300 sec: 15925.9). Total num frames: 74424320. Throughput: 0: 16125.8. Samples: 62496922. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 22:40:23,106][26276] Avg episode reward: [(0, '-1236.722')]
[2023-08-31 22:40:25,278][26288] Updated weights for policy 0, policy_version 145432 (0.0002)
[2023-08-31 22:40:27,934][26288] Updated weights for policy 0, policy_version 145512 (0.0002)
[2023-08-31 22:40:28,115][26276] Fps is (10 sec: 16377.5, 60 sec: 16042.2, 300 sec: 15925.8). Total num frames: 74502144. Throughput: 0: 16084.1. Samples: 62546050. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 22:40:28,115][26276] Avg episode reward: [(0, '-1349.439')]
[2023-08-31 22:40:30,487][26288] Updated weights for policy 0, policy_version 145592 (0.0002)
[2023-08-31 22:40:32,953][26288] Updated weights for policy 0, policy_version 145672 (0.0002)
[2023-08-31 22:40:33,106][26276] Fps is (10 sec: 15973.5, 60 sec: 16112.8, 300 sec: 15940.0). Total num frames: 74584064. Throughput: 0: 16130.5. Samples: 62641167. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 22:40:33,106][26276] Avg episode reward: [(0, '-1349.439')]
[2023-08-31 22:40:35,406][26288] Updated weights for policy 0, policy_version 145752 (0.0002)
[2023-08-31 22:40:38,109][26276] Fps is (10 sec: 15984.2, 60 sec: 16042.6, 300 sec: 15939.5). Total num frames: 74661888. Throughput: 0: 16149.8. Samples: 62737786. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 22:40:38,110][26276] Avg episode reward: [(0, '-1409.592')]
[2023-08-31 22:40:38,145][26288] Updated weights for policy 0, policy_version 145832 (0.0002)
[2023-08-31 22:40:40,644][26288] Updated weights for policy 0, policy_version 145912 (0.0002)
[2023-08-31 22:40:43,107][26276] Fps is (10 sec: 15973.5, 60 sec: 16044.6, 300 sec: 15967.9). Total num frames: 74743808. Throughput: 0: 16130.1. Samples: 62787183. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 22:40:43,107][26276] Avg episode reward: [(0, '-1409.592')]
[2023-08-31 22:40:43,109][26287] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000145984_74743808.pth...
[2023-08-31 22:40:43,111][26287] Removing /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000139712_71532544.pth
[2023-08-31 22:40:43,161][26288] Updated weights for policy 0, policy_version 145992 (0.0002)
[2023-08-31 22:40:45,626][26288] Updated weights for policy 0, policy_version 146072 (0.0002)
[2023-08-31 22:40:48,115][26276] Fps is (10 sec: 15964.3, 60 sec: 16108.7, 300 sec: 15953.3). Total num frames: 74821632. Throughput: 0: 16138.6. Samples: 62884310. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 22:40:48,116][26276] Avg episode reward: [(0, '-1432.080')]
[2023-08-31 22:40:48,567][26288] Updated weights for policy 0, policy_version 146152 (0.0002)
[2023-08-31 22:40:51,040][26288] Updated weights for policy 0, policy_version 146232 (0.0002)
[2023-08-31 22:40:53,115][26276] Fps is (10 sec: 15961.4, 60 sec: 16111.0, 300 sec: 15967.0). Total num frames: 74903552. Throughput: 0: 16068.1. Samples: 62976018. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 22:40:53,115][26276] Avg episode reward: [(0, '-1432.080')]
[2023-08-31 22:40:53,480][26288] Updated weights for policy 0, policy_version 146312 (0.0002)
[2023-08-31 22:40:55,893][26288] Updated weights for policy 0, policy_version 146392 (0.0002)
[2023-08-31 22:40:58,111][26276] Fps is (10 sec: 15981.3, 60 sec: 16043.8, 300 sec: 15953.4). Total num frames: 74981376. Throughput: 0: 16123.0. Samples: 63026634. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:40:58,111][26276] Avg episode reward: [(0, '-1538.725')]
[2023-08-31 22:40:58,651][26288] Updated weights for policy 0, policy_version 146472 (0.0002)
[2023-08-31 22:41:01,026][26288] Updated weights for policy 0, policy_version 146552 (0.0002)
[2023-08-31 22:41:03,115][26276] Fps is (10 sec: 16383.9, 60 sec: 16110.1, 300 sec: 15994.9). Total num frames: 75067392. Throughput: 0: 16091.4. Samples: 63123570. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:41:03,115][26276] Avg episode reward: [(0, '-1538.725')]
[2023-08-31 22:41:03,461][26288] Updated weights for policy 0, policy_version 146632 (0.0002)
[2023-08-31 22:41:06,008][26288] Updated weights for policy 0, policy_version 146712 (0.0002)
[2023-08-31 22:41:08,110][26276] Fps is (10 sec: 16384.5, 60 sec: 16111.9, 300 sec: 15981.1). Total num frames: 75145216. Throughput: 0: 16021.1. Samples: 63217945. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:41:08,111][26276] Avg episode reward: [(0, '-1644.021')]
[2023-08-31 22:41:08,738][26288] Updated weights for policy 0, policy_version 146792 (0.0002)
[2023-08-31 22:41:11,266][26288] Updated weights for policy 0, policy_version 146872 (0.0002)
[2023-08-31 22:41:13,114][26276] Fps is (10 sec: 15976.2, 60 sec: 16110.6, 300 sec: 15994.9). Total num frames: 75227136. Throughput: 0: 16029.4. Samples: 63267361. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:41:13,114][26276] Avg episode reward: [(0, '-1644.021')]
[2023-08-31 22:41:13,623][26288] Updated weights for policy 0, policy_version 146952 (0.0002)
[2023-08-31 22:41:16,124][26288] Updated weights for policy 0, policy_version 147032 (0.0002)
[2023-08-31 22:41:18,106][26276] Fps is (10 sec: 15981.5, 60 sec: 16112.2, 300 sec: 15995.4). Total num frames: 75304960. Throughput: 0: 16112.4. Samples: 63366219. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:41:18,106][26276] Avg episode reward: [(0, '-1828.309')]
[2023-08-31 22:41:18,865][26288] Updated weights for policy 0, policy_version 147112 (0.0002)
[2023-08-31 22:41:21,390][26288] Updated weights for policy 0, policy_version 147192 (0.0002)
[2023-08-31 22:41:23,106][26276] Fps is (10 sec: 15987.0, 60 sec: 16042.6, 300 sec: 16009.6). Total num frames: 75386880. Throughput: 0: 16095.9. Samples: 63462061. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:41:23,106][26276] Avg episode reward: [(0, '-1828.309')]
[2023-08-31 22:41:23,929][26288] Updated weights for policy 0, policy_version 147272 (0.0002)
[2023-08-31 22:41:26,772][26288] Updated weights for policy 0, policy_version 147352 (0.0002)
[2023-08-31 22:41:28,114][26276] Fps is (10 sec: 15961.3, 60 sec: 16042.8, 300 sec: 15994.9). Total num frames: 75464704. Throughput: 0: 16026.7. Samples: 63508504. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:41:28,114][26276] Avg episode reward: [(0, '-1885.984')]
[2023-08-31 22:41:29,234][26288] Updated weights for policy 0, policy_version 147432 (0.0002)
[2023-08-31 22:41:31,788][26288] Updated weights for policy 0, policy_version 147512 (0.0002)
[2023-08-31 22:41:33,108][26276] Fps is (10 sec: 15971.5, 60 sec: 16042.2, 300 sec: 16009.0). Total num frames: 75546624. Throughput: 0: 15978.2. Samples: 63603214. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:41:33,108][26276] Avg episode reward: [(0, '-1885.984')]
[2023-08-31 22:41:34,278][26288] Updated weights for policy 0, policy_version 147592 (0.0002)
[2023-08-31 22:41:37,066][26288] Updated weights for policy 0, policy_version 147672 (0.0002)
[2023-08-31 22:41:38,108][26276] Fps is (10 sec: 15983.5, 60 sec: 16042.7, 300 sec: 15995.1). Total num frames: 75624448. Throughput: 0: 16022.3. Samples: 63696917. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:41:38,109][26276] Avg episode reward: [(0, '-1945.814')]
[2023-08-31 22:41:39,526][26288] Updated weights for policy 0, policy_version 147752 (0.0002)
[2023-08-31 22:41:42,112][26288] Updated weights for policy 0, policy_version 147832 (0.0002)
[2023-08-31 22:41:43,114][26276] Fps is (10 sec: 15554.8, 60 sec: 15972.4, 300 sec: 15994.7). Total num frames: 75702272. Throughput: 0: 15986.2. Samples: 63746069. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:41:43,115][26276] Avg episode reward: [(0, '-1945.814')]
[2023-08-31 22:41:44,621][26288] Updated weights for policy 0, policy_version 147912 (0.0002)
[2023-08-31 22:41:47,443][26288] Updated weights for policy 0, policy_version 147992 (0.0002)
[2023-08-31 22:41:48,113][26276] Fps is (10 sec: 15557.8, 60 sec: 15974.9, 300 sec: 16009.2). Total num frames: 75780096. Throughput: 0: 15963.0. Samples: 63841873. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:41:48,113][26276] Avg episode reward: [(0, '-1992.132')]
[2023-08-31 22:41:49,970][26288] Updated weights for policy 0, policy_version 148072 (0.0002)
[2023-08-31 22:41:52,392][26288] Updated weights for policy 0, policy_version 148152 (0.0002)
[2023-08-31 22:41:53,115][26276] Fps is (10 sec: 15973.4, 60 sec: 15974.4, 300 sec: 16036.9). Total num frames: 75862016. Throughput: 0: 15980.8. Samples: 63937156. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:41:53,115][26276] Avg episode reward: [(0, '-1992.132')]
[2023-08-31 22:41:54,845][26288] Updated weights for policy 0, policy_version 148232 (0.0002)
[2023-08-31 22:41:57,593][26288] Updated weights for policy 0, policy_version 148312 (0.0002)
[2023-08-31 22:41:58,109][26276] Fps is (10 sec: 16390.0, 60 sec: 16043.0, 300 sec: 16037.0). Total num frames: 75943936. Throughput: 0: 16001.1. Samples: 63987335. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:41:58,110][26276] Avg episode reward: [(0, '-2011.463')]
[2023-08-31 22:42:00,036][26288] Updated weights for policy 0, policy_version 148392 (0.0002)
[2023-08-31 22:42:02,593][26288] Updated weights for policy 0, policy_version 148472 (0.0002)
[2023-08-31 22:42:03,109][26276] Fps is (10 sec: 16393.1, 60 sec: 15975.9, 300 sec: 16064.5). Total num frames: 76025856. Throughput: 0: 15903.6. Samples: 64081936. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 22:42:03,110][26276] Avg episode reward: [(0, '-2011.463')]
[2023-08-31 22:42:05,206][26288] Updated weights for policy 0, policy_version 148552 (0.0002)
[2023-08-31 22:42:07,967][26288] Updated weights for policy 0, policy_version 148632 (0.0002)
[2023-08-31 22:42:08,106][26276] Fps is (10 sec: 15569.3, 60 sec: 15907.2, 300 sec: 16037.3). Total num frames: 76099584. Throughput: 0: 15827.2. Samples: 64174290. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 22:42:08,107][26276] Avg episode reward: [(0, '-2071.871')]
[2023-08-31 22:42:10,567][26288] Updated weights for policy 0, policy_version 148712 (0.0002)
[2023-08-31 22:42:13,073][26288] Updated weights for policy 0, policy_version 148792 (0.0002)
[2023-08-31 22:42:13,107][26276] Fps is (10 sec: 15568.5, 60 sec: 15908.0, 300 sec: 16036.8). Total num frames: 76181504. Throughput: 0: 15840.2. Samples: 64221200. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 22:42:13,107][26276] Avg episode reward: [(0, '-2071.871')]
[2023-08-31 22:42:15,492][26288] Updated weights for policy 0, policy_version 148872 (0.0002)
[2023-08-31 22:42:18,107][26276] Fps is (10 sec: 15973.6, 60 sec: 15905.9, 300 sec: 16023.0). Total num frames: 76259328. Throughput: 0: 15917.9. Samples: 64319504. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 22:42:18,107][26276] Avg episode reward: [(0, '-2064.009')]
[2023-08-31 22:42:18,200][26288] Updated weights for policy 0, policy_version 148952 (0.0002)
[2023-08-31 22:42:20,683][26288] Updated weights for policy 0, policy_version 149032 (0.0002)
[2023-08-31 22:42:23,105][26276] Fps is (10 sec: 15977.7, 60 sec: 15906.4, 300 sec: 16037.0). Total num frames: 76341248. Throughput: 0: 15979.3. Samples: 64415928. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 22:42:23,105][26276] Avg episode reward: [(0, '-2064.009')]
[2023-08-31 22:42:23,106][26288] Updated weights for policy 0, policy_version 149112 (0.0002)
[2023-08-31 22:42:23,108][26287] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000149112_76345344.pth...
[2023-08-31 22:42:23,110][26287] Removing /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000142848_73138176.pth
[2023-08-31 22:42:25,511][26288] Updated weights for policy 0, policy_version 149192 (0.0002)
[2023-08-31 22:42:28,109][26276] Fps is (10 sec: 16380.7, 60 sec: 15975.8, 300 sec: 16036.7). Total num frames: 76423168. Throughput: 0: 16024.1. Samples: 64467069. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 22:42:28,109][26276] Avg episode reward: [(0, '-2380.313')]
[2023-08-31 22:42:28,234][26288] Updated weights for policy 0, policy_version 149272 (0.0002)
[2023-08-31 22:42:30,737][26288] Updated weights for policy 0, policy_version 149352 (0.0002)
[2023-08-31 22:42:33,108][26276] Fps is (10 sec: 16378.7, 60 sec: 15974.3, 300 sec: 16051.1). Total num frames: 76505088. Throughput: 0: 16020.2. Samples: 64562704. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 22:42:33,108][26276] Avg episode reward: [(0, '-2380.313')]
[2023-08-31 22:42:33,196][26288] Updated weights for policy 0, policy_version 149432 (0.0002)
[2023-08-31 22:42:35,678][26288] Updated weights for policy 0, policy_version 149512 (0.0002)
[2023-08-31 22:42:38,107][26276] Fps is (10 sec: 15977.3, 60 sec: 15974.7, 300 sec: 16023.3). Total num frames: 76582912. Throughput: 0: 16003.9. Samples: 64657206. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 22:42:38,107][26276] Avg episode reward: [(0, '-2727.535')]
[2023-08-31 22:42:38,440][26288] Updated weights for policy 0, policy_version 149592 (0.0002)
[2023-08-31 22:42:40,931][26288] Updated weights for policy 0, policy_version 149672 (0.0002)
[2023-08-31 22:42:43,114][26276] Fps is (10 sec: 15965.5, 60 sec: 16042.8, 300 sec: 16050.5). Total num frames: 76664832. Throughput: 0: 15971.7. Samples: 64706134. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 22:42:43,114][26276] Avg episode reward: [(0, '-2727.535')]
[2023-08-31 22:42:43,427][26288] Updated weights for policy 0, policy_version 149752 (0.0002)
[2023-08-31 22:42:45,924][26288] Updated weights for policy 0, policy_version 149832 (0.0002)
[2023-08-31 22:42:48,115][26276] Fps is (10 sec: 15961.9, 60 sec: 16042.1, 300 sec: 16036.7). Total num frames: 76742656. Throughput: 0: 16057.9. Samples: 64804631. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 22:42:48,116][26276] Avg episode reward: [(0, '-2789.159')]
[2023-08-31 22:42:48,796][26288] Updated weights for policy 0, policy_version 149912 (0.0002)
[2023-08-31 22:42:51,224][26288] Updated weights for policy 0, policy_version 149992 (0.0002)
[2023-08-31 22:42:53,107][26276] Fps is (10 sec: 15985.2, 60 sec: 16044.8, 300 sec: 16036.9). Total num frames: 76824576. Throughput: 0: 16078.1. Samples: 64897816. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 22:42:53,107][26276] Avg episode reward: [(0, '-2789.159')]
[2023-08-31 22:42:53,828][26288] Updated weights for policy 0, policy_version 150072 (0.0002)
[2023-08-31 22:42:56,447][26288] Updated weights for policy 0, policy_version 150152 (0.0002)
[2023-08-31 22:42:58,108][26276] Fps is (10 sec: 15575.4, 60 sec: 15906.5, 300 sec: 16009.5). Total num frames: 76898304. Throughput: 0: 16099.1. Samples: 64945676. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 22:42:58,109][26276] Avg episode reward: [(0, '-2824.433')]
[2023-08-31 22:42:59,265][26288] Updated weights for policy 0, policy_version 150232 (0.0002)
[2023-08-31 22:43:01,709][26288] Updated weights for policy 0, policy_version 150312 (0.0002)
[2023-08-31 22:43:03,107][26276] Fps is (10 sec: 15564.8, 60 sec: 15906.7, 300 sec: 16037.3). Total num frames: 76980224. Throughput: 0: 15946.3. Samples: 65037090. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:43:03,107][26276] Avg episode reward: [(0, '-2824.433')]
[2023-08-31 22:43:04,254][26288] Updated weights for policy 0, policy_version 150392 (0.0002)
[2023-08-31 22:43:07,013][26288] Updated weights for policy 0, policy_version 150472 (0.0002)
[2023-08-31 22:43:08,111][26276] Fps is (10 sec: 15969.9, 60 sec: 15973.2, 300 sec: 16023.2). Total num frames: 77058048. Throughput: 0: 15862.2. Samples: 65129820. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:43:08,112][26276] Avg episode reward: [(0, '-2817.415')]
[2023-08-31 22:43:09,598][26288] Updated weights for policy 0, policy_version 150552 (0.0002)
[2023-08-31 22:43:12,206][26288] Updated weights for policy 0, policy_version 150632 (0.0002)
[2023-08-31 22:43:13,106][26276] Fps is (10 sec: 15565.8, 60 sec: 15906.3, 300 sec: 16023.5). Total num frames: 77135872. Throughput: 0: 15814.9. Samples: 65178702. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:43:13,107][26276] Avg episode reward: [(0, '-2817.415')]
[2023-08-31 22:43:14,736][26288] Updated weights for policy 0, policy_version 150712 (0.0002)
[2023-08-31 22:43:17,460][26288] Updated weights for policy 0, policy_version 150792 (0.0002)
[2023-08-31 22:43:18,108][26276] Fps is (10 sec: 15570.2, 60 sec: 15906.0, 300 sec: 16009.1). Total num frames: 77213696. Throughput: 0: 15823.3. Samples: 65274739. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:43:18,108][26276] Avg episode reward: [(0, '-2792.714')]
[2023-08-31 22:43:19,954][26288] Updated weights for policy 0, policy_version 150872 (0.0002)
[2023-08-31 22:43:22,492][26288] Updated weights for policy 0, policy_version 150952 (0.0002)
[2023-08-31 22:43:23,107][26276] Fps is (10 sec: 15973.3, 60 sec: 15905.6, 300 sec: 16023.1). Total num frames: 77295616. Throughput: 0: 15809.3. Samples: 65368626. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:43:23,107][26276] Avg episode reward: [(0, '-2792.714')]
[2023-08-31 22:43:25,033][26288] Updated weights for policy 0, policy_version 151032 (0.0002)
[2023-08-31 22:43:27,875][26288] Updated weights for policy 0, policy_version 151112 (0.0002)
[2023-08-31 22:43:28,107][26276] Fps is (10 sec: 15974.6, 60 sec: 15838.3, 300 sec: 15995.6). Total num frames: 77373440. Throughput: 0: 15803.4. Samples: 65417183. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:43:28,108][26276] Avg episode reward: [(0, '-2573.311')]
[2023-08-31 22:43:30,370][26288] Updated weights for policy 0, policy_version 151192 (0.0002)
[2023-08-31 22:43:32,920][26288] Updated weights for policy 0, policy_version 151272 (0.0002)
[2023-08-31 22:43:33,112][26276] Fps is (10 sec: 15558.0, 60 sec: 15768.7, 300 sec: 15994.9). Total num frames: 77451264. Throughput: 0: 15670.5. Samples: 65509747. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:43:33,112][26276] Avg episode reward: [(0, '-2573.311')]
[2023-08-31 22:43:35,459][26288] Updated weights for policy 0, policy_version 151352 (0.0002)
[2023-08-31 22:43:38,107][26276] Fps is (10 sec: 15564.9, 60 sec: 15769.6, 300 sec: 15981.8). Total num frames: 77529088. Throughput: 0: 15727.3. Samples: 65605546. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:43:38,108][26276] Avg episode reward: [(0, '-2290.862')]
[2023-08-31 22:43:38,263][26288] Updated weights for policy 0, policy_version 151432 (0.0002)
[2023-08-31 22:43:40,722][26288] Updated weights for policy 0, policy_version 151512 (0.0002)
[2023-08-31 22:43:43,108][26276] Fps is (10 sec: 15979.4, 60 sec: 15771.0, 300 sec: 15981.7). Total num frames: 77611008. Throughput: 0: 15691.8. Samples: 65651810. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:43:43,109][26276] Avg episode reward: [(0, '-2290.862')]
[2023-08-31 22:43:43,205][26288] Updated weights for policy 0, policy_version 151592 (0.0002)
[2023-08-31 22:43:45,644][26288] Updated weights for policy 0, policy_version 151672 (0.0002)
[2023-08-31 22:43:48,115][26276] Fps is (10 sec: 15962.2, 60 sec: 15769.6, 300 sec: 15967.0). Total num frames: 77688832. Throughput: 0: 15878.1. Samples: 65751731. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:43:48,116][26276] Avg episode reward: [(0, '-2319.327')]
[2023-08-31 22:43:48,392][26288] Updated weights for policy 0, policy_version 151752 (0.0002)
[2023-08-31 22:43:50,845][26288] Updated weights for policy 0, policy_version 151832 (0.0002)
[2023-08-31 22:43:53,113][26276] Fps is (10 sec: 16375.7, 60 sec: 15836.2, 300 sec: 15994.8). Total num frames: 77774848. Throughput: 0: 15943.4. Samples: 65847312. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:43:53,114][26276] Avg episode reward: [(0, '-2319.327')]
[2023-08-31 22:43:53,291][26288] Updated weights for policy 0, policy_version 151912 (0.0002)
[2023-08-31 22:43:55,722][26288] Updated weights for policy 0, policy_version 151992 (0.0002)
[2023-08-31 22:43:58,106][26276] Fps is (10 sec: 16398.3, 60 sec: 15906.6, 300 sec: 15981.5). Total num frames: 77852672. Throughput: 0: 15982.0. Samples: 65897888. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:43:58,107][26276] Avg episode reward: [(0, '-2327.725')]
[2023-08-31 22:43:58,420][26288] Updated weights for policy 0, policy_version 152072 (0.0002)
[2023-08-31 22:44:00,845][26288] Updated weights for policy 0, policy_version 152152 (0.0002)
[2023-08-31 22:44:03,109][26276] Fps is (10 sec: 15981.7, 60 sec: 15905.7, 300 sec: 15995.5). Total num frames: 77934592. Throughput: 0: 15990.5. Samples: 65994334. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:44:03,109][26276] Avg episode reward: [(0, '-2327.725')]
[2023-08-31 22:44:03,113][26287] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000152216_77934592.pth...
[2023-08-31 22:44:03,115][26287] Removing /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000145984_74743808.pth
[2023-08-31 22:44:03,419][26288] Updated weights for policy 0, policy_version 152232 (0.0002)
[2023-08-31 22:44:05,925][26288] Updated weights for policy 0, policy_version 152312 (0.0002)
[2023-08-31 22:44:08,110][26276] Fps is (10 sec: 15149.4, 60 sec: 15769.9, 300 sec: 15953.8). Total num frames: 78004224. Throughput: 0: 15923.5. Samples: 66085230. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:44:08,110][26276] Avg episode reward: [(0, '-2456.270')]
[2023-08-31 22:44:09,607][26288] Updated weights for policy 0, policy_version 152392 (0.0003)
[2023-08-31 22:44:09,844][26287] High loss value: l:249.7767 pl:-0.0454 vl:0.1261 exp_l:0.0000 kl_l:249.6961 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:09,844][26287] KL-divergence is very high: 100170.0469
[2023-08-31 22:44:09,848][26287] High loss value: l:2111.5452 pl:-0.0393 vl:0.4456 exp_l:0.0000 kl_l:2111.1389 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:09,848][26287] KL-divergence is very high: 666442.0625
[2023-08-31 22:44:09,852][26287] High loss value: l:2548.0754 pl:0.0309 vl:0.7139 exp_l:0.0000 kl_l:2547.3306 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:09,852][26287] KL-divergence is very high: 308500.0938
[2023-08-31 22:44:09,856][26287] KL-divergence is very high: 654.7380
[2023-08-31 22:44:09,859][26287] High loss value: l:3338.4624 pl:-0.0331 vl:0.1196 exp_l:0.0000 kl_l:3338.3757 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:09,859][26287] KL-divergence is very high: 1781796.1250
[2023-08-31 22:44:09,864][26287] High loss value: l:1253.9061 pl:-0.0228 vl:0.4398 exp_l:0.0000 kl_l:1253.4891 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:09,864][26287] KL-divergence is very high: 384909.9688
[2023-08-31 22:44:09,867][26287] High loss value: l:7516.4751 pl:0.1013 vl:0.7125 exp_l:0.0000 kl_l:7515.6611 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:09,867][26287] KL-divergence is very high: 1188023.3750
[2023-08-31 22:44:10,178][26287] High loss value: l:7010.8999 pl:-0.0113 vl:1.1625 exp_l:0.0000 kl_l:7009.7485 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:10,179][26287] KL-divergence is very high: 820274.9375
[2023-08-31 22:44:10,182][26287] High loss value: l:5140.5103 pl:-0.0236 vl:1.0730 exp_l:0.0000 kl_l:5139.4604 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:10,183][26287] KL-divergence is very high: 739723.4375
[2023-08-31 22:44:10,187][26287] High loss value: l:4810.7505 pl:-0.0471 vl:0.4522 exp_l:0.0000 kl_l:4810.3452 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:10,187][26287] KL-divergence is very high: 758014.1250
[2023-08-31 22:44:10,191][26287] High loss value: l:710.2736 pl:0.0308 vl:0.9432 exp_l:0.0000 kl_l:709.2996 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:10,191][26287] KL-divergence is very high: 94374.9844
[2023-08-31 22:44:10,195][26287] High loss value: l:1680.0587 pl:0.0234 vl:1.1376 exp_l:0.0000 kl_l:1678.8977 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:10,195][26287] KL-divergence is very high: 198773.9844
[2023-08-31 22:44:10,199][26287] High loss value: l:2282.3943 pl:-0.0188 vl:1.0295 exp_l:0.0000 kl_l:2281.3835 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:10,199][26287] KL-divergence is very high: 314111.6562
[2023-08-31 22:44:10,202][26287] High loss value: l:1315.1583 pl:-0.0492 vl:0.4103 exp_l:0.0000 kl_l:1314.7972 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:10,202][26287] KL-divergence is very high: 237743.6719
[2023-08-31 22:44:10,470][26287] High loss value: l:4710.6436 pl:-0.0218 vl:0.2441 exp_l:0.0000 kl_l:4710.4214 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:10,470][26287] KL-divergence is very high: 863844.3750
[2023-08-31 22:44:10,474][26287] High loss value: l:2490.4675 pl:-0.0298 vl:0.5776 exp_l:0.0000 kl_l:2489.9197 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:10,474][26287] KL-divergence is very high: 947993.8750
[2023-08-31 22:44:10,478][26287] High loss value: l:7207.5742 pl:-0.0029 vl:1.0327 exp_l:0.0000 kl_l:7206.5444 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:10,478][26287] KL-divergence is very high: 870791.2500
[2023-08-31 22:44:10,482][26287] High loss value: l:2074.3867 pl:-0.0215 vl:0.2806 exp_l:0.0000 kl_l:2074.1277 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:10,482][26287] KL-divergence is very high: 849019.6250
[2023-08-31 22:44:10,486][26287] High loss value: l:13923.2822 pl:-0.0175 vl:0.2482 exp_l:0.0000 kl_l:13923.0518 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:10,486][26287] KL-divergence is very high: 3081842.7500
[2023-08-31 22:44:10,490][26287] High loss value: l:5162.6665 pl:-0.0173 vl:0.5813 exp_l:0.0000 kl_l:5162.1021 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:10,490][26287] KL-divergence is very high: 2286002.5000
[2023-08-31 22:44:10,494][26287] High loss value: l:2591.3184 pl:-0.0030 vl:1.0355 exp_l:0.0000 kl_l:2590.2859 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:10,495][26287] KL-divergence is very high: 298597.5312
[2023-08-31 22:44:10,796][26287] High loss value: l:11365.9854 pl:0.0409 vl:1.6160 exp_l:0.0000 kl_l:11364.3281 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:10,796][26287] KL-divergence is very high: 2972400.7500
[2023-08-31 22:44:10,800][26287] High loss value: l:41986.7500 pl:0.0507 vl:1.7736 exp_l:0.0000 kl_l:41984.9258 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:10,800][26287] KL-divergence is very high: 6100927.5000
[2023-08-31 22:44:10,803][26287] High loss value: l:26576.8438 pl:0.0078 vl:1.8540 exp_l:0.0000 kl_l:26574.9824 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:10,803][26287] KL-divergence is very high: 6852057.5000
[2023-08-31 22:44:10,807][26287] High loss value: l:39942.0352 pl:0.0520 vl:1.3477 exp_l:0.0000 kl_l:39940.6367 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:10,807][26287] KL-divergence is very high: 4455345.0000
[2023-08-31 22:44:10,811][26287] High loss value: l:5708.7690 pl:0.0433 vl:1.5462 exp_l:0.0000 kl_l:5707.1792 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:10,811][26287] KL-divergence is very high: 1841469.2500
[2023-08-31 22:44:10,815][26287] High loss value: l:12887.1523 pl:0.0343 vl:1.6802 exp_l:0.0000 kl_l:12885.4385 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:10,815][26287] KL-divergence is very high: 2934354.5000
[2023-08-31 22:44:10,820][26287] High loss value: l:8742.2568 pl:0.0213 vl:1.7585 exp_l:0.0000 kl_l:8740.4766 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:10,820][26287] KL-divergence is very high: 2971678.5000
[2023-08-31 22:44:11,138][26287] High loss value: l:834.8693 pl:-0.0358 vl:1.9042 exp_l:0.0000 kl_l:833.0010 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:11,138][26287] KL-divergence is very high: 290053.7812
[2023-08-31 22:44:11,141][26287] KL-divergence is very high: 7492.1021
[2023-08-31 22:44:11,148][26287] High loss value: l:633.6671 pl:-0.0350 vl:1.8294 exp_l:0.0000 kl_l:631.8727 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:11,149][26287] KL-divergence is very high: 225134.7969
[2023-08-31 22:44:11,152][26287] High loss value: l:281.0573 pl:0.0039 vl:1.8091 exp_l:0.0000 kl_l:279.2443 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:11,152][26287] KL-divergence is very high: 80554.3203
[2023-08-31 22:44:11,156][26287] KL-divergence is very high: 3693.5942
[2023-08-31 22:44:12,720][26288] Updated weights for policy 0, policy_version 152472 (0.0003)
[2023-08-31 22:44:13,109][26276] Fps is (10 sec: 13516.3, 60 sec: 15564.1, 300 sec: 15911.9). Total num frames: 78069760. Throughput: 0: 15593.8. Samples: 66118932. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 22:44:13,110][26276] Avg episode reward: [(0, '-2456.270')]
[2023-08-31 22:44:15,305][26288] Updated weights for policy 0, policy_version 152552 (0.0002)
[2023-08-31 22:44:17,829][26288] Updated weights for policy 0, policy_version 152632 (0.0002)
[2023-08-31 22:44:18,107][26276] Fps is (10 sec: 14750.8, 60 sec: 15633.3, 300 sec: 15898.1). Total num frames: 78151680. Throughput: 0: 15517.3. Samples: 66207946. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 22:44:18,107][26276] Avg episode reward: [(0, '-2456.270')]
[2023-08-31 22:44:20,449][26287] Early stopping after 2 epochs (8 sgd steps), loss delta 0.0000005
[2023-08-31 22:44:20,695][26288] Updated weights for policy 0, policy_version 152712 (0.0002)
[2023-08-31 22:44:23,110][26276] Fps is (10 sec: 15563.2, 60 sec: 15495.7, 300 sec: 15884.3). Total num frames: 78225408. Throughput: 0: 15430.8. Samples: 66299976. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 22:44:23,111][26276] Avg episode reward: [(0, '-17952.348')]
[2023-08-31 22:44:23,197][26288] Updated weights for policy 0, policy_version 152792 (0.0002)
[2023-08-31 22:44:25,592][26288] Updated weights for policy 0, policy_version 152872 (0.0002)
[2023-08-31 22:44:28,098][26288] Updated weights for policy 0, policy_version 152952 (0.0003)
[2023-08-31 22:44:28,107][26276] Fps is (10 sec: 15973.7, 60 sec: 15633.2, 300 sec: 15912.3). Total num frames: 78311424. Throughput: 0: 15533.5. Samples: 66350795. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 22:44:28,107][26276] Avg episode reward: [(0, '-17952.348')]
[2023-08-31 22:44:29,047][26287] KL-divergence is very high: 2800.0310
[2023-08-31 22:44:29,253][26287] KL-divergence is very high: 795.1854
[2023-08-31 22:44:29,255][26287] KL-divergence is very high: 1215.8861
[2023-08-31 22:44:29,258][26287] KL-divergence is very high: 1551.9980
[2023-08-31 22:44:29,261][26287] KL-divergence is very high: 1476.8845
[2023-08-31 22:44:29,264][26287] KL-divergence is very high: 355.0025
[2023-08-31 22:44:29,267][26287] KL-divergence is very high: 1857.4031
[2023-08-31 22:44:29,270][26287] KL-divergence is very high: 1236.6770
[2023-08-31 22:44:29,499][26287] KL-divergence is very high: 7022.5791
[2023-08-31 22:44:29,502][26287] KL-divergence is very high: 3336.5381
[2023-08-31 22:44:29,507][26287] KL-divergence is very high: 308.4040
[2023-08-31 22:44:29,510][26287] High loss value: l:396.3717 pl:-0.0326 vl:0.1693 exp_l:0.0000 kl_l:396.2350 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:29,510][26287] KL-divergence is very high: 419113.4375
[2023-08-31 22:44:29,513][26287] KL-divergence is very high: 59304.0820
[2023-08-31 22:44:30,738][26288] Updated weights for policy 0, policy_version 153032 (0.0002)
[2023-08-31 22:44:33,110][26276] Fps is (10 sec: 16384.2, 60 sec: 15633.4, 300 sec: 15897.9). Total num frames: 78389248. Throughput: 0: 15425.2. Samples: 66445789. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 22:44:33,110][26276] Avg episode reward: [(0, '-18092.154')]
[2023-08-31 22:44:33,228][26288] Updated weights for policy 0, policy_version 153112 (0.0002)
[2023-08-31 22:44:35,646][26288] Updated weights for policy 0, policy_version 153192 (0.0002)
[2023-08-31 22:44:38,106][26276] Fps is (10 sec: 15976.5, 60 sec: 15701.8, 300 sec: 15898.5). Total num frames: 78471168. Throughput: 0: 15543.8. Samples: 66546662. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 22:44:38,106][26276] Avg episode reward: [(0, '-18092.154')]
[2023-08-31 22:44:38,151][26288] Updated weights for policy 0, policy_version 153272 (0.0002)
[2023-08-31 22:44:40,750][26288] Updated weights for policy 0, policy_version 153352 (0.0002)
[2023-08-31 22:44:43,110][26276] Fps is (10 sec: 16384.3, 60 sec: 15700.9, 300 sec: 15925.6). Total num frames: 78553088. Throughput: 0: 15444.6. Samples: 66592953. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 22:44:43,110][26276] Avg episode reward: [(0, '-22518.403')]
[2023-08-31 22:44:43,207][26288] Updated weights for policy 0, policy_version 153432 (0.0002)
[2023-08-31 22:44:45,541][26288] Updated weights for policy 0, policy_version 153512 (0.0002)
[2023-08-31 22:44:48,043][26288] Updated weights for policy 0, policy_version 153592 (0.0002)
[2023-08-31 22:44:48,107][26276] Fps is (10 sec: 16792.1, 60 sec: 15840.1, 300 sec: 15940.2). Total num frames: 78639104. Throughput: 0: 15589.3. Samples: 66695816. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 22:44:48,107][26276] Avg episode reward: [(0, '-22518.403')]
[2023-08-31 22:44:48,507][26287] High loss value: l:45.3572 pl:0.0627 vl:0.2199 exp_l:0.0000 kl_l:45.0745 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:48,507][26287] KL-divergence is very high: 13238.7168
[2023-08-31 22:44:48,510][26287] High loss value: l:4602.5557 pl:0.1493 vl:0.5155 exp_l:0.0000 kl_l:4601.8906 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:48,511][26287] KL-divergence is very high: 341396.2188
[2023-08-31 22:44:48,520][26287] High loss value: l:414.2053 pl:0.0708 vl:0.2036 exp_l:0.0000 kl_l:413.9309 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:48,520][26287] KL-divergence is very high: 91768.8047
[2023-08-31 22:44:48,524][26287] High loss value: l:1988.8192 pl:0.1504 vl:0.4859 exp_l:0.0000 kl_l:1988.1830 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:48,524][26287] KL-divergence is very high: 233203.3438
[2023-08-31 22:44:48,722][26287] High loss value: l:933.6946 pl:0.1174 vl:1.6960 exp_l:0.0000 kl_l:931.8812 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:48,722][26287] KL-divergence is very high: 320075.5312
[2023-08-31 22:44:48,725][26287] High loss value: l:811.4984 pl:0.1083 vl:1.9131 exp_l:0.0000 kl_l:809.4770 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:48,725][26287] KL-divergence is very high: 459862.8125
[2023-08-31 22:44:48,728][26287] High loss value: l:565.5316 pl:0.2182 vl:2.5207 exp_l:0.0000 kl_l:562.7927 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:48,728][26287] KL-divergence is very high: 186340.0781
[2023-08-31 22:44:48,732][26287] High loss value: l:1150.0663 pl:0.1790 vl:1.3186 exp_l:0.0000 kl_l:1148.5687 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:48,732][26287] KL-divergence is very high: 311768.7500
[2023-08-31 22:44:48,735][26287] High loss value: l:596.6951 pl:0.1197 vl:1.6135 exp_l:0.0000 kl_l:594.9619 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:48,735][26287] KL-divergence is very high: 243864.9219
[2023-08-31 22:44:48,738][26287] High loss value: l:220.7871 pl:0.1977 vl:1.9067 exp_l:0.0000 kl_l:218.6826 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:48,739][26287] KL-divergence is very high: 192940.1562
[2023-08-31 22:44:48,742][26287] High loss value: l:993.8454 pl:0.2486 vl:2.5502 exp_l:0.0000 kl_l:991.0467 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:48,742][26287] KL-divergence is very high: 284755.6562
[2023-08-31 22:44:48,942][26287] KL-divergence is very high: 5604.8960
[2023-08-31 22:44:48,944][26287] KL-divergence is very high: 45136.2812
[2023-08-31 22:44:48,947][26287] High loss value: l:133.5129 pl:0.0236 vl:4.0225 exp_l:0.0000 kl_l:129.4668 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:48,947][26287] KL-divergence is very high: 155993.9844
[2023-08-31 22:44:48,950][26287] High loss value: l:1055.3091 pl:0.1730 vl:3.0035 exp_l:0.0000 kl_l:1052.1326 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:48,951][26287] KL-divergence is very high: 418518.1875
[2023-08-31 22:44:48,954][26287] High loss value: l:33.8762 pl:0.0547 vl:3.4362 exp_l:0.0000 kl_l:30.3853 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:48,954][26287] KL-divergence is very high: 10172.4355
[2023-08-31 22:44:48,957][26287] High loss value: l:86.3457 pl:0.0282 vl:3.8692 exp_l:0.0000 kl_l:82.4482 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:48,957][26287] KL-divergence is very high: 392197.6875
[2023-08-31 22:44:48,960][26287] High loss value: l:173.1578 pl:0.1045 vl:3.9796 exp_l:0.0000 kl_l:169.0737 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:48,960][26287] KL-divergence is very high: 239133.7812
[2023-08-31 22:44:49,197][26287] High loss value: l:5942.2490 pl:0.0160 vl:3.9352 exp_l:0.0000 kl_l:5938.2979 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:49,197][26287] KL-divergence is very high: 1103979.5000
[2023-08-31 22:44:49,201][26287] High loss value: l:3094.2085 pl:0.1114 vl:3.8514 exp_l:0.0000 kl_l:3090.2458 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:49,201][26287] KL-divergence is very high: 1450840.6250
[2023-08-31 22:44:49,204][26287] High loss value: l:1364.4519 pl:-0.0013 vl:5.1209 exp_l:0.0000 kl_l:1359.3324 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:49,205][26287] KL-divergence is very high: 1029978.1250
[2023-08-31 22:44:49,208][26287] High loss value: l:4620.2954 pl:0.0800 vl:4.1609 exp_l:0.0000 kl_l:4616.0542 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:49,208][26287] KL-divergence is very high: 730313.6250
[2023-08-31 22:44:49,212][26287] High loss value: l:3956.4607 pl:0.0174 vl:3.6505 exp_l:0.0000 kl_l:3952.7927 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:49,212][26287] KL-divergence is very high: 878227.5625
[2023-08-31 22:44:49,216][26287] High loss value: l:662.3175 pl:0.2414 vl:3.6059 exp_l:0.0000 kl_l:658.4702 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:49,216][26287] KL-divergence is very high: 1112795.1250
[2023-08-31 22:44:49,220][26287] High loss value: l:543.3099 pl:0.0117 vl:4.8400 exp_l:0.0000 kl_l:538.4582 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:49,220][26287] KL-divergence is very high: 434291.3750
[2023-08-31 22:44:49,421][26287] High loss value: l:102.8250 pl:0.0391 vl:7.6551 exp_l:0.0000 kl_l:95.1308 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:49,422][26287] KL-divergence is very high: 56205.4023
[2023-08-31 22:44:49,425][26287] High loss value: l:53.8636 pl:0.1306 vl:8.2624 exp_l:0.0000 kl_l:45.4706 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:49,425][26287] KL-divergence is very high: 48944.4414
[2023-08-31 22:44:49,429][26287] High loss value: l:158.7728 pl:0.1761 vl:9.5994 exp_l:0.0000 kl_l:148.9973 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:49,429][26287] KL-divergence is very high: 52342.9297
[2023-08-31 22:44:49,432][26287] High loss value: l:427.2304 pl:0.0415 vl:5.9331 exp_l:0.0000 kl_l:421.2558 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:49,432][26287] KL-divergence is very high: 130904.1172
[2023-08-31 22:44:49,436][26287] High loss value: l:412.3812 pl:0.0991 vl:7.3712 exp_l:0.0000 kl_l:404.9109 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:49,436][26287] KL-divergence is very high: 312155.5625
[2023-08-31 22:44:49,439][26287] High loss value: l:271.0470 pl:0.1757 vl:7.9560 exp_l:0.0000 kl_l:262.9153 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:49,439][26287] KL-divergence is very high: 246674.5781
[2023-08-31 22:44:49,443][26287] High loss value: l:1133.8518 pl:0.1734 vl:9.3265 exp_l:0.0000 kl_l:1124.3519 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:49,443][26287] KL-divergence is very high: 309616.7812
[2023-08-31 22:44:49,664][26287] KL-divergence is very high: 158.8808
[2023-08-31 22:44:49,668][26287] High loss value: l:224.9160 pl:0.0801 vl:11.2939 exp_l:0.0000 kl_l:213.5420 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:49,668][26287] KL-divergence is very high: 164222.7500
[2023-08-31 22:44:49,671][26287] High loss value: l:198.7693 pl:0.1290 vl:8.6939 exp_l:0.0000 kl_l:189.9464 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:49,671][26287] KL-divergence is very high: 52395.6719
[2023-08-31 22:44:49,675][26287] High loss value: l:571.5001 pl:0.1318 vl:9.0369 exp_l:0.0000 kl_l:562.3314 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:49,675][26287] KL-divergence is very high: 159095.2500
[2023-08-31 22:44:49,678][26287] KL-divergence is very high: 7157.3408
[2023-08-31 22:44:49,681][26287] High loss value: l:626.1169 pl:0.1167 vl:10.6786 exp_l:0.0000 kl_l:615.3216 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:49,681][26287] KL-divergence is very high: 409750.7188
[2023-08-31 22:44:49,684][26287] High loss value: l:681.8708 pl:0.1743 vl:8.3690 exp_l:0.0000 kl_l:673.3275 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:49,684][26287] KL-divergence is very high: 180870.8125
[2023-08-31 22:44:49,910][26287] High loss value: l:1491.0251 pl:0.1397 vl:7.9511 exp_l:0.0000 kl_l:1482.9342 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:49,910][26287] KL-divergence is very high: 357061.5000
[2023-08-31 22:44:49,914][26287] High loss value: l:368.3554 pl:0.0948 vl:7.8272 exp_l:0.0000 kl_l:360.4334 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:49,914][26287] KL-divergence is very high: 500801.0625
[2023-08-31 22:44:49,917][26287] High loss value: l:503.3926 pl:0.1492 vl:7.4026 exp_l:0.0000 kl_l:495.8408 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:49,917][26287] KL-divergence is very high: 190502.4531
[2023-08-31 22:44:49,920][26287] High loss value: l:668.0530 pl:0.1163 vl:8.1359 exp_l:0.0000 kl_l:659.8008 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:49,920][26287] KL-divergence is very high: 192779.1406
[2023-08-31 22:44:49,923][26287] High loss value: l:934.9667 pl:0.1471 vl:7.6930 exp_l:0.0000 kl_l:927.1266 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:49,923][26287] KL-divergence is very high: 355270.4062
[2023-08-31 22:44:49,926][26287] High loss value: l:240.0323 pl:0.1187 vl:7.7171 exp_l:0.0000 kl_l:232.1965 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:49,926][26287] KL-divergence is very high: 124518.1406
[2023-08-31 22:44:49,930][26287] High loss value: l:520.7313 pl:0.1689 vl:7.4525 exp_l:0.0000 kl_l:513.1099 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:49,930][26287] KL-divergence is very high: 205341.3594
[2023-08-31 22:44:50,168][26287] High loss value: l:35.7242 pl:0.1182 vl:6.6639 exp_l:0.0000 kl_l:28.9421 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:50,168][26287] KL-divergence is very high: 31154.0430
[2023-08-31 22:44:50,171][26287] KL-divergence is very high: 171.5361
[2023-08-31 22:44:50,177][26287] High loss value: l:104.7501 pl:0.1812 vl:6.4546 exp_l:0.0000 kl_l:98.1143 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:50,177][26287] KL-divergence is very high: 83653.4922
[2023-08-31 22:44:50,180][26287] High loss value: l:51.8696 pl:0.3148 vl:5.3429 exp_l:0.0000 kl_l:46.2119 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:50,180][26287] KL-divergence is very high: 49358.9883
[2023-08-31 22:44:50,184][26287] KL-divergence is very high: 693.1277
[2023-08-31 22:44:50,417][26287] High loss value: l:336.0900 pl:0.1520 vl:2.0988 exp_l:0.0000 kl_l:333.8392 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:50,417][26287] KL-divergence is very high: 158685.5938
[2023-08-31 22:44:50,420][26287] High loss value: l:268.9956 pl:0.1050 vl:1.7688 exp_l:0.0000 kl_l:267.1218 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:50,420][26287] KL-divergence is very high: 126838.4609
[2023-08-31 22:44:50,423][26287] High loss value: l:37.8517 pl:0.2660 vl:1.3469 exp_l:0.0000 kl_l:36.2388 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:50,423][26287] KL-divergence is very high: 23629.4922
[2023-08-31 22:44:50,426][26287] High loss value: l:82.1207 pl:0.1111 vl:1.7723 exp_l:0.0000 kl_l:80.2372 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:50,426][26287] KL-divergence is very high: 89095.7344
[2023-08-31 22:44:50,429][26287] High loss value: l:1007.3230 pl:0.1902 vl:1.5215 exp_l:0.0000 kl_l:1005.6113 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:50,429][26287] KL-divergence is very high: 330346.3438
[2023-08-31 22:44:50,432][26287] High loss value: l:493.9084 pl:0.1152 vl:1.4866 exp_l:0.0000 kl_l:492.3066 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:50,432][26287] KL-divergence is very high: 167542.5156
[2023-08-31 22:44:50,435][26287] High loss value: l:193.8183 pl:0.2743 vl:1.2093 exp_l:0.0000 kl_l:192.3347 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:50,435][26287] KL-divergence is very high: 103630.8281
[2023-08-31 22:44:50,638][26287] High loss value: l:487.1895 pl:0.2531 vl:1.2016 exp_l:0.0000 kl_l:485.7348 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:50,638][26287] KL-divergence is very high: 160281.9688
[2023-08-31 22:44:50,642][26287] High loss value: l:658.3262 pl:0.0930 vl:1.1152 exp_l:0.0000 kl_l:657.1181 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:50,642][26287] KL-divergence is very high: 205590.9688
[2023-08-31 22:44:50,646][26287] High loss value: l:315.7659 pl:0.0721 vl:1.1038 exp_l:0.0000 kl_l:314.5899 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:50,646][26287] KL-divergence is very high: 105892.6094
[2023-08-31 22:44:50,649][26287] High loss value: l:61.5205 pl:0.0078 vl:1.3368 exp_l:0.0000 kl_l:60.1759 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:50,649][26287] KL-divergence is very high: 132344.1875
[2023-08-31 22:44:50,653][26287] High loss value: l:582.5022 pl:0.0248 vl:1.2766 exp_l:0.0000 kl_l:581.2009 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:50,653][26287] KL-divergence is very high: 175807.2188
[2023-08-31 22:44:50,656][26287] High loss value: l:898.2289 pl:0.0321 vl:1.2147 exp_l:0.0000 kl_l:896.9821 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:50,657][26287] KL-divergence is very high: 262922.0312
[2023-08-31 22:44:50,660][26287] High loss value: l:449.9461 pl:0.0352 vl:1.1872 exp_l:0.0000 kl_l:448.7236 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:50,660][26287] KL-divergence is very high: 167541.6719
[2023-08-31 22:44:50,663][26288] Updated weights for policy 0, policy_version 153672 (0.0002)
[2023-08-31 22:44:50,862][26287] High loss value: l:85.6851 pl:0.2436 vl:1.2455 exp_l:0.0000 kl_l:84.1959 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:50,862][26287] KL-divergence is very high: 21357.3418
[2023-08-31 22:44:50,866][26287] KL-divergence is very high: 20454.6406
[2023-08-31 22:44:50,869][26287] KL-divergence is very high: 298.2792
[2023-08-31 22:44:50,872][26287] High loss value: l:173.8292 pl:0.1172 vl:1.2430 exp_l:0.0000 kl_l:172.4690 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:50,872][26287] KL-divergence is very high: 57877.8438
[2023-08-31 22:44:50,875][26287] High loss value: l:183.3706 pl:0.1172 vl:1.2270 exp_l:0.0000 kl_l:182.0264 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:50,875][26287] KL-divergence is very high: 52280.2383
[2023-08-31 22:44:50,878][26287] High loss value: l:39.5637 pl:0.0837 vl:1.2069 exp_l:0.0000 kl_l:38.2731 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:50,879][26287] KL-divergence is very high: 21006.1699
[2023-08-31 22:44:50,882][26287] KL-divergence is very high: 26004.1816
[2023-08-31 22:44:51,107][26287] High loss value: l:479.0551 pl:0.2196 vl:1.4289 exp_l:0.0000 kl_l:477.4066 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:51,108][26287] KL-divergence is very high: 233665.8906
[2023-08-31 22:44:51,111][26287] High loss value: l:1582.3208 pl:0.2684 vl:1.9383 exp_l:0.0000 kl_l:1580.1141 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:51,111][26287] KL-divergence is very high: 341194.7500
[2023-08-31 22:44:51,114][26287] High loss value: l:210.7856 pl:0.1995 vl:1.7597 exp_l:0.0000 kl_l:208.8263 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:51,114][26287] KL-divergence is very high: 154992.4531
[2023-08-31 22:44:51,117][26287] High loss value: l:222.8541 pl:0.1930 vl:1.3422 exp_l:0.0000 kl_l:221.3189 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:51,118][26287] KL-divergence is very high: 215254.4844
[2023-08-31 22:44:51,121][26287] High loss value: l:846.7515 pl:0.2674 vl:1.3946 exp_l:0.0000 kl_l:845.0895 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:51,121][26287] KL-divergence is very high: 541538.0000
[2023-08-31 22:44:51,124][26287] High loss value: l:522.0497 pl:0.2727 vl:1.9737 exp_l:0.0000 kl_l:519.8034 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:51,124][26287] KL-divergence is very high: 206629.3906
[2023-08-31 22:44:51,127][26287] High loss value: l:300.8109 pl:0.3240 vl:1.7287 exp_l:0.0000 kl_l:298.7581 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:51,127][26287] KL-divergence is very high: 228904.9219
[2023-08-31 22:44:51,400][26287] High loss value: l:142.2244 pl:0.1661 vl:1.7983 exp_l:0.0000 kl_l:140.2600 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:51,400][26287] KL-divergence is very high: 33471.4766
[2023-08-31 22:44:51,403][26287] High loss value: l:189.1534 pl:0.2291 vl:1.5742 exp_l:0.0000 kl_l:187.3501 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:51,403][26287] KL-divergence is very high: 35768.5312
[2023-08-31 22:44:51,407][26287] KL-divergence is very high: 11091.0049
[2023-08-31 22:44:51,409][26287] High loss value: l:113.1392 pl:0.1544 vl:2.4140 exp_l:0.0000 kl_l:110.5709 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:51,409][26287] KL-divergence is very high: 88100.8828
[2023-08-31 22:44:51,413][26287] High loss value: l:159.6039 pl:0.2356 vl:1.7657 exp_l:0.0000 kl_l:157.6025 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:51,413][26287] KL-divergence is very high: 75022.2188
[2023-08-31 22:44:51,417][26287] High loss value: l:129.1863 pl:0.1966 vl:1.5285 exp_l:0.0000 kl_l:127.4612 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:51,417][26287] KL-divergence is very high: 26060.5254
[2023-08-31 22:44:51,420][26287] KL-divergence is very high: 10469.8984
[2023-08-31 22:44:51,623][26287] High loss value: l:78.9639 pl:0.2131 vl:1.9491 exp_l:0.0000 kl_l:76.8017 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:51,624][26287] KL-divergence is very high: 53001.1094
[2023-08-31 22:44:51,627][26287] KL-divergence is very high: 20323.4219
[2023-08-31 22:44:51,629][26287] KL-divergence is very high: 13854.7803
[2023-08-31 22:44:51,632][26287] High loss value: l:44.8420 pl:0.0387 vl:1.7529 exp_l:0.0000 kl_l:43.0504 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:51,632][26287] KL-divergence is very high: 35480.3828
[2023-08-31 22:44:51,636][26287] High loss value: l:429.0525 pl:0.1542 vl:1.8974 exp_l:0.0000 kl_l:427.0009 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:51,636][26287] KL-divergence is very high: 301506.3438
[2023-08-31 22:44:51,639][26287] High loss value: l:75.7969 pl:0.2529 vl:1.8719 exp_l:0.0000 kl_l:73.6721 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:51,639][26287] KL-divergence is very high: 81698.0234
[2023-08-31 22:44:51,643][26287] KL-divergence is very high: 25988.0820
[2023-08-31 22:44:51,875][26287] KL-divergence is very high: 1499.6023
[2023-08-31 22:44:51,878][26287] High loss value: l:92.9249 pl:-0.0212 vl:2.5940 exp_l:0.0000 kl_l:90.3521 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:51,878][26287] KL-divergence is very high: 64625.8320
[2023-08-31 22:44:51,881][26287] KL-divergence is very high: 25941.8789
[2023-08-31 22:44:51,884][26287] KL-divergence is very high: 10667.2705
[2023-08-31 22:44:51,887][26287] KL-divergence is very high: 10097.0000
[2023-08-31 22:44:51,889][26287] High loss value: l:63.7825 pl:-0.0154 vl:2.3738 exp_l:0.0000 kl_l:61.4242 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:51,889][26287] KL-divergence is very high: 43029.6484
[2023-08-31 22:44:51,892][26287] KL-divergence is very high: 23429.2539
[2023-08-31 22:44:52,097][26287] KL-divergence is very high: 7708.2319
[2023-08-31 22:44:52,100][26287] KL-divergence is very high: 192.3674
[2023-08-31 22:44:52,103][26287] KL-divergence is very high: 49009.0039
[2023-08-31 22:44:52,108][26287] KL-divergence is very high: 1782.4503
[2023-08-31 22:44:52,111][26287] KL-divergence is very high: 200.9737
[2023-08-31 22:44:52,347][26287] KL-divergence is very high: 914.6656
[2023-08-31 22:44:52,350][26287] KL-divergence is very high: 816.0436
[2023-08-31 22:44:52,353][26287] KL-divergence is very high: 2729.9731
[2023-08-31 22:44:52,356][26287] KL-divergence is very high: 262.7354
[2023-08-31 22:44:52,359][26287] High loss value: l:52.1662 pl:-0.0135 vl:2.1107 exp_l:0.0000 kl_l:50.0690 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:52,359][26287] KL-divergence is very high: 227583.2500
[2023-08-31 22:44:52,363][26287] High loss value: l:50.7186 pl:-0.0237 vl:2.2034 exp_l:0.0000 kl_l:48.5389 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:52,363][26287] KL-divergence is very high: 101286.0938
[2023-08-31 22:44:52,366][26287] KL-divergence is very high: 471.0014
[2023-08-31 22:44:52,602][26287] KL-divergence is very high: 100.9730
[2023-08-31 22:44:52,877][26287] KL-divergence is very high: 209.4880
[2023-08-31 22:44:53,086][26287] KL-divergence is very high: 8333.8799
[2023-08-31 22:44:53,089][26287] KL-divergence is very high: 307.0218
[2023-08-31 22:44:53,092][26287] KL-divergence is very high: 222.1371
[2023-08-31 22:44:53,095][26287] KL-divergence is very high: 242.7113
[2023-08-31 22:44:53,098][26287] High loss value: l:57.7504 pl:-0.0400 vl:1.9391 exp_l:0.0000 kl_l:55.8513 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:53,098][26287] KL-divergence is very high: 202894.8438
[2023-08-31 22:44:53,101][26287] KL-divergence is very high: 329.9233
[2023-08-31 22:44:53,104][26287] KL-divergence is very high: 241.7653
[2023-08-31 22:44:53,106][26276] Fps is (10 sec: 16390.6, 60 sec: 15703.3, 300 sec: 15926.3). Total num frames: 78716928. Throughput: 0: 15729.8. Samples: 66793006. Policy #0 lag: (min: 6.0, avg: 6.0, max: 6.0)
[2023-08-31 22:44:53,106][26276] Avg episode reward: [(0, '-22376.849')]
[2023-08-31 22:44:53,107][26288] Updated weights for policy 0, policy_version 153752 (0.0002)
[2023-08-31 22:44:53,338][26287] KL-divergence is very high: 309.3521
[2023-08-31 22:44:53,341][26287] KL-divergence is very high: 514.8367
[2023-08-31 22:44:53,343][26287] KL-divergence is very high: 383.0112
[2023-08-31 22:44:53,349][26287] KL-divergence is very high: 229.6663
[2023-08-31 22:44:53,352][26287] KL-divergence is very high: 513.0887
[2023-08-31 22:44:53,355][26287] KL-divergence is very high: 470.3102
[2023-08-31 22:44:53,571][26287] KL-divergence is very high: 105.8291
[2023-08-31 22:44:53,574][26287] KL-divergence is very high: 288.7001
[2023-08-31 22:44:53,777][26287] KL-divergence is very high: 7944.3711
[2023-08-31 22:44:53,779][26287] KL-divergence is very high: 2350.8105
[2023-08-31 22:44:53,782][26287] KL-divergence is very high: 301.0092
[2023-08-31 22:44:53,785][26287] KL-divergence is very high: 3464.3420
[2023-08-31 22:44:53,787][26287] KL-divergence is very high: 8362.2520
[2023-08-31 22:44:53,790][26287] KL-divergence is very high: 3784.0603
[2023-08-31 22:44:53,793][26287] KL-divergence is very high: 335.8267
[2023-08-31 22:44:53,992][26287] KL-divergence is very high: 412.5286
[2023-08-31 22:44:53,998][26287] KL-divergence is very high: 18158.6875
[2023-08-31 22:44:54,000][26287] KL-divergence is very high: 267.0122
[2023-08-31 22:44:54,003][26287] KL-divergence is very high: 314.3704
[2023-08-31 22:44:54,008][26287] High loss value: l:43.7566 pl:-0.0181 vl:2.1227 exp_l:0.0000 kl_l:41.6519 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:54,008][26287] KL-divergence is very high: 86504.5312
[2023-08-31 22:44:54,208][26287] KL-divergence is very high: 3776.3289
[2023-08-31 22:44:54,211][26287] High loss value: l:118.8390 pl:-0.0117 vl:1.8619 exp_l:0.0000 kl_l:116.9888 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:54,211][26287] KL-divergence is very high: 59046.2656
[2023-08-31 22:44:54,214][26287] KL-divergence is very high: 29468.0703
[2023-08-31 22:44:54,217][26287] KL-divergence is very high: 4599.6431
[2023-08-31 22:44:54,219][26287] KL-divergence is very high: 4364.5396
[2023-08-31 22:44:54,222][26287] High loss value: l:69.2158 pl:-0.0081 vl:1.7184 exp_l:0.0000 kl_l:67.5055 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:54,222][26287] KL-divergence is very high: 40728.9805
[2023-08-31 22:44:54,225][26287] KL-divergence is very high: 8336.0723
[2023-08-31 22:44:54,431][26287] KL-divergence is very high: 4016.1819
[2023-08-31 22:44:54,434][26287] KL-divergence is very high: 10110.8828
[2023-08-31 22:44:54,440][26287] High loss value: l:87.2186 pl:0.1899 vl:1.9246 exp_l:0.0000 kl_l:85.1041 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:54,440][26287] KL-divergence is very high: 57540.6445
[2023-08-31 22:44:54,443][26287] KL-divergence is very high: 22654.6641
[2023-08-31 22:44:54,447][26287] High loss value: l:33.2951 pl:0.0019 vl:1.8313 exp_l:0.0000 kl_l:31.4619 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:54,447][26287] KL-divergence is very high: 48561.0078
[2023-08-31 22:44:54,450][26287] KL-divergence is very high: 113.0020
[2023-08-31 22:44:55,389][26287] KL-divergence is very high: 315.6660
[2023-08-31 22:44:55,392][26287] High loss value: l:33.3171 pl:-0.0344 vl:1.7747 exp_l:0.0000 kl_l:31.5768 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:55,392][26287] KL-divergence is very high: 17005.3652
[2023-08-31 22:44:55,400][26287] KL-divergence is very high: 551.6296
[2023-08-31 22:44:55,403][26287] High loss value: l:361.8223 pl:0.0327 vl:1.6426 exp_l:0.0000 kl_l:360.1471 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:55,403][26287] KL-divergence is very high: 151980.1719
[2023-08-31 22:44:55,406][26288] Updated weights for policy 0, policy_version 153832 (0.0002)
[2023-08-31 22:44:55,643][26287] High loss value: l:206.1193 pl:0.0744 vl:1.2709 exp_l:0.0000 kl_l:204.7741 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:55,643][26287] KL-divergence is very high: 31788.3379
[2023-08-31 22:44:55,647][26287] High loss value: l:269.5359 pl:0.0246 vl:1.1453 exp_l:0.0000 kl_l:268.3661 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:55,647][26287] KL-divergence is very high: 38297.8047
[2023-08-31 22:44:55,651][26287] KL-divergence is very high: 5959.7554
[2023-08-31 22:44:55,654][26287] High loss value: l:279.6421 pl:0.0043 vl:1.3020 exp_l:0.0000 kl_l:278.3358 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:55,654][26287] KL-divergence is very high: 45469.9844
[2023-08-31 22:44:55,657][26287] High loss value: l:416.0177 pl:0.0098 vl:1.1859 exp_l:0.0000 kl_l:414.8220 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:55,657][26287] KL-divergence is very high: 68096.2891
[2023-08-31 22:44:55,661][26287] High loss value: l:282.8423 pl:0.0338 vl:1.0740 exp_l:0.0000 kl_l:281.7345 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:55,661][26287] KL-divergence is very high: 40786.1445
[2023-08-31 22:44:55,664][26287] KL-divergence is very high: 12417.7041
[2023-08-31 22:44:55,900][26287] KL-divergence is very high: 287.0431
[2023-08-31 22:44:55,903][26287] KL-divergence is very high: 420.0800
[2023-08-31 22:44:55,906][26287] KL-divergence is very high: 171.1488
[2023-08-31 22:44:55,909][26287] KL-divergence is very high: 425.5670
[2023-08-31 22:44:55,912][26287] KL-divergence is very high: 149.1065
[2023-08-31 22:44:55,918][26287] KL-divergence is very high: 173.1745
[2023-08-31 22:44:56,119][26287] KL-divergence is very high: 589.8942
[2023-08-31 22:44:56,121][26287] KL-divergence is very high: 610.5759
[2023-08-31 22:44:56,124][26287] KL-divergence is very high: 107.9070
[2023-08-31 22:44:56,126][26287] KL-divergence is very high: 344.1409
[2023-08-31 22:44:56,129][26287] KL-divergence is very high: 581.2414
[2023-08-31 22:44:56,132][26287] KL-divergence is very high: 930.2944
[2023-08-31 22:44:56,366][26287] KL-divergence is very high: 15867.5820
[2023-08-31 22:44:56,368][26287] KL-divergence is very high: 1371.6578
[2023-08-31 22:44:56,374][26287] High loss value: l:49.1137 pl:-0.0238 vl:0.8905 exp_l:0.0000 kl_l:48.2469 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:56,374][26287] KL-divergence is very high: 47758.7930
[2023-08-31 22:44:56,377][26287] High loss value: l:57.1082 pl:-0.0324 vl:0.8684 exp_l:0.0000 kl_l:56.2722 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:56,378][26287] KL-divergence is very high: 44764.5703
[2023-08-31 22:44:56,381][26287] KL-divergence is very high: 2558.8564
[2023-08-31 22:44:56,384][26287] KL-divergence is very high: 183.9593
[2023-08-31 22:44:56,590][26287] KL-divergence is very high: 39497.3398
[2023-08-31 22:44:56,593][26287] KL-divergence is very high: 1961.2273
[2023-08-31 22:44:56,596][26287] KL-divergence is very high: 2963.3486
[2023-08-31 22:44:56,602][26287] High loss value: l:53.5160 pl:0.0129 vl:1.9310 exp_l:0.0000 kl_l:51.5722 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:56,602][26287] KL-divergence is very high: 75111.0469
[2023-08-31 22:44:56,606][26287] KL-divergence is very high: 16615.9082
[2023-08-31 22:44:56,608][26287] High loss value: l:34.0962 pl:0.0749 vl:2.1627 exp_l:0.0000 kl_l:31.8585 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:56,609][26287] KL-divergence is very high: 21225.7949
[2023-08-31 22:44:56,820][26287] KL-divergence is very high: 187.7595
[2023-08-31 22:44:56,825][26287] KL-divergence is very high: 25916.1055
[2023-08-31 22:44:57,245][26287] KL-divergence is very high: 178.2919
[2023-08-31 22:44:57,247][26287] KL-divergence is very high: 300.1225
[2023-08-31 22:44:57,250][26287] KL-divergence is very high: 175.5325
[2023-08-31 22:44:57,259][26287] KL-divergence is very high: 152.4787
[2023-08-31 22:44:57,467][26287] KL-divergence is very high: 125.1575
[2023-08-31 22:44:57,941][26287] KL-divergence is very high: 131.2486
[2023-08-31 22:44:57,944][26287] KL-divergence is very high: 890.0408
[2023-08-31 22:44:57,952][26287] KL-divergence is very high: 373.3147
[2023-08-31 22:44:57,955][26287] KL-divergence is very high: 6752.2100
[2023-08-31 22:44:57,957][26288] Updated weights for policy 0, policy_version 153912 (0.0002)
[2023-08-31 22:44:58,110][26276] Fps is (10 sec: 16378.3, 60 sec: 15836.9, 300 sec: 15939.8). Total num frames: 78802944. Throughput: 0: 16140.3. Samples: 66845257. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:44:58,110][26276] Avg episode reward: [(0, '-89552.984')]
[2023-08-31 22:44:58,178][26287] KL-divergence is very high: 1984.6200
[2023-08-31 22:44:58,181][26287] KL-divergence is very high: 608.4322
[2023-08-31 22:44:58,184][26287] KL-divergence is very high: 1091.2666
[2023-08-31 22:44:58,186][26287] KL-divergence is very high: 1474.4099
[2023-08-31 22:44:58,189][26287] KL-divergence is very high: 9539.4736
[2023-08-31 22:44:58,192][26287] KL-divergence is very high: 707.8047
[2023-08-31 22:44:58,195][26287] KL-divergence is very high: 2496.7119
[2023-08-31 22:44:58,410][26287] KL-divergence is very high: 12754.7598
[2023-08-31 22:44:58,413][26287] KL-divergence is very high: 4773.2798
[2023-08-31 22:44:58,415][26287] KL-divergence is very high: 633.9029
[2023-08-31 22:44:58,418][26287] KL-divergence is very high: 6007.8955
[2023-08-31 22:44:58,421][26287] KL-divergence is very high: 7501.6260
[2023-08-31 22:44:58,424][26287] KL-divergence is very high: 1757.8401
[2023-08-31 22:44:58,426][26287] KL-divergence is very high: 2100.6904
[2023-08-31 22:44:58,668][26287] KL-divergence is very high: 3178.3235
[2023-08-31 22:44:58,671][26287] KL-divergence is very high: 231.5438
[2023-08-31 22:44:58,674][26287] KL-divergence is very high: 520.7794
[2023-08-31 22:44:58,677][26287] KL-divergence is very high: 1218.0492
[2023-08-31 22:44:58,681][26287] KL-divergence is very high: 3702.6960
[2023-08-31 22:44:58,684][26287] KL-divergence is very high: 4387.8071
[2023-08-31 22:44:58,687][26287] KL-divergence is very high: 530.5630
[2023-08-31 22:44:58,921][26287] KL-divergence is very high: 20430.9824
[2023-08-31 22:44:58,924][26287] High loss value: l:269.3089 pl:0.0891 vl:1.3091 exp_l:0.0000 kl_l:267.9108 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:58,924][26287] KL-divergence is very high: 122847.1875
[2023-08-31 22:44:58,927][26287] High loss value: l:178.9711 pl:-0.0034 vl:2.0160 exp_l:0.0000 kl_l:176.9585 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:58,928][26287] KL-divergence is very high: 57674.8867
[2023-08-31 22:44:58,931][26287] High loss value: l:35.7713 pl:0.0510 vl:0.8370 exp_l:0.0000 kl_l:34.8832 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:58,931][26287] KL-divergence is very high: 39668.3555
[2023-08-31 22:44:58,934][26287] KL-divergence is very high: 17172.6758
[2023-08-31 22:44:58,937][26287] High loss value: l:35.9307 pl:0.0613 vl:1.3280 exp_l:0.0000 kl_l:34.5413 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:58,937][26287] KL-divergence is very high: 23738.0664
[2023-08-31 22:44:58,940][26287] High loss value: l:189.9594 pl:-0.0099 vl:2.1606 exp_l:0.0000 kl_l:187.8086 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:58,940][26287] KL-divergence is very high: 64293.8125
[2023-08-31 22:44:59,138][26287] High loss value: l:279.7562 pl:0.0234 vl:2.8902 exp_l:0.0000 kl_l:276.8426 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:59,139][26287] KL-divergence is very high: 93446.4531
[2023-08-31 22:44:59,142][26287] High loss value: l:95.0669 pl:-0.0126 vl:1.5433 exp_l:0.0000 kl_l:93.5361 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:59,142][26287] KL-divergence is very high: 130255.1094
[2023-08-31 22:44:59,145][26287] KL-divergence is very high: 912.5293
[2023-08-31 22:44:59,148][26287] High loss value: l:251.0194 pl:-0.0036 vl:2.3688 exp_l:0.0000 kl_l:248.6542 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:59,148][26287] KL-divergence is very high: 70800.4297
[2023-08-31 22:44:59,151][26287] High loss value: l:355.8983 pl:-0.0142 vl:2.9743 exp_l:0.0000 kl_l:352.9382 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:59,151][26287] KL-divergence is very high: 98618.1875
[2023-08-31 22:44:59,154][26287] KL-divergence is very high: 26732.3359
[2023-08-31 22:44:59,157][26287] KL-divergence is very high: 2056.5229
[2023-08-31 22:44:59,357][26287] High loss value: l:81.3628 pl:0.0845 vl:2.7808 exp_l:0.0000 kl_l:78.4975 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:59,357][26287] KL-divergence is very high: 66219.5312
[2023-08-31 22:44:59,360][26287] High loss value: l:284.9129 pl:0.0925 vl:2.4680 exp_l:0.0000 kl_l:282.3525 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:59,360][26287] KL-divergence is very high: 117290.1719
[2023-08-31 22:44:59,364][26287] High loss value: l:215.4994 pl:0.0581 vl:2.1427 exp_l:0.0000 kl_l:213.2986 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:59,364][26287] KL-divergence is very high: 68305.8828
[2023-08-31 22:44:59,367][26287] KL-divergence is very high: 10792.3037
[2023-08-31 22:44:59,369][26287] High loss value: l:53.0572 pl:0.0596 vl:2.7051 exp_l:0.0000 kl_l:50.2925 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:59,370][26287] KL-divergence is very high: 39427.5508
[2023-08-31 22:44:59,373][26287] High loss value: l:87.6788 pl:0.0397 vl:2.4026 exp_l:0.0000 kl_l:85.2364 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:59,373][26287] KL-divergence is very high: 31903.5215
[2023-08-31 22:44:59,376][26287] High loss value: l:100.7108 pl:0.0201 vl:2.0869 exp_l:0.0000 kl_l:98.6039 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:44:59,376][26287] KL-divergence is very high: 22775.9297
[2023-08-31 22:44:59,611][26287] KL-divergence is very high: 188.7280
[2023-08-31 22:44:59,618][26287] KL-divergence is very high: 7578.7466
[2023-08-31 22:44:59,621][26287] KL-divergence is very high: 645.1638
[2023-08-31 22:44:59,626][26287] KL-divergence is very high: 345.4680
[2023-08-31 22:45:00,134][26287] KL-divergence is very high: 1863.3517
[2023-08-31 22:45:00,144][26287] High loss value: l:34.1883 pl:0.0387 vl:0.5788 exp_l:0.0000 kl_l:33.5708 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:45:00,144][26287] KL-divergence is very high: 66566.3125
[2023-08-31 22:45:00,371][26287] KL-divergence is very high: 8532.4385
[2023-08-31 22:45:00,374][26287] KL-divergence is very high: 13877.9688
[2023-08-31 22:45:00,376][26287] High loss value: l:49.6515 pl:0.1704 vl:0.7907 exp_l:0.0000 kl_l:48.6904 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:45:00,377][26287] KL-divergence is very high: 13042.1143
[2023-08-31 22:45:00,380][26287] KL-divergence is very high: 2374.9102
[2023-08-31 22:45:00,383][26287] KL-divergence is very high: 10614.4814
[2023-08-31 22:45:00,386][26287] High loss value: l:31.0425 pl:0.1872 vl:0.5011 exp_l:0.0000 kl_l:30.3542 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:45:00,386][26287] KL-divergence is very high: 21357.1445
[2023-08-31 22:45:00,390][26287] High loss value: l:74.0448 pl:0.2252 vl:0.8052 exp_l:0.0000 kl_l:73.0144 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:45:00,390][26287] KL-divergence is very high: 24860.6836
[2023-08-31 22:45:00,393][26288] Updated weights for policy 0, policy_version 153992 (0.0002)
[2023-08-31 22:45:00,623][26287] High loss value: l:34.1443 pl:0.0932 vl:0.9555 exp_l:0.0000 kl_l:33.0956 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:45:00,623][26287] KL-divergence is very high: 9499.6582
[2023-08-31 22:45:00,627][26287] High loss value: l:68.6391 pl:0.1047 vl:0.7658 exp_l:0.0000 kl_l:67.7687 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:45:00,627][26287] KL-divergence is very high: 20217.4004
[2023-08-31 22:45:00,630][26287] High loss value: l:61.6017 pl:0.1390 vl:0.7776 exp_l:0.0000 kl_l:60.6851 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:45:00,630][26287] KL-divergence is very high: 22966.5137
[2023-08-31 22:45:00,633][26287] KL-divergence is very high: 7008.4531
[2023-08-31 22:45:00,636][26287] KL-divergence is very high: 7720.6553
[2023-08-31 22:45:00,638][26287] High loss value: l:63.5446 pl:0.1101 vl:0.7386 exp_l:0.0000 kl_l:62.6959 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:45:00,639][26287] KL-divergence is very high: 18961.7266
[2023-08-31 22:45:00,642][26287] High loss value: l:78.4873 pl:0.1666 vl:0.7185 exp_l:0.0000 kl_l:77.6022 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:45:00,642][26287] KL-divergence is very high: 23272.1523
[2023-08-31 22:45:00,887][26287] KL-divergence is very high: 137.5835
[2023-08-31 22:45:00,890][26287] KL-divergence is very high: 262.9092
[2023-08-31 22:45:00,893][26287] KL-divergence is very high: 872.0078
[2023-08-31 22:45:00,896][26287] KL-divergence is very high: 7533.2905
[2023-08-31 22:45:00,899][26287] KL-divergence is very high: 742.9842
[2023-08-31 22:45:00,901][26287] KL-divergence is very high: 175.7072
[2023-08-31 22:45:00,905][26287] KL-divergence is very high: 16284.1377
[2023-08-31 22:45:01,148][26287] KL-divergence is very high: 13127.0049
[2023-08-31 22:45:01,398][26287] KL-divergence is very high: 1115.4781
[2023-08-31 22:45:01,409][26287] KL-divergence is very high: 976.0221
[2023-08-31 22:45:01,631][26287] KL-divergence is very high: 176.6707
[2023-08-31 22:45:02,152][26287] KL-divergence is very high: 218.0117
[2023-08-31 22:45:02,155][26287] KL-divergence is very high: 101.0232
[2023-08-31 22:45:02,165][26287] KL-divergence is very high: 3099.2180
[2023-08-31 22:45:02,168][26287] KL-divergence is very high: 730.7756
[2023-08-31 22:45:02,395][26287] KL-divergence is very high: 680.3615
[2023-08-31 22:45:02,404][26287] KL-divergence is very high: 207.6194
[2023-08-31 22:45:02,407][26287] KL-divergence is very high: 191.1089
[2023-08-31 22:45:02,935][26288] Updated weights for policy 0, policy_version 154072 (0.0002)
[2023-08-31 22:45:03,109][26276] Fps is (10 sec: 16788.1, 60 sec: 15837.8, 300 sec: 15953.8). Total num frames: 78884864. Throughput: 0: 16343.7. Samples: 66943455. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:45:03,109][26276] Avg episode reward: [(0, '-89552.984')]
[2023-08-31 22:45:03,387][26287] KL-divergence is very high: 1761.5702
[2023-08-31 22:45:05,447][26288] Updated weights for policy 0, policy_version 154152 (0.0002)
[2023-08-31 22:45:06,821][26287] KL-divergence is very high: 624.9044
[2023-08-31 22:45:07,062][26287] KL-divergence is very high: 175.5620
[2023-08-31 22:45:07,065][26287] KL-divergence is very high: 161.1816
[2023-08-31 22:45:07,332][26287] KL-divergence is very high: 894.7413
[2023-08-31 22:45:07,335][26287] KL-divergence is very high: 408.8610
[2023-08-31 22:45:07,337][26287] KL-divergence is very high: 1308.0334
[2023-08-31 22:45:07,340][26287] KL-divergence is very high: 862.6404
[2023-08-31 22:45:07,343][26287] KL-divergence is very high: 2126.1152
[2023-08-31 22:45:07,346][26287] KL-divergence is very high: 797.9382
[2023-08-31 22:45:07,349][26287] KL-divergence is very high: 5509.3735
[2023-08-31 22:45:07,839][26287] KL-divergence is very high: 1060.6294
[2023-08-31 22:45:07,842][26287] KL-divergence is very high: 1171.4517
[2023-08-31 22:45:07,850][26287] KL-divergence is very high: 3794.8921
[2023-08-31 22:45:08,066][26287] KL-divergence is very high: 7448.8325
[2023-08-31 22:45:08,069][26287] KL-divergence is very high: 283.1043
[2023-08-31 22:45:08,077][26288] Updated weights for policy 0, policy_version 154232 (0.0002)
[2023-08-31 22:45:08,109][26276] Fps is (10 sec: 16385.2, 60 sec: 16042.9, 300 sec: 15953.8). Total num frames: 78966784. Throughput: 0: 16516.4. Samples: 67043197. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:45:08,110][26276] Avg episode reward: [(0, '-133146.441')]
[2023-08-31 22:45:10,541][26288] Updated weights for policy 0, policy_version 154312 (0.0002)
[2023-08-31 22:45:11,193][26287] KL-divergence is very high: 404.4670
[2023-08-31 22:45:11,411][26287] KL-divergence is very high: 156.8201
[2023-08-31 22:45:11,664][26287] KL-divergence is very high: 198.2131
[2023-08-31 22:45:11,675][26287] KL-divergence is very high: 102.7509
[2023-08-31 22:45:11,883][26287] KL-divergence is very high: 5842.5757
[2023-08-31 22:45:12,900][26288] Updated weights for policy 0, policy_version 154392 (0.0002)
[2023-08-31 22:45:13,109][26276] Fps is (10 sec: 16384.0, 60 sec: 16315.7, 300 sec: 15967.5). Total num frames: 79048704. Throughput: 0: 16392.8. Samples: 67088507. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:45:13,110][26276] Avg episode reward: [(0, '-133146.441')]
[2023-08-31 22:45:15,360][26288] Updated weights for policy 0, policy_version 154472 (0.0002)
[2023-08-31 22:45:17,721][26287] KL-divergence is very high: 844.4255
[2023-08-31 22:45:17,968][26288] Updated weights for policy 0, policy_version 154552 (0.0002)
[2023-08-31 22:45:18,110][26276] Fps is (10 sec: 16382.9, 60 sec: 16314.8, 300 sec: 15953.3). Total num frames: 79130624. Throughput: 0: 16568.0. Samples: 67191345. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:45:18,110][26276] Avg episode reward: [(0, '-125249.435')]
[2023-08-31 22:45:20,360][26288] Updated weights for policy 0, policy_version 154632 (0.0002)
[2023-08-31 22:45:22,710][26288] Updated weights for policy 0, policy_version 154712 (0.0002)
[2023-08-31 22:45:22,983][26287] KL-divergence is very high: 180.9140
[2023-08-31 22:45:23,107][26276] Fps is (10 sec: 16797.7, 60 sec: 16521.5, 300 sec: 15981.8). Total num frames: 79216640. Throughput: 0: 16524.2. Samples: 67290269. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:45:23,107][26276] Avg episode reward: [(0, '-125249.435')]
[2023-08-31 22:45:23,236][26287] KL-divergence is very high: 424.3116
[2023-08-31 22:45:25,195][26288] Updated weights for policy 0, policy_version 154792 (0.0002)
[2023-08-31 22:45:27,625][26287] KL-divergence is very high: 191.9220
[2023-08-31 22:45:27,628][26287] KL-divergence is very high: 113.6198
[2023-08-31 22:45:27,875][26287] KL-divergence is very high: 170.4524
[2023-08-31 22:45:27,883][26288] Updated weights for policy 0, policy_version 154872 (0.0002)
[2023-08-31 22:45:28,109][26276] Fps is (10 sec: 16385.8, 60 sec: 16383.5, 300 sec: 15967.3). Total num frames: 79294464. Throughput: 0: 16604.1. Samples: 67340122. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:45:28,109][26276] Avg episode reward: [(0, '-124563.300')]
[2023-08-31 22:45:28,365][26287] KL-divergence is very high: 167.3870
[2023-08-31 22:45:29,984][26287] KL-divergence is very high: 117.2126
[2023-08-31 22:45:29,992][26287] KL-divergence is very high: 190.4074
[2023-08-31 22:45:29,995][26287] KL-divergence is very high: 239.5894
[2023-08-31 22:45:30,249][26288] Updated weights for policy 0, policy_version 154952 (0.0002)
[2023-08-31 22:45:31,422][26287] KL-divergence is very high: 157.4642
[2023-08-31 22:45:32,357][26287] KL-divergence is very high: 634.5045
[2023-08-31 22:45:32,587][26288] Updated weights for policy 0, policy_version 155032 (0.0002)
[2023-08-31 22:45:33,106][26276] Fps is (10 sec: 16795.0, 60 sec: 16590.0, 300 sec: 16009.3). Total num frames: 79384576. Throughput: 0: 16498.9. Samples: 67438256. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:45:33,106][26276] Avg episode reward: [(0, '-124563.300')]
[2023-08-31 22:45:35,186][26288] Updated weights for policy 0, policy_version 155112 (0.0002)
[2023-08-31 22:45:35,655][26287] KL-divergence is very high: 2334.2278
[2023-08-31 22:45:35,657][26287] KL-divergence is very high: 198.4898
[2023-08-31 22:45:35,908][26287] KL-divergence is very high: 179.1977
[2023-08-31 22:45:35,911][26287] KL-divergence is very high: 308.6716
[2023-08-31 22:45:35,919][26287] KL-divergence is very high: 232.4813
[2023-08-31 22:45:35,922][26287] KL-divergence is very high: 206.0597
[2023-08-31 22:45:37,787][26287] KL-divergence is very high: 292.2965
[2023-08-31 22:45:37,797][26288] Updated weights for policy 0, policy_version 155192 (0.0002)
[2023-08-31 22:45:38,007][26287] KL-divergence is very high: 246.4935
[2023-08-31 22:45:38,010][26287] KL-divergence is very high: 118.6526
[2023-08-31 22:45:38,106][26276] Fps is (10 sec: 16798.6, 60 sec: 16520.5, 300 sec: 15995.3). Total num frames: 79462400. Throughput: 0: 16467.7. Samples: 67534052. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:45:38,106][26276] Avg episode reward: [(0, '-135970.653')]
[2023-08-31 22:45:39,576][26287] KL-divergence is very high: 120.1876
[2023-08-31 22:45:39,806][26287] KL-divergence is very high: 158.9330
[2023-08-31 22:45:39,808][26287] KL-divergence is very high: 188.9200
[2023-08-31 22:45:40,388][26288] Updated weights for policy 0, policy_version 155272 (0.0002)
[2023-08-31 22:45:43,110][26276] Fps is (10 sec: 15149.0, 60 sec: 16384.0, 300 sec: 15981.6). Total num frames: 79536128. Throughput: 0: 16388.0. Samples: 67582715. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:45:43,111][26276] Avg episode reward: [(0, '-135970.653')]
[2023-08-31 22:45:43,113][26287] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000155344_79536128.pth...
[2023-08-31 22:45:43,114][26287] Removing /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000149112_76345344.pth
[2023-08-31 22:45:43,153][26288] Updated weights for policy 0, policy_version 155352 (0.0002)
[2023-08-31 22:45:45,543][26288] Updated weights for policy 0, policy_version 155432 (0.0002)
[2023-08-31 22:45:48,106][26276] Fps is (10 sec: 15564.1, 60 sec: 16315.8, 300 sec: 15981.8). Total num frames: 79618048. Throughput: 0: 16344.6. Samples: 67678916. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:45:48,108][26276] Avg episode reward: [(0, '-149096.757')]
[2023-08-31 22:45:48,259][26288] Updated weights for policy 0, policy_version 155512 (0.0002)
[2023-08-31 22:45:50,623][26288] Updated weights for policy 0, policy_version 155592 (0.0002)
[2023-08-31 22:45:52,956][26288] Updated weights for policy 0, policy_version 155672 (0.0002)
[2023-08-31 22:45:53,108][26276] Fps is (10 sec: 16796.2, 60 sec: 16451.6, 300 sec: 16009.2). Total num frames: 79704064. Throughput: 0: 16308.9. Samples: 67777084. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:45:53,109][26276] Avg episode reward: [(0, '-149096.757')]
[2023-08-31 22:45:55,361][26288] Updated weights for policy 0, policy_version 155752 (0.0002)
[2023-08-31 22:45:58,002][26288] Updated weights for policy 0, policy_version 155832 (0.0002)
[2023-08-31 22:45:58,105][26276] Fps is (10 sec: 16795.3, 60 sec: 16385.3, 300 sec: 15995.8). Total num frames: 79785984. Throughput: 0: 16463.6. Samples: 67829304. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:45:58,106][26276] Avg episode reward: [(0, '-95434.121')]
[2023-08-31 22:46:00,394][26288] Updated weights for policy 0, policy_version 155912 (0.0002)
[2023-08-31 22:46:02,782][26288] Updated weights for policy 0, policy_version 155992 (0.0002)
[2023-08-31 22:46:03,107][26276] Fps is (10 sec: 16796.0, 60 sec: 16452.9, 300 sec: 16023.2). Total num frames: 79872000. Throughput: 0: 16351.9. Samples: 67927132. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:46:03,107][26276] Avg episode reward: [(0, '-95434.121')]
[2023-08-31 22:46:03,975][26287] KL-divergence is very high: 139.8593
[2023-08-31 22:46:04,253][26287] KL-divergence is very high: 706.0817
[2023-08-31 22:46:05,227][26287] KL-divergence is very high: 366.9034
[2023-08-31 22:46:05,237][26287] KL-divergence is very high: 9493.1377
[2023-08-31 22:46:05,240][26288] Updated weights for policy 0, policy_version 156072 (0.0002)
[2023-08-31 22:46:05,445][26287] KL-divergence is very high: 8990.1182
[2023-08-31 22:46:05,447][26287] KL-divergence is very high: 15399.1055
[2023-08-31 22:46:05,452][26287] KL-divergence is very high: 750.7176
[2023-08-31 22:46:05,455][26287] KL-divergence is very high: 4679.6133
[2023-08-31 22:46:05,458][26287] KL-divergence is very high: 5449.9399
[2023-08-31 22:46:05,699][26287] KL-divergence is very high: 451.4416
[2023-08-31 22:46:05,702][26287] KL-divergence is very high: 4470.3013
[2023-08-31 22:46:05,705][26287] KL-divergence is very high: 2648.7976
[2023-08-31 22:46:05,708][26287] KL-divergence is very high: 124.4257
[2023-08-31 22:46:05,711][26287] KL-divergence is very high: 173.1158
[2023-08-31 22:46:05,714][26287] KL-divergence is very high: 5222.8950
[2023-08-31 22:46:05,717][26287] KL-divergence is very high: 5516.3218
[2023-08-31 22:46:06,075][26287] KL-divergence is very high: 153.6770
[2023-08-31 22:46:06,083][26287] KL-divergence is very high: 2078.6284
[2023-08-31 22:46:06,486][26287] KL-divergence is very high: 153.8433
[2023-08-31 22:46:07,228][26287] KL-divergence is very high: 177.3233
[2023-08-31 22:46:07,238][26287] KL-divergence is very high: 264.0676
[2023-08-31 22:46:07,449][26287] KL-divergence is very high: 124.2525
[2023-08-31 22:46:07,452][26287] KL-divergence is very high: 727.7716
[2023-08-31 22:46:07,454][26287] KL-divergence is very high: 240.3440
[2023-08-31 22:46:07,459][26287] KL-divergence is very high: 150.0844
[2023-08-31 22:46:07,462][26287] KL-divergence is very high: 771.8932
[2023-08-31 22:46:07,465][26287] KL-divergence is very high: 419.1336
[2023-08-31 22:46:07,906][26287] KL-divergence is very high: 243.1788
[2023-08-31 22:46:07,916][26287] KL-divergence is very high: 5643.2368
[2023-08-31 22:46:07,919][26287] KL-divergence is very high: 3309.3872
[2023-08-31 22:46:07,922][26287] KL-divergence is very high: 544.7006
[2023-08-31 22:46:07,924][26288] Updated weights for policy 0, policy_version 156152 (0.0002)
[2023-08-31 22:46:08,106][26276] Fps is (10 sec: 16383.0, 60 sec: 16384.9, 300 sec: 16009.5). Total num frames: 79949824. Throughput: 0: 16286.3. Samples: 68023140. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[2023-08-31 22:46:08,106][26276] Avg episode reward: [(0, '-47422.552')]
[2023-08-31 22:46:08,137][26287] KL-divergence is very high: 420.3626
[2023-08-31 22:46:08,142][26287] KL-divergence is very high: 2207.2354
[2023-08-31 22:46:08,380][26287] KL-divergence is very high: 955.6627
[2023-08-31 22:46:08,384][26287] KL-divergence is very high: 588.2857
[2023-08-31 22:46:08,391][26287] KL-divergence is very high: 3098.8760
[2023-08-31 22:46:08,394][26287] KL-divergence is very high: 1949.6829
[2023-08-31 22:46:09,571][26287] KL-divergence is very high: 551.1346
[2023-08-31 22:46:09,579][26287] KL-divergence is very high: 615.3514
[2023-08-31 22:46:09,582][26287] KL-divergence is very high: 385.7292
[2023-08-31 22:46:10,346][26288] Updated weights for policy 0, policy_version 156232 (0.0002)
[2023-08-31 22:46:10,553][26287] KL-divergence is very high: 447.5352
[2023-08-31 22:46:10,556][26287] KL-divergence is very high: 428.9528
[2023-08-31 22:46:10,559][26287] KL-divergence is very high: 132.8592
[2023-08-31 22:46:10,562][26287] KL-divergence is very high: 251.0448
[2023-08-31 22:46:10,565][26287] KL-divergence is very high: 719.4878
[2023-08-31 22:46:10,804][26287] KL-divergence is very high: 2100.1863
[2023-08-31 22:46:11,537][26287] KL-divergence is very high: 396.0324
[2023-08-31 22:46:11,540][26287] KL-divergence is very high: 1267.5031
[2023-08-31 22:46:11,775][26287] KL-divergence is very high: 516.4596
[2023-08-31 22:46:11,778][26287] KL-divergence is very high: 835.1183
[2023-08-31 22:46:11,780][26287] KL-divergence is very high: 757.5630
[2023-08-31 22:46:11,783][26287] KL-divergence is very high: 526.5367
[2023-08-31 22:46:11,786][26287] KL-divergence is very high: 799.3777
[2023-08-31 22:46:11,788][26287] KL-divergence is very high: 412.1009
[2023-08-31 22:46:11,791][26287] KL-divergence is very high: 223.1739
[2023-08-31 22:46:12,001][26287] KL-divergence is very high: 325.6134
[2023-08-31 22:46:12,009][26287] KL-divergence is very high: 2815.9338
[2023-08-31 22:46:12,012][26287] KL-divergence is very high: 1787.7389
[2023-08-31 22:46:12,016][26287] KL-divergence is very high: 137.3224
[2023-08-31 22:46:12,769][26287] KL-divergence is very high: 234.4976
[2023-08-31 22:46:12,774][26288] Updated weights for policy 0, policy_version 156312 (0.0002)
[2023-08-31 22:46:13,107][26276] Fps is (10 sec: 16384.7, 60 sec: 16453.0, 300 sec: 16036.8). Total num frames: 80035840. Throughput: 0: 16326.9. Samples: 68074795. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[2023-08-31 22:46:13,107][26276] Avg episode reward: [(0, '-47422.552')]
[2023-08-31 22:46:14,230][26287] KL-divergence is very high: 841.0240
[2023-08-31 22:46:14,240][26287] KL-divergence is very high: 257.8376
[2023-08-31 22:46:14,457][26287] KL-divergence is very high: 231.4235
[2023-08-31 22:46:14,460][26287] KL-divergence is very high: 209.9509
[2023-08-31 22:46:14,468][26287] KL-divergence is very high: 793.2566
[2023-08-31 22:46:14,471][26287] KL-divergence is very high: 433.6951
[2023-08-31 22:46:14,474][26287] KL-divergence is very high: 458.5193
[2023-08-31 22:46:14,693][26287] KL-divergence is very high: 356.1858
[2023-08-31 22:46:15,239][26288] Updated weights for policy 0, policy_version 156392 (0.0002)
[2023-08-31 22:46:16,481][26287] KL-divergence is very high: 1196.1675
[2023-08-31 22:46:16,700][26287] KL-divergence is very high: 190.9226
[2023-08-31 22:46:16,706][26287] KL-divergence is very high: 256.5661
[2023-08-31 22:46:16,709][26287] KL-divergence is very high: 266.0869
[2023-08-31 22:46:16,712][26287] KL-divergence is very high: 1832.6584
[2023-08-31 22:46:16,953][26287] KL-divergence is very high: 282.4662
[2023-08-31 22:46:16,956][26287] KL-divergence is very high: 170.9759
[2023-08-31 22:46:16,962][26287] KL-divergence is very high: 897.6602
[2023-08-31 22:46:16,964][26287] KL-divergence is very high: 623.5344
[2023-08-31 22:46:17,889][26288] Updated weights for policy 0, policy_version 156472 (0.0002)
[2023-08-31 22:46:18,107][26276] Fps is (10 sec: 16791.2, 60 sec: 16453.0, 300 sec: 16036.8). Total num frames: 80117760. Throughput: 0: 16271.3. Samples: 68170488. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[2023-08-31 22:46:18,108][26276] Avg episode reward: [(0, '-41738.305')]
[2023-08-31 22:46:18,337][26287] KL-divergence is very high: 174.8387
[2023-08-31 22:46:18,547][26287] KL-divergence is very high: 253.0205
[2023-08-31 22:46:18,549][26287] KL-divergence is very high: 480.0422
[2023-08-31 22:46:18,552][26287] KL-divergence is very high: 109.4278
[2023-08-31 22:46:18,557][26287] KL-divergence is very high: 141.3851
[2023-08-31 22:46:18,559][26287] KL-divergence is very high: 168.9150
[2023-08-31 22:46:18,562][26287] KL-divergence is very high: 214.1659
[2023-08-31 22:46:20,278][26288] Updated weights for policy 0, policy_version 156552 (0.0002)
[2023-08-31 22:46:22,672][26288] Updated weights for policy 0, policy_version 156632 (0.0002)
[2023-08-31 22:46:23,106][26276] Fps is (10 sec: 16385.3, 60 sec: 16384.3, 300 sec: 16051.2). Total num frames: 80199680. Throughput: 0: 16445.2. Samples: 68274082. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[2023-08-31 22:46:23,106][26276] Avg episode reward: [(0, '-41738.305')]
[2023-08-31 22:46:25,080][26288] Updated weights for policy 0, policy_version 156712 (0.0002)
[2023-08-31 22:46:26,033][26287] KL-divergence is very high: 161.0927
[2023-08-31 22:46:26,276][26287] KL-divergence is very high: 405.9740
[2023-08-31 22:46:26,279][26287] KL-divergence is very high: 485.6931
[2023-08-31 22:46:26,282][26287] KL-divergence is very high: 300.0086
[2023-08-31 22:46:26,285][26287] KL-divergence is very high: 244.9763
[2023-08-31 22:46:26,288][26287] KL-divergence is very high: 645.9631
[2023-08-31 22:46:26,292][26287] KL-divergence is very high: 895.3748
[2023-08-31 22:46:26,295][26287] KL-divergence is very high: 995.8129
[2023-08-31 22:46:26,519][26287] KL-divergence is very high: 133.0372
[2023-08-31 22:46:26,527][26287] KL-divergence is very high: 266.9727
[2023-08-31 22:46:26,530][26287] KL-divergence is very high: 210.7973
[2023-08-31 22:46:26,753][26287] KL-divergence is very high: 102.8246
[2023-08-31 22:46:27,755][26287] KL-divergence is very high: 156.5334
[2023-08-31 22:46:27,757][26287] KL-divergence is very high: 123.8523
[2023-08-31 22:46:27,763][26288] Updated weights for policy 0, policy_version 156792 (0.0002)
[2023-08-31 22:46:28,106][26276] Fps is (10 sec: 16386.7, 60 sec: 16453.1, 300 sec: 16050.9). Total num frames: 80281600. Throughput: 0: 16505.6. Samples: 68325397. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[2023-08-31 22:46:28,106][26276] Avg episode reward: [(0, '-46649.734')]
[2023-08-31 22:46:28,278][26287] KL-divergence is very high: 122.2225
[2023-08-31 22:46:28,287][26287] KL-divergence is very high: 106.3866
[2023-08-31 22:46:30,296][26288] Updated weights for policy 0, policy_version 156872 (0.0002)
[2023-08-31 22:46:32,249][26287] KL-divergence is very high: 385.4008
[2023-08-31 22:46:32,252][26287] KL-divergence is very high: 203.2396
[2023-08-31 22:46:32,494][26287] KL-divergence is very high: 255.9383
[2023-08-31 22:46:32,793][26288] Updated weights for policy 0, policy_version 156952 (0.0002)
[2023-08-31 22:46:33,107][26276] Fps is (10 sec: 16382.5, 60 sec: 16315.5, 300 sec: 16064.8). Total num frames: 80363520. Throughput: 0: 16476.7. Samples: 68420371. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[2023-08-31 22:46:33,107][26276] Avg episode reward: [(0, '-46649.734')]
[2023-08-31 22:46:35,185][26288] Updated weights for policy 0, policy_version 157032 (0.0002)
[2023-08-31 22:46:35,915][26287] KL-divergence is very high: 361.6021
[2023-08-31 22:46:36,170][26287] KL-divergence is very high: 143.1008
[2023-08-31 22:46:37,945][26288] Updated weights for policy 0, policy_version 157112 (0.0002)
[2023-08-31 22:46:38,107][26276] Fps is (10 sec: 15973.1, 60 sec: 16315.5, 300 sec: 16065.1). Total num frames: 80441344. Throughput: 0: 16422.4. Samples: 68516063. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[2023-08-31 22:46:38,107][26276] Avg episode reward: [(0, '-39485.454')]
[2023-08-31 22:46:40,465][26288] Updated weights for policy 0, policy_version 157192 (0.0002)
[2023-08-31 22:46:42,875][26287] KL-divergence is very high: 291.8688
[2023-08-31 22:46:42,883][26288] Updated weights for policy 0, policy_version 157272 (0.0002)
[2023-08-31 22:46:43,105][26276] Fps is (10 sec: 15976.9, 60 sec: 16453.6, 300 sec: 16079.0). Total num frames: 80523264. Throughput: 0: 16330.0. Samples: 68564149. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[2023-08-31 22:46:43,106][26276] Avg episode reward: [(0, '-39485.454')]
[2023-08-31 22:46:45,564][26288] Updated weights for policy 0, policy_version 157352 (0.0002)
[2023-08-31 22:46:46,490][26287] KL-divergence is very high: 266.7429
[2023-08-31 22:46:48,109][26276] Fps is (10 sec: 15560.5, 60 sec: 16314.9, 300 sec: 16051.1). Total num frames: 80596992. Throughput: 0: 16324.6. Samples: 68661780. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[2023-08-31 22:46:48,110][26276] Avg episode reward: [(0, '-27737.622')]
[2023-08-31 22:46:48,708][26288] Updated weights for policy 0, policy_version 157432 (0.0002)
[2023-08-31 22:46:49,498][26287] KL-divergence is very high: 453.4091
[2023-08-31 22:46:49,501][26287] KL-divergence is very high: 2260.2466
[2023-08-31 22:46:49,513][26287] KL-divergence is very high: 593.1292
[2023-08-31 22:46:49,516][26287] KL-divergence is very high: 601.7108
[2023-08-31 22:46:49,762][26287] KL-divergence is very high: 222.6215
[2023-08-31 22:46:49,768][26287] KL-divergence is very high: 540.2552
[2023-08-31 22:46:50,051][26287] KL-divergence is very high: 522.1381
[2023-08-31 22:46:50,054][26287] KL-divergence is very high: 1700.8523
[2023-08-31 22:46:50,057][26287] KL-divergence is very high: 152.3887
[2023-08-31 22:46:50,061][26287] KL-divergence is very high: 229.6429
[2023-08-31 22:46:50,064][26287] KL-divergence is very high: 370.2614
[2023-08-31 22:46:50,364][26287] KL-divergence is very high: 5632.5483
[2023-08-31 22:46:50,367][26287] KL-divergence is very high: 10864.0605
[2023-08-31 22:46:50,373][26287] KL-divergence is very high: 540.2806
[2023-08-31 22:46:50,376][26287] KL-divergence is very high: 1655.5558
[2023-08-31 22:46:50,378][26287] KL-divergence is very high: 1705.0873
[2023-08-31 22:46:50,994][26287] KL-divergence is very high: 461.1161
[2023-08-31 22:46:51,000][26287] KL-divergence is very high: 216.4460
[2023-08-31 22:46:51,002][26287] KL-divergence is very high: 1214.9391
[2023-08-31 22:46:51,006][26287] KL-divergence is very high: 5761.8296
[2023-08-31 22:46:51,009][26287] KL-divergence is very high: 1114.7828
[2023-08-31 22:46:51,256][26287] KL-divergence is very high: 300.9094
[2023-08-31 22:46:51,259][26287] KL-divergence is very high: 1340.0592
[2023-08-31 22:46:51,262][26287] KL-divergence is very high: 360.6335
[2023-08-31 22:46:51,265][26287] High loss value: l:122.1442 pl:0.0918 vl:0.1139 exp_l:0.0000 kl_l:121.9386 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:46:51,265][26287] KL-divergence is very high: 95948.9141
[2023-08-31 22:46:51,269][26287] KL-divergence is very high: 348.3414
[2023-08-31 22:46:51,273][26287] KL-divergence is very high: 2288.8589
[2023-08-31 22:46:51,276][26287] KL-divergence is very high: 1174.2294
[2023-08-31 22:46:51,526][26287] KL-divergence is very high: 567.2588
[2023-08-31 22:46:51,534][26287] KL-divergence is very high: 342.6391
[2023-08-31 22:46:51,537][26287] KL-divergence is very high: 642.6681
[2023-08-31 22:46:51,547][26288] Updated weights for policy 0, policy_version 157512 (0.0002)
[2023-08-31 22:46:53,107][26276] Fps is (10 sec: 14333.7, 60 sec: 16043.1, 300 sec: 16009.3). Total num frames: 80666624. Throughput: 0: 16000.5. Samples: 68743175. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 22:46:53,107][26276] Avg episode reward: [(0, '-27737.622')]
[2023-08-31 22:46:54,197][26288] Updated weights for policy 0, policy_version 157592 (0.0002)
[2023-08-31 22:46:56,885][26287] KL-divergence is very high: 3700.2849
[2023-08-31 22:46:56,896][26288] Updated weights for policy 0, policy_version 157672 (0.0002)
[2023-08-31 22:46:57,750][26287] KL-divergence is very high: 335.7468
[2023-08-31 22:46:57,753][26287] KL-divergence is very high: 416.0432
[2023-08-31 22:46:57,759][26287] KL-divergence is very high: 284.4157
[2023-08-31 22:46:57,762][26287] KL-divergence is very high: 522.1079
[2023-08-31 22:46:57,765][26287] KL-divergence is very high: 594.7593
[2023-08-31 22:46:58,107][26276] Fps is (10 sec: 14749.7, 60 sec: 15974.1, 300 sec: 15995.4). Total num frames: 80744448. Throughput: 0: 15893.2. Samples: 68789989. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 22:46:58,107][26276] Avg episode reward: [(0, '-25281.771')]
[2023-08-31 22:46:58,346][26287] KL-divergence is very high: 117.7837
[2023-08-31 22:46:58,350][26287] KL-divergence is very high: 174.5130
[2023-08-31 22:46:58,360][26287] KL-divergence is very high: 316.9411
[2023-08-31 22:46:58,657][26287] KL-divergence is very high: 877.0840
[2023-08-31 22:46:58,660][26287] KL-divergence is very high: 163.4384
[2023-08-31 22:46:59,531][26287] KL-divergence is very high: 381.1208
[2023-08-31 22:46:59,534][26287] KL-divergence is very high: 1255.2716
[2023-08-31 22:46:59,537][26287] KL-divergence is very high: 531.0522
[2023-08-31 22:46:59,541][26287] KL-divergence is very high: 174.3435
[2023-08-31 22:46:59,544][26287] KL-divergence is very high: 756.9130
[2023-08-31 22:46:59,547][26287] KL-divergence is very high: 2894.0857
[2023-08-31 22:46:59,551][26287] KL-divergence is very high: 3650.7251
[2023-08-31 22:46:59,785][26287] KL-divergence is very high: 221.2126
[2023-08-31 22:46:59,787][26287] KL-divergence is very high: 204.5941
[2023-08-31 22:46:59,791][26287] KL-divergence is very high: 536.6562
[2023-08-31 22:46:59,796][26287] KL-divergence is very high: 210.5439
[2023-08-31 22:46:59,799][26287] KL-divergence is very high: 266.3418
[2023-08-31 22:46:59,802][26288] Updated weights for policy 0, policy_version 157752 (0.0003)
[2023-08-31 22:47:00,058][26287] KL-divergence is very high: 679.3497
[2023-08-31 22:47:01,326][26287] KL-divergence is very high: 1333.8577
[2023-08-31 22:47:01,328][26287] KL-divergence is very high: 308.2200
[2023-08-31 22:47:01,331][26287] KL-divergence is very high: 2120.6643
[2023-08-31 22:47:01,334][26287] KL-divergence is very high: 156.5447
[2023-08-31 22:47:01,337][26287] KL-divergence is very high: 9422.1133
[2023-08-31 22:47:01,340][26287] KL-divergence is very high: 357.8027
[2023-08-31 22:47:01,343][26287] KL-divergence is very high: 6146.4946
[2023-08-31 22:47:02,086][26287] KL-divergence is very high: 1681.3230
[2023-08-31 22:47:02,094][26287] KL-divergence is very high: 632.2413
[2023-08-31 22:47:02,097][26287] KL-divergence is very high: 112.0448
[2023-08-31 22:47:02,102][26287] KL-divergence is very high: 202.2922
[2023-08-31 22:47:02,319][26287] KL-divergence is very high: 4110.2432
[2023-08-31 22:47:02,321][26287] KL-divergence is very high: 6310.7046
[2023-08-31 22:47:02,324][26287] KL-divergence is very high: 242.6966
[2023-08-31 22:47:02,326][26287] KL-divergence is very high: 4429.8833
[2023-08-31 22:47:02,329][26287] KL-divergence is very high: 6415.7891
[2023-08-31 22:47:02,332][26287] KL-divergence is very high: 5157.9380
[2023-08-31 22:47:02,334][26287] KL-divergence is very high: 317.5953
[2023-08-31 22:47:02,337][26288] Updated weights for policy 0, policy_version 157832 (0.0002)
[2023-08-31 22:47:02,595][26287] KL-divergence is very high: 118.3101
[2023-08-31 22:47:02,599][26287] KL-divergence is very high: 3695.3936
[2023-08-31 22:47:02,604][26287] KL-divergence is very high: 327.4129
[2023-08-31 22:47:02,607][26287] KL-divergence is very high: 540.3932
[2023-08-31 22:47:02,610][26287] KL-divergence is very high: 29367.0137
[2023-08-31 22:47:02,829][26287] KL-divergence is very high: 254.7948
[2023-08-31 22:47:02,837][26287] High loss value: l:31.6063 pl:-0.0206 vl:1.5065 exp_l:0.0000 kl_l:30.1204 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:02,837][26287] KL-divergence is very high: 34101.4844
[2023-08-31 22:47:03,086][26287] KL-divergence is very high: 1395.9650
[2023-08-31 22:47:03,089][26287] KL-divergence is very high: 449.5110
[2023-08-31 22:47:03,097][26287] KL-divergence is very high: 850.5928
[2023-08-31 22:47:03,099][26287] KL-divergence is very high: 351.8560
[2023-08-31 22:47:03,105][26276] Fps is (10 sec: 15567.3, 60 sec: 15838.4, 300 sec: 16009.2). Total num frames: 80822272. Throughput: 0: 15717.3. Samples: 68877731. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 22:47:03,105][26276] Avg episode reward: [(0, '-25281.771')]
[2023-08-31 22:47:03,318][26287] KL-divergence is very high: 213.4875
[2023-08-31 22:47:03,323][26287] KL-divergence is very high: 1973.2775
[2023-08-31 22:47:03,328][26287] KL-divergence is very high: 391.0993
[2023-08-31 22:47:03,557][26287] KL-divergence is very high: 296.7321
[2023-08-31 22:47:04,893][26288] Updated weights for policy 0, policy_version 157912 (0.0002)
[2023-08-31 22:47:05,655][26287] KL-divergence is very high: 456.0044
[2023-08-31 22:47:05,658][26287] KL-divergence is very high: 301.2664
[2023-08-31 22:47:05,667][26287] KL-divergence is very high: 10379.5586
[2023-08-31 22:47:05,669][26287] KL-divergence is very high: 421.2504
[2023-08-31 22:47:05,893][26287] KL-divergence is very high: 5339.7256
[2023-08-31 22:47:05,895][26287] KL-divergence is very high: 2826.0046
[2023-08-31 22:47:05,901][26287] KL-divergence is very high: 111.5961
[2023-08-31 22:47:05,904][26287] KL-divergence is very high: 6840.9619
[2023-08-31 22:47:05,906][26287] KL-divergence is very high: 2242.6948
[2023-08-31 22:47:06,125][26287] KL-divergence is very high: 12818.2627
[2023-08-31 22:47:06,133][26287] KL-divergence is very high: 108.3717
[2023-08-31 22:47:06,372][26287] KL-divergence is very high: 148.9060
[2023-08-31 22:47:06,375][26287] KL-divergence is very high: 1096.0563
[2023-08-31 22:47:06,377][26287] KL-divergence is very high: 1185.4132
[2023-08-31 22:47:06,383][26287] KL-divergence is very high: 115.5573
[2023-08-31 22:47:06,386][26287] KL-divergence is very high: 1274.3611
[2023-08-31 22:47:06,388][26287] KL-divergence is very high: 2709.9172
[2023-08-31 22:47:06,606][26287] KL-divergence is very high: 519.2739
[2023-08-31 22:47:06,609][26287] KL-divergence is very high: 3982.7749
[2023-08-31 22:47:06,611][26287] KL-divergence is very high: 1076.5928
[2023-08-31 22:47:06,614][26287] KL-divergence is very high: 3356.4141
[2023-08-31 22:47:06,617][26287] KL-divergence is very high: 4399.9932
[2023-08-31 22:47:06,620][26287] KL-divergence is very high: 2013.9708
[2023-08-31 22:47:06,623][26287] KL-divergence is very high: 2181.0444
[2023-08-31 22:47:07,185][26287] KL-divergence is very high: 1160.1387
[2023-08-31 22:47:07,193][26287] High loss value: l:111.1935 pl:0.0099 vl:1.9547 exp_l:0.0000 kl_l:109.2289 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:07,193][26287] KL-divergence is very high: 93173.4297
[2023-08-31 22:47:07,196][26287] High loss value: l:36.5733 pl:0.0822 vl:2.4904 exp_l:0.0000 kl_l:34.0006 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:07,196][26287] KL-divergence is very high: 48353.4688
[2023-08-31 22:47:07,202][26287] KL-divergence is very high: 1716.8374
[2023-08-31 22:47:07,435][26287] KL-divergence is very high: 375.8955
[2023-08-31 22:47:07,445][26287] KL-divergence is very high: 1145.4279
[2023-08-31 22:47:07,683][26287] KL-divergence is very high: 6290.9023
[2023-08-31 22:47:07,693][26287] KL-divergence is very high: 15955.6201
[2023-08-31 22:47:07,696][26288] Updated weights for policy 0, policy_version 157992 (0.0002)
[2023-08-31 22:47:07,940][26287] KL-divergence is very high: 440.2954
[2023-08-31 22:47:07,943][26287] KL-divergence is very high: 169.2645
[2023-08-31 22:47:07,946][26287] KL-divergence is very high: 5208.4946
[2023-08-31 22:47:07,949][26287] KL-divergence is very high: 3652.4304
[2023-08-31 22:47:07,952][26287] KL-divergence is very high: 1112.6195
[2023-08-31 22:47:07,955][26287] KL-divergence is very high: 1835.7681
[2023-08-31 22:47:07,958][26287] KL-divergence is very high: 2711.1545
[2023-08-31 22:47:08,108][26276] Fps is (10 sec: 15153.6, 60 sec: 15769.1, 300 sec: 15981.3). Total num frames: 80896000. Throughput: 0: 15467.1. Samples: 68970130. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 22:47:08,108][26276] Avg episode reward: [(0, '-39657.531')]
[2023-08-31 22:47:08,172][26287] KL-divergence is very high: 144.9026
[2023-08-31 22:47:08,175][26287] KL-divergence is very high: 1155.2356
[2023-08-31 22:47:08,177][26287] KL-divergence is very high: 347.1345
[2023-08-31 22:47:08,180][26287] KL-divergence is very high: 272.3351
[2023-08-31 22:47:08,183][26287] KL-divergence is very high: 1627.8555
[2023-08-31 22:47:08,421][26287] KL-divergence is very high: 126.8270
[2023-08-31 22:47:08,426][26287] KL-divergence is very high: 2202.1802
[2023-08-31 22:47:08,428][26287] KL-divergence is very high: 196.7203
[2023-08-31 22:47:08,434][26287] KL-divergence is very high: 538.5449
[2023-08-31 22:47:08,436][26287] KL-divergence is very high: 296.7648
[2023-08-31 22:47:08,653][26287] KL-divergence is very high: 240.3173
[2023-08-31 22:47:08,881][26287] KL-divergence is very high: 148.4494
[2023-08-31 22:47:09,132][26287] KL-divergence is very high: 142.3338
[2023-08-31 22:47:09,142][26287] KL-divergence is very high: 453.9864
[2023-08-31 22:47:09,388][26287] KL-divergence is very high: 128.3931
[2023-08-31 22:47:09,394][26287] KL-divergence is very high: 121.2513
[2023-08-31 22:47:09,635][26287] KL-divergence is very high: 167.1016
[2023-08-31 22:47:09,638][26287] KL-divergence is very high: 181.7558
[2023-08-31 22:47:09,640][26287] KL-divergence is very high: 237.4392
[2023-08-31 22:47:09,646][26287] KL-divergence is very high: 108.1303
[2023-08-31 22:47:09,652][26287] KL-divergence is very high: 342.0181
[2023-08-31 22:47:09,891][26287] KL-divergence is very high: 634.8945
[2023-08-31 22:47:09,894][26287] KL-divergence is very high: 1577.1464
[2023-08-31 22:47:09,897][26287] KL-divergence is very high: 1852.3536
[2023-08-31 22:47:09,900][26287] KL-divergence is very high: 366.4427
[2023-08-31 22:47:09,902][26287] KL-divergence is very high: 552.8129
[2023-08-31 22:47:09,905][26287] KL-divergence is very high: 2081.2830
[2023-08-31 22:47:09,907][26287] KL-divergence is very high: 4606.6025
[2023-08-31 22:47:10,156][26287] High loss value: l:52.4529 pl:-0.0213 vl:2.1274 exp_l:0.0000 kl_l:50.3467 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:10,156][26287] KL-divergence is very high: 25562.3906
[2023-08-31 22:47:10,159][26287] High loss value: l:83.4809 pl:-0.0102 vl:2.2684 exp_l:0.0000 kl_l:81.2227 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:10,159][26287] KL-divergence is very high: 42428.3594
[2023-08-31 22:47:10,163][26287] High loss value: l:62.1429 pl:0.0005 vl:2.8853 exp_l:0.0000 kl_l:59.2571 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:10,163][26287] KL-divergence is very high: 26558.4844
[2023-08-31 22:47:10,166][26287] KL-divergence is very high: 4710.1104
[2023-08-31 22:47:10,168][26287] High loss value: l:59.9352 pl:-0.0040 vl:2.0925 exp_l:0.0000 kl_l:57.8467 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:10,169][26287] KL-divergence is very high: 33849.6641
[2023-08-31 22:47:10,172][26287] High loss value: l:83.8414 pl:0.0060 vl:2.2464 exp_l:0.0000 kl_l:81.5890 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:10,172][26287] KL-divergence is very high: 53372.3789
[2023-08-31 22:47:10,175][26287] High loss value: l:88.6905 pl:0.0473 vl:2.8356 exp_l:0.0000 kl_l:85.8076 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:10,175][26287] KL-divergence is very high: 44969.1953
[2023-08-31 22:47:10,178][26288] Updated weights for policy 0, policy_version 158072 (0.0002)
[2023-08-31 22:47:10,397][26287] High loss value: l:378.5593 pl:0.0053 vl:3.1309 exp_l:0.0000 kl_l:375.4231 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:10,398][26287] KL-divergence is very high: 178500.2031
[2023-08-31 22:47:10,401][26287] High loss value: l:635.1395 pl:0.0115 vl:3.4865 exp_l:0.0000 kl_l:631.6415 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:10,401][26287] KL-divergence is very high: 324244.5625
[2023-08-31 22:47:10,404][26287] High loss value: l:415.3507 pl:0.0114 vl:2.9769 exp_l:0.0000 kl_l:412.3624 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:10,404][26287] KL-divergence is very high: 114262.2266
[2023-08-31 22:47:10,408][26287] High loss value: l:267.4842 pl:0.0309 vl:3.2004 exp_l:0.0000 kl_l:264.2529 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:10,408][26287] KL-divergence is very high: 90371.7266
[2023-08-31 22:47:10,412][26287] High loss value: l:142.9550 pl:0.0215 vl:3.1894 exp_l:0.0000 kl_l:139.7441 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:10,412][26287] KL-divergence is very high: 61977.6016
[2023-08-31 22:47:10,415][26287] High loss value: l:169.2372 pl:0.0103 vl:3.5957 exp_l:0.0000 kl_l:165.6312 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:10,415][26287] KL-divergence is very high: 62229.8984
[2023-08-31 22:47:10,419][26287] High loss value: l:329.0331 pl:-0.0066 vl:3.0820 exp_l:0.0000 kl_l:325.9577 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:10,419][26287] KL-divergence is very high: 95510.1250
[2023-08-31 22:47:10,642][26287] High loss value: l:40.4247 pl:-0.0338 vl:3.0613 exp_l:0.0000 kl_l:37.3972 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:10,642][26287] KL-divergence is very high: 13819.0068
[2023-08-31 22:47:10,645][26287] High loss value: l:76.6308 pl:-0.0337 vl:3.0356 exp_l:0.0000 kl_l:73.6288 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:10,645][26287] KL-divergence is very high: 21828.4941
[2023-08-31 22:47:10,648][26287] KL-divergence is very high: 2947.7678
[2023-08-31 22:47:10,651][26287] High loss value: l:137.1692 pl:-0.0217 vl:2.9681 exp_l:0.0000 kl_l:134.2228 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:10,651][26287] KL-divergence is very high: 73294.7578
[2023-08-31 22:47:10,654][26287] High loss value: l:84.9563 pl:-0.0168 vl:3.1115 exp_l:0.0000 kl_l:81.8616 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:10,655][26287] KL-divergence is very high: 22278.5059
[2023-08-31 22:47:10,658][26287] High loss value: l:218.7209 pl:-0.0077 vl:3.0937 exp_l:0.0000 kl_l:215.6349 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:10,658][26287] KL-divergence is very high: 61289.8438
[2023-08-31 22:47:10,662][26287] High loss value: l:144.9049 pl:-0.0256 vl:2.9840 exp_l:0.0000 kl_l:141.9465 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:10,662][26287] KL-divergence is very high: 43718.1172
[2023-08-31 22:47:10,895][26287] High loss value: l:38.4934 pl:-0.0336 vl:3.8450 exp_l:0.0000 kl_l:34.6820 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:10,895][26287] KL-divergence is very high: 8744.5928
[2023-08-31 22:47:10,899][26287] High loss value: l:32.3437 pl:-0.0318 vl:3.7617 exp_l:0.0000 kl_l:28.6139 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:10,899][26287] KL-divergence is very high: 9633.4160
[2023-08-31 22:47:10,902][26287] High loss value: l:37.9669 pl:-0.0298 vl:3.6040 exp_l:0.0000 kl_l:34.3927 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:10,902][26287] KL-divergence is very high: 12724.2969
[2023-08-31 22:47:10,906][26287] High loss value: l:44.9631 pl:-0.0312 vl:3.6908 exp_l:0.0000 kl_l:41.3035 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:10,906][26287] KL-divergence is very high: 18260.6934
[2023-08-31 22:47:10,910][26287] KL-divergence is very high: 3629.8875
[2023-08-31 22:47:10,912][26287] High loss value: l:30.9149 pl:-0.0378 vl:3.7534 exp_l:0.0000 kl_l:27.1993 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:10,912][26287] KL-divergence is very high: 11297.8184
[2023-08-31 22:47:10,915][26287] High loss value: l:38.4014 pl:-0.0306 vl:3.5587 exp_l:0.0000 kl_l:34.8733 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:10,916][26287] KL-divergence is very high: 15532.1465
[2023-08-31 22:47:11,132][26287] High loss value: l:304.1563 pl:-0.0317 vl:3.9837 exp_l:0.0000 kl_l:300.2044 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:11,132][26287] KL-divergence is very high: 115251.8516
[2023-08-31 22:47:11,135][26287] High loss value: l:373.9170 pl:-0.0249 vl:3.8911 exp_l:0.0000 kl_l:370.0508 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:11,136][26287] KL-divergence is very high: 146756.8750
[2023-08-31 22:47:11,139][26287] High loss value: l:251.4807 pl:-0.0260 vl:3.7432 exp_l:0.0000 kl_l:247.7635 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:11,139][26287] KL-divergence is very high: 82103.7656
[2023-08-31 22:47:11,142][26287] High loss value: l:117.0382 pl:-0.0240 vl:3.8194 exp_l:0.0000 kl_l:113.2428 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:11,142][26287] KL-divergence is very high: 39622.9336
[2023-08-31 22:47:11,145][26287] High loss value: l:97.2769 pl:-0.0326 vl:3.8726 exp_l:0.0000 kl_l:93.4368 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:11,145][26287] KL-divergence is very high: 27606.9141
[2023-08-31 22:47:11,149][26287] High loss value: l:169.7222 pl:-0.0291 vl:3.8037 exp_l:0.0000 kl_l:165.9476 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:11,149][26287] KL-divergence is very high: 53468.0898
[2023-08-31 22:47:11,152][26287] High loss value: l:90.0218 pl:-0.0172 vl:3.7129 exp_l:0.0000 kl_l:86.3261 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:11,152][26287] KL-divergence is very high: 37700.2930
[2023-08-31 22:47:11,399][26287] High loss value: l:134.5861 pl:-0.0312 vl:3.6764 exp_l:0.0000 kl_l:130.9409 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:11,399][26287] KL-divergence is very high: 63885.3672
[2023-08-31 22:47:11,402][26287] High loss value: l:127.6491 pl:-0.0293 vl:3.6924 exp_l:0.0000 kl_l:123.9859 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:11,402][26287] KL-divergence is very high: 48091.6680
[2023-08-31 22:47:11,405][26287] High loss value: l:131.7363 pl:-0.0249 vl:3.5977 exp_l:0.0000 kl_l:128.1634 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:11,405][26287] KL-divergence is very high: 50265.6523
[2023-08-31 22:47:11,409][26287] High loss value: l:91.1164 pl:-0.0207 vl:3.6973 exp_l:0.0000 kl_l:87.4398 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:11,409][26287] KL-divergence is very high: 34087.5820
[2023-08-31 22:47:11,412][26287] High loss value: l:65.9847 pl:-0.0314 vl:3.6391 exp_l:0.0000 kl_l:62.3770 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:11,412][26287] KL-divergence is very high: 40937.0391
[2023-08-31 22:47:11,415][26287] High loss value: l:57.7487 pl:-0.0330 vl:3.6537 exp_l:0.0000 kl_l:54.1280 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:11,416][26287] KL-divergence is very high: 29711.7168
[2023-08-31 22:47:11,419][26287] High loss value: l:108.6739 pl:-0.0239 vl:3.5807 exp_l:0.0000 kl_l:105.1171 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:11,419][26287] KL-divergence is very high: 33766.1523
[2023-08-31 22:47:11,630][26287] High loss value: l:36.3633 pl:-0.0365 vl:3.4829 exp_l:0.0000 kl_l:32.9168 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:11,630][26287] KL-divergence is very high: 19717.5430
[2023-08-31 22:47:11,633][26287] High loss value: l:50.4776 pl:-0.0330 vl:3.3292 exp_l:0.0000 kl_l:47.1814 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:11,633][26287] KL-divergence is very high: 22407.2168
[2023-08-31 22:47:11,637][26287] KL-divergence is very high: 9452.3984
[2023-08-31 22:47:11,639][26287] High loss value: l:113.5704 pl:-0.0248 vl:3.3570 exp_l:0.0000 kl_l:110.2381 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:11,640][26287] KL-divergence is very high: 37261.7070
[2023-08-31 22:47:11,643][26287] High loss value: l:64.9678 pl:-0.0356 vl:3.4601 exp_l:0.0000 kl_l:61.5433 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:11,643][26287] KL-divergence is very high: 21465.7695
[2023-08-31 22:47:11,647][26287] High loss value: l:61.3523 pl:-0.0321 vl:3.3139 exp_l:0.0000 kl_l:58.0706 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:11,647][26287] KL-divergence is very high: 42218.4336
[2023-08-31 22:47:11,651][26287] High loss value: l:75.8805 pl:-0.0338 vl:2.9778 exp_l:0.0000 kl_l:72.9365 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:11,651][26287] KL-divergence is very high: 43805.4922
[2023-08-31 22:47:11,861][26287] High loss value: l:168.3527 pl:-0.0337 vl:3.0254 exp_l:0.0000 kl_l:165.3609 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:11,861][26287] KL-divergence is very high: 57944.4492
[2023-08-31 22:47:11,864][26287] High loss value: l:172.6320 pl:-0.0269 vl:2.9429 exp_l:0.0000 kl_l:169.7161 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:11,864][26287] KL-divergence is very high: 52371.7227
[2023-08-31 22:47:11,867][26287] High loss value: l:58.4257 pl:-0.0186 vl:2.8406 exp_l:0.0000 kl_l:55.6037 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:11,867][26287] KL-divergence is very high: 14843.5645
[2023-08-31 22:47:11,871][26287] High loss value: l:104.4442 pl:-0.0238 vl:3.8916 exp_l:0.0000 kl_l:100.5763 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:11,871][26287] KL-divergence is very high: 53119.3398
[2023-08-31 22:47:11,874][26287] High loss value: l:66.4593 pl:-0.0290 vl:2.9970 exp_l:0.0000 kl_l:63.4912 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:11,874][26287] KL-divergence is very high: 21582.7539
[2023-08-31 22:47:11,877][26287] High loss value: l:98.5089 pl:-0.0248 vl:2.8616 exp_l:0.0000 kl_l:95.6721 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:11,877][26287] KL-divergence is very high: 36544.7734
[2023-08-31 22:47:11,880][26287] High loss value: l:112.3192 pl:-0.0158 vl:2.7498 exp_l:0.0000 kl_l:109.5852 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:11,880][26287] KL-divergence is very high: 43165.1445
[2023-08-31 22:47:12,126][26287] High loss value: l:88.1107 pl:-0.0210 vl:2.9814 exp_l:0.0000 kl_l:85.1503 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:12,126][26287] KL-divergence is very high: 27037.7305
[2023-08-31 22:47:12,130][26287] High loss value: l:76.8416 pl:-0.0156 vl:2.9682 exp_l:0.0000 kl_l:73.8890 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:12,130][26287] KL-divergence is very high: 18771.5273
[2023-08-31 22:47:12,133][26287] High loss value: l:63.3857 pl:-0.0237 vl:2.8913 exp_l:0.0000 kl_l:60.5181 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:12,134][26287] KL-divergence is very high: 19371.1387
[2023-08-31 22:47:12,137][26287] High loss value: l:46.8518 pl:-0.0304 vl:2.9383 exp_l:0.0000 kl_l:43.9439 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:12,137][26287] KL-divergence is very high: 18189.8145
[2023-08-31 22:47:12,141][26287] High loss value: l:37.1603 pl:-0.0276 vl:2.9194 exp_l:0.0000 kl_l:34.2684 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:12,141][26287] KL-divergence is very high: 12479.4775
[2023-08-31 22:47:12,145][26287] High loss value: l:39.8995 pl:-0.0300 vl:2.9010 exp_l:0.0000 kl_l:37.0285 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:12,145][26287] KL-divergence is very high: 12038.4277
[2023-08-31 22:47:12,149][26287] High loss value: l:35.8059 pl:-0.0337 vl:2.8487 exp_l:0.0000 kl_l:32.9909 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:12,149][26287] KL-divergence is very high: 10545.9414
[2023-08-31 22:47:12,363][26287] High loss value: l:72.9868 pl:-0.0341 vl:3.1641 exp_l:0.0000 kl_l:69.8567 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:12,363][26287] KL-divergence is very high: 22022.8340
[2023-08-31 22:47:12,366][26287] High loss value: l:65.6231 pl:-0.0170 vl:4.0074 exp_l:0.0000 kl_l:61.6326 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:12,367][26287] KL-divergence is very high: 28767.3730
[2023-08-31 22:47:12,369][26287] High loss value: l:76.7320 pl:-0.0209 vl:3.7224 exp_l:0.0000 kl_l:73.0305 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:12,370][26287] KL-divergence is very high: 33556.6641
[2023-08-31 22:47:12,373][26287] High loss value: l:55.1807 pl:-0.0299 vl:2.8500 exp_l:0.0000 kl_l:52.3606 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:12,373][26287] KL-divergence is very high: 22082.4805
[2023-08-31 22:47:12,376][26287] KL-divergence is very high: 8116.9243
[2023-08-31 22:47:12,379][26287] KL-divergence is very high: 10309.1416
[2023-08-31 22:47:12,381][26287] High loss value: l:69.6225 pl:-0.0142 vl:3.6784 exp_l:0.0000 kl_l:65.9583 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:12,381][26287] KL-divergence is very high: 22353.0000
[2023-08-31 22:47:12,615][26287] High loss value: l:41.3797 pl:-0.0201 vl:4.2135 exp_l:0.0000 kl_l:37.1863 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:12,615][26287] KL-divergence is very high: 13049.2949
[2023-08-31 22:47:12,618][26287] High loss value: l:46.4344 pl:-0.0255 vl:3.8746 exp_l:0.0000 kl_l:42.5853 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:12,619][26287] KL-divergence is very high: 18835.3457
[2023-08-31 22:47:12,622][26287] High loss value: l:30.3085 pl:-0.0133 vl:3.9780 exp_l:0.0000 kl_l:26.3439 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:12,622][26287] KL-divergence is very high: 10679.1904
[2023-08-31 22:47:12,625][26287] KL-divergence is very high: 6808.7280
[2023-08-31 22:47:12,628][26287] KL-divergence is very high: 3050.2556
[2023-08-31 22:47:12,630][26287] High loss value: l:45.1592 pl:-0.0200 vl:3.8371 exp_l:0.0000 kl_l:41.3421 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:12,630][26287] KL-divergence is very high: 18999.6543
[2023-08-31 22:47:12,634][26287] High loss value: l:48.4575 pl:-0.0086 vl:3.9704 exp_l:0.0000 kl_l:44.4957 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:12,634][26287] KL-divergence is very high: 13425.2871
[2023-08-31 22:47:12,638][26288] Updated weights for policy 0, policy_version 158152 (0.0003)
[2023-08-31 22:47:12,844][26287] High loss value: l:148.0575 pl:-0.0215 vl:4.0911 exp_l:0.0000 kl_l:143.9879 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:12,844][26287] KL-divergence is very high: 55847.2500
[2023-08-31 22:47:12,847][26287] High loss value: l:207.4657 pl:0.0107 vl:3.9544 exp_l:0.0000 kl_l:203.5006 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:12,847][26287] KL-divergence is very high: 84640.6719
[2023-08-31 22:47:12,850][26287] High loss value: l:73.6761 pl:0.0075 vl:3.8596 exp_l:0.0000 kl_l:69.8090 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:12,850][26287] KL-divergence is very high: 29141.7715
[2023-08-31 22:47:12,854][26287] High loss value: l:63.3210 pl:-0.0106 vl:4.1692 exp_l:0.0000 kl_l:59.1624 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:12,854][26287] KL-divergence is very high: 27106.0742
[2023-08-31 22:47:12,857][26287] High loss value: l:113.6761 pl:-0.0104 vl:4.1266 exp_l:0.0000 kl_l:109.5598 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:12,857][26287] KL-divergence is very high: 41309.1602
[2023-08-31 22:47:12,860][26287] High loss value: l:42.0370 pl:-0.0094 vl:4.0145 exp_l:0.0000 kl_l:38.0319 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:12,860][26287] KL-divergence is very high: 14177.3457
[2023-08-31 22:47:12,864][26287] High loss value: l:83.4943 pl:0.0045 vl:3.8841 exp_l:0.0000 kl_l:79.6056 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:12,864][26287] KL-divergence is very high: 40898.0586
[2023-08-31 22:47:13,081][26287] High loss value: l:76.5111 pl:-0.0147 vl:3.7646 exp_l:0.0000 kl_l:72.7612 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:13,081][26287] KL-divergence is very high: 25505.2930
[2023-08-31 22:47:13,084][26287] High loss value: l:69.4404 pl:0.0080 vl:3.7165 exp_l:0.0000 kl_l:65.7158 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:13,084][26287] KL-divergence is very high: 24864.3145
[2023-08-31 22:47:13,088][26287] KL-divergence is very high: 8618.1133
[2023-08-31 22:47:13,091][26287] KL-divergence is very high: 8888.1982
[2023-08-31 22:47:13,094][26287] KL-divergence is very high: 4769.6787
[2023-08-31 22:47:13,096][26287] KL-divergence is very high: 6930.9668
[2023-08-31 22:47:13,099][26287] KL-divergence is very high: 5789.8354
[2023-08-31 22:47:13,106][26276] Fps is (10 sec: 15972.9, 60 sec: 15769.7, 300 sec: 16009.2). Total num frames: 80982016. Throughput: 0: 15429.6. Samples: 69019734. Policy #0 lag: (min: 2.0, avg: 2.0, max: 2.0)
[2023-08-31 22:47:13,106][26276] Avg episode reward: [(0, '-39657.531')]
[2023-08-31 22:47:13,379][26287] High loss value: l:123.5787 pl:-0.0264 vl:3.6606 exp_l:0.0000 kl_l:119.9445 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:13,379][26287] KL-divergence is very high: 41361.0703
[2023-08-31 22:47:13,382][26287] High loss value: l:148.0529 pl:-0.0069 vl:3.5752 exp_l:0.0000 kl_l:144.4846 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:13,382][26287] KL-divergence is very high: 56537.3711
[2023-08-31 22:47:13,385][26287] High loss value: l:47.8425 pl:-0.0266 vl:3.6933 exp_l:0.0000 kl_l:44.1758 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:13,385][26287] KL-divergence is very high: 17720.3809
[2023-08-31 22:47:13,389][26287] High loss value: l:54.8180 pl:-0.0223 vl:3.8083 exp_l:0.0000 kl_l:51.0320 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:13,389][26287] KL-divergence is very high: 18440.2148
[2023-08-31 22:47:13,392][26287] High loss value: l:108.8209 pl:-0.0333 vl:3.6867 exp_l:0.0000 kl_l:105.1676 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:13,392][26287] KL-divergence is very high: 36171.8125
[2023-08-31 22:47:13,395][26287] KL-divergence is very high: 8388.1875
[2023-08-31 22:47:13,398][26287] High loss value: l:63.6980 pl:-0.0277 vl:3.6766 exp_l:0.0000 kl_l:60.0490 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:13,399][26287] KL-divergence is very high: 23631.7598
[2023-08-31 22:47:13,641][26287] High loss value: l:112.7446 pl:-0.0163 vl:3.5689 exp_l:0.0000 kl_l:109.1920 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:13,641][26287] KL-divergence is very high: 37948.2305
[2023-08-31 22:47:13,644][26287] High loss value: l:152.7475 pl:-0.0196 vl:3.6674 exp_l:0.0000 kl_l:149.0997 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:13,644][26287] KL-divergence is very high: 54919.6719
[2023-08-31 22:47:13,647][26287] High loss value: l:42.9609 pl:-0.0260 vl:3.5829 exp_l:0.0000 kl_l:39.4040 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:13,648][26287] KL-divergence is very high: 16547.0625
[2023-08-31 22:47:13,651][26287] High loss value: l:68.8429 pl:-0.0299 vl:3.6640 exp_l:0.0000 kl_l:65.2089 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:13,651][26287] KL-divergence is very high: 25988.1992
[2023-08-31 22:47:13,654][26287] High loss value: l:163.0270 pl:-0.0027 vl:3.5959 exp_l:0.0000 kl_l:159.4338 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:13,654][26287] KL-divergence is very high: 57661.3945
[2023-08-31 22:47:13,658][26287] High loss value: l:85.8660 pl:-0.0198 vl:3.6917 exp_l:0.0000 kl_l:82.1941 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:13,658][26287] KL-divergence is very high: 30392.9180
[2023-08-31 22:47:13,662][26287] KL-divergence is very high: 3051.6011
[2023-08-31 22:47:13,876][26287] High loss value: l:40.8296 pl:-0.0129 vl:3.5875 exp_l:0.0000 kl_l:37.2550 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:13,877][26287] KL-divergence is very high: 13238.7344
[2023-08-31 22:47:13,880][26287] High loss value: l:43.5350 pl:-0.0257 vl:3.6502 exp_l:0.0000 kl_l:39.9105 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:13,880][26287] KL-divergence is very high: 11604.9170
[2023-08-31 22:47:13,883][26287] KL-divergence is very high: 8678.5322
[2023-08-31 22:47:13,885][26287] KL-divergence is very high: 5589.6094
[2023-08-31 22:47:13,888][26287] High loss value: l:31.2751 pl:-0.0184 vl:3.5253 exp_l:0.0000 kl_l:27.7682 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:13,888][26287] KL-divergence is very high: 11787.1426
[2023-08-31 22:47:13,892][26287] KL-divergence is very high: 6024.5420
[2023-08-31 22:47:13,895][26287] KL-divergence is very high: 6971.0068
[2023-08-31 22:47:14,109][26287] High loss value: l:51.6838 pl:-0.0244 vl:3.5558 exp_l:0.0000 kl_l:48.1524 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:14,109][26287] KL-divergence is very high: 23546.4551
[2023-08-31 22:47:14,112][26287] High loss value: l:53.0764 pl:-0.0181 vl:3.6189 exp_l:0.0000 kl_l:49.4756 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:14,112][26287] KL-divergence is very high: 22150.8848
[2023-08-31 22:47:14,116][26287] KL-divergence is very high: 2578.0627
[2023-08-31 22:47:14,119][26287] KL-divergence is very high: 7332.9370
[2023-08-31 22:47:14,122][26287] KL-divergence is very high: 5738.5781
[2023-08-31 22:47:14,125][26287] KL-divergence is very high: 8811.0273
[2023-08-31 22:47:14,128][26287] KL-divergence is very high: 967.0558
[2023-08-31 22:47:14,380][26287] High loss value: l:56.2266 pl:-0.0232 vl:3.4560 exp_l:0.0000 kl_l:52.7938 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:14,380][26287] KL-divergence is very high: 30116.3770
[2023-08-31 22:47:14,384][26287] High loss value: l:66.4854 pl:-0.0186 vl:3.4985 exp_l:0.0000 kl_l:63.0056 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:14,384][26287] KL-divergence is very high: 34666.1445
[2023-08-31 22:47:14,387][26287] KL-divergence is very high: 5468.1665
[2023-08-31 22:47:14,390][26287] High loss value: l:53.4367 pl:-0.0214 vl:3.5864 exp_l:0.0000 kl_l:49.8716 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:14,390][26287] KL-divergence is very high: 15822.2002
[2023-08-31 22:47:14,394][26287] High loss value: l:57.5596 pl:-0.0056 vl:3.4825 exp_l:0.0000 kl_l:54.0827 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:14,394][26287] KL-divergence is very high: 17170.8594
[2023-08-31 22:47:14,397][26287] High loss value: l:42.1451 pl:-0.0131 vl:3.5202 exp_l:0.0000 kl_l:38.6380 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:14,397][26287] KL-divergence is very high: 13038.2949
[2023-08-31 22:47:14,401][26287] KL-divergence is very high: 21902.5957
[2023-08-31 22:47:14,611][26287] High loss value: l:98.2504 pl:-0.0067 vl:3.4396 exp_l:0.0000 kl_l:94.8176 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:14,612][26287] KL-divergence is very high: 43632.0703
[2023-08-31 22:47:14,615][26287] High loss value: l:183.5184 pl:0.0187 vl:3.4075 exp_l:0.0000 kl_l:180.0922 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:14,615][26287] KL-divergence is very high: 60645.9688
[2023-08-31 22:47:14,618][26287] High loss value: l:113.4042 pl:0.0157 vl:3.3700 exp_l:0.0000 kl_l:110.0185 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:14,618][26287] KL-divergence is very high: 43586.6875
[2023-08-31 22:47:14,622][26287] High loss value: l:51.7949 pl:-0.0046 vl:3.4243 exp_l:0.0000 kl_l:48.3752 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:14,622][26287] KL-divergence is very high: 13638.0693
[2023-08-31 22:47:14,625][26287] High loss value: l:41.5262 pl:-0.0249 vl:3.3942 exp_l:0.0000 kl_l:38.1568 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:14,625][26287] KL-divergence is very high: 21772.4395
[2023-08-31 22:47:14,628][26287] High loss value: l:53.4020 pl:-0.0097 vl:3.4037 exp_l:0.0000 kl_l:50.0080 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:14,628][26287] KL-divergence is very high: 17111.6445
[2023-08-31 22:47:14,631][26287] High loss value: l:50.0055 pl:0.0284 vl:3.4029 exp_l:0.0000 kl_l:46.5742 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:14,631][26287] KL-divergence is very high: 15220.6963
[2023-08-31 22:47:14,871][26287] High loss value: l:79.0039 pl:-0.0232 vl:3.4393 exp_l:0.0000 kl_l:75.5878 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:14,871][26287] KL-divergence is very high: 38582.3086
[2023-08-31 22:47:14,874][26287] High loss value: l:137.7475 pl:-0.0066 vl:3.4525 exp_l:0.0000 kl_l:134.3017 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:14,874][26287] KL-divergence is very high: 59489.6641
[2023-08-31 22:47:14,877][26287] High loss value: l:66.7172 pl:-0.0068 vl:3.3506 exp_l:0.0000 kl_l:63.3734 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:14,877][26287] KL-divergence is very high: 29200.1855
[2023-08-31 22:47:14,881][26287] High loss value: l:51.4416 pl:-0.0253 vl:3.4030 exp_l:0.0000 kl_l:48.0640 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:14,881][26287] KL-divergence is very high: 20374.0762
[2023-08-31 22:47:14,884][26287] High loss value: l:47.9531 pl:-0.0212 vl:3.3866 exp_l:0.0000 kl_l:44.5877 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:14,884][26287] KL-divergence is very high: 26304.0430
[2023-08-31 22:47:14,887][26287] KL-divergence is very high: 7830.4536
[2023-08-31 22:47:14,890][26287] High loss value: l:46.3359 pl:-0.0151 vl:3.3555 exp_l:0.0000 kl_l:42.9955 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:14,890][26287] KL-divergence is very high: 17924.6133
[2023-08-31 22:47:15,131][26287] High loss value: l:30.3523 pl:-0.0228 vl:3.3167 exp_l:0.0000 kl_l:27.0585 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:15,131][26287] KL-divergence is very high: 11161.3740
[2023-08-31 22:47:15,135][26287] KL-divergence is very high: 7272.8311
[2023-08-31 22:47:15,138][26287] KL-divergence is very high: 2562.1655
[2023-08-31 22:47:15,141][26287] KL-divergence is very high: 3351.0029
[2023-08-31 22:47:15,144][26287] KL-divergence is very high: 3767.1992
[2023-08-31 22:47:15,147][26287] KL-divergence is very high: 2228.0635
[2023-08-31 22:47:15,150][26287] KL-divergence is very high: 7844.7739
[2023-08-31 22:47:15,153][26288] Updated weights for policy 0, policy_version 158232 (0.0002)
[2023-08-31 22:47:15,366][26287] KL-divergence is very high: 7318.9922
[2023-08-31 22:47:15,369][26287] KL-divergence is very high: 3863.1680
[2023-08-31 22:47:15,372][26287] KL-divergence is very high: 12741.1836
[2023-08-31 22:47:15,375][26287] KL-divergence is very high: 10442.6191
[2023-08-31 22:47:15,377][26287] KL-divergence is very high: 949.4626
[2023-08-31 22:47:15,380][26287] KL-divergence is very high: 9025.3359
[2023-08-31 22:47:15,383][26287] KL-divergence is very high: 8487.9297
[2023-08-31 22:47:15,598][26287] High loss value: l:41.6423 pl:-0.0235 vl:3.1232 exp_l:0.0000 kl_l:38.5427 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:15,598][26287] KL-divergence is very high: 21034.6914
[2023-08-31 22:47:15,601][26287] High loss value: l:49.3534 pl:-0.0027 vl:3.0845 exp_l:0.0000 kl_l:46.2715 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:15,601][26287] KL-divergence is very high: 25654.7988
[2023-08-31 22:47:15,604][26287] KL-divergence is very high: 10138.5518
[2023-08-31 22:47:15,607][26287] High loss value: l:41.4170 pl:-0.0045 vl:3.1808 exp_l:0.0000 kl_l:38.2407 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:15,607][26287] KL-divergence is very high: 13752.4258
[2023-08-31 22:47:15,610][26287] High loss value: l:55.5464 pl:-0.0087 vl:3.0861 exp_l:0.0000 kl_l:52.4690 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:15,610][26287] KL-divergence is very high: 21879.3457
[2023-08-31 22:47:15,613][26287] KL-divergence is very high: 8906.5850
[2023-08-31 22:47:15,615][26287] KL-divergence is very high: 14059.3867
[2023-08-31 22:47:15,839][26287] High loss value: l:38.0616 pl:-0.0161 vl:2.9977 exp_l:0.0000 kl_l:35.0800 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:15,839][26287] KL-divergence is very high: 12696.4375
[2023-08-31 22:47:15,842][26287] High loss value: l:48.3553 pl:-0.0056 vl:2.9987 exp_l:0.0000 kl_l:45.3621 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:15,842][26287] KL-divergence is very high: 18719.8906
[2023-08-31 22:47:15,845][26287] KL-divergence is very high: 6806.1230
[2023-08-31 22:47:15,848][26287] KL-divergence is very high: 9480.1719
[2023-08-31 22:47:15,850][26287] High loss value: l:43.3009 pl:-0.0123 vl:2.9770 exp_l:0.0000 kl_l:40.3362 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:15,850][26287] KL-divergence is very high: 15963.5117
[2023-08-31 22:47:15,854][26287] KL-divergence is very high: 6117.7031
[2023-08-31 22:47:15,857][26287] KL-divergence is very high: 5799.8657
[2023-08-31 22:47:16,080][26287] KL-divergence is very high: 1503.7360
[2023-08-31 22:47:16,083][26287] KL-divergence is very high: 1121.7871
[2023-08-31 22:47:16,086][26287] KL-divergence is very high: 4124.3696
[2023-08-31 22:47:16,089][26287] KL-divergence is very high: 3808.3782
[2023-08-31 22:47:16,092][26287] KL-divergence is very high: 971.3029
[2023-08-31 22:47:16,094][26287] KL-divergence is very high: 2660.4016
[2023-08-31 22:47:16,098][26287] KL-divergence is very high: 4236.8384
[2023-08-31 22:47:16,312][26287] KL-divergence is very high: 9635.7412
[2023-08-31 22:47:16,315][26287] High loss value: l:45.8210 pl:0.0045 vl:2.8209 exp_l:0.0000 kl_l:42.9956 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:16,315][26287] KL-divergence is very high: 20867.3340
[2023-08-31 22:47:16,318][26287] KL-divergence is very high: 10845.4189
[2023-08-31 22:47:16,321][26287] KL-divergence is very high: 1369.1407
[2023-08-31 22:47:16,325][26287] KL-divergence is very high: 8253.2275
[2023-08-31 22:47:16,327][26287] High loss value: l:49.3475 pl:0.0518 vl:2.7497 exp_l:0.0000 kl_l:46.5460 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:16,328][26287] KL-divergence is very high: 18995.8926
[2023-08-31 22:47:16,331][26287] High loss value: l:33.4057 pl:0.0389 vl:2.7828 exp_l:0.0000 kl_l:30.5839 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:16,331][26287] KL-divergence is very high: 14349.5938
[2023-08-31 22:47:16,552][26287] High loss value: l:33.3529 pl:-0.0007 vl:2.7706 exp_l:0.0000 kl_l:30.5830 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:16,553][26287] KL-divergence is very high: 12982.9268
[2023-08-31 22:47:16,556][26287] High loss value: l:66.6363 pl:0.0448 vl:2.7938 exp_l:0.0000 kl_l:63.7978 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:16,557][26287] KL-divergence is very high: 26586.6055
[2023-08-31 22:47:16,560][26287] High loss value: l:55.3309 pl:0.0341 vl:2.7380 exp_l:0.0000 kl_l:52.5587 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:16,560][26287] KL-divergence is very high: 23035.7031
[2023-08-31 22:47:16,563][26287] High loss value: l:30.6010 pl:0.0001 vl:2.7639 exp_l:0.0000 kl_l:27.8370 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:16,563][26287] KL-divergence is very high: 12094.0322
[2023-08-31 22:47:16,566][26287] KL-divergence is very high: 3984.6470
[2023-08-31 22:47:16,569][26287] KL-divergence is very high: 9442.0039
[2023-08-31 22:47:16,573][26287] KL-divergence is very high: 9828.9834
[2023-08-31 22:47:17,007][26287] KL-divergence is very high: 5939.2759
[2023-08-31 22:47:17,015][26287] High loss value: l:37.5209 pl:0.0388 vl:2.7302 exp_l:0.0000 kl_l:34.7519 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:17,015][26287] KL-divergence is very high: 12807.6963
[2023-08-31 22:47:17,018][26287] KL-divergence is very high: 12202.7842
[2023-08-31 22:47:17,698][26288] Updated weights for policy 0, policy_version 158312 (0.0002)
[2023-08-31 22:47:18,105][26276] Fps is (10 sec: 16387.8, 60 sec: 15701.9, 300 sec: 15995.2). Total num frames: 81059840. Throughput: 0: 15540.7. Samples: 69119684. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 22:47:18,106][26276] Avg episode reward: [(0, '-80880.892')]
[2023-08-31 22:47:19,638][26287] KL-divergence is very high: 102.4393
[2023-08-31 22:47:20,128][26288] Updated weights for policy 0, policy_version 158392 (0.0002)
[2023-08-31 22:47:22,525][26288] Updated weights for policy 0, policy_version 158472 (0.0002)
[2023-08-31 22:47:23,110][26276] Fps is (10 sec: 16377.2, 60 sec: 15768.4, 300 sec: 16009.0). Total num frames: 81145856. Throughput: 0: 15604.6. Samples: 69218325. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 22:47:23,110][26276] Avg episode reward: [(0, '-80880.892')]
[2023-08-31 22:47:23,113][26287] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000158488_81145856.pth...
[2023-08-31 22:47:23,115][26287] Removing /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000152216_77934592.pth
[2023-08-31 22:47:24,884][26288] Updated weights for policy 0, policy_version 158552 (0.0002)
[2023-08-31 22:47:27,578][26287] KL-divergence is very high: 160.8378
[2023-08-31 22:47:27,587][26288] Updated weights for policy 0, policy_version 158632 (0.0002)
[2023-08-31 22:47:28,107][26276] Fps is (10 sec: 16790.1, 60 sec: 15769.2, 300 sec: 16009.2). Total num frames: 81227776. Throughput: 0: 15706.7. Samples: 69270987. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 22:47:28,108][26276] Avg episode reward: [(0, '-101351.921')]
[2023-08-31 22:47:29,947][26288] Updated weights for policy 0, policy_version 158712 (0.0002)
[2023-08-31 22:47:32,328][26288] Updated weights for policy 0, policy_version 158792 (0.0002)
[2023-08-31 22:47:33,108][26276] Fps is (10 sec: 16796.9, 60 sec: 15837.5, 300 sec: 16036.8). Total num frames: 81313792. Throughput: 0: 15732.8. Samples: 69369739. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 22:47:33,108][26276] Avg episode reward: [(0, '-101351.921')]
[2023-08-31 22:47:34,696][26288] Updated weights for policy 0, policy_version 158872 (0.0002)
[2023-08-31 22:47:37,237][26288] Updated weights for policy 0, policy_version 158952 (0.0002)
[2023-08-31 22:47:38,106][26276] Fps is (10 sec: 16795.9, 60 sec: 15906.3, 300 sec: 16037.3). Total num frames: 81395712. Throughput: 0: 16134.8. Samples: 69469230. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 22:47:38,106][26276] Avg episode reward: [(0, '-134134.777')]
[2023-08-31 22:47:39,583][26288] Updated weights for policy 0, policy_version 159032 (0.0002)
[2023-08-31 22:47:41,953][26288] Updated weights for policy 0, policy_version 159112 (0.0002)
[2023-08-31 22:47:43,110][26276] Fps is (10 sec: 16790.6, 60 sec: 15973.1, 300 sec: 16064.9). Total num frames: 81481728. Throughput: 0: 16270.2. Samples: 69522201. Policy #0 lag: (min: 4.0, avg: 4.0, max: 4.0)
[2023-08-31 22:47:43,110][26276] Avg episode reward: [(0, '-134134.777')]
[2023-08-31 22:47:43,135][26287] KL-divergence is very high: 103.9683
[2023-08-31 22:47:43,138][26287] KL-divergence is very high: 172.3354
[2023-08-31 22:47:43,147][26287] KL-divergence is very high: 184.4684
[2023-08-31 22:47:43,150][26287] KL-divergence is very high: 191.7379
[2023-08-31 22:47:43,153][26287] KL-divergence is very high: 148.1973
[2023-08-31 22:47:43,393][26287] KL-divergence is very high: 290.9606
[2023-08-31 22:47:43,399][26287] KL-divergence is very high: 689.9290
[2023-08-31 22:47:43,402][26287] KL-divergence is very high: 761.0664
[2023-08-31 22:47:43,408][26287] KL-divergence is very high: 1539.3767
[2023-08-31 22:47:43,410][26287] High loss value: l:36.2287 pl:0.0915 vl:0.3686 exp_l:0.0000 kl_l:35.7686 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:43,410][26287] KL-divergence is very high: 2891.0046
[2023-08-31 22:47:43,612][26287] KL-divergence is very high: 647.9892
[2023-08-31 22:47:43,614][26287] KL-divergence is very high: 581.8166
[2023-08-31 22:47:43,620][26287] KL-divergence is very high: 246.0109
[2023-08-31 22:47:43,625][26287] KL-divergence is very high: 735.1736
[2023-08-31 22:47:43,628][26287] KL-divergence is very high: 964.0219
[2023-08-31 22:47:43,832][26287] KL-divergence is very high: 179.3707
[2023-08-31 22:47:43,837][26287] KL-divergence is very high: 372.3005
[2023-08-31 22:47:43,840][26287] KL-divergence is very high: 294.3227
[2023-08-31 22:47:43,846][26287] KL-divergence is very high: 104.0763
[2023-08-31 22:47:43,848][26287] KL-divergence is very high: 134.2979
[2023-08-31 22:47:44,058][26287] KL-divergence is very high: 286.5032
[2023-08-31 22:47:44,060][26287] KL-divergence is very high: 214.8510
[2023-08-31 22:47:44,063][26287] KL-divergence is very high: 131.9660
[2023-08-31 22:47:44,065][26287] KL-divergence is very high: 117.9158
[2023-08-31 22:47:44,073][26287] KL-divergence is very high: 198.7451
[2023-08-31 22:47:44,309][26287] KL-divergence is very high: 140.3079
[2023-08-31 22:47:44,312][26287] KL-divergence is very high: 113.6305
[2023-08-31 22:47:44,314][26288] Updated weights for policy 0, policy_version 159192 (0.0002)
[2023-08-31 22:47:44,516][26287] KL-divergence is very high: 922.8450
[2023-08-31 22:47:44,519][26287] KL-divergence is very high: 1653.1125
[2023-08-31 22:47:44,521][26287] KL-divergence is very high: 1137.2756
[2023-08-31 22:47:44,524][26287] KL-divergence is very high: 195.3488
[2023-08-31 22:47:44,527][26287] KL-divergence is very high: 698.0276
[2023-08-31 22:47:44,529][26287] KL-divergence is very high: 1579.1729
[2023-08-31 22:47:44,532][26287] KL-divergence is very high: 1290.8077
[2023-08-31 22:47:44,739][26287] KL-divergence is very high: 191.0054
[2023-08-31 22:47:44,742][26287] KL-divergence is very high: 182.3411
[2023-08-31 22:47:44,745][26287] KL-divergence is very high: 168.8778
[2023-08-31 22:47:44,748][26287] KL-divergence is very high: 156.6831
[2023-08-31 22:47:44,962][26287] KL-divergence is very high: 105.7924
[2023-08-31 22:47:44,968][26287] KL-divergence is very high: 298.3463
[2023-08-31 22:47:44,971][26287] KL-divergence is very high: 417.1605
[2023-08-31 22:47:44,977][26287] KL-divergence is very high: 321.8337
[2023-08-31 22:47:44,980][26287] KL-divergence is very high: 687.4166
[2023-08-31 22:47:45,513][26287] KL-divergence is very high: 287.8270
[2023-08-31 22:47:45,516][26287] KL-divergence is very high: 157.7315
[2023-08-31 22:47:45,519][26287] KL-divergence is very high: 114.5072
[2023-08-31 22:47:47,016][26288] Updated weights for policy 0, policy_version 159272 (0.0002)
[2023-08-31 22:47:48,106][26276] Fps is (10 sec: 16794.2, 60 sec: 16111.9, 300 sec: 16064.7). Total num frames: 81563648. Throughput: 0: 16516.2. Samples: 69620971. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:47:48,106][26276] Avg episode reward: [(0, '-152416.709')]
[2023-08-31 22:47:49,436][26288] Updated weights for policy 0, policy_version 159352 (0.0002)
[2023-08-31 22:47:51,801][26288] Updated weights for policy 0, policy_version 159432 (0.0002)
[2023-08-31 22:47:52,514][26287] KL-divergence is very high: 160.6903
[2023-08-31 22:47:52,517][26287] KL-divergence is very high: 273.9647
[2023-08-31 22:47:52,524][26287] KL-divergence is very high: 171.0305
[2023-08-31 22:47:52,527][26287] KL-divergence is very high: 215.2833
[2023-08-31 22:47:52,748][26287] KL-divergence is very high: 485.2678
[2023-08-31 22:47:52,751][26287] KL-divergence is very high: 372.2432
[2023-08-31 22:47:52,754][26287] KL-divergence is very high: 4531.0806
[2023-08-31 22:47:52,757][26287] KL-divergence is very high: 564.7531
[2023-08-31 22:47:52,760][26287] KL-divergence is very high: 104.1345
[2023-08-31 22:47:52,764][26287] KL-divergence is very high: 1188.3186
[2023-08-31 22:47:52,766][26287] KL-divergence is very high: 880.9487
[2023-08-31 22:47:52,999][26287] KL-divergence is very high: 7247.3501
[2023-08-31 22:47:53,002][26287] KL-divergence is very high: 5369.4741
[2023-08-31 22:47:53,006][26287] KL-divergence is very high: 9505.3467
[2023-08-31 22:47:53,009][26287] KL-divergence is very high: 4874.9351
[2023-08-31 22:47:53,011][26287] KL-divergence is very high: 349.8632
[2023-08-31 22:47:53,014][26287] High loss value: l:53.2547 pl:0.0258 vl:0.7944 exp_l:0.0000 kl_l:52.4345 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:53,014][26287] KL-divergence is very high: 30020.8906
[2023-08-31 22:47:53,017][26287] High loss value: l:109.4736 pl:0.0239 vl:0.8050 exp_l:0.0000 kl_l:108.6447 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:53,017][26287] KL-divergence is very high: 52646.0000
[2023-08-31 22:47:53,110][26276] Fps is (10 sec: 16793.6, 60 sec: 16383.1, 300 sec: 16106.2). Total num frames: 81649664. Throughput: 0: 16712.8. Samples: 69722243. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:47:53,110][26276] Avg episode reward: [(0, '-152416.709')]
[2023-08-31 22:47:53,248][26287] KL-divergence is very high: 2193.8447
[2023-08-31 22:47:53,251][26287] KL-divergence is very high: 184.9925
[2023-08-31 22:47:53,255][26287] KL-divergence is very high: 937.7197
[2023-08-31 22:47:53,258][26287] KL-divergence is very high: 1277.8685
[2023-08-31 22:47:53,260][26287] KL-divergence is very high: 198.2903
[2023-08-31 22:47:53,263][26287] KL-divergence is very high: 624.3446
[2023-08-31 22:47:53,267][26287] KL-divergence is very high: 1796.3691
[2023-08-31 22:47:53,500][26287] KL-divergence is very high: 3306.9084
[2023-08-31 22:47:53,502][26287] KL-divergence is very high: 3516.0139
[2023-08-31 22:47:53,506][26287] KL-divergence is very high: 2031.1399
[2023-08-31 22:47:53,508][26287] KL-divergence is very high: 1145.9956
[2023-08-31 22:47:53,512][26287] KL-divergence is very high: 2397.8057
[2023-08-31 22:47:53,515][26287] KL-divergence is very high: 742.9863
[2023-08-31 22:47:53,517][26287] KL-divergence is very high: 3689.4382
[2023-08-31 22:47:53,747][26287] KL-divergence is very high: 2312.6379
[2023-08-31 22:47:53,751][26287] KL-divergence is very high: 2760.6602
[2023-08-31 22:47:53,753][26287] KL-divergence is very high: 1452.0691
[2023-08-31 22:47:53,756][26287] KL-divergence is very high: 590.6478
[2023-08-31 22:47:53,759][26287] KL-divergence is very high: 1027.4070
[2023-08-31 22:47:53,762][26287] KL-divergence is very high: 345.6491
[2023-08-31 22:47:53,765][26287] KL-divergence is very high: 1817.7104
[2023-08-31 22:47:54,027][26287] KL-divergence is very high: 5044.1133
[2023-08-31 22:47:54,031][26287] KL-divergence is very high: 5654.4375
[2023-08-31 22:47:54,034][26287] KL-divergence is very high: 619.3098
[2023-08-31 22:47:54,036][26287] KL-divergence is very high: 6451.9995
[2023-08-31 22:47:54,039][26287] KL-divergence is very high: 12356.2256
[2023-08-31 22:47:54,043][26287] KL-divergence is very high: 6868.0908
[2023-08-31 22:47:54,045][26287] KL-divergence is very high: 701.4499
[2023-08-31 22:47:54,261][26287] KL-divergence is very high: 13350.7568
[2023-08-31 22:47:54,264][26287] High loss value: l:51.8117 pl:0.0185 vl:0.4550 exp_l:0.0000 kl_l:51.3382 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:54,264][26287] KL-divergence is very high: 26899.1504
[2023-08-31 22:47:54,267][26287] High loss value: l:44.1478 pl:0.0042 vl:0.5115 exp_l:0.0000 kl_l:43.6321 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:47:54,267][26287] KL-divergence is very high: 23673.4570
[2023-08-31 22:47:54,270][26287] KL-divergence is very high: 8890.6426
[2023-08-31 22:47:54,272][26287] KL-divergence is very high: 2502.8877
[2023-08-31 22:47:54,275][26287] KL-divergence is very high: 8266.9209
[2023-08-31 22:47:54,278][26287] KL-divergence is very high: 8931.6416
[2023-08-31 22:47:54,281][26288] Updated weights for policy 0, policy_version 159512 (0.0002)
[2023-08-31 22:47:54,519][26287] KL-divergence is very high: 1118.9121
[2023-08-31 22:47:54,522][26287] KL-divergence is very high: 1461.8350
[2023-08-31 22:47:54,525][26287] KL-divergence is very high: 441.4116
[2023-08-31 22:47:54,528][26287] KL-divergence is very high: 1302.4401
[2023-08-31 22:47:54,531][26287] KL-divergence is very high: 2338.3022
[2023-08-31 22:47:54,534][26287] KL-divergence is very high: 1326.9271
[2023-08-31 22:47:54,537][26287] KL-divergence is very high: 148.0882
[2023-08-31 22:47:54,741][26287] KL-divergence is very high: 1014.5803
[2023-08-31 22:47:54,743][26287] KL-divergence is very high: 1136.3285
[2023-08-31 22:47:54,746][26287] KL-divergence is very high: 275.3319
[2023-08-31 22:47:54,749][26287] KL-divergence is very high: 1317.5222
[2023-08-31 22:47:54,752][26287] KL-divergence is very high: 2247.9382
[2023-08-31 22:47:54,755][26287] KL-divergence is very high: 1165.9435
[2023-08-31 22:47:54,758][26287] KL-divergence is very high: 179.5830
[2023-08-31 22:47:55,237][26287] KL-divergence is very high: 1882.0532
[2023-08-31 22:47:55,240][26287] KL-divergence is very high: 1235.5012
[2023-08-31 22:47:55,245][26287] KL-divergence is very high: 6467.5288
[2023-08-31 22:47:55,248][26287] KL-divergence is very high: 6086.2686
[2023-08-31 22:47:55,251][26287] KL-divergence is very high: 912.6516
[2023-08-31 22:47:56,929][26288] Updated weights for policy 0, policy_version 159592 (0.0002)
[2023-08-31 22:47:58,108][26276] Fps is (10 sec: 16381.1, 60 sec: 16383.8, 300 sec: 16092.4). Total num frames: 81727488. Throughput: 0: 16623.1. Samples: 69767799. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 22:47:58,108][26276] Avg episode reward: [(0, '-185373.156')]
[2023-08-31 22:47:59,283][26288] Updated weights for policy 0, policy_version 159672 (0.0002)
[2023-08-31 22:48:01,729][26288] Updated weights for policy 0, policy_version 159752 (0.0002)
[2023-08-31 22:48:03,110][26276] Fps is (10 sec: 16383.5, 60 sec: 16519.1, 300 sec: 16120.2). Total num frames: 81813504. Throughput: 0: 16676.3. Samples: 69870200. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 22:48:03,110][26276] Avg episode reward: [(0, '-185373.156')]
[2023-08-31 22:48:04,170][26288] Updated weights for policy 0, policy_version 159832 (0.0002)
[2023-08-31 22:48:06,787][26288] Updated weights for policy 0, policy_version 159912 (0.0002)
[2023-08-31 22:48:08,109][26276] Fps is (10 sec: 16791.8, 60 sec: 16656.8, 300 sec: 16134.0). Total num frames: 81895424. Throughput: 0: 16681.6. Samples: 69968973. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 22:48:08,109][26276] Avg episode reward: [(0, '-192022.214')]
[2023-08-31 22:48:09,109][26288] Updated weights for policy 0, policy_version 159992 (0.0002)
[2023-08-31 22:48:11,062][26287] KL-divergence is very high: 203.3417
[2023-08-31 22:48:11,554][26288] Updated weights for policy 0, policy_version 160072 (0.0002)
[2023-08-31 22:48:13,106][26276] Fps is (10 sec: 16799.9, 60 sec: 16656.9, 300 sec: 16161.9). Total num frames: 81981440. Throughput: 0: 16670.3. Samples: 70021136. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 22:48:13,107][26276] Avg episode reward: [(0, '-192022.214')]
[2023-08-31 22:48:13,931][26288] Updated weights for policy 0, policy_version 160152 (0.0002)
[2023-08-31 22:48:16,549][26288] Updated weights for policy 0, policy_version 160232 (0.0002)
[2023-08-31 22:48:18,109][26276] Fps is (10 sec: 16383.1, 60 sec: 16656.0, 300 sec: 16147.9). Total num frames: 82059264. Throughput: 0: 16659.3. Samples: 70119424. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 22:48:18,109][26276] Avg episode reward: [(0, '-182072.463')]
[2023-08-31 22:48:19,161][26288] Updated weights for policy 0, policy_version 160312 (0.0002)
[2023-08-31 22:48:21,568][26288] Updated weights for policy 0, policy_version 160392 (0.0002)
[2023-08-31 22:48:23,109][26276] Fps is (10 sec: 16379.3, 60 sec: 16657.3, 300 sec: 16175.6). Total num frames: 82145280. Throughput: 0: 16637.5. Samples: 70217973. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 22:48:23,110][26276] Avg episode reward: [(0, '-182072.463')]
[2023-08-31 22:48:24,068][26288] Updated weights for policy 0, policy_version 160472 (0.0002)
[2023-08-31 22:48:26,550][26288] Updated weights for policy 0, policy_version 160552 (0.0002)
[2023-08-31 22:48:28,108][26276] Fps is (10 sec: 16795.7, 60 sec: 16656.9, 300 sec: 16189.8). Total num frames: 82227200. Throughput: 0: 16523.9. Samples: 70265744. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 22:48:28,108][26276] Avg episode reward: [(0, '-165125.109')]
[2023-08-31 22:48:28,949][26288] Updated weights for policy 0, policy_version 160632 (0.0002)
[2023-08-31 22:48:30,951][26287] KL-divergence is very high: 148.3680
[2023-08-31 22:48:30,954][26287] KL-divergence is very high: 237.2827
[2023-08-31 22:48:31,172][26287] KL-divergence is very high: 232.0047
[2023-08-31 22:48:31,174][26287] KL-divergence is very high: 363.2569
[2023-08-31 22:48:31,178][26287] KL-divergence is very high: 153.8634
[2023-08-31 22:48:31,184][26287] KL-divergence is very high: 103.0782
[2023-08-31 22:48:31,190][26287] KL-divergence is very high: 166.0142
[2023-08-31 22:48:31,193][26288] Updated weights for policy 0, policy_version 160712 (0.0002)
[2023-08-31 22:48:33,106][26276] Fps is (10 sec: 16800.0, 60 sec: 16657.8, 300 sec: 16217.5). Total num frames: 82313216. Throughput: 0: 16670.3. Samples: 70371132. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 22:48:33,106][26276] Avg episode reward: [(0, '-165125.109')]
[2023-08-31 22:48:33,837][26288] Updated weights for policy 0, policy_version 160792 (0.0002)
[2023-08-31 22:48:36,195][26288] Updated weights for policy 0, policy_version 160872 (0.0002)
[2023-08-31 22:48:38,106][26276] Fps is (10 sec: 16796.5, 60 sec: 16657.0, 300 sec: 16217.5). Total num frames: 82395136. Throughput: 0: 16607.9. Samples: 70469534. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 22:48:38,106][26276] Avg episode reward: [(0, '-155475.231')]
[2023-08-31 22:48:38,715][26288] Updated weights for policy 0, policy_version 160952 (0.0002)
[2023-08-31 22:48:41,102][26288] Updated weights for policy 0, policy_version 161032 (0.0002)
[2023-08-31 22:48:43,107][26276] Fps is (10 sec: 16791.1, 60 sec: 16657.9, 300 sec: 16245.6). Total num frames: 82481152. Throughput: 0: 16721.5. Samples: 70520258. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 22:48:43,107][26276] Avg episode reward: [(0, '-155869.671')]
[2023-08-31 22:48:43,735][26288] Updated weights for policy 0, policy_version 161112 (0.0002)
[2023-08-31 22:48:46,095][26288] Updated weights for policy 0, policy_version 161192 (0.0002)
[2023-08-31 22:48:48,109][26276] Fps is (10 sec: 16789.7, 60 sec: 16656.3, 300 sec: 16231.5). Total num frames: 82563072. Throughput: 0: 16636.7. Samples: 70618824. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 22:48:48,109][26276] Avg episode reward: [(0, '-152248.103')]
[2023-08-31 22:48:48,449][26288] Updated weights for policy 0, policy_version 161272 (0.0002)
[2023-08-31 22:48:50,841][26288] Updated weights for policy 0, policy_version 161352 (0.0002)
[2023-08-31 22:48:53,108][26276] Fps is (10 sec: 16382.9, 60 sec: 16589.4, 300 sec: 16245.1). Total num frames: 82644992. Throughput: 0: 16731.8. Samples: 70721887. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 22:48:53,108][26276] Avg episode reward: [(0, '-119575.223')]
[2023-08-31 22:48:53,474][26288] Updated weights for policy 0, policy_version 161432 (0.0002)
[2023-08-31 22:48:55,846][26288] Updated weights for policy 0, policy_version 161512 (0.0002)
[2023-08-31 22:48:58,107][26276] Fps is (10 sec: 16796.3, 60 sec: 16725.5, 300 sec: 16259.1). Total num frames: 82731008. Throughput: 0: 16639.2. Samples: 70769908. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-08-31 22:48:58,107][26276] Avg episode reward: [(0, '-119575.223')]
[2023-08-31 22:48:58,155][26288] Updated weights for policy 0, policy_version 161592 (0.0002)
[2023-08-31 22:49:00,532][26288] Updated weights for policy 0, policy_version 161672 (0.0002)
[2023-08-31 22:49:03,110][26276] Fps is (10 sec: 16789.7, 60 sec: 16657.1, 300 sec: 16300.7). Total num frames: 82812928. Throughput: 0: 16757.1. Samples: 70873506. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:49:03,111][26276] Avg episode reward: [(0, '-104638.576')]
[2023-08-31 22:49:03,111][26288] Updated weights for policy 0, policy_version 161752 (0.0002)
[2023-08-31 22:49:03,113][26287] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000161752_82817024.pth...
[2023-08-31 22:49:03,115][26287] Removing /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000155344_79536128.pth
[2023-08-31 22:49:05,609][26288] Updated weights for policy 0, policy_version 161832 (0.0002)
[2023-08-31 22:49:08,059][26288] Updated weights for policy 0, policy_version 161912 (0.0002)
[2023-08-31 22:49:08,107][26276] Fps is (10 sec: 16794.2, 60 sec: 16725.9, 300 sec: 16370.3). Total num frames: 82898944. Throughput: 0: 16733.3. Samples: 70970925. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:49:08,107][26276] Avg episode reward: [(0, '-104638.576')]
[2023-08-31 22:49:10,483][26288] Updated weights for policy 0, policy_version 161992 (0.0002)
[2023-08-31 22:49:13,084][26288] Updated weights for policy 0, policy_version 162072 (0.0002)
[2023-08-31 22:49:13,107][26276] Fps is (10 sec: 16798.4, 60 sec: 16656.9, 300 sec: 16370.1). Total num frames: 82980864. Throughput: 0: 16789.5. Samples: 71021260. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:49:13,107][26276] Avg episode reward: [(0, '-84207.706')]
[2023-08-31 22:49:15,459][26288] Updated weights for policy 0, policy_version 162152 (0.0002)
[2023-08-31 22:49:17,832][26288] Updated weights for policy 0, policy_version 162232 (0.0002)
[2023-08-31 22:49:18,110][26276] Fps is (10 sec: 16787.6, 60 sec: 16793.3, 300 sec: 16411.8). Total num frames: 83066880. Throughput: 0: 16651.4. Samples: 71120520. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:49:18,110][26276] Avg episode reward: [(0, '-84207.706')]
[2023-08-31 22:49:20,182][26288] Updated weights for policy 0, policy_version 162312 (0.0002)
[2023-08-31 22:49:22,840][26288] Updated weights for policy 0, policy_version 162392 (0.0002)
[2023-08-31 22:49:23,110][26276] Fps is (10 sec: 16788.8, 60 sec: 16725.2, 300 sec: 16397.7). Total num frames: 83148800. Throughput: 0: 16667.8. Samples: 71219646. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:49:23,110][26276] Avg episode reward: [(0, '-69788.875')]
[2023-08-31 22:49:25,381][26288] Updated weights for policy 0, policy_version 162472 (0.0002)
[2023-08-31 22:49:27,838][26288] Updated weights for policy 0, policy_version 162552 (0.0002)
[2023-08-31 22:49:28,105][26276] Fps is (10 sec: 16392.1, 60 sec: 16726.1, 300 sec: 16412.0). Total num frames: 83230720. Throughput: 0: 16651.6. Samples: 71269549. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:49:28,105][26276] Avg episode reward: [(0, '-69788.875')]
[2023-08-31 22:49:30,333][26288] Updated weights for policy 0, policy_version 162632 (0.0002)
[2023-08-31 22:49:32,869][26288] Updated weights for policy 0, policy_version 162712 (0.0002)
[2023-08-31 22:49:33,106][26276] Fps is (10 sec: 15980.1, 60 sec: 16588.6, 300 sec: 16397.8). Total num frames: 83308544. Throughput: 0: 16630.0. Samples: 71367140. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:49:33,108][26276] Avg episode reward: [(0, '-68601.805')]
[2023-08-31 22:49:35,294][26288] Updated weights for policy 0, policy_version 162792 (0.0002)
[2023-08-31 22:49:37,808][26288] Updated weights for policy 0, policy_version 162872 (0.0002)
[2023-08-31 22:49:38,106][26276] Fps is (10 sec: 16381.9, 60 sec: 16657.0, 300 sec: 16412.0). Total num frames: 83394560. Throughput: 0: 16566.7. Samples: 71467367. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:49:38,107][26276] Avg episode reward: [(0, '-68601.805')]
[2023-08-31 22:49:40,192][26288] Updated weights for policy 0, policy_version 162952 (0.0002)
[2023-08-31 22:49:42,780][26288] Updated weights for policy 0, policy_version 163032 (0.0002)
[2023-08-31 22:49:43,108][26276] Fps is (10 sec: 16791.0, 60 sec: 16588.5, 300 sec: 16397.8). Total num frames: 83476480. Throughput: 0: 16626.8. Samples: 71518131. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:49:43,108][26276] Avg episode reward: [(0, '-57376.025')]
[2023-08-31 22:49:45,241][26288] Updated weights for policy 0, policy_version 163112 (0.0002)
[2023-08-31 22:49:47,715][26288] Updated weights for policy 0, policy_version 163192 (0.0002)
[2023-08-31 22:49:48,107][26276] Fps is (10 sec: 16383.6, 60 sec: 16589.3, 300 sec: 16411.7). Total num frames: 83558400. Throughput: 0: 16504.8. Samples: 71616166. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:49:48,107][26276] Avg episode reward: [(0, '-57376.025')]
[2023-08-31 22:49:50,165][26288] Updated weights for policy 0, policy_version 163272 (0.0002)
[2023-08-31 22:49:52,824][26288] Updated weights for policy 0, policy_version 163352 (0.0002)
[2023-08-31 22:49:53,106][26276] Fps is (10 sec: 16386.9, 60 sec: 16589.2, 300 sec: 16398.1). Total num frames: 83640320. Throughput: 0: 16485.9. Samples: 71712784. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:49:53,106][26276] Avg episode reward: [(0, '-52460.074')]
[2023-08-31 22:49:55,294][26288] Updated weights for policy 0, policy_version 163432 (0.0002)
[2023-08-31 22:49:57,402][26287] High loss value: l:34.2274 pl:0.0625 vl:1.4688 exp_l:0.0000 kl_l:32.6961 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:49:57,403][26287] KL-divergence is very high: 9468.3301
[2023-08-31 22:49:57,406][26287] KL-divergence is very high: 3897.9976
[2023-08-31 22:49:57,413][26287] High loss value: l:146.7381 pl:0.0622 vl:1.3407 exp_l:0.0000 kl_l:145.3352 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:49:57,413][26287] KL-divergence is very high: 43016.5117
[2023-08-31 22:49:57,417][26287] High loss value: l:142.6348 pl:0.0370 vl:1.7026 exp_l:0.0000 kl_l:140.8952 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:49:57,417][26287] KL-divergence is very high: 38617.0156
[2023-08-31 22:49:57,662][26287] KL-divergence is very high: 1018.1391
[2023-08-31 22:49:57,665][26287] KL-divergence is very high: 993.5601
[2023-08-31 22:49:57,668][26287] KL-divergence is very high: 1545.3772
[2023-08-31 22:49:57,674][26287] KL-divergence is very high: 527.6652
[2023-08-31 22:49:57,677][26287] KL-divergence is very high: 1045.9039
[2023-08-31 22:49:57,680][26287] KL-divergence is very high: 1530.8470
[2023-08-31 22:49:57,682][26288] Updated weights for policy 0, policy_version 163512 (0.0002)
[2023-08-31 22:49:57,906][26287] High loss value: l:57.8177 pl:-0.0315 vl:1.9106 exp_l:0.0000 kl_l:55.9385 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:49:57,906][26287] KL-divergence is very high: 5066.1157
[2023-08-31 22:49:57,909][26287] High loss value: l:69.1861 pl:-0.0104 vl:1.8965 exp_l:0.0000 kl_l:67.3000 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:49:57,909][26287] KL-divergence is very high: 5931.4824
[2023-08-31 22:49:57,912][26287] KL-divergence is very high: 2206.6187
[2023-08-31 22:49:57,915][26287] KL-divergence is very high: 1804.2583
[2023-08-31 22:49:57,918][26287] High loss value: l:32.1686 pl:-0.0254 vl:1.8641 exp_l:0.0000 kl_l:30.3298 (recommended to adjust the --reward_scale parameter)
[2023-08-31 22:49:57,918][26287] KL-divergence is very high: 2546.8223
[2023-08-31 22:49:57,921][26287] KL-divergence is very high: 885.4146
[2023-08-31 22:49:57,925][26287] KL-divergence is very high: 1552.6525
[2023-08-31 22:49:58,110][26276] Fps is (10 sec: 16378.8, 60 sec: 16519.7, 300 sec: 16397.8). Total num frames: 83722240. Throughput: 0: 16458.6. Samples: 71761940. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 22:49:58,110][26276] Avg episode reward: [(0, '-52460.074')]
[2023-08-31 22:49:58,160][26287] KL-divergence is very high: 382.5095
[2023-08-31 22:49:58,162][26287] KL-divergence is very high: 173.6282
[2023-08-31 22:49:58,165][26287] KL-divergence is very high: 318.7671
[2023-08-31 22:49:58,168][26287] KL-divergence is very high: 530.7676
[2023-08-31 22:49:58,173][26287] KL-divergence is very high: 650.5579
[2023-08-31 22:49:58,176][26287] KL-divergence is very high: 809.4477
[2023-08-31 22:49:58,388][26287] KL-divergence is very high: 163.6722
[2023-08-31 22:49:58,398][26287] KL-divergence is very high: 102.9155
[2023-08-31 22:49:58,401][26287] KL-divergence is very high: 101.2475
[2023-08-31 22:50:00,105][26288] Updated weights for policy 0, policy_version 163592 (0.0002)
[2023-08-31 22:50:02,438][26287] KL-divergence is very high: 108.2247
[2023-08-31 22:50:02,449][26287] KL-divergence is very high: 195.8815
[2023-08-31 22:50:02,656][26287] KL-divergence is very high: 131.5095
[2023-08-31 22:50:02,667][26288] Updated weights for policy 0, policy_version 163672 (0.0003)
[2023-08-31 22:50:03,110][26276] Fps is (10 sec: 16377.8, 60 sec: 16520.6, 300 sec: 16397.9). Total num frames: 83804160. Throughput: 0: 16438.3. Samples: 71860242. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 22:50:03,110][26276] Avg episode reward: [(0, '-61483.426')]
[2023-08-31 22:50:04,912][26288] Updated weights for policy 0, policy_version 163752 (0.0002)
[2023-08-31 22:50:07,217][26288] Updated weights for policy 0, policy_version 163832 (0.0002)
[2023-08-31 22:50:08,110][26276] Fps is (10 sec: 17202.9, 60 sec: 16587.8, 300 sec: 16425.6). Total num frames: 83894272. Throughput: 0: 16615.2. Samples: 71967332. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 22:50:08,110][26276] Avg episode reward: [(0, '-61483.426')]
[2023-08-31 22:50:09,896][26288] Updated weights for policy 0, policy_version 163912 (0.0002)
[2023-08-31 22:50:12,312][26288] Updated weights for policy 0, policy_version 163992 (0.0002)
[2023-08-31 22:50:13,110][26276] Fps is (10 sec: 17203.2, 60 sec: 16588.0, 300 sec: 16425.7). Total num frames: 83976192. Throughput: 0: 16563.3. Samples: 72014975. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 22:50:13,110][26276] Avg episode reward: [(0, '-19254.757')]
[2023-08-31 22:50:14,650][26288] Updated weights for policy 0, policy_version 164072 (0.0002)
[2023-08-31 22:50:17,097][26288] Updated weights for policy 0, policy_version 164152 (0.0002)
[2023-08-31 22:50:18,110][26276] Fps is (10 sec: 16793.3, 60 sec: 16588.8, 300 sec: 16425.5). Total num frames: 84062208. Throughput: 0: 16675.2. Samples: 72117587. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 22:50:18,110][26276] Avg episode reward: [(0, '-19254.757')]
[2023-08-31 22:50:19,663][26288] Updated weights for policy 0, policy_version 164232 (0.0002)
[2023-08-31 22:50:22,004][26288] Updated weights for policy 0, policy_version 164312 (0.0002)
[2023-08-31 22:50:23,106][26276] Fps is (10 sec: 16799.4, 60 sec: 16589.8, 300 sec: 16439.7). Total num frames: 84144128. Throughput: 0: 16679.1. Samples: 72217926. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 22:50:23,107][26276] Avg episode reward: [(0, '-41064.844')]
[2023-08-31 22:50:24,402][26288] Updated weights for policy 0, policy_version 164392 (0.0002)
[2023-08-31 22:50:26,790][26288] Updated weights for policy 0, policy_version 164472 (0.0002)
[2023-08-31 22:50:28,109][26276] Fps is (10 sec: 16795.8, 60 sec: 16656.0, 300 sec: 16425.5). Total num frames: 84230144. Throughput: 0: 16682.5. Samples: 72268860. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 22:50:28,109][26276] Avg episode reward: [(0, '-41064.844')]
[2023-08-31 22:50:29,341][26288] Updated weights for policy 0, policy_version 164552 (0.0002)
[2023-08-31 22:50:31,756][26288] Updated weights for policy 0, policy_version 164632 (0.0002)
[2023-08-31 22:50:33,106][26276] Fps is (10 sec: 16793.7, 60 sec: 16725.3, 300 sec: 16439.5). Total num frames: 84312064. Throughput: 0: 16711.3. Samples: 72368169. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 22:50:33,107][26276] Avg episode reward: [(0, '-70886.632')]
[2023-08-31 22:50:34,103][26288] Updated weights for policy 0, policy_version 164712 (0.0002)
[2023-08-31 22:50:36,533][26288] Updated weights for policy 0, policy_version 164792 (0.0002)
[2023-08-31 22:50:38,110][26276] Fps is (10 sec: 16791.8, 60 sec: 16724.3, 300 sec: 16481.2). Total num frames: 84398080. Throughput: 0: 16839.2. Samples: 72470612. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 22:50:38,111][26276] Avg episode reward: [(0, '-70886.632')]
[2023-08-31 22:50:39,184][26288] Updated weights for policy 0, policy_version 164872 (0.0002)
[2023-08-31 22:50:41,496][26288] Updated weights for policy 0, policy_version 164952 (0.0002)
[2023-08-31 22:50:43,107][26276] Fps is (10 sec: 16793.2, 60 sec: 16725.7, 300 sec: 16481.2). Total num frames: 84480000. Throughput: 0: 16823.2. Samples: 72518932. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 22:50:43,107][26276] Avg episode reward: [(0, '-84661.708')]
[2023-08-31 22:50:43,110][26287] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000165000_84480000.pth...
[2023-08-31 22:50:43,112][26287] Removing /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000158488_81145856.pth
[2023-08-31 22:50:43,971][26288] Updated weights for policy 0, policy_version 165032 (0.0002)
[2023-08-31 22:50:46,843][26288] Updated weights for policy 0, policy_version 165112 (0.0003)
[2023-08-31 22:50:48,107][26276] Fps is (10 sec: 14750.7, 60 sec: 16452.3, 300 sec: 16411.9). Total num frames: 84545536. Throughput: 0: 16812.1. Samples: 72616732. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 22:50:48,107][26276] Avg episode reward: [(0, '-84661.708')]
[2023-08-31 22:50:51,082][26288] Updated weights for policy 0, policy_version 165192 (0.0003)
[2023-08-31 22:50:53,107][26276] Fps is (10 sec: 12697.5, 60 sec: 16110.8, 300 sec: 16342.3). Total num frames: 84606976. Throughput: 0: 15862.4. Samples: 72681089. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 22:50:53,107][26276] Avg episode reward: [(0, '-90928.625')]
[2023-08-31 22:50:53,747][26288] Updated weights for policy 0, policy_version 165272 (0.0002)
[2023-08-31 22:50:56,298][26288] Updated weights for policy 0, policy_version 165352 (0.0002)
[2023-08-31 22:50:58,105][26276] Fps is (10 sec: 13928.1, 60 sec: 16043.9, 300 sec: 16314.7). Total num frames: 84684800. Throughput: 0: 15878.1. Samples: 72729419. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 22:50:58,106][26276] Avg episode reward: [(0, '-90928.625')]
[2023-08-31 22:50:58,919][26288] Updated weights for policy 0, policy_version 165432 (0.0002)
[2023-08-31 22:51:01,588][26288] Updated weights for policy 0, policy_version 165512 (0.0002)
[2023-08-31 22:51:03,109][26276] Fps is (10 sec: 15971.2, 60 sec: 16043.0, 300 sec: 16328.3). Total num frames: 84766720. Throughput: 0: 15642.9. Samples: 72821495. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:51:03,109][26276] Avg episode reward: [(0, '-78693.646')]
[2023-08-31 22:51:03,411][26287] KL-divergence is very high: 111.2380
[2023-08-31 22:51:03,859][26288] Updated weights for policy 0, policy_version 165592 (0.0002)
[2023-08-31 22:51:06,287][26288] Updated weights for policy 0, policy_version 165672 (0.0002)
[2023-08-31 22:51:08,106][26276] Fps is (10 sec: 16792.7, 60 sec: 15975.5, 300 sec: 16328.5). Total num frames: 84852736. Throughput: 0: 15738.1. Samples: 72926133. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:51:08,106][26276] Avg episode reward: [(0, '-78693.646')]
[2023-08-31 22:51:08,586][26288] Updated weights for policy 0, policy_version 165752 (0.0002)
[2023-08-31 22:51:11,113][26288] Updated weights for policy 0, policy_version 165832 (0.0002)
[2023-08-31 22:51:13,107][26276] Fps is (10 sec: 17206.6, 60 sec: 16043.5, 300 sec: 16342.4). Total num frames: 84938752. Throughput: 0: 15729.0. Samples: 72976631. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:51:13,107][26276] Avg episode reward: [(0, '-172064.153')]
[2023-08-31 22:51:13,513][26288] Updated weights for policy 0, policy_version 165912 (0.0002)
[2023-08-31 22:51:16,105][26288] Updated weights for policy 0, policy_version 165992 (0.0002)
[2023-08-31 22:51:18,108][26276] Fps is (10 sec: 16379.8, 60 sec: 15906.6, 300 sec: 16328.3). Total num frames: 85016576. Throughput: 0: 15701.6. Samples: 73074774. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:51:18,110][26276] Avg episode reward: [(0, '-172064.153')]
[2023-08-31 22:51:18,818][26288] Updated weights for policy 0, policy_version 166072 (0.0003)
[2023-08-31 22:51:21,558][26288] Updated weights for policy 0, policy_version 166152 (0.0002)
[2023-08-31 22:51:23,109][26276] Fps is (10 sec: 15560.6, 60 sec: 15837.1, 300 sec: 16314.4). Total num frames: 85094400. Throughput: 0: 15483.9. Samples: 73167378. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:51:23,111][26276] Avg episode reward: [(0, '-221609.059')]
[2023-08-31 22:51:24,078][26288] Updated weights for policy 0, policy_version 166232 (0.0002)
[2023-08-31 22:51:26,537][26288] Updated weights for policy 0, policy_version 166312 (0.0002)
[2023-08-31 22:51:28,107][26276] Fps is (10 sec: 15977.3, 60 sec: 15770.2, 300 sec: 16314.6). Total num frames: 85176320. Throughput: 0: 15496.4. Samples: 73216271. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:51:28,107][26276] Avg episode reward: [(0, '-221609.059')]
[2023-08-31 22:51:28,931][26288] Updated weights for policy 0, policy_version 166392 (0.0002)
[2023-08-31 22:51:31,522][26288] Updated weights for policy 0, policy_version 166472 (0.0002)
[2023-08-31 22:51:33,110][26276] Fps is (10 sec: 16382.7, 60 sec: 15768.6, 300 sec: 16328.3). Total num frames: 85258240. Throughput: 0: 15510.8. Samples: 73314776. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:51:33,110][26276] Avg episode reward: [(0, '-184885.077')]
[2023-08-31 22:51:33,999][26288] Updated weights for policy 0, policy_version 166552 (0.0002)
[2023-08-31 22:51:36,375][26288] Updated weights for policy 0, policy_version 166632 (0.0002)
[2023-08-31 22:51:38,109][26276] Fps is (10 sec: 16379.6, 60 sec: 15701.5, 300 sec: 16328.2). Total num frames: 85340160. Throughput: 0: 16339.3. Samples: 73416398. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:51:38,110][26276] Avg episode reward: [(0, '-184885.077')]
[2023-08-31 22:51:38,855][26288] Updated weights for policy 0, policy_version 166712 (0.0002)
[2023-08-31 22:51:41,563][26288] Updated weights for policy 0, policy_version 166792 (0.0002)
[2023-08-31 22:51:43,108][26276] Fps is (10 sec: 16387.5, 60 sec: 15701.0, 300 sec: 16356.3). Total num frames: 85422080. Throughput: 0: 16248.3. Samples: 73460636. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:51:43,108][26276] Avg episode reward: [(0, '-158725.387')]
[2023-08-31 22:51:44,017][26288] Updated weights for policy 0, policy_version 166872 (0.0002)
[2023-08-31 22:51:46,456][26288] Updated weights for policy 0, policy_version 166952 (0.0002)
[2023-08-31 22:51:48,108][26276] Fps is (10 sec: 16386.1, 60 sec: 15974.0, 300 sec: 16397.8). Total num frames: 85504000. Throughput: 0: 16449.0. Samples: 73561690. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:51:48,108][26276] Avg episode reward: [(0, '-158725.387')]
[2023-08-31 22:51:48,872][26288] Updated weights for policy 0, policy_version 167032 (0.0002)
[2023-08-31 22:51:51,495][26288] Updated weights for policy 0, policy_version 167112 (0.0002)
[2023-08-31 22:51:53,110][26276] Fps is (10 sec: 16790.5, 60 sec: 16383.1, 300 sec: 16425.5). Total num frames: 85590016. Throughput: 0: 16322.5. Samples: 73660713. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:51:53,110][26276] Avg episode reward: [(0, '-166403.704')]
[2023-08-31 22:51:53,767][26288] Updated weights for policy 0, policy_version 167192 (0.0002)
[2023-08-31 22:51:56,046][26288] Updated weights for policy 0, policy_version 167272 (0.0002)
[2023-08-31 22:51:58,108][26276] Fps is (10 sec: 17612.5, 60 sec: 16588.0, 300 sec: 16467.1). Total num frames: 85680128. Throughput: 0: 16423.8. Samples: 73715728. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:51:58,111][26276] Avg episode reward: [(0, '-166403.704')]
[2023-08-31 22:51:58,457][26288] Updated weights for policy 0, policy_version 167352 (0.0002)
[2023-08-31 22:52:00,780][26288] Updated weights for policy 0, policy_version 167432 (0.0002)
[2023-08-31 22:52:03,106][26276] Fps is (10 sec: 17209.6, 60 sec: 16589.5, 300 sec: 16495.2). Total num frames: 85762048. Throughput: 0: 16520.8. Samples: 73818175. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:52:03,106][26276] Avg episode reward: [(0, '-248901.325')]
[2023-08-31 22:52:03,166][26288] Updated weights for policy 0, policy_version 167512 (0.0002)
[2023-08-31 22:52:05,435][26288] Updated weights for policy 0, policy_version 167592 (0.0002)
[2023-08-31 22:52:08,015][26288] Updated weights for policy 0, policy_version 167672 (0.0002)
[2023-08-31 22:52:08,108][26276] Fps is (10 sec: 16793.2, 60 sec: 16588.1, 300 sec: 16494.9). Total num frames: 85848064. Throughput: 0: 16832.5. Samples: 73924825. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:52:08,109][26276] Avg episode reward: [(0, '-283017.665')]
[2023-08-31 22:52:10,478][26288] Updated weights for policy 0, policy_version 167752 (0.0002)
[2023-08-31 22:52:12,976][26288] Updated weights for policy 0, policy_version 167832 (0.0002)
[2023-08-31 22:52:13,108][26276] Fps is (10 sec: 16791.5, 60 sec: 16520.3, 300 sec: 16508.8). Total num frames: 85929984. Throughput: 0: 16773.3. Samples: 73971086. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:52:13,108][26276] Avg episode reward: [(0, '-283017.665')]
[2023-08-31 22:52:15,352][26288] Updated weights for policy 0, policy_version 167912 (0.0002)
[2023-08-31 22:52:18,005][26288] Updated weights for policy 0, policy_version 167992 (0.0002)
[2023-08-31 22:52:18,106][26276] Fps is (10 sec: 16387.2, 60 sec: 16589.3, 300 sec: 16495.3). Total num frames: 86011904. Throughput: 0: 16846.1. Samples: 74072785. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:52:18,107][26276] Avg episode reward: [(0, '-233391.696')]
[2023-08-31 22:52:20,311][26288] Updated weights for policy 0, policy_version 168072 (0.0002)
[2023-08-31 22:52:22,682][26288] Updated weights for policy 0, policy_version 168152 (0.0002)
[2023-08-31 22:52:23,106][26276] Fps is (10 sec: 16796.1, 60 sec: 16726.3, 300 sec: 16509.0). Total num frames: 86097920. Throughput: 0: 16782.5. Samples: 74171555. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:52:23,106][26276] Avg episode reward: [(0, '-233391.696')]
[2023-08-31 22:52:23,110][26287] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000168160_86097920.pth...
[2023-08-31 22:52:23,113][26287] Removing /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000161752_82817024.pth
[2023-08-31 22:52:25,127][26288] Updated weights for policy 0, policy_version 168232 (0.0002)
[2023-08-31 22:52:27,853][26288] Updated weights for policy 0, policy_version 168312 (0.0002)
[2023-08-31 22:52:28,107][26276] Fps is (10 sec: 16383.8, 60 sec: 16657.1, 300 sec: 16481.3). Total num frames: 86175744. Throughput: 0: 16939.0. Samples: 74222867. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:52:28,107][26276] Avg episode reward: [(0, '-253492.789')]
[2023-08-31 22:52:30,244][26288] Updated weights for policy 0, policy_version 168392 (0.0002)
[2023-08-31 22:52:32,508][26288] Updated weights for policy 0, policy_version 168472 (0.0002)
[2023-08-31 22:52:33,107][26276] Fps is (10 sec: 16792.1, 60 sec: 16794.5, 300 sec: 16508.9). Total num frames: 86265856. Throughput: 0: 16882.5. Samples: 74321383. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:52:33,107][26276] Avg episode reward: [(0, '-253492.789')]
[2023-08-31 22:52:34,827][26288] Updated weights for policy 0, policy_version 168552 (0.0002)
[2023-08-31 22:52:37,517][26288] Updated weights for policy 0, policy_version 168632 (0.0002)
[2023-08-31 22:52:38,106][26276] Fps is (10 sec: 17204.6, 60 sec: 16794.6, 300 sec: 16495.3). Total num frames: 86347776. Throughput: 0: 16889.8. Samples: 74420683. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:52:38,106][26276] Avg episode reward: [(0, '-346676.988')]
[2023-08-31 22:52:39,882][26288] Updated weights for policy 0, policy_version 168712 (0.0002)
[2023-08-31 22:52:42,188][26288] Updated weights for policy 0, policy_version 168792 (0.0002)
[2023-08-31 22:52:43,106][26276] Fps is (10 sec: 16794.9, 60 sec: 16862.4, 300 sec: 16508.9). Total num frames: 86433792. Throughput: 0: 16831.6. Samples: 74473117. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:52:43,106][26276] Avg episode reward: [(0, '-346676.988')]
[2023-08-31 22:52:44,598][26288] Updated weights for policy 0, policy_version 168872 (0.0002)
[2023-08-31 22:52:47,202][26288] Updated weights for policy 0, policy_version 168952 (0.0002)
[2023-08-31 22:52:48,108][26276] Fps is (10 sec: 16790.5, 60 sec: 16862.0, 300 sec: 16495.2). Total num frames: 86515712. Throughput: 0: 16746.5. Samples: 74571792. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:52:48,108][26276] Avg episode reward: [(0, '-460133.784')]
[2023-08-31 22:52:49,636][26288] Updated weights for policy 0, policy_version 169032 (0.0002)
[2023-08-31 22:52:51,956][26288] Updated weights for policy 0, policy_version 169112 (0.0002)
[2023-08-31 22:52:53,106][26276] Fps is (10 sec: 17203.7, 60 sec: 16931.3, 300 sec: 16536.8). Total num frames: 86605824. Throughput: 0: 16702.9. Samples: 74676414. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:52:53,106][26276] Avg episode reward: [(0, '-460133.784')]
[2023-08-31 22:52:54,272][26288] Updated weights for policy 0, policy_version 169192 (0.0002)
[2023-08-31 22:52:56,832][26288] Updated weights for policy 0, policy_version 169272 (0.0002)
[2023-08-31 22:52:58,110][26276] Fps is (10 sec: 17198.8, 60 sec: 16793.1, 300 sec: 16522.9). Total num frames: 86687744. Throughput: 0: 16807.0. Samples: 74727445. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:52:58,111][26276] Avg episode reward: [(0, '-440011.511')]
[2023-08-31 22:52:59,204][26288] Updated weights for policy 0, policy_version 169352 (0.0002)
[2023-08-31 22:53:01,537][26288] Updated weights for policy 0, policy_version 169432 (0.0002)
[2023-08-31 22:53:03,106][26276] Fps is (10 sec: 16793.7, 60 sec: 16862.0, 300 sec: 16536.9). Total num frames: 86773760. Throughput: 0: 16821.5. Samples: 74829741. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:53:03,106][26276] Avg episode reward: [(0, '-440011.511')]
[2023-08-31 22:53:03,943][26288] Updated weights for policy 0, policy_version 169512 (0.0002)
[2023-08-31 22:53:06,712][26288] Updated weights for policy 0, policy_version 169592 (0.0002)
[2023-08-31 22:53:08,110][26276] Fps is (10 sec: 16384.5, 60 sec: 16724.9, 300 sec: 16508.8). Total num frames: 86851584. Throughput: 0: 16777.5. Samples: 74926607. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:53:08,110][26276] Avg episode reward: [(0, '-411930.173')]
[2023-08-31 22:53:09,072][26288] Updated weights for policy 0, policy_version 169672 (0.0002)
[2023-08-31 22:53:11,366][26288] Updated weights for policy 0, policy_version 169752 (0.0002)
[2023-08-31 22:53:13,110][26276] Fps is (10 sec: 16786.6, 60 sec: 16861.2, 300 sec: 16550.6). Total num frames: 86941696. Throughput: 0: 16779.5. Samples: 74978004. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:53:13,111][26276] Avg episode reward: [(0, '-411930.173')]
[2023-08-31 22:53:13,752][26288] Updated weights for policy 0, policy_version 169832 (0.0002)
[2023-08-31 22:53:16,306][26288] Updated weights for policy 0, policy_version 169912 (0.0002)
[2023-08-31 22:53:18,110][26276] Fps is (10 sec: 17202.6, 60 sec: 16860.8, 300 sec: 16536.7). Total num frames: 87023616. Throughput: 0: 16850.4. Samples: 75079705. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:53:18,110][26276] Avg episode reward: [(0, '-461956.636')]
[2023-08-31 22:53:18,596][26288] Updated weights for policy 0, policy_version 169992 (0.0002)
[2023-08-31 22:53:20,807][26288] Updated weights for policy 0, policy_version 170072 (0.0002)
[2023-08-31 22:53:23,006][26288] Updated weights for policy 0, policy_version 170152 (0.0002)
[2023-08-31 22:53:23,110][26276] Fps is (10 sec: 17612.7, 60 sec: 16997.3, 300 sec: 16578.3). Total num frames: 87117824. Throughput: 0: 17091.7. Samples: 75189884. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:53:23,110][26276] Avg episode reward: [(0, '-461956.636')]
[2023-08-31 22:53:25,669][26288] Updated weights for policy 0, policy_version 170232 (0.0002)
[2023-08-31 22:53:27,967][26288] Updated weights for policy 0, policy_version 170312 (0.0003)
[2023-08-31 22:53:28,107][26276] Fps is (10 sec: 17619.3, 60 sec: 17066.7, 300 sec: 16564.4). Total num frames: 87199744. Throughput: 0: 16977.6. Samples: 75237112. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:53:28,107][26276] Avg episode reward: [(0, '-545426.896')]
[2023-08-31 22:53:30,446][26288] Updated weights for policy 0, policy_version 170392 (0.0002)
[2023-08-31 22:53:32,784][26288] Updated weights for policy 0, policy_version 170472 (0.0002)
[2023-08-31 22:53:33,106][26276] Fps is (10 sec: 16391.2, 60 sec: 16930.5, 300 sec: 16564.5). Total num frames: 87281664. Throughput: 0: 17096.1. Samples: 75341085. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:53:33,106][26276] Avg episode reward: [(0, '-521691.335')]
[2023-08-31 22:53:35,440][26288] Updated weights for policy 0, policy_version 170552 (0.0002)
[2023-08-31 22:53:37,801][26288] Updated weights for policy 0, policy_version 170632 (0.0002)
[2023-08-31 22:53:38,107][26276] Fps is (10 sec: 16793.6, 60 sec: 16998.2, 300 sec: 16564.5). Total num frames: 87367680. Throughput: 0: 16963.0. Samples: 75439758. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:53:38,107][26276] Avg episode reward: [(0, '-516079.462')]
[2023-08-31 22:53:40,232][26288] Updated weights for policy 0, policy_version 170712 (0.0002)
[2023-08-31 22:53:42,883][26288] Updated weights for policy 0, policy_version 170792 (0.0002)
[2023-08-31 22:53:43,110][26276] Fps is (10 sec: 16377.0, 60 sec: 16860.8, 300 sec: 16550.5). Total num frames: 87445504. Throughput: 0: 16953.7. Samples: 75490359. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:53:43,110][26276] Avg episode reward: [(0, '-461568.525')]
[2023-08-31 22:53:45,313][26288] Updated weights for policy 0, policy_version 170872 (0.0002)
[2023-08-31 22:53:47,803][26288] Updated weights for policy 0, policy_version 170952 (0.0002)
[2023-08-31 22:53:48,107][26276] Fps is (10 sec: 16384.0, 60 sec: 16930.4, 300 sec: 16564.6). Total num frames: 87531520. Throughput: 0: 16841.7. Samples: 75587629. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:53:48,107][26276] Avg episode reward: [(0, '-461568.525')]
[2023-08-31 22:53:50,254][26288] Updated weights for policy 0, policy_version 171032 (0.0002)
[2023-08-31 22:53:53,076][26288] Updated weights for policy 0, policy_version 171112 (0.0002)
[2023-08-31 22:53:53,107][26276] Fps is (10 sec: 16389.2, 60 sec: 16725.1, 300 sec: 16536.7). Total num frames: 87609344. Throughput: 0: 16874.6. Samples: 75685914. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:53:53,107][26276] Avg episode reward: [(0, '-390506.663')]
[2023-08-31 22:53:55,376][26288] Updated weights for policy 0, policy_version 171192 (0.0002)
[2023-08-31 22:53:57,866][26288] Updated weights for policy 0, policy_version 171272 (0.0002)
[2023-08-31 22:53:58,108][26276] Fps is (10 sec: 16381.6, 60 sec: 16794.2, 300 sec: 16550.7). Total num frames: 87695360. Throughput: 0: 16798.2. Samples: 75733889. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:53:58,108][26276] Avg episode reward: [(0, '-390506.663')]
[2023-08-31 22:54:00,164][26288] Updated weights for policy 0, policy_version 171352 (0.0002)
[2023-08-31 22:54:02,836][26288] Updated weights for policy 0, policy_version 171432 (0.0002)
[2023-08-31 22:54:03,106][26276] Fps is (10 sec: 16794.9, 60 sec: 16725.3, 300 sec: 16536.8). Total num frames: 87777280. Throughput: 0: 16815.0. Samples: 75836310. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:54:03,106][26276] Avg episode reward: [(0, '-381168.997')]
[2023-08-31 22:54:03,110][26287] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000171440_87777280.pth...
[2023-08-31 22:54:03,113][26287] Removing /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000165000_84480000.pth
[2023-08-31 22:54:05,126][26288] Updated weights for policy 0, policy_version 171512 (0.0002)
[2023-08-31 22:54:07,469][26288] Updated weights for policy 0, policy_version 171592 (0.0002)
[2023-08-31 22:54:08,106][26276] Fps is (10 sec: 16797.4, 60 sec: 16863.0, 300 sec: 16550.7). Total num frames: 87863296. Throughput: 0: 16593.5. Samples: 75936520. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:54:08,106][26276] Avg episode reward: [(0, '-381168.997')]
[2023-08-31 22:54:09,840][26288] Updated weights for policy 0, policy_version 171672 (0.0002)
[2023-08-31 22:54:12,568][26288] Updated weights for policy 0, policy_version 171752 (0.0002)
[2023-08-31 22:54:13,106][26276] Fps is (10 sec: 16793.6, 60 sec: 16726.4, 300 sec: 16537.0). Total num frames: 87945216. Throughput: 0: 16693.1. Samples: 75988296. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:54:13,106][26276] Avg episode reward: [(0, '-352972.135')]
[2023-08-31 22:54:14,998][26288] Updated weights for policy 0, policy_version 171832 (0.0002)
[2023-08-31 22:54:17,449][26288] Updated weights for policy 0, policy_version 171912 (0.0002)
[2023-08-31 22:54:18,106][26276] Fps is (10 sec: 16383.7, 60 sec: 16726.5, 300 sec: 16537.0). Total num frames: 88027136. Throughput: 0: 16530.8. Samples: 76084975. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:54:18,106][26276] Avg episode reward: [(0, '-352972.135')]
[2023-08-31 22:54:19,869][26288] Updated weights for policy 0, policy_version 171992 (0.0002)
[2023-08-31 22:54:22,484][26288] Updated weights for policy 0, policy_version 172072 (0.0002)
[2023-08-31 22:54:23,108][26276] Fps is (10 sec: 16381.3, 60 sec: 16521.2, 300 sec: 16536.6). Total num frames: 88109056. Throughput: 0: 16496.5. Samples: 76182122. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:54:23,108][26276] Avg episode reward: [(0, '-258020.623')]
[2023-08-31 22:54:24,892][26288] Updated weights for policy 0, policy_version 172152 (0.0002)
[2023-08-31 22:54:27,289][26288] Updated weights for policy 0, policy_version 172232 (0.0002)
[2023-08-31 22:54:28,110][26276] Fps is (10 sec: 16786.9, 60 sec: 16587.8, 300 sec: 16564.3). Total num frames: 88195072. Throughput: 0: 16533.4. Samples: 76234360. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:54:28,110][26276] Avg episode reward: [(0, '-258020.623')]
[2023-08-31 22:54:29,685][26288] Updated weights for policy 0, policy_version 172312 (0.0002)
[2023-08-31 22:54:32,280][26288] Updated weights for policy 0, policy_version 172392 (0.0002)
[2023-08-31 22:54:33,106][26276] Fps is (10 sec: 16796.7, 60 sec: 16588.7, 300 sec: 16550.6). Total num frames: 88276992. Throughput: 0: 16578.8. Samples: 76333666. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:54:33,106][26276] Avg episode reward: [(0, '-351388.986')]
[2023-08-31 22:54:34,669][26288] Updated weights for policy 0, policy_version 172472 (0.0002)
[2023-08-31 22:54:37,127][26288] Updated weights for policy 0, policy_version 172552 (0.0002)
[2023-08-31 22:54:38,107][26276] Fps is (10 sec: 16388.2, 60 sec: 16520.3, 300 sec: 16550.6). Total num frames: 88358912. Throughput: 0: 16639.2. Samples: 76434686. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:54:38,108][26276] Avg episode reward: [(0, '-351388.986')]
[2023-08-31 22:54:39,600][26288] Updated weights for policy 0, policy_version 172632 (0.0002)
[2023-08-31 22:54:42,356][26288] Updated weights for policy 0, policy_version 172712 (0.0002)
[2023-08-31 22:54:43,108][26276] Fps is (10 sec: 15971.5, 60 sec: 16521.2, 300 sec: 16536.7). Total num frames: 88436736. Throughput: 0: 16675.0. Samples: 76484258. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:54:43,108][26276] Avg episode reward: [(0, '-417923.296')]
[2023-08-31 22:54:44,892][26288] Updated weights for policy 0, policy_version 172792 (0.0002)
[2023-08-31 22:54:47,273][26288] Updated weights for policy 0, policy_version 172872 (0.0002)
[2023-08-31 22:54:48,108][26276] Fps is (10 sec: 16382.5, 60 sec: 16520.0, 300 sec: 16550.5). Total num frames: 88522752. Throughput: 0: 16499.7. Samples: 76578834. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:54:48,109][26276] Avg episode reward: [(0, '-417923.296')]
[2023-08-31 22:54:49,777][26288] Updated weights for policy 0, policy_version 172952 (0.0002)
[2023-08-31 22:54:52,396][26288] Updated weights for policy 0, policy_version 173032 (0.0002)
[2023-08-31 22:54:53,107][26276] Fps is (10 sec: 16385.6, 60 sec: 16520.5, 300 sec: 16536.9). Total num frames: 88600576. Throughput: 0: 16433.6. Samples: 76676050. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:54:53,107][26276] Avg episode reward: [(0, '-460912.167')]
[2023-08-31 22:54:54,757][26288] Updated weights for policy 0, policy_version 173112 (0.0002)
[2023-08-31 22:54:57,134][26288] Updated weights for policy 0, policy_version 173192 (0.0002)
[2023-08-31 22:54:58,110][26276] Fps is (10 sec: 16790.1, 60 sec: 16588.1, 300 sec: 16564.5). Total num frames: 88690688. Throughput: 0: 16410.6. Samples: 76726847. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:54:58,111][26276] Avg episode reward: [(0, '-460912.167')]
[2023-08-31 22:54:59,530][26288] Updated weights for policy 0, policy_version 173272 (0.0002)
[2023-08-31 22:55:02,238][26288] Updated weights for policy 0, policy_version 173352 (0.0002)
[2023-08-31 22:55:03,110][26276] Fps is (10 sec: 16787.7, 60 sec: 16519.4, 300 sec: 16522.8). Total num frames: 88768512. Throughput: 0: 16441.5. Samples: 76824914. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:55:03,110][26276] Avg episode reward: [(0, '-527465.292')]
[2023-08-31 22:55:04,553][26288] Updated weights for policy 0, policy_version 173432 (0.0002)
[2023-08-31 22:55:07,074][26288] Updated weights for policy 0, policy_version 173512 (0.0002)
[2023-08-31 22:55:08,108][26276] Fps is (10 sec: 16388.4, 60 sec: 16520.0, 300 sec: 16536.9). Total num frames: 88854528. Throughput: 0: 16552.7. Samples: 76926992. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:55:08,108][26276] Avg episode reward: [(0, '-527465.292')]
[2023-08-31 22:55:09,531][26288] Updated weights for policy 0, policy_version 173592 (0.0002)
[2023-08-31 22:55:13,111][26276] Fps is (10 sec: 13926.3, 60 sec: 16041.5, 300 sec: 16425.6). Total num frames: 88907776. Throughput: 0: 16340.9. Samples: 76969705. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:55:13,112][26276] Avg episode reward: [(0, '-568528.511')]
[2023-08-31 22:55:13,748][26288] Updated weights for policy 0, policy_version 173672 (0.0003)
[2023-08-31 22:55:17,240][26288] Updated weights for policy 0, policy_version 173752 (0.0002)
[2023-08-31 22:55:18,106][26276] Fps is (10 sec: 11470.3, 60 sec: 15701.2, 300 sec: 16356.2). Total num frames: 88969216. Throughput: 0: 15681.3. Samples: 77039335. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:55:18,107][26276] Avg episode reward: [(0, '-568528.511')]
[2023-08-31 22:55:19,990][26288] Updated weights for policy 0, policy_version 173832 (0.0002)
[2023-08-31 22:55:23,040][26288] Updated weights for policy 0, policy_version 173912 (0.0003)
[2023-08-31 22:55:23,110][26276] Fps is (10 sec: 13517.2, 60 sec: 15564.2, 300 sec: 16314.5). Total num frames: 89042944. Throughput: 0: 15279.1. Samples: 77122288. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:55:23,110][26276] Avg episode reward: [(0, '-595856.134')]
[2023-08-31 22:55:24,954][26287] KL-divergence is very high: 113.2401
[2023-08-31 22:55:25,763][26288] Updated weights for policy 0, policy_version 173992 (0.0003)
[2023-08-31 22:55:28,106][26276] Fps is (10 sec: 14747.0, 60 sec: 15361.1, 300 sec: 16286.9). Total num frames: 89116672. Throughput: 0: 15071.3. Samples: 77162435. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:55:28,106][26276] Avg episode reward: [(0, '-619239.179')]
[2023-08-31 22:55:28,555][26288] Updated weights for policy 0, policy_version 174072 (0.0002)
[2023-08-31 22:55:31,130][26288] Updated weights for policy 0, policy_version 174152 (0.0002)
[2023-08-31 22:55:33,110][26276] Fps is (10 sec: 15155.2, 60 sec: 15290.7, 300 sec: 16259.0). Total num frames: 89194496. Throughput: 0: 14982.6. Samples: 77253076. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:55:33,110][26276] Avg episode reward: [(0, '-619239.179')]
[2023-08-31 22:55:34,027][26288] Updated weights for policy 0, policy_version 174232 (0.0002)
[2023-08-31 22:55:36,365][26288] Updated weights for policy 0, policy_version 174312 (0.0002)
[2023-08-31 22:55:36,829][26287] KL-divergence is very high: 238.2054
[2023-08-31 22:55:37,796][26287] KL-divergence is very high: 213.5028
[2023-08-31 22:55:38,106][26276] Fps is (10 sec: 15973.9, 60 sec: 15292.1, 300 sec: 16259.1). Total num frames: 89276416. Throughput: 0: 14952.1. Samples: 77348880. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:55:38,106][26276] Avg episode reward: [(0, '-507248.226')]
[2023-08-31 22:55:38,777][26288] Updated weights for policy 0, policy_version 174392 (0.0002)
[2023-08-31 22:55:41,129][26288] Updated weights for policy 0, policy_version 174472 (0.0002)
[2023-08-31 22:55:43,106][26276] Fps is (10 sec: 16801.0, 60 sec: 15428.8, 300 sec: 16328.5). Total num frames: 89362432. Throughput: 0: 14945.3. Samples: 77399313. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:55:43,106][26276] Avg episode reward: [(0, '-606223.416')]
[2023-08-31 22:55:43,109][26287] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000174536_89362432.pth...
[2023-08-31 22:55:43,111][26287] Removing /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000168160_86097920.pth
[2023-08-31 22:55:43,866][26288] Updated weights for policy 0, policy_version 174552 (0.0003)
[2023-08-31 22:55:46,528][26288] Updated weights for policy 0, policy_version 174632 (0.0003)
[2023-08-31 22:55:48,110][26276] Fps is (10 sec: 15967.8, 60 sec: 15223.0, 300 sec: 16369.9). Total num frames: 89436160. Throughput: 0: 14829.6. Samples: 77492240. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:55:48,110][26276] Avg episode reward: [(0, '-680172.618')]
[2023-08-31 22:55:49,031][26288] Updated weights for policy 0, policy_version 174712 (0.0002)
[2023-08-31 22:55:51,528][26288] Updated weights for policy 0, policy_version 174792 (0.0003)
[2023-08-31 22:55:53,108][26276] Fps is (10 sec: 15561.3, 60 sec: 15291.4, 300 sec: 16383.9). Total num frames: 89518080. Throughput: 0: 14765.2. Samples: 77591431. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:55:53,111][26276] Avg episode reward: [(0, '-680172.618')]
[2023-08-31 22:55:54,046][26288] Updated weights for policy 0, policy_version 174872 (0.0002)
[2023-08-31 22:55:56,392][26288] Updated weights for policy 0, policy_version 174952 (0.0002)
[2023-08-31 22:55:58,106][26276] Fps is (10 sec: 16799.7, 60 sec: 15224.5, 300 sec: 16398.0). Total num frames: 89604096. Throughput: 0: 14914.5. Samples: 77640796. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:55:58,107][26276] Avg episode reward: [(0, '-761884.952')]
[2023-08-31 22:55:58,620][26288] Updated weights for policy 0, policy_version 175032 (0.0002)
[2023-08-31 22:56:01,102][26288] Updated weights for policy 0, policy_version 175112 (0.0002)
[2023-08-31 22:56:03,106][26276] Fps is (10 sec: 16797.1, 60 sec: 15292.9, 300 sec: 16384.0). Total num frames: 89686016. Throughput: 0: 15706.2. Samples: 77746105. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:56:03,106][26276] Avg episode reward: [(0, '-805556.049')]
[2023-08-31 22:56:03,625][26288] Updated weights for policy 0, policy_version 175192 (0.0002)
[2023-08-31 22:56:05,825][26288] Updated weights for policy 0, policy_version 175272 (0.0002)
[2023-08-31 22:56:08,048][26288] Updated weights for policy 0, policy_version 175352 (0.0002)
[2023-08-31 22:56:08,106][26276] Fps is (10 sec: 17614.3, 60 sec: 15428.8, 300 sec: 16411.8). Total num frames: 89780224. Throughput: 0: 16205.4. Samples: 77851459. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:56:08,106][26276] Avg episode reward: [(0, '-805556.049')]
[2023-08-31 22:56:10,203][26288] Updated weights for policy 0, policy_version 175432 (0.0002)
[2023-08-31 22:56:12,667][26288] Updated weights for policy 0, policy_version 175512 (0.0002)
[2023-08-31 22:56:13,105][26276] Fps is (10 sec: 18023.1, 60 sec: 15975.7, 300 sec: 16439.7). Total num frames: 89866240. Throughput: 0: 16564.0. Samples: 77907816. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:56:13,106][26276] Avg episode reward: [(0, '-878800.106')]
[2023-08-31 22:56:14,863][26288] Updated weights for policy 0, policy_version 175592 (0.0002)
[2023-08-31 22:56:17,071][26288] Updated weights for policy 0, policy_version 175672 (0.0002)
[2023-08-31 22:56:18,106][26276] Fps is (10 sec: 18021.9, 60 sec: 16520.7, 300 sec: 16495.3). Total num frames: 89960448. Throughput: 0: 16919.1. Samples: 78014363. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:56:18,106][26276] Avg episode reward: [(0, '-878800.106')]
[2023-08-31 22:56:19,335][26288] Updated weights for policy 0, policy_version 175752 (0.0002)
[2023-08-31 22:56:21,840][26288] Updated weights for policy 0, policy_version 175832 (0.0002)
[2023-08-31 22:56:23,110][26276] Fps is (10 sec: 18014.7, 60 sec: 16725.4, 300 sec: 16508.8). Total num frames: 90046464. Throughput: 0: 17110.9. Samples: 78118936. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:56:23,110][26276] Avg episode reward: [(0, '-1013085.741')]
[2023-08-31 22:56:24,100][26288] Updated weights for policy 0, policy_version 175912 (0.0002)
[2023-08-31 22:56:26,354][26288] Updated weights for policy 0, policy_version 175992 (0.0002)
[2023-08-31 22:56:28,108][26276] Fps is (10 sec: 17609.4, 60 sec: 16997.8, 300 sec: 16536.9). Total num frames: 90136576. Throughput: 0: 17188.3. Samples: 78172821. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:56:28,108][26276] Avg episode reward: [(0, '-1013085.741')]
[2023-08-31 22:56:28,575][26288] Updated weights for policy 0, policy_version 176072 (0.0002)
[2023-08-31 22:56:31,030][26288] Updated weights for policy 0, policy_version 176152 (0.0002)
[2023-08-31 22:56:33,106][26276] Fps is (10 sec: 18029.9, 60 sec: 17204.5, 300 sec: 16564.7). Total num frames: 90226688. Throughput: 0: 17481.6. Samples: 78278837. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:56:33,106][26276] Avg episode reward: [(0, '-1151948.989')]
[2023-08-31 22:56:33,301][26288] Updated weights for policy 0, policy_version 176232 (0.0002)
[2023-08-31 22:56:35,609][26288] Updated weights for policy 0, policy_version 176312 (0.0002)
[2023-08-31 22:56:37,764][26288] Updated weights for policy 0, policy_version 176392 (0.0002)
[2023-08-31 22:56:38,107][26276] Fps is (10 sec: 18022.9, 60 sec: 17339.3, 300 sec: 16592.3). Total num frames: 90316800. Throughput: 0: 17729.8. Samples: 78389264. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:56:38,108][26276] Avg episode reward: [(0, '-1151948.989')]
[2023-08-31 22:56:40,165][26288] Updated weights for policy 0, policy_version 176472 (0.0003)
[2023-08-31 22:56:42,376][26288] Updated weights for policy 0, policy_version 176552 (0.0002)
[2023-08-31 22:56:43,110][26276] Fps is (10 sec: 18015.2, 60 sec: 17406.9, 300 sec: 16620.0). Total num frames: 90406912. Throughput: 0: 17784.6. Samples: 78441160. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:56:43,110][26276] Avg episode reward: [(0, '-1214278.855')]
[2023-08-31 22:56:44,652][26288] Updated weights for policy 0, policy_version 176632 (0.0002)
[2023-08-31 22:56:46,895][26288] Updated weights for policy 0, policy_version 176712 (0.0002)
[2023-08-31 22:56:48,107][26276] Fps is (10 sec: 17614.1, 60 sec: 17613.8, 300 sec: 16620.2). Total num frames: 90492928. Throughput: 0: 17860.4. Samples: 78549840. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:56:48,107][26276] Avg episode reward: [(0, '-1234134.787')]
[2023-08-31 22:56:49,382][26288] Updated weights for policy 0, policy_version 176792 (0.0002)
[2023-08-31 22:56:51,645][26288] Updated weights for policy 0, policy_version 176872 (0.0002)
[2023-08-31 22:56:53,110][26276] Fps is (10 sec: 17612.1, 60 sec: 17748.7, 300 sec: 16619.9). Total num frames: 90583040. Throughput: 0: 17865.9. Samples: 78655506. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:56:53,110][26276] Avg episode reward: [(0, '-1234134.787')]
[2023-08-31 22:56:53,918][26288] Updated weights for policy 0, policy_version 176952 (0.0002)
[2023-08-31 22:56:56,151][26288] Updated weights for policy 0, policy_version 177032 (0.0002)
[2023-08-31 22:56:58,109][26276] Fps is (10 sec: 17608.9, 60 sec: 17748.6, 300 sec: 16633.8). Total num frames: 90669056. Throughput: 0: 17804.4. Samples: 78709075. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:56:58,109][26276] Avg episode reward: [(0, '-1318608.840')]
[2023-08-31 22:56:58,606][26288] Updated weights for policy 0, policy_version 177112 (0.0002)
[2023-08-31 22:57:00,924][26288] Updated weights for policy 0, policy_version 177192 (0.0002)
[2023-08-31 22:57:03,107][26276] Fps is (10 sec: 17618.3, 60 sec: 17885.6, 300 sec: 16647.9). Total num frames: 90759168. Throughput: 0: 17783.3. Samples: 78814628. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:57:03,107][26276] Avg episode reward: [(0, '-1318608.840')]
[2023-08-31 22:57:03,165][26288] Updated weights for policy 0, policy_version 177272 (0.0002)
[2023-08-31 22:57:05,672][26288] Updated weights for policy 0, policy_version 177352 (0.0002)
[2023-08-31 22:57:07,912][26288] Updated weights for policy 0, policy_version 177432 (0.0002)
[2023-08-31 22:57:08,108][26276] Fps is (10 sec: 17615.0, 60 sec: 17748.7, 300 sec: 16661.7). Total num frames: 90845184. Throughput: 0: 17761.7. Samples: 78918175. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:57:08,108][26276] Avg episode reward: [(0, '-1508563.477')]
[2023-08-31 22:57:10,112][26288] Updated weights for policy 0, policy_version 177512 (0.0002)
[2023-08-31 22:57:12,279][26288] Updated weights for policy 0, policy_version 177592 (0.0002)
[2023-08-31 22:57:13,110][26276] Fps is (10 sec: 18016.7, 60 sec: 17884.5, 300 sec: 16703.1). Total num frames: 90939392. Throughput: 0: 17823.2. Samples: 78974905. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:57:13,110][26276] Avg episode reward: [(0, '-1508563.477')]
[2023-08-31 22:57:14,694][26288] Updated weights for policy 0, policy_version 177672 (0.0002)
[2023-08-31 22:57:16,916][26288] Updated weights for policy 0, policy_version 177752 (0.0002)
[2023-08-31 22:57:18,107][26276] Fps is (10 sec: 18434.0, 60 sec: 17817.4, 300 sec: 16717.2). Total num frames: 91029504. Throughput: 0: 17844.7. Samples: 79081865. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:57:18,107][26276] Avg episode reward: [(0, '-1524450.576')]
[2023-08-31 22:57:19,142][26288] Updated weights for policy 0, policy_version 177832 (0.0002)
[2023-08-31 22:57:21,492][26288] Updated weights for policy 0, policy_version 177912 (0.0002)
[2023-08-31 22:57:23,108][26276] Fps is (10 sec: 17616.6, 60 sec: 17818.1, 300 sec: 16744.9). Total num frames: 91115520. Throughput: 0: 17804.9. Samples: 79190491. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:57:23,108][26276] Avg episode reward: [(0, '-1524450.576')]
[2023-08-31 22:57:23,124][26287] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000177968_91119616.pth...
[2023-08-31 22:57:23,126][26287] Removing /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000171440_87777280.pth
[2023-08-31 22:57:24,033][26288] Updated weights for policy 0, policy_version 177992 (0.0002)
[2023-08-31 22:57:26,221][26288] Updated weights for policy 0, policy_version 178072 (0.0002)
[2023-08-31 22:57:28,107][26276] Fps is (10 sec: 17611.9, 60 sec: 17817.8, 300 sec: 16745.0). Total num frames: 91205632. Throughput: 0: 17764.1. Samples: 79240501. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:57:28,107][26276] Avg episode reward: [(0, '-1523174.646')]
[2023-08-31 22:57:28,446][26288] Updated weights for policy 0, policy_version 178152 (0.0002)
[2023-08-31 22:57:30,737][26288] Updated weights for policy 0, policy_version 178232 (0.0002)
[2023-08-31 22:57:33,110][26276] Fps is (10 sec: 17608.3, 60 sec: 17747.9, 300 sec: 16758.6). Total num frames: 91291648. Throughput: 0: 17780.0. Samples: 79350008. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:57:33,111][26276] Avg episode reward: [(0, '-1491574.710')]
[2023-08-31 22:57:33,264][26288] Updated weights for policy 0, policy_version 178312 (0.0002)
[2023-08-31 22:57:35,461][26288] Updated weights for policy 0, policy_version 178392 (0.0002)
[2023-08-31 22:57:38,108][26276] Fps is (10 sec: 16791.9, 60 sec: 17612.6, 300 sec: 16744.9). Total num frames: 91373568. Throughput: 0: 17659.0. Samples: 79450128. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:57:38,108][26276] Avg episode reward: [(0, '-1491574.710')]
[2023-08-31 22:57:38,294][26288] Updated weights for policy 0, policy_version 178472 (0.0003)
[2023-08-31 22:57:40,709][26288] Updated weights for policy 0, policy_version 178552 (0.0002)
[2023-08-31 22:57:43,107][26276] Fps is (10 sec: 15571.0, 60 sec: 17340.6, 300 sec: 16717.3). Total num frames: 91447296. Throughput: 0: 17470.2. Samples: 79495193. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:57:43,107][26276] Avg episode reward: [(0, '-1464676.126')]
[2023-08-31 22:57:43,722][26288] Updated weights for policy 0, policy_version 178632 (0.0002)
[2023-08-31 22:57:46,195][26288] Updated weights for policy 0, policy_version 178712 (0.0002)
[2023-08-31 22:57:48,110][26276] Fps is (10 sec: 15970.8, 60 sec: 17338.7, 300 sec: 16703.1). Total num frames: 91533312. Throughput: 0: 17170.3. Samples: 79587350. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:57:48,111][26276] Avg episode reward: [(0, '-1464676.126')]
[2023-08-31 22:57:48,496][26288] Updated weights for policy 0, policy_version 178792 (0.0002)
[2023-08-31 22:57:50,670][26288] Updated weights for policy 0, policy_version 178872 (0.0002)
[2023-08-31 22:57:53,106][26276] Fps is (10 sec: 17204.2, 60 sec: 17272.6, 300 sec: 16717.5). Total num frames: 91619328. Throughput: 0: 17206.6. Samples: 79692441. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:57:53,106][26276] Avg episode reward: [(0, '-1357675.259')]
[2023-08-31 22:57:53,148][26288] Updated weights for policy 0, policy_version 178952 (0.0002)
[2023-08-31 22:57:55,419][26288] Updated weights for policy 0, policy_version 179032 (0.0002)
[2023-08-31 22:57:57,669][26288] Updated weights for policy 0, policy_version 179112 (0.0002)
[2023-08-31 22:57:58,105][26276] Fps is (10 sec: 17622.3, 60 sec: 17340.9, 300 sec: 16731.2). Total num frames: 91709440. Throughput: 0: 17169.3. Samples: 79747437. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:57:58,105][26276] Avg episode reward: [(0, '-1357675.259')]
[2023-08-31 22:57:59,901][26288] Updated weights for policy 0, policy_version 179192 (0.0002)
[2023-08-31 22:58:02,442][26288] Updated weights for policy 0, policy_version 179272 (0.0002)
[2023-08-31 22:58:03,110][26276] Fps is (10 sec: 18014.8, 60 sec: 17338.8, 300 sec: 16772.8). Total num frames: 91799552. Throughput: 0: 17102.7. Samples: 79851545. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:58:03,110][26276] Avg episode reward: [(0, '-1208676.872')]
[2023-08-31 22:58:04,606][26288] Updated weights for policy 0, policy_version 179352 (0.0002)
[2023-08-31 22:58:06,824][26288] Updated weights for policy 0, policy_version 179432 (0.0002)
[2023-08-31 22:58:08,106][26276] Fps is (10 sec: 18021.4, 60 sec: 17408.6, 300 sec: 16773.0). Total num frames: 91889664. Throughput: 0: 17158.3. Samples: 79962574. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:58:08,106][26276] Avg episode reward: [(0, '-1208676.872')]
[2023-08-31 22:58:09,076][26288] Updated weights for policy 0, policy_version 179512 (0.0002)
[2023-08-31 22:58:11,660][26288] Updated weights for policy 0, policy_version 179592 (0.0002)
[2023-08-31 22:58:13,106][26276] Fps is (10 sec: 17619.3, 60 sec: 17272.5, 300 sec: 16786.9). Total num frames: 91975680. Throughput: 0: 17130.7. Samples: 80011373. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:58:13,107][26276] Avg episode reward: [(0, '-1242263.139')]
[2023-08-31 22:58:13,914][26288] Updated weights for policy 0, policy_version 179672 (0.0002)
[2023-08-31 22:58:16,105][26288] Updated weights for policy 0, policy_version 179752 (0.0002)
[2023-08-31 22:58:18,110][26276] Fps is (10 sec: 17604.6, 60 sec: 17270.4, 300 sec: 16772.8). Total num frames: 92065792. Throughput: 0: 17152.6. Samples: 80121872. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:58:18,110][26276] Avg episode reward: [(0, '-1242263.139')]
[2023-08-31 22:58:18,464][26288] Updated weights for policy 0, policy_version 179832 (0.0002)
[2023-08-31 22:58:20,954][26288] Updated weights for policy 0, policy_version 179912 (0.0002)
[2023-08-31 22:58:23,106][26276] Fps is (10 sec: 17613.6, 60 sec: 17272.0, 300 sec: 16786.7). Total num frames: 92151808. Throughput: 0: 17204.1. Samples: 80224278. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:58:23,106][26276] Avg episode reward: [(0, '-1233887.253')]
[2023-08-31 22:58:23,180][26288] Updated weights for policy 0, policy_version 179992 (0.0002)
[2023-08-31 22:58:25,507][26288] Updated weights for policy 0, policy_version 180072 (0.0002)
[2023-08-31 22:58:27,749][26288] Updated weights for policy 0, policy_version 180152 (0.0002)
[2023-08-31 22:58:28,111][26276] Fps is (10 sec: 17611.9, 60 sec: 17270.4, 300 sec: 16814.1). Total num frames: 92241920. Throughput: 0: 17391.4. Samples: 80277879. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:58:28,111][26276] Avg episode reward: [(0, '-1233887.253')]
[2023-08-31 22:58:30,244][26288] Updated weights for policy 0, policy_version 180232 (0.0002)
[2023-08-31 22:58:32,476][26288] Updated weights for policy 0, policy_version 180312 (0.0002)
[2023-08-31 22:58:33,107][26276] Fps is (10 sec: 17611.7, 60 sec: 17272.6, 300 sec: 16814.4). Total num frames: 92327936. Throughput: 0: 17660.1. Samples: 80381987. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:58:33,107][26276] Avg episode reward: [(0, '-1144343.554')]
[2023-08-31 22:58:34,700][26288] Updated weights for policy 0, policy_version 180392 (0.0002)
[2023-08-31 22:58:36,954][26288] Updated weights for policy 0, policy_version 180472 (0.0002)
[2023-08-31 22:58:38,107][26276] Fps is (10 sec: 17619.1, 60 sec: 17408.3, 300 sec: 16856.2). Total num frames: 92418048. Throughput: 0: 17692.9. Samples: 80488642. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:58:38,107][26276] Avg episode reward: [(0, '-1142783.464')]
[2023-08-31 22:58:39,384][26288] Updated weights for policy 0, policy_version 180552 (0.0002)
[2023-08-31 22:58:41,634][26288] Updated weights for policy 0, policy_version 180632 (0.0002)
[2023-08-31 22:58:43,110][26276] Fps is (10 sec: 18016.2, 60 sec: 17680.0, 300 sec: 16869.8). Total num frames: 92508160. Throughput: 0: 17694.3. Samples: 80543769. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:58:43,110][26276] Avg episode reward: [(0, '-1142783.464')]
[2023-08-31 22:58:43,893][26288] Updated weights for policy 0, policy_version 180712 (0.0002)
[2023-08-31 22:58:46,343][26288] Updated weights for policy 0, policy_version 180792 (0.0002)
[2023-08-31 22:58:48,105][26276] Fps is (10 sec: 18025.6, 60 sec: 17750.8, 300 sec: 16911.7). Total num frames: 92598272. Throughput: 0: 17750.2. Samples: 80650217. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:58:48,105][26276] Avg episode reward: [(0, '-1191754.061')]
[2023-08-31 22:58:48,573][26288] Updated weights for policy 0, policy_version 180872 (0.0002)
[2023-08-31 22:58:50,863][26288] Updated weights for policy 0, policy_version 180952 (0.0003)
[2023-08-31 22:58:53,106][26276] Fps is (10 sec: 17619.7, 60 sec: 17749.2, 300 sec: 16911.7). Total num frames: 92684288. Throughput: 0: 17685.5. Samples: 80758432. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:58:53,106][26276] Avg episode reward: [(0, '-1191754.061')]
[2023-08-31 22:58:53,140][26288] Updated weights for policy 0, policy_version 181032 (0.0002)
[2023-08-31 22:58:55,670][26288] Updated weights for policy 0, policy_version 181112 (0.0002)
[2023-08-31 22:58:58,110][26276] Fps is (10 sec: 16785.8, 60 sec: 17611.3, 300 sec: 16911.4). Total num frames: 92766208. Throughput: 0: 17714.2. Samples: 80808576. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:58:58,110][26276] Avg episode reward: [(0, '-1196672.549')]
[2023-08-31 22:58:58,139][26288] Updated weights for policy 0, policy_version 181192 (0.0002)
[2023-08-31 22:59:00,387][26288] Updated weights for policy 0, policy_version 181272 (0.0002)
[2023-08-31 22:59:02,569][26288] Updated weights for policy 0, policy_version 181352 (0.0002)
[2023-08-31 22:59:03,110][26276] Fps is (10 sec: 17606.1, 60 sec: 17681.1, 300 sec: 16939.1). Total num frames: 92860416. Throughput: 0: 17567.4. Samples: 80912400. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:59:03,110][26276] Avg episode reward: [(0, '-1196672.549')]
[2023-08-31 22:59:03,113][26287] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000181368_92860416.pth...
[2023-08-31 22:59:03,116][26287] Removing /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000174536_89362432.pth
[2023-08-31 22:59:05,098][26288] Updated weights for policy 0, policy_version 181432 (0.0002)
[2023-08-31 22:59:07,350][26288] Updated weights for policy 0, policy_version 181512 (0.0002)
[2023-08-31 22:59:08,106][26276] Fps is (10 sec: 18029.7, 60 sec: 17612.7, 300 sec: 16953.3). Total num frames: 92946432. Throughput: 0: 17654.6. Samples: 81018732. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:59:08,106][26276] Avg episode reward: [(0, '-1102817.352')]
[2023-08-31 22:59:09,506][26288] Updated weights for policy 0, policy_version 181592 (0.0002)
[2023-08-31 22:59:11,744][26288] Updated weights for policy 0, policy_version 181672 (0.0002)
[2023-08-31 22:59:13,106][26276] Fps is (10 sec: 17620.2, 60 sec: 17681.3, 300 sec: 16981.1). Total num frames: 93036544. Throughput: 0: 17706.2. Samples: 81074573. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:59:13,106][26276] Avg episode reward: [(0, '-1102817.352')]
[2023-08-31 22:59:14,317][26288] Updated weights for policy 0, policy_version 181752 (0.0002)
[2023-08-31 22:59:16,643][26288] Updated weights for policy 0, policy_version 181832 (0.0002)
[2023-08-31 22:59:18,105][26276] Fps is (10 sec: 17613.6, 60 sec: 17614.2, 300 sec: 16995.1). Total num frames: 93122560. Throughput: 0: 17670.5. Samples: 81177137. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:59:18,107][26276] Avg episode reward: [(0, '-1140935.215')]
[2023-08-31 22:59:18,914][26288] Updated weights for policy 0, policy_version 181912 (0.0002)
[2023-08-31 22:59:21,131][26288] Updated weights for policy 0, policy_version 181992 (0.0002)
[2023-08-31 22:59:23,106][26276] Fps is (10 sec: 17202.8, 60 sec: 17612.8, 300 sec: 16995.2). Total num frames: 93208576. Throughput: 0: 17726.2. Samples: 81286304. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:59:23,107][26276] Avg episode reward: [(0, '-1156988.566')]
[2023-08-31 22:59:23,610][26288] Updated weights for policy 0, policy_version 182072 (0.0002)
[2023-08-31 22:59:25,785][26288] Updated weights for policy 0, policy_version 182152 (0.0002)
[2023-08-31 22:59:27,968][26288] Updated weights for policy 0, policy_version 182232 (0.0002)
[2023-08-31 22:59:28,106][26276] Fps is (10 sec: 18022.2, 60 sec: 17682.6, 300 sec: 17036.6). Total num frames: 93302784. Throughput: 0: 17659.0. Samples: 81338344. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:59:28,106][26276] Avg episode reward: [(0, '-1156988.566')]
[2023-08-31 22:59:30,311][26288] Updated weights for policy 0, policy_version 182312 (0.0002)
[2023-08-31 22:59:32,806][26288] Updated weights for policy 0, policy_version 182392 (0.0002)
[2023-08-31 22:59:33,106][26276] Fps is (10 sec: 18022.0, 60 sec: 17681.2, 300 sec: 17050.5). Total num frames: 93388800. Throughput: 0: 17680.4. Samples: 81445853. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:59:33,106][26276] Avg episode reward: [(0, '-1168305.828')]
[2023-08-31 22:59:35,060][26288] Updated weights for policy 0, policy_version 182472 (0.0002)
[2023-08-31 22:59:37,459][26288] Updated weights for policy 0, policy_version 182552 (0.0002)
[2023-08-31 22:59:38,110][26276] Fps is (10 sec: 17195.6, 60 sec: 17612.0, 300 sec: 17078.1). Total num frames: 93474816. Throughput: 0: 17558.3. Samples: 81548623. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:59:38,110][26276] Avg episode reward: [(0, '-1168305.828')]
[2023-08-31 22:59:39,758][26288] Updated weights for policy 0, policy_version 182632 (0.0002)
[2023-08-31 22:59:42,252][26288] Updated weights for policy 0, policy_version 182712 (0.0002)
[2023-08-31 22:59:43,107][26276] Fps is (10 sec: 17201.7, 60 sec: 17545.4, 300 sec: 17078.3). Total num frames: 93560832. Throughput: 0: 17640.7. Samples: 81602359. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:59:43,107][26276] Avg episode reward: [(0, '-1109102.805')]
[2023-08-31 22:59:44,599][26288] Updated weights for policy 0, policy_version 182792 (0.0002)
[2023-08-31 22:59:46,843][26288] Updated weights for policy 0, policy_version 182872 (0.0002)
[2023-08-31 22:59:48,106][26276] Fps is (10 sec: 17620.5, 60 sec: 17544.4, 300 sec: 17120.0). Total num frames: 93650944. Throughput: 0: 17634.9. Samples: 81705893. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:59:48,106][26276] Avg episode reward: [(0, '-1109102.805')]
[2023-08-31 22:59:49,132][26288] Updated weights for policy 0, policy_version 182952 (0.0002)
[2023-08-31 22:59:51,649][26288] Updated weights for policy 0, policy_version 183032 (0.0002)
[2023-08-31 22:59:53,110][26276] Fps is (10 sec: 17607.3, 60 sec: 17543.3, 300 sec: 17106.0). Total num frames: 93736960. Throughput: 0: 17552.9. Samples: 81808690. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:59:53,111][26276] Avg episode reward: [(0, '-1107239.637')]
[2023-08-31 22:59:53,907][26288] Updated weights for policy 0, policy_version 183112 (0.0002)
[2023-08-31 22:59:56,117][26288] Updated weights for policy 0, policy_version 183192 (0.0002)
[2023-08-31 22:59:58,106][26276] Fps is (10 sec: 18021.5, 60 sec: 17750.5, 300 sec: 17161.8). Total num frames: 93831168. Throughput: 0: 17553.6. Samples: 81864492. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 22:59:58,106][26276] Avg episode reward: [(0, '-1107239.637')]
[2023-08-31 22:59:58,270][26288] Updated weights for policy 0, policy_version 183272 (0.0002)
[2023-08-31 23:00:00,674][26288] Updated weights for policy 0, policy_version 183352 (0.0002)
[2023-08-31 23:00:02,914][26288] Updated weights for policy 0, policy_version 183432 (0.0002)
[2023-08-31 23:00:03,107][26276] Fps is (10 sec: 18027.5, 60 sec: 17613.5, 300 sec: 17161.6). Total num frames: 93917184. Throughput: 0: 17679.6. Samples: 81972754. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 23:00:03,108][26276] Avg episode reward: [(0, '-1139685.152')]
[2023-08-31 23:00:05,109][26288] Updated weights for policy 0, policy_version 183512 (0.0002)
[2023-08-31 23:00:07,451][26288] Updated weights for policy 0, policy_version 183592 (0.0002)
[2023-08-31 23:00:08,106][26276] Fps is (10 sec: 17202.7, 60 sec: 17612.7, 300 sec: 17272.9). Total num frames: 94003200. Throughput: 0: 17668.5. Samples: 82081391. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 23:00:08,107][26276] Avg episode reward: [(0, '-1144646.881')]
[2023-08-31 23:00:09,898][26288] Updated weights for policy 0, policy_version 183672 (0.0002)
[2023-08-31 23:00:12,219][26288] Updated weights for policy 0, policy_version 183752 (0.0002)
[2023-08-31 23:00:13,108][26276] Fps is (10 sec: 18021.6, 60 sec: 17680.4, 300 sec: 17383.6). Total num frames: 94097408. Throughput: 0: 17651.7. Samples: 82132714. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 23:00:13,108][26276] Avg episode reward: [(0, '-1144646.881')]
[2023-08-31 23:00:14,471][26288] Updated weights for policy 0, policy_version 183832 (0.0002)
[2023-08-31 23:00:16,853][26288] Updated weights for policy 0, policy_version 183912 (0.0002)
[2023-08-31 23:00:18,108][26276] Fps is (10 sec: 17610.0, 60 sec: 17612.1, 300 sec: 17411.6). Total num frames: 94179328. Throughput: 0: 17636.0. Samples: 82239504. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 23:00:18,108][26276] Avg episode reward: [(0, '-1191961.492')]
[2023-08-31 23:00:19,781][26288] Updated weights for policy 0, policy_version 183992 (0.0017)
[2023-08-31 23:00:22,260][26288] Updated weights for policy 0, policy_version 184072 (0.0002)
[2023-08-31 23:00:23,108][26276] Fps is (10 sec: 15565.3, 60 sec: 17407.5, 300 sec: 17411.3). Total num frames: 94253056. Throughput: 0: 17367.6. Samples: 82330123. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 23:00:23,108][26276] Avg episode reward: [(0, '-1191961.492')]
[2023-08-31 23:00:25,202][26288] Updated weights for policy 0, policy_version 184152 (0.0003)
[2023-08-31 23:00:27,717][26288] Updated weights for policy 0, policy_version 184232 (0.0002)
[2023-08-31 23:00:28,106][26276] Fps is (10 sec: 15158.0, 60 sec: 17134.8, 300 sec: 17411.7). Total num frames: 94330880. Throughput: 0: 17111.3. Samples: 82372350. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 23:00:28,106][26276] Avg episode reward: [(0, '-1151191.212')]
[2023-08-31 23:00:30,205][26288] Updated weights for policy 0, policy_version 184312 (0.0003)
[2023-08-31 23:00:32,501][26288] Updated weights for policy 0, policy_version 184392 (0.0002)
[2023-08-31 23:00:33,106][26276] Fps is (10 sec: 16387.1, 60 sec: 17135.1, 300 sec: 17425.4). Total num frames: 94416896. Throughput: 0: 17034.2. Samples: 82472434. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 23:00:33,106][26276] Avg episode reward: [(0, '-1151191.212')]
[2023-08-31 23:00:34,717][26288] Updated weights for policy 0, policy_version 184472 (0.0002)
[2023-08-31 23:00:37,237][26288] Updated weights for policy 0, policy_version 184552 (0.0002)
[2023-08-31 23:00:38,110][26276] Fps is (10 sec: 17196.6, 60 sec: 17134.9, 300 sec: 17425.1). Total num frames: 94502912. Throughput: 0: 17056.4. Samples: 82576221. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 23:00:38,110][26276] Avg episode reward: [(0, '-1204746.653')]
[2023-08-31 23:00:39,494][26288] Updated weights for policy 0, policy_version 184632 (0.0002)
[2023-08-31 23:00:41,807][26288] Updated weights for policy 0, policy_version 184712 (0.0002)
[2023-08-31 23:00:43,106][26276] Fps is (10 sec: 17612.3, 60 sec: 17203.5, 300 sec: 17481.1). Total num frames: 94593024. Throughput: 0: 17051.1. Samples: 82631789. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 23:00:43,106][26276] Avg episode reward: [(0, '-1204746.653')]
[2023-08-31 23:00:43,114][26287] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000184760_94597120.pth...
[2023-08-31 23:00:43,116][26287] Removing /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000177968_91119616.pth
[2023-08-31 23:00:43,959][26288] Updated weights for policy 0, policy_version 184792 (0.0002)
[2023-08-31 23:00:46,500][26288] Updated weights for policy 0, policy_version 184872 (0.0002)
[2023-08-31 23:00:48,106][26276] Fps is (10 sec: 18029.3, 60 sec: 17203.0, 300 sec: 17508.8). Total num frames: 94683136. Throughput: 0: 16953.3. Samples: 82735628. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 23:00:48,107][26276] Avg episode reward: [(0, '-1266970.528')]
[2023-08-31 23:00:48,725][26288] Updated weights for policy 0, policy_version 184952 (0.0002)
[2023-08-31 23:00:51,056][26288] Updated weights for policy 0, policy_version 185032 (0.0002)
[2023-08-31 23:00:53,106][26276] Fps is (10 sec: 18022.3, 60 sec: 17272.7, 300 sec: 17522.6). Total num frames: 94773248. Throughput: 0: 16955.2. Samples: 82844368. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 23:00:53,106][26276] Avg episode reward: [(0, '-1266970.528')]
[2023-08-31 23:00:53,296][26288] Updated weights for policy 0, policy_version 185112 (0.0002)
[2023-08-31 23:00:55,796][26288] Updated weights for policy 0, policy_version 185192 (0.0002)
[2023-08-31 23:00:57,996][26288] Updated weights for policy 0, policy_version 185272 (0.0002)
[2023-08-31 23:00:58,107][26276] Fps is (10 sec: 17611.9, 60 sec: 17134.8, 300 sec: 17536.4). Total num frames: 94859264. Throughput: 0: 16937.1. Samples: 82894864. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 23:00:58,107][26276] Avg episode reward: [(0, '-1321894.449')]
[2023-08-31 23:01:00,166][26288] Updated weights for policy 0, policy_version 185352 (0.0002)
[2023-08-31 23:01:02,445][26288] Updated weights for policy 0, policy_version 185432 (0.0002)
[2023-08-31 23:01:03,105][26276] Fps is (10 sec: 18023.7, 60 sec: 17272.1, 300 sec: 17536.4). Total num frames: 94953472. Throughput: 0: 17016.0. Samples: 83005178. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 23:01:03,106][26276] Avg episode reward: [(0, '-1321894.449')]
[2023-08-31 23:01:04,862][26288] Updated weights for policy 0, policy_version 185512 (0.0002)
[2023-08-31 23:01:07,114][26288] Updated weights for policy 0, policy_version 185592 (0.0002)
[2023-08-31 23:01:08,106][26276] Fps is (10 sec: 18023.0, 60 sec: 17271.5, 300 sec: 17536.4). Total num frames: 95039488. Throughput: 0: 17365.4. Samples: 83111544. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 23:01:08,107][26276] Avg episode reward: [(0, '-1405193.511')]
[2023-08-31 23:01:09,383][26288] Updated weights for policy 0, policy_version 185672 (0.0002)
[2023-08-31 23:01:11,686][26288] Updated weights for policy 0, policy_version 185752 (0.0002)
[2023-08-31 23:01:13,110][26276] Fps is (10 sec: 16786.0, 60 sec: 17066.1, 300 sec: 17494.5). Total num frames: 95121408. Throughput: 0: 17617.4. Samples: 83165200. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 23:01:13,111][26276] Avg episode reward: [(0, '-1392302.028')]
[2023-08-31 23:01:14,342][26288] Updated weights for policy 0, policy_version 185832 (0.0002)
[2023-08-31 23:01:16,532][26288] Updated weights for policy 0, policy_version 185912 (0.0002)
[2023-08-31 23:01:18,109][26276] Fps is (10 sec: 17608.1, 60 sec: 17271.2, 300 sec: 17522.6). Total num frames: 95215616. Throughput: 0: 17666.8. Samples: 83267500. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 23:01:18,109][26276] Avg episode reward: [(0, '-1392302.028')]
[2023-08-31 23:01:18,743][26288] Updated weights for policy 0, policy_version 185992 (0.0002)
[2023-08-31 23:01:21,076][26288] Updated weights for policy 0, policy_version 186072 (0.0002)
[2023-08-31 23:01:23,105][26276] Fps is (10 sec: 17620.9, 60 sec: 17408.7, 300 sec: 17494.9). Total num frames: 95297536. Throughput: 0: 17641.4. Samples: 83370000. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 23:01:23,106][26276] Avg episode reward: [(0, '-1469538.483')]
[2023-08-31 23:01:23,642][26288] Updated weights for policy 0, policy_version 186152 (0.0002)
[2023-08-31 23:01:25,910][26288] Updated weights for policy 0, policy_version 186232 (0.0002)
[2023-08-31 23:01:28,035][26288] Updated weights for policy 0, policy_version 186312 (0.0002)
[2023-08-31 23:01:28,105][26276] Fps is (10 sec: 17619.3, 60 sec: 17681.3, 300 sec: 17508.7). Total num frames: 95391744. Throughput: 0: 17628.6. Samples: 83425063. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 23:01:28,106][26276] Avg episode reward: [(0, '-1469538.483')]
[2023-08-31 23:01:30,265][26288] Updated weights for policy 0, policy_version 186392 (0.0002)
[2023-08-31 23:01:32,777][26288] Updated weights for policy 0, policy_version 186472 (0.0002)
[2023-08-31 23:01:33,105][26276] Fps is (10 sec: 18022.1, 60 sec: 17681.1, 300 sec: 17494.9). Total num frames: 95477760. Throughput: 0: 17708.8. Samples: 83532510. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 23:01:33,106][26276] Avg episode reward: [(0, '-1427688.561')]
[2023-08-31 23:01:34,986][26288] Updated weights for policy 0, policy_version 186552 (0.0002)
[2023-08-31 23:01:37,172][26288] Updated weights for policy 0, policy_version 186632 (0.0002)
[2023-08-31 23:01:38,110][26276] Fps is (10 sec: 18013.4, 60 sec: 17817.5, 300 sec: 17508.6). Total num frames: 95571968. Throughput: 0: 17739.6. Samples: 83642727. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 23:01:38,111][26276] Avg episode reward: [(0, '-1427688.561')]
[2023-08-31 23:01:39,393][26288] Updated weights for policy 0, policy_version 186712 (0.0002)
[2023-08-31 23:01:41,934][26288] Updated weights for policy 0, policy_version 186792 (0.0002)
[2023-08-31 23:01:43,106][26276] Fps is (10 sec: 18022.1, 60 sec: 17749.4, 300 sec: 17508.7). Total num frames: 95657984. Throughput: 0: 17749.7. Samples: 83693584. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 23:01:43,106][26276] Avg episode reward: [(0, '-1409510.667')]
[2023-08-31 23:01:44,126][26288] Updated weights for policy 0, policy_version 186872 (0.0002)
[2023-08-31 23:01:46,427][26288] Updated weights for policy 0, policy_version 186952 (0.0002)
[2023-08-31 23:01:48,110][26276] Fps is (10 sec: 17613.3, 60 sec: 17748.2, 300 sec: 17508.7). Total num frames: 95748096. Throughput: 0: 17698.6. Samples: 83801696. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 23:01:48,110][26276] Avg episode reward: [(0, '-1409510.667')]
[2023-08-31 23:01:48,606][26288] Updated weights for policy 0, policy_version 187032 (0.0002)
[2023-08-31 23:01:51,057][26288] Updated weights for policy 0, policy_version 187112 (0.0002)
[2023-08-31 23:01:53,105][26276] Fps is (10 sec: 17613.2, 60 sec: 17681.3, 300 sec: 17508.9). Total num frames: 95834112. Throughput: 0: 17700.0. Samples: 83908027. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 23:01:53,106][26276] Avg episode reward: [(0, '-1385123.290')]
[2023-08-31 23:01:53,358][26288] Updated weights for policy 0, policy_version 187192 (0.0002)
[2023-08-31 23:01:55,540][26288] Updated weights for policy 0, policy_version 187272 (0.0002)
[2023-08-31 23:01:58,009][26288] Updated weights for policy 0, policy_version 187352 (0.0002)
[2023-08-31 23:01:58,106][26276] Fps is (10 sec: 17619.7, 60 sec: 17749.5, 300 sec: 17508.7). Total num frames: 95924224. Throughput: 0: 17740.7. Samples: 83963463. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 23:01:58,106][26276] Avg episode reward: [(0, '-1424921.344')]
[2023-08-31 23:02:00,313][26288] Updated weights for policy 0, policy_version 187432 (0.0002)
[2023-08-31 23:02:02,522][26288] Updated weights for policy 0, policy_version 187512 (0.0002)
[2023-08-31 23:02:03,106][26276] Fps is (10 sec: 18022.1, 60 sec: 17681.0, 300 sec: 17522.7). Total num frames: 96014336. Throughput: 0: 17796.8. Samples: 84068294. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 23:02:03,106][26276] Avg episode reward: [(0, '-1424921.344')]
[2023-08-31 23:02:04,761][26288] Updated weights for policy 0, policy_version 187592 (0.0002)
[2023-08-31 23:02:07,253][26288] Updated weights for policy 0, policy_version 187672 (0.0002)
[2023-08-31 23:02:08,107][26276] Fps is (10 sec: 17611.5, 60 sec: 17680.9, 300 sec: 17495.0). Total num frames: 96100352. Throughput: 0: 17854.0. Samples: 84173460. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 23:02:08,107][26276] Avg episode reward: [(0, '-1466682.143')]
[2023-08-31 23:02:09,430][26288] Updated weights for policy 0, policy_version 187752 (0.0002)
[2023-08-31 23:02:11,619][26288] Updated weights for policy 0, policy_version 187832 (0.0002)
[2023-08-31 23:02:13,108][26276] Fps is (10 sec: 18018.9, 60 sec: 17886.6, 300 sec: 17508.6). Total num frames: 96194560. Throughput: 0: 17890.3. Samples: 84230166. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 23:02:13,108][26276] Avg episode reward: [(0, '-1466682.143')]
[2023-08-31 23:02:13,908][26288] Updated weights for policy 0, policy_version 187912 (0.0002)
[2023-08-31 23:02:16,390][26288] Updated weights for policy 0, policy_version 187992 (0.0002)
[2023-08-31 23:02:18,106][26276] Fps is (10 sec: 18023.8, 60 sec: 17750.2, 300 sec: 17508.8). Total num frames: 96280576. Throughput: 0: 17832.6. Samples: 84334987. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 23:02:18,106][26276] Avg episode reward: [(0, '-1421384.376')]
[2023-08-31 23:02:18,636][26288] Updated weights for policy 0, policy_version 188072 (0.0002)
[2023-08-31 23:02:20,870][26288] Updated weights for policy 0, policy_version 188152 (0.0002)
[2023-08-31 23:02:23,094][26288] Updated weights for policy 0, policy_version 188232 (0.0002)
[2023-08-31 23:02:23,106][26276] Fps is (10 sec: 18025.1, 60 sec: 17953.9, 300 sec: 17522.6). Total num frames: 96374784. Throughput: 0: 17839.4. Samples: 84445423. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 23:02:23,106][26276] Avg episode reward: [(0, '-1421384.376')]
[2023-08-31 23:02:23,109][26287] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000188232_96374784.pth...
[2023-08-31 23:02:23,111][26287] Removing /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000181368_92860416.pth
[2023-08-31 23:02:25,657][26288] Updated weights for policy 0, policy_version 188312 (0.0002)
[2023-08-31 23:02:27,933][26288] Updated weights for policy 0, policy_version 188392 (0.0002)
[2023-08-31 23:02:28,110][26276] Fps is (10 sec: 17605.9, 60 sec: 17747.9, 300 sec: 17508.7). Total num frames: 96456704. Throughput: 0: 17769.3. Samples: 84493279. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 23:02:28,110][26276] Avg episode reward: [(0, '-1489134.209')]
[2023-08-31 23:02:30,218][26288] Updated weights for policy 0, policy_version 188472 (0.0002)
[2023-08-31 23:02:32,498][26288] Updated weights for policy 0, policy_version 188552 (0.0002)
[2023-08-31 23:02:33,108][26276] Fps is (10 sec: 17199.2, 60 sec: 17816.7, 300 sec: 17536.4). Total num frames: 96546816. Throughput: 0: 17804.8. Samples: 84602882. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 23:02:33,109][26276] Avg episode reward: [(0, '-1489134.209')]
[2023-08-31 23:02:34,968][26288] Updated weights for policy 0, policy_version 188632 (0.0002)
[2023-08-31 23:02:37,180][26288] Updated weights for policy 0, policy_version 188712 (0.0002)
[2023-08-31 23:02:38,107][26276] Fps is (10 sec: 18028.7, 60 sec: 17750.5, 300 sec: 17592.0). Total num frames: 96636928. Throughput: 0: 17768.1. Samples: 84707611. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 23:02:38,107][26276] Avg episode reward: [(0, '-1560359.398')]
[2023-08-31 23:02:39,469][26288] Updated weights for policy 0, policy_version 188792 (0.0003)
[2023-08-31 23:02:41,665][26288] Updated weights for policy 0, policy_version 188872 (0.0002)
[2023-08-31 23:02:43,109][26276] Fps is (10 sec: 17611.2, 60 sec: 17748.3, 300 sec: 17592.0). Total num frames: 96722944. Throughput: 0: 17743.8. Samples: 84761989. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 23:02:43,110][26276] Avg episode reward: [(0, '-1658072.591')]
[2023-08-31 23:02:44,155][26288] Updated weights for policy 0, policy_version 188952 (0.0002)
[2023-08-31 23:02:46,399][26288] Updated weights for policy 0, policy_version 189032 (0.0002)
[2023-08-31 23:02:48,106][26276] Fps is (10 sec: 17613.6, 60 sec: 17750.5, 300 sec: 17605.8). Total num frames: 96813056. Throughput: 0: 17771.0. Samples: 84867998. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 23:02:48,106][26276] Avg episode reward: [(0, '-1658072.591')]
[2023-08-31 23:02:48,718][26288] Updated weights for policy 0, policy_version 189112 (0.0003)
[2023-08-31 23:02:50,984][26288] Updated weights for policy 0, policy_version 189192 (0.0002)
[2023-08-31 23:02:53,110][26276] Fps is (10 sec: 17611.4, 60 sec: 17748.0, 300 sec: 17591.7). Total num frames: 96899072. Throughput: 0: 17730.6. Samples: 84971392. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 23:02:53,110][26276] Avg episode reward: [(0, '-1688951.108')]
[2023-08-31 23:02:53,383][26288] Updated weights for policy 0, policy_version 189272 (0.0002)
[2023-08-31 23:02:55,581][26288] Updated weights for policy 0, policy_version 189352 (0.0002)
[2023-08-31 23:02:57,850][26288] Updated weights for policy 0, policy_version 189432 (0.0002)
[2023-08-31 23:02:58,110][26276] Fps is (10 sec: 18015.1, 60 sec: 17816.4, 300 sec: 17605.9). Total num frames: 96993280. Throughput: 0: 17722.2. Samples: 85027711. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 23:02:58,110][26276] Avg episode reward: [(0, '-1688951.108')]
[2023-08-31 23:03:00,150][26288] Updated weights for policy 0, policy_version 189512 (0.0002)
[2023-08-31 23:03:02,656][26288] Updated weights for policy 0, policy_version 189592 (0.0002)
[2023-08-31 23:03:03,106][26276] Fps is (10 sec: 18030.5, 60 sec: 17749.4, 300 sec: 17592.0). Total num frames: 97079296. Throughput: 0: 17699.6. Samples: 85131460. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 23:03:03,106][26276] Avg episode reward: [(0, '-1693077.473')]
[2023-08-31 23:03:04,896][26288] Updated weights for policy 0, policy_version 189672 (0.0002)
[2023-08-31 23:03:07,243][26288] Updated weights for policy 0, policy_version 189752 (0.0002)
[2023-08-31 23:03:08,105][26276] Fps is (10 sec: 17621.3, 60 sec: 17818.1, 300 sec: 17605.9). Total num frames: 97169408. Throughput: 0: 17629.1. Samples: 85238720. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 23:03:08,105][26276] Avg episode reward: [(0, '-1693077.473')]
[2023-08-31 23:03:09,473][26288] Updated weights for policy 0, policy_version 189832 (0.0002)
[2023-08-31 23:03:11,926][26288] Updated weights for policy 0, policy_version 189912 (0.0002)
[2023-08-31 23:03:13,108][26276] Fps is (10 sec: 17608.3, 60 sec: 17680.9, 300 sec: 17592.1). Total num frames: 97255424. Throughput: 0: 17714.7. Samples: 85290407. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 23:03:13,108][26276] Avg episode reward: [(0, '-1835654.421')]
[2023-08-31 23:03:14,158][26288] Updated weights for policy 0, policy_version 189992 (0.0002)
[2023-08-31 23:03:16,315][26288] Updated weights for policy 0, policy_version 190072 (0.0002)
[2023-08-31 23:03:18,108][26276] Fps is (10 sec: 18016.8, 60 sec: 17816.9, 300 sec: 17619.6). Total num frames: 97349632. Throughput: 0: 17749.3. Samples: 85401603. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 23:03:18,109][26276] Avg episode reward: [(0, '-1835654.421')]
[2023-08-31 23:03:18,522][26288] Updated weights for policy 0, policy_version 190152 (0.0002)
[2023-08-31 23:03:20,995][26288] Updated weights for policy 0, policy_version 190232 (0.0002)
[2023-08-31 23:03:23,110][26276] Fps is (10 sec: 18018.8, 60 sec: 17679.9, 300 sec: 17605.9). Total num frames: 97435648. Throughput: 0: 17787.7. Samples: 85508119. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 23:03:23,110][26276] Avg episode reward: [(0, '-1856343.070')]
[2023-08-31 23:03:23,170][26288] Updated weights for policy 0, policy_version 190312 (0.0002)
[2023-08-31 23:03:25,628][26288] Updated weights for policy 0, policy_version 190392 (0.0003)
[2023-08-31 23:03:28,089][26288] Updated weights for policy 0, policy_version 190472 (0.0003)
[2023-08-31 23:03:28,107][26276] Fps is (10 sec: 17205.5, 60 sec: 17750.2, 300 sec: 17605.8). Total num frames: 97521664. Throughput: 0: 17753.5. Samples: 85560858. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 23:03:28,107][26276] Avg episode reward: [(0, '-1856343.070')]
[2023-08-31 23:03:30,746][26288] Updated weights for policy 0, policy_version 190552 (0.0003)
[2023-08-31 23:03:33,035][26288] Updated weights for policy 0, policy_version 190632 (0.0002)
[2023-08-31 23:03:33,107][26276] Fps is (10 sec: 16798.8, 60 sec: 17613.2, 300 sec: 17578.1). Total num frames: 97603584. Throughput: 0: 17543.5. Samples: 85657471. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 23:03:33,107][26276] Avg episode reward: [(0, '-1747589.938')]
[2023-08-31 23:03:35,208][26288] Updated weights for policy 0, policy_version 190712 (0.0002)
[2023-08-31 23:03:37,802][26288] Updated weights for policy 0, policy_version 190792 (0.0002)
[2023-08-31 23:03:38,110][26276] Fps is (10 sec: 16788.5, 60 sec: 17543.5, 300 sec: 17564.2). Total num frames: 97689600. Throughput: 0: 17669.4. Samples: 85766515. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 23:03:38,110][26276] Avg episode reward: [(0, '-1777863.229')]
[2023-08-31 23:03:40,180][26288] Updated weights for policy 0, policy_version 190872 (0.0003)
[2023-08-31 23:03:42,460][26288] Updated weights for policy 0, policy_version 190952 (0.0002)
[2023-08-31 23:03:43,105][26276] Fps is (10 sec: 17205.8, 60 sec: 17545.6, 300 sec: 17550.3). Total num frames: 97775616. Throughput: 0: 17466.9. Samples: 85813639. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 23:03:43,106][26276] Avg episode reward: [(0, '-1777863.229')]
[2023-08-31 23:03:44,714][26288] Updated weights for policy 0, policy_version 191032 (0.0002)
[2023-08-31 23:03:47,194][26288] Updated weights for policy 0, policy_version 191112 (0.0002)
[2023-08-31 23:03:48,110][26276] Fps is (10 sec: 17203.2, 60 sec: 17475.1, 300 sec: 17550.1). Total num frames: 97861632. Throughput: 0: 17565.3. Samples: 85921977. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 23:03:48,111][26276] Avg episode reward: [(0, '-1667884.687')]
[2023-08-31 23:03:49,469][26288] Updated weights for policy 0, policy_version 191192 (0.0002)
[2023-08-31 23:03:51,771][26288] Updated weights for policy 0, policy_version 191272 (0.0002)
[2023-08-31 23:03:53,108][26276] Fps is (10 sec: 18018.1, 60 sec: 17613.4, 300 sec: 17592.1). Total num frames: 97955840. Throughput: 0: 17506.2. Samples: 86026542. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 23:03:53,108][26276] Avg episode reward: [(0, '-1667884.687')]
[2023-08-31 23:03:53,967][26288] Updated weights for policy 0, policy_version 191352 (0.0002)
[2023-08-31 23:03:56,461][26288] Updated weights for policy 0, policy_version 191432 (0.0002)
[2023-08-31 23:03:58,106][26276] Fps is (10 sec: 18030.7, 60 sec: 17477.6, 300 sec: 17564.5). Total num frames: 98041856. Throughput: 0: 17583.3. Samples: 86081609. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 23:03:58,106][26276] Avg episode reward: [(0, '-1601671.268')]
[2023-08-31 23:03:58,717][26288] Updated weights for policy 0, policy_version 191512 (0.0002)
[2023-08-31 23:04:00,924][26288] Updated weights for policy 0, policy_version 191592 (0.0002)
[2023-08-31 23:04:03,110][26276] Fps is (10 sec: 17609.0, 60 sec: 17543.2, 300 sec: 17577.8). Total num frames: 98131968. Throughput: 0: 17462.8. Samples: 86187457. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 23:04:03,110][26276] Avg episode reward: [(0, '-1601671.268')]
[2023-08-31 23:04:03,135][26288] Updated weights for policy 0, policy_version 191672 (0.0002)
[2023-08-31 23:04:03,135][26287] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000191672_98136064.pth...
[2023-08-31 23:04:03,138][26287] Removing /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000184760_94597120.pth
[2023-08-31 23:04:05,607][26288] Updated weights for policy 0, policy_version 191752 (0.0002)
[2023-08-31 23:04:07,872][26288] Updated weights for policy 0, policy_version 191832 (0.0002)
[2023-08-31 23:04:08,105][26276] Fps is (10 sec: 18022.5, 60 sec: 17544.5, 300 sec: 17578.1). Total num frames: 98222080. Throughput: 0: 17435.1. Samples: 86292616. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 23:04:08,106][26276] Avg episode reward: [(0, '-1525410.662')]
[2023-08-31 23:04:10,157][26288] Updated weights for policy 0, policy_version 191912 (0.0002)
[2023-08-31 23:04:12,389][26288] Updated weights for policy 0, policy_version 191992 (0.0002)
[2023-08-31 23:04:13,110][26276] Fps is (10 sec: 18022.4, 60 sec: 17612.2, 300 sec: 17591.7). Total num frames: 98312192. Throughput: 0: 17457.7. Samples: 86346507. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 23:04:13,110][26276] Avg episode reward: [(0, '-1525410.662')]
[2023-08-31 23:04:14,846][26288] Updated weights for policy 0, policy_version 192072 (0.0002)
[2023-08-31 23:04:17,017][26288] Updated weights for policy 0, policy_version 192152 (0.0002)
[2023-08-31 23:04:18,106][26276] Fps is (10 sec: 17612.5, 60 sec: 17477.1, 300 sec: 17592.0). Total num frames: 98398208. Throughput: 0: 17659.8. Samples: 86452139. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 23:04:18,106][26276] Avg episode reward: [(0, '-1403569.296')]
[2023-08-31 23:04:19,276][26288] Updated weights for policy 0, policy_version 192232 (0.0002)
[2023-08-31 23:04:21,506][26288] Updated weights for policy 0, policy_version 192312 (0.0002)
[2023-08-31 23:04:23,107][26276] Fps is (10 sec: 17208.0, 60 sec: 17477.1, 300 sec: 17564.1). Total num frames: 98484224. Throughput: 0: 17697.5. Samples: 86562852. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 23:04:23,108][26276] Avg episode reward: [(0, '-1390467.569')]
[2023-08-31 23:04:24,066][26288] Updated weights for policy 0, policy_version 192392 (0.0002)
[2023-08-31 23:04:26,410][26288] Updated weights for policy 0, policy_version 192472 (0.0002)
[2023-08-31 23:04:28,106][26276] Fps is (10 sec: 17612.0, 60 sec: 17544.8, 300 sec: 17578.1). Total num frames: 98574336. Throughput: 0: 17723.2. Samples: 86611192. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 23:04:28,106][26276] Avg episode reward: [(0, '-1390467.569')]
[2023-08-31 23:04:28,575][26288] Updated weights for policy 0, policy_version 192552 (0.0002)
[2023-08-31 23:04:30,840][26288] Updated weights for policy 0, policy_version 192632 (0.0002)
[2023-08-31 23:04:33,105][26276] Fps is (10 sec: 18026.0, 60 sec: 17681.6, 300 sec: 17592.3). Total num frames: 98664448. Throughput: 0: 17763.3. Samples: 86721241. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 23:04:33,106][26276] Avg episode reward: [(0, '-1339277.273')]
[2023-08-31 23:04:33,340][26288] Updated weights for policy 0, policy_version 192712 (0.0002)
[2023-08-31 23:04:35,626][26288] Updated weights for policy 0, policy_version 192792 (0.0002)
[2023-08-31 23:04:37,819][26288] Updated weights for policy 0, policy_version 192872 (0.0002)
[2023-08-31 23:04:38,110][26276] Fps is (10 sec: 18015.0, 60 sec: 17749.3, 300 sec: 17605.7). Total num frames: 98754560. Throughput: 0: 17758.6. Samples: 86825722. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 23:04:38,110][26276] Avg episode reward: [(0, '-1339277.273')]
[2023-08-31 23:04:39,969][26288] Updated weights for policy 0, policy_version 192952 (0.0002)
[2023-08-31 23:04:42,410][26288] Updated weights for policy 0, policy_version 193032 (0.0002)
[2023-08-31 23:04:43,108][26276] Fps is (10 sec: 18017.3, 60 sec: 17816.8, 300 sec: 17605.7). Total num frames: 98844672. Throughput: 0: 17785.9. Samples: 86882022. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 23:04:43,108][26276] Avg episode reward: [(0, '-1242963.933')]
[2023-08-31 23:04:44,681][26288] Updated weights for policy 0, policy_version 193112 (0.0002)
[2023-08-31 23:04:46,909][26288] Updated weights for policy 0, policy_version 193192 (0.0002)
[2023-08-31 23:04:48,106][26276] Fps is (10 sec: 18030.5, 60 sec: 17887.2, 300 sec: 17620.0). Total num frames: 98934784. Throughput: 0: 17775.9. Samples: 86987297. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 23:04:48,106][26276] Avg episode reward: [(0, '-1242963.933')]
[2023-08-31 23:04:49,161][26288] Updated weights for policy 0, policy_version 193272 (0.0002)
[2023-08-31 23:04:51,634][26288] Updated weights for policy 0, policy_version 193352 (0.0002)
[2023-08-31 23:04:53,106][26276] Fps is (10 sec: 17616.4, 60 sec: 17749.9, 300 sec: 17592.0). Total num frames: 99020800. Throughput: 0: 17791.9. Samples: 87093264. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 23:04:53,106][26276] Avg episode reward: [(0, '-1215160.938')]
[2023-08-31 23:04:53,862][26288] Updated weights for policy 0, policy_version 193432 (0.0002)
[2023-08-31 23:04:56,079][26288] Updated weights for policy 0, policy_version 193512 (0.0002)
[2023-08-31 23:04:58,105][26276] Fps is (10 sec: 18022.9, 60 sec: 17885.9, 300 sec: 17619.9). Total num frames: 99115008. Throughput: 0: 17830.5. Samples: 87148796. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 23:04:58,106][26276] Avg episode reward: [(0, '-1215160.938')]
[2023-08-31 23:04:58,286][26288] Updated weights for policy 0, policy_version 193592 (0.0002)
[2023-08-31 23:05:00,697][26288] Updated weights for policy 0, policy_version 193672 (0.0002)
[2023-08-31 23:05:02,905][26288] Updated weights for policy 0, policy_version 193752 (0.0002)
[2023-08-31 23:05:03,110][26276] Fps is (10 sec: 18015.3, 60 sec: 17817.6, 300 sec: 17619.5). Total num frames: 99201024. Throughput: 0: 17856.2. Samples: 87255744. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 23:05:03,110][26276] Avg episode reward: [(0, '-1098078.824')]
[2023-08-31 23:05:05,175][26288] Updated weights for policy 0, policy_version 193832 (0.0002)
[2023-08-31 23:05:07,459][26288] Updated weights for policy 0, policy_version 193912 (0.0002)
[2023-08-31 23:05:08,106][26276] Fps is (10 sec: 17201.6, 60 sec: 17749.1, 300 sec: 17592.1). Total num frames: 99287040. Throughput: 0: 17825.7. Samples: 87364994. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 23:05:08,107][26276] Avg episode reward: [(0, '-1179665.680')]
[2023-08-31 23:05:09,925][26288] Updated weights for policy 0, policy_version 193992 (0.0002)
[2023-08-31 23:05:12,254][26288] Updated weights for policy 0, policy_version 194072 (0.0002)
[2023-08-31 23:05:13,110][26276] Fps is (10 sec: 17612.7, 60 sec: 17749.3, 300 sec: 17619.6). Total num frames: 99377152. Throughput: 0: 17887.7. Samples: 87416209. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-08-31 23:05:13,110][26276] Avg episode reward: [(0, '-1179665.680')]
[2023-08-31 23:05:14,456][26288] Updated weights for policy 0, policy_version 194152 (0.0002)
[2023-08-31 23:05:16,917][26288] Updated weights for policy 0, policy_version 194232 (0.0002)
[2023-08-31 23:05:18,106][26276] Fps is (10 sec: 18022.4, 60 sec: 17817.4, 300 sec: 17675.4). Total num frames: 99467264. Throughput: 0: 17856.6. Samples: 87524808. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 23:05:18,108][26276] Avg episode reward: [(0, '-1205891.931')]
[2023-08-31 23:05:19,094][26288] Updated weights for policy 0, policy_version 194312 (0.0002)
[2023-08-31 23:05:21,296][26288] Updated weights for policy 0, policy_version 194392 (0.0002)
[2023-08-31 23:05:23,110][26276] Fps is (10 sec: 18022.5, 60 sec: 17885.0, 300 sec: 17716.7). Total num frames: 99557376. Throughput: 0: 17894.1. Samples: 87630955. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 23:05:23,111][26276] Avg episode reward: [(0, '-1205891.931')]
[2023-08-31 23:05:23,586][26288] Updated weights for policy 0, policy_version 194472 (0.0002)
[2023-08-31 23:05:26,026][26288] Updated weights for policy 0, policy_version 194552 (0.0002)
[2023-08-31 23:05:28,105][26276] Fps is (10 sec: 18024.1, 60 sec: 17886.1, 300 sec: 17730.8). Total num frames: 99647488. Throughput: 0: 17893.6. Samples: 87687184. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 23:05:28,106][26276] Avg episode reward: [(0, '-1152582.858')]
[2023-08-31 23:05:28,214][26288] Updated weights for policy 0, policy_version 194632 (0.0002)
[2023-08-31 23:05:30,440][26288] Updated weights for policy 0, policy_version 194712 (0.0002)
[2023-08-31 23:05:32,652][26288] Updated weights for policy 0, policy_version 194792 (0.0002)
[2023-08-31 23:05:33,108][26276] Fps is (10 sec: 18436.2, 60 sec: 17953.4, 300 sec: 17758.7). Total num frames: 99741696. Throughput: 0: 17902.9. Samples: 87792966. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 23:05:33,108][26276] Avg episode reward: [(0, '-1152582.858')]
[2023-08-31 23:05:35,161][26288] Updated weights for policy 0, policy_version 194872 (0.0002)
[2023-08-31 23:05:37,478][26288] Updated weights for policy 0, policy_version 194952 (0.0002)
[2023-08-31 23:05:38,110][26276] Fps is (10 sec: 17604.7, 60 sec: 17817.7, 300 sec: 17730.6). Total num frames: 99823616. Throughput: 0: 17866.4. Samples: 87897323. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 23:05:38,110][26276] Avg episode reward: [(0, '-1191245.922')]
[2023-08-31 23:05:39,819][26288] Updated weights for policy 0, policy_version 195032 (0.0002)
[2023-08-31 23:05:42,038][26288] Updated weights for policy 0, policy_version 195112 (0.0002)
[2023-08-31 23:05:43,110][26276] Fps is (10 sec: 17199.0, 60 sec: 17817.0, 300 sec: 17730.6). Total num frames: 99913728. Throughput: 0: 17796.2. Samples: 87949711. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 23:05:43,110][26276] Avg episode reward: [(0, '-1191245.922')]
[2023-08-31 23:05:43,114][26287] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000195144_99913728.pth...
[2023-08-31 23:05:43,116][26287] Removing /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000188232_96374784.pth
[2023-08-31 23:05:44,900][26288] Updated weights for policy 0, policy_version 195192 (0.0002)
[2023-08-31 23:05:47,163][26288] Updated weights for policy 0, policy_version 195272 (0.0002)
[2023-08-31 23:05:48,105][26276] Fps is (10 sec: 17211.4, 60 sec: 17681.2, 300 sec: 17703.1). Total num frames: 99995648. Throughput: 0: 17599.4. Samples: 88047632. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2023-08-31 23:05:48,105][26276] Avg episode reward: [(0, '-1244271.803')]
[2023-08-31 23:05:48,658][26287] Stopping Batcher_0...
[2023-08-31 23:05:48,658][26287] Loop batcher_evt_loop terminating...
[2023-08-31 23:05:48,658][26291] Stopping RolloutWorker_w2...
[2023-08-31 23:05:48,658][26294] Stopping RolloutWorker_w4...
[2023-08-31 23:05:48,658][26296] Stopping RolloutWorker_w6...
[2023-08-31 23:05:48,658][26295] Stopping RolloutWorker_w5...
[2023-08-31 23:05:48,659][26291] Loop rollout_proc2_evt_loop terminating...
[2023-08-31 23:05:48,658][26293] Stopping RolloutWorker_w7...
[2023-08-31 23:05:48,659][26296] Loop rollout_proc6_evt_loop terminating...
[2023-08-31 23:05:48,659][26294] Loop rollout_proc4_evt_loop terminating...
[2023-08-31 23:05:48,659][26295] Loop rollout_proc5_evt_loop terminating...
[2023-08-31 23:05:48,659][26293] Loop rollout_proc7_evt_loop terminating...
[2023-08-31 23:05:48,659][26292] Stopping RolloutWorker_w3...
[2023-08-31 23:05:48,660][26292] Loop rollout_proc3_evt_loop terminating...
[2023-08-31 23:05:48,660][26289] Stopping RolloutWorker_w0...
[2023-08-31 23:05:48,661][26276] Component Batcher_0 stopped!
[2023-08-31 23:05:48,661][26287] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000195328_100007936.pth...
[2023-08-31 23:05:48,668][26289] Loop rollout_proc0_evt_loop terminating...
[2023-08-31 23:05:48,660][26290] Stopping RolloutWorker_w1...
[2023-08-31 23:05:48,669][26290] Loop rollout_proc1_evt_loop terminating...
[2023-08-31 23:05:48,670][26287] Removing /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000191672_98136064.pth
[2023-08-31 23:05:48,669][26276] Component RolloutWorker_w2 stopped!
[2023-08-31 23:05:48,670][26276] Component RolloutWorker_w4 stopped!
[2023-08-31 23:05:48,670][26276] Component RolloutWorker_w5 stopped!
[2023-08-31 23:05:48,670][26276] Component RolloutWorker_w6 stopped!
[2023-08-31 23:05:48,670][26276] Component RolloutWorker_w7 stopped!
[2023-08-31 23:05:48,670][26287] Saving /Users/xinsonglin/Triped/train_dir/./example_gym_triped_sim-v0/checkpoint_p0/checkpoint_000195328_100007936.pth...
[2023-08-31 23:05:48,670][26276] Component RolloutWorker_w3 stopped!
[2023-08-31 23:05:48,670][26276] Component RolloutWorker_w0 stopped!
[2023-08-31 23:05:48,670][26276] Component RolloutWorker_w1 stopped!
[2023-08-31 23:05:48,672][26287] Stopping LearnerWorker_p0...
[2023-08-31 23:05:48,672][26287] Loop learner_proc0_evt_loop terminating...
[2023-08-31 23:05:48,673][26276] Component LearnerWorker_p0 stopped!
[2023-08-31 23:05:48,813][26288] Weights refcount: 2 0
[2023-08-31 23:05:48,818][26288] Stopping InferenceWorker_p0-w0...
[2023-08-31 23:05:48,818][26288] Loop inference_proc0-0_evt_loop terminating...
[2023-08-31 23:05:48,818][26276] Component InferenceWorker_p0-w0 stopped!
[2023-08-31 23:05:48,819][26276] Waiting for process learner_proc0 to stop...
[2023-08-31 23:05:49,302][26276] Waiting for process inference_proc0-0 to join...
[2023-08-31 23:05:49,348][26276] Waiting for process rollout_proc0 to join...
[2023-08-31 23:05:49,350][26276] Waiting for process rollout_proc1 to join...
[2023-08-31 23:05:49,350][26276] Waiting for process rollout_proc2 to join...
[2023-08-31 23:05:49,350][26276] Waiting for process rollout_proc3 to join...
[2023-08-31 23:05:49,350][26276] Waiting for process rollout_proc4 to join...
[2023-08-31 23:05:49,350][26276] Waiting for process rollout_proc5 to join...
[2023-08-31 23:05:49,350][26276] Waiting for process rollout_proc6 to join...
[2023-08-31 23:05:49,350][26276] Waiting for process rollout_proc7 to join...
[2023-08-31 23:05:49,350][26276] Batcher 0 profile tree view:
batching: 22.0188, releasing_batches: 7.5499
[2023-08-31 23:05:49,350][26276] InferenceWorker_p0-w0 profile tree view:
wait_policy: 0.0065
  wait_policy_total: 1083.4202
update_model: 63.7468
  weight_update: 0.0002
one_step: 0.0007
  handle_policy_step: 3845.4964
    deserialize: 130.6351, stack: 37.5322, obs_to_device_normalize: 654.0182, forward: 1683.2793, send_messages: 645.9027
    prepare_outputs: 342.8269
      to_cpu: 49.0237
[2023-08-31 23:05:49,351][26276] Learner 0 profile tree view:
misc: 0.0341, prepare_batch: 50.1342
train: 484.3499
  epoch_init: 0.2111, minibatch_init: 5.0311, losses_postprocess: 7.1535, kl_divergence: 1.9281, after_optimizer: 2.3236
  calculate_losses: 212.9177
    losses_init: 0.2286, forward_head: 96.3357, bptt_initial: 0.5619, bptt: 0.5912, tail: 54.0700, advantages_returns: 5.0028, losses: 49.6943
  update: 247.7174
    clip: 22.7114
[2023-08-31 23:05:49,351][26276] RolloutWorker_w0 profile tree view:
wait_for_trajectories: 3.1163, enqueue_policy_requests: 212.2977, env_step: 1369.7374, overhead: 155.0538, complete_rollouts: 8.5175
save_policy_outputs: 403.6613
  split_output_tensors: 142.7925
[2023-08-31 23:05:49,351][26276] RolloutWorker_w7 profile tree view:
wait_for_trajectories: 3.1320, enqueue_policy_requests: 214.5463, env_step: 1364.0329, overhead: 149.0376, complete_rollouts: 8.6032
save_policy_outputs: 406.9534
  split_output_tensors: 142.1605
[2023-08-31 23:05:49,351][26276] Loop Runner_EvtLoop terminating...
[2023-08-31 23:05:49,351][26276] Runner profile tree view:
main_loop: 5504.9264
[2023-08-31 23:05:49,351][26276] Collected {0: 100007936}, FPS: 16002.5
